
------------------------------------------------------------
Sender: LSF System <lsfadmin@c020n01>
Subject: Job 348156: <numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126> was submitted from host <c011n03> by user <sdehgha2> in cluster <Hazel> at Sun Jan 26 13:04:41 2025
Job was executed on host(s) <6*c020n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 26 13:04:43 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 26 13:04:43 2025
Terminated at Sun Jan 26 13:04:49 2025
Results reported at Sun Jan 26 13:04:49 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh with padding"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)" "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3.51 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   32 sec.
    Turnaround time :                            8 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003991022854536421), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 62), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011385818546954403), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01574409614005024), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 190), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010286281569408992), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006447981864115292), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013184718492823349), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 90), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013845261590169652), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 1900), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005862115566867436), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007548927241294831), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 68), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04346116523211833), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 67), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007681717371661463), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 78), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012946302534073787), ('regressor__regressor__estimator__max_depth', 22), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011343807613372581), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014352139276121027), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.018624415882236473), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011040864287922957), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007064480985028678), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 214), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009638849716520893), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 132), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0014176432376727048), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005384935293896424), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01450286766728525), ('regressor__regressor__estimator__max_depth', 485), ('regressor__regressor__estimator__n_estimators', 169), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008895293474789607), ('regressor__regressor__estimator__max_depth', 5397), ('regressor__regressor__estimator__n_estimators', 345), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0026926691148483743), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 80), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04524223358940583), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0010520625714290997), ('regressor__regressor__estimator__max_depth', 26), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013120606372109326), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 71), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010283112986204126), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 207), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04702495531120445), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0022573870303259002), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 392), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005363030323786265), ('regressor__regressor__estimator__max_depth', 17), ('regressor__regressor__estimator__n_estimators', 275), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [-1075.564   -10.286    -9.003]±[3977.164   44.177   51.386]
[array([-1075.56430737,   -10.28581682,    -9.00295323]), array([86131.60186328,  9587.24380666,  8799.85956295]), array([14726.58429358,  2248.31072801,  2181.56221243])]
scaler
Filename: (PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh with padding/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh with padding/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh with padding/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c026n02>
Subject: Job 348226: <numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126> was submitted from host <c011n03> by user <sdehgha2> in cluster <Hazel> at Sun Jan 26 13:12:49 2025
Job was executed on host(s) <6*c026n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 26 13:12:51 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 26 13:12:51 2025
Terminated at Sun Jan 26 13:51:59 2025
Results reported at Sun Jan 26 13:51:59 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh with padding"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4783.44 sec.
    Max Memory :                                 9 GB
    Average Memory :                             8.79 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               7.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   2366 sec.
    Turnaround time :                            2350 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004377205829647495), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0029135297754428148), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 138), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.035987341947628405), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 78), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007280765269658696), ('regressor__regressor__estimator__max_depth', 388), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006377559163038073), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001960347140167471), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0015143420020011773), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 1744), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0060654082944616135), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 62), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00723479928143212), ('regressor__regressor__estimator__max_depth', 5006), ('regressor__regressor__estimator__n_estimators', 71), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.06801375122240097), ('regressor__regressor__estimator__max_depth', 1233), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007771704738733036), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016411443790606328), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011342847093428244), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014130993468660456), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 53), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020934775305344603), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011124366897479322), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010751969984949062), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 111), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009207450038589143), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 152), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001739204014789805), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 60), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005199188445263106), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 113), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00408384279504596), ('regressor__regressor__estimator__max_depth', 29), ('regressor__regressor__estimator__n_estimators', 590), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007616305066690215), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 265), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0036202236446906642), ('regressor__regressor__estimator__max_depth', 12), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006148021809820408), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 387), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0010465424867408322), ('regressor__regressor__estimator__max_depth', 26), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014270168943617803), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 67), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012465991181278037), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 179), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0290643261250398), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 93), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0022580683240480594), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 387), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005540164327314324), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 296), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [-456.51    -2.597   -2.438]±[1166.962    7.01    14.064]
[array([-456.51000347,   -2.59739317,   -2.4378554 ]), array([85727.49077294,  8950.54187978,  9174.97263233]), array([14892.12100031,  2176.03073927,  2280.23084661])]
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh with padding/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh with padding/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh with padding/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c026n01>
Subject: Job 348192: <numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126> was submitted from host <c011n03> by user <sdehgha2> in cluster <Hazel> at Sun Jan 26 13:08:43 2025
Job was executed on host(s) <6*c026n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 26 13:08:43 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 26 13:08:43 2025
Terminated at Sun Jan 26 13:54:32 2025
Results reported at Sun Jan 26 13:54:32 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh with padding_all_num_20250126"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh with padding"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)" "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6407.35 sec.
    Max Memory :                                 10 GB
    Average Memory :                             9.15 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               6.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   2776 sec.
    Turnaround time :                            2749 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh with padding_20250126.err> for stderr output of this job.

