
------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 330387: <numerical_MLP_with_feats_on_log Rg (nm)_20250520> in cluster <Hazel> Done

Job <numerical_MLP_with_feats_on_log Rg (nm)_20250520> was submitted from host <c201n02> by user <sdehgha2> in cluster <Hazel> at Tue May 20 17:18:10 2025
Job was executed on host(s) <6*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue May 20 17:18:10 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue May 20 17:18:10 2025
Terminated at Tue May 20 17:18:19 2025
Results reported at Tue May 20 17:18:19 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 8:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "numerical_MLP_with_feats_on_log Rg (nm)_20250520"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "log Rg (nm)"                                   --regressor_type "MLP"                                   --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4.27 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   26 sec.
    Turnaround time :                            9 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err> for stderr output of this job.

Average scores:	 r: 0.77±0.08	 r2: 0.57±0.14
Filename: (Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_MLP_hypOFF_Standard
{6: {'fit_time': array([0.30548739, 0.24710989, 0.24414849, 0.24782562, 0.23983169]), 'score_time': array([0.01007795, 0.01003885, 0.00999427, 0.0100317 , 0.00998497]), 'test_pearson_r': array([0.80784317, 0.78612751, 0.67961195, 0.78527721, 0.75043198]), 'test_spearman_r': array([0.83782747, 0.77769003, 0.72249499, 0.7861062 , 0.7572631 ]), 'test_rmse': array([-0.39260747, -0.39616759, -0.4852421 , -0.39829046, -0.36860264]), 'test_mae': array([-0.24317143, -0.27847756, -0.28219564, -0.25321899, -0.2556382 ]), 'test_r2': array([0.64685604, 0.60778049, 0.4023161 , 0.59605142, 0.55485526])}, 13: {'fit_time': array([0.21767831, 0.2039063 , 0.2097857 , 0.20820022, 0.20806742]), 'score_time': array([0.00995827, 0.00961041, 0.00989962, 0.00959945, 0.00962901]), 'test_pearson_r': array([0.66960584, 0.86496534, 0.58221559, 0.74988086, 0.81493366]), 'test_spearman_r': array([0.82196461, 0.89273593, 0.67146305, 0.78696016, 0.8004254 ]), 'test_rmse': array([-0.49174026, -0.3363793 , -0.55584259, -0.42988891, -0.34314229]), 'test_mae': array([-0.29549694, -0.25611194, -0.31800545, -0.28102419, -0.25787603]), 'test_r2': array([0.38530935, 0.73233679, 0.20722149, 0.55421908, 0.63223257])}, 42: {'fit_time': array([0.21661735, 0.16978645, 0.20527983, 0.20778108, 0.20296311]), 'score_time': array([0.00919032, 0.00916052, 0.0088973 , 0.00888395, 0.00894308]), 'test_pearson_r': array([0.81049488, 0.6139718 , 0.73633132, 0.91436193, 0.74075515]), 'test_spearman_r': array([0.80542214, 0.6836286 , 0.74281201, 0.90832248, 0.7314193 ]), 'test_rmse': array([-0.40231745, -0.54139782, -0.34826043, -0.26686625, -0.44718061]), 'test_mae': array([-0.31356933, -0.32891571, -0.24427676, -0.20803741, -0.25128844]), 'test_r2': array([0.6353691 , 0.31973856, 0.51135858, 0.82715273, 0.52028222])}, 69: {'fit_time': array([0.20551205, 0.20782876, 0.21605682, 0.21432304, 0.21736193]), 'score_time': array([0.00901222, 0.00894547, 0.00929856, 0.00924277, 0.00948238]), 'test_pearson_r': array([0.8686223 , 0.70346116, 0.80367434, 0.68132751, 0.84813364]), 'test_spearman_r': array([0.87001537, 0.71420046, 0.83579541, 0.73276837, 0.87121589]), 'test_rmse': array([-0.32407282, -0.4270794 , -0.37378803, -0.4429403 , -0.39143933]), 'test_mae': array([-0.23584305, -0.26803888, -0.25022018, -0.2679122 , -0.2739296 ]), 'test_r2': array([0.72775637, 0.48117138, 0.64401362, 0.44618026, 0.67426893])}, 420: {'fit_time': array([0.20890999, 0.20157766, 0.2045958 , 0.21022534, 0.21414638]), 'score_time': array([0.00888824, 0.00895667, 0.00944495, 0.00917721, 0.00886798]), 'test_pearson_r': array([0.85581089, 0.74790252, 0.83774182, 0.75951984, 0.704924  ]), 'test_spearman_r': array([0.80849074, 0.80309078, 0.80288638, 0.76355952, 0.72579587]), 'test_rmse': array([-0.31407606, -0.41826233, -0.31311793, -0.43764619, -0.46392364]), 'test_mae': array([-0.22689691, -0.29408857, -0.22647111, -0.28709781, -0.28573305]), 'test_r2': array([0.72896558, 0.55171566, 0.69632005, 0.55753472, 0.49627613])}, 1234567890: {'fit_time': array([0.21333885, 0.20537806, 0.21269941, 0.2077992 , 0.21842027]), 'score_time': array([0.00933146, 0.00862455, 0.00855398, 0.00863576, 0.00955153]), 'test_pearson_r': array([0.84483994, 0.88877772, 0.77290055, 0.7491378 , 0.62696303]), 'test_spearman_r': array([0.83048026, 0.86295611, 0.79136783, 0.76659339, 0.68829088]), 'test_rmse': array([-0.30963144, -0.26600254, -0.40741653, -0.42637917, -0.54572845]), 'test_mae': array([-0.21624775, -0.18956021, -0.27824127, -0.28885958, -0.32442526]), 'test_r2': array([0.70931948, 0.78606683, 0.59076415, 0.55312611, 0.37466037])}, 473129: {'fit_time': array([0.20058584, 0.20491171, 0.20742106, 0.20802498, 0.20859432]), 'score_time': array([0.00902343, 0.00909901, 0.00929999, 0.00918937, 0.00922894]), 'test_pearson_r': array([0.60765879, 0.78666651, 0.83677548, 0.85042364, 0.78404976]), 'test_spearman_r': array([0.72113441, 0.81498721, 0.81601025, 0.82595332, 0.76932127]), 'test_rmse': array([-0.53228568, -0.37822361, -0.32668094, -0.34640154, -0.39983194]), 'test_mae': array([-0.29405198, -0.25439802, -0.22668445, -0.25432801, -0.31278754]), 'test_r2': array([0.36013575, 0.55661047, 0.6911337 , 0.71102665, 0.57645848])}, 'pearson_r_avg': 0.7676034117163957, 'pearson_r_stdev': 0.08285711579841884, 'spearman_r_avg': 0.786898548499544, 'spearman_r_stdev': 0.05853923855230339, 'rmse_avg': 0.40139583076231095, 'rmse_stdev': 0.0748258583781406, 'mae_avg': 0.2663748413422705, 'mae_stdev': 0.03320037792580905, 'r2_avg': 0.5727595572635009, 'r2_stdev': 0.138009788847169}
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 330459: <numerical_MLP_with_feats_on_log Rg (nm)_20250520> in cluster <Hazel> Done

Job <numerical_MLP_with_feats_on_log Rg (nm)_20250520> was submitted from host <c201n02> by user <sdehgha2> in cluster <Hazel> at Tue May 20 17:20:52 2025
Job was executed on host(s) <6*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue May 20 17:20:52 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue May 20 17:20:52 2025
Terminated at Tue May 20 17:21:13 2025
Results reported at Tue May 20 17:21:13 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 8:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "numerical_MLP_with_feats_on_log Rg (nm)_20250520"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "log Rg (nm)"                                   --regressor_type "MLP"                                   --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   44.30 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   22 sec.
    Turnaround time :                            21 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n13>
Subject: Job 347346: <numerical_MLP_with_feats_on_log Rg (nm)_20250520> in cluster <Hazel> Done

Job <numerical_MLP_with_feats_on_log Rg (nm)_20250520> was submitted from host <c203n13> by user <sdehgha2> in cluster <Hazel> at Wed May 21 00:09:16 2025
Job was executed on host(s) <6*c203n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed May 21 00:09:18 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed May 21 00:09:18 2025
Terminated at Wed May 21 00:09:30 2025
Results reported at Wed May 21 00:09:30 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 20:01
#BSUB -x
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "numerical_MLP_with_feats_on_log Rg (nm)_20250520"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "log Rg (nm)"                                   --regressor_type "MLP"                                   --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   13.00 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   14 sec.
    Turnaround time :                            14 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 6.498410777236803e-07), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0006615742508580729), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0004278334860996038), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 6.161938820451174e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.017335964512317413), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 128), ('regressor__regressor__learning_rate_init', 0.0010979775198143374), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 128), ('regressor__regressor__learning_rate_init', 0.0009223744955797581), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.0), ('regressor__regressor__batch_size', 256), ('regressor__regressor__learning_rate_init', 0.001263029864483422), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 0.004180046119613635), ('regressor__regressor__batch_size', 128), ('regressor__regressor__learning_rate_init', 0.0010042221112117724), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.9199405185711804e-06), ('regressor__regressor__batch_size', 128), ('regressor__regressor__learning_rate_init', 0.0016309931576505778), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.0), ('regressor__regressor__batch_size', 256), ('regressor__regressor__learning_rate_init', 0.025324073681758878), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.0182278831634622e-08), ('regressor__regressor__batch_size', 64), ('regressor__regressor__learning_rate_init', 0.0012538694788060344), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 128), ('regressor__regressor__learning_rate_init', 0.001343980165450088), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 64), ('regressor__regressor__learning_rate_init', 0.0005595490434649263), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0008666167774072739), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 4.9340316268455766e-05), ('regressor__regressor__batch_size', 64), ('regressor__regressor__learning_rate_init', 0.00035890733421703545), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 8.651802232299344e-05), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0011126130882419228), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 0.00016274356859524733), ('regressor__regressor__batch_size', 256), ('regressor__regressor__learning_rate_init', 0.0032259649736700526), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 3.351458522894035e-06), ('regressor__regressor__batch_size', 64), ('regressor__regressor__learning_rate_init', 0.0005744247502698656), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 3.1067165080118477e-07), ('regressor__regressor__batch_size', 128), ('regressor__regressor__learning_rate_init', 0.0006805748693139633), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 64), ('regressor__regressor__learning_rate_init', 0.0015848722616231376), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.00043085968116137434), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.6568733808394798e-07), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0004556589946363439), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0023863033967662815), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 64), ('regressor__regressor__learning_rate_init', 0.0007990140311703282), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.001051311612645535), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 256), ('regressor__regressor__learning_rate_init', 0.0010809453191141737), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 0.0002968681574006739), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.000965489193490481), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.0114396451643861e-08), ('regressor__regressor__batch_size', 256), ('regressor__regressor__learning_rate_init', 0.0012870940768877138), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0043614844444045875), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.011916388220725011), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0019445732766568073), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.0011047816215412642), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__learning_rate_init', 0.001449028395035683), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 0.00010297249699804213), ('regressor__regressor__batch_size', 64), ('regressor__regressor__learning_rate_init', 0.0046116193980522925), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 2.4349891755080895e-06), ('regressor__regressor__batch_size', 128), ('regressor__regressor__learning_rate_init', 0.0005272535010633554), ('regressor__regressor__max_iter', 500)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 0.11620738285507774), ('regressor__regressor__batch_size', 256), ('regressor__regressor__learning_rate_init', 0.1), ('regressor__regressor__max_iter', 500)])


Average scores:	 r: 0.83±0.09	 r2: 0.65±0.2
Filename: (Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_MLP_Standard
{6: {'fit_time': array([0.5098114 , 0.49971771, 0.52131891, 0.5108707 , 0.48178673]), 'score_time': array([0.01017427, 0.00909567, 0.00948811, 0.00943637, 0.01070809]), 'test_pearson_r': array([0.93574418, 0.85080767, 0.73254662, 0.83419391, 0.73202213]), 'test_spearman_r': array([0.92911891, 0.85820402, 0.7674935 , 0.84643797, 0.7297493 ]), 'test_rmse': array([-0.23370518, -0.33969928, -0.44674635, -0.34871045, -0.40109302]), 'test_mae': array([-0.14986474, -0.20320736, -0.22443343, -0.19525797, -0.23215444]), 'test_r2': array([0.87486715, 0.71162305, 0.49338665, 0.69036062, 0.47292238]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 128, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0010979775198143374, 'regressor__max_fun': 15000, 'regressor__max_iter': 500, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'fit_time': array([0.51917529, 0.48360705, 0.30774307, 0.49363685, 0.50428629]), 'score_time': array([0.00904059, 0.00897622, 0.00878   , 0.00847554, 0.00849843]), 'test_pearson_r': array([0.90940506, 0.90311514, 0.63418567, 0.80562985, 0.86646424]), 'test_spearman_r': array([0.89925063, 0.90554358, 0.70801222, 0.81001689, 0.83065575]), 'test_rmse': array([-0.27208276, -0.29035524, -0.53178482, -0.39079602, -0.2924796 ]), 'test_mae': array([-0.17269215, -0.15540057, -0.27675089, -0.21551095, -0.17063926]), 'test_r2': array([0.81181409, 0.80057046, 0.27436187, 0.6316088 , 0.73281263]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1.9199405185711804e-06, 'regressor__batch_size': 128, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0016309931576505778, 'regressor__max_fun': 15000, 'regressor__max_iter': 500, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'fit_time': array([0.49999404, 0.49864483, 0.51400638, 0.48706388, 0.46463275]), 'score_time': array([0.00848079, 0.00838637, 0.00901413, 0.00877643, 0.00855494]), 'test_pearson_r': array([0.89359895, 0.79897532, 0.75325785, 0.94446953, 0.80504133]), 'test_spearman_r': array([0.86105241, 0.81067236, 0.81107388, 0.94512156, 0.8048828 ]), 'test_rmse': array([-0.30294058, -0.39918044, -0.36433542, -0.21257324, -0.39551732]), 'test_mae': array([-0.18684267, -0.23566749, -0.20719166, -0.13355333, -0.17815914]), 'test_r2': array([0.79325709, 0.6301877 , 0.46520813, 0.89032884, 0.62472391]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 128, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.001343980165450088, 'regressor__max_fun': 15000, 'regressor__max_iter': 500, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'fit_time': array([0.6680975 , 0.47067237, 0.75372863, 0.40533757, 0.60215735]), 'score_time': array([0.00841856, 0.00872111, 0.00799966, 0.0090723 , 0.00873733]), 'test_pearson_r': array([0.91664222, 0.89946187, 0.9215614 , 0.60531407, 0.8643954 ]), 'test_spearman_r': array([0.92227393, 0.88431329, 0.9204594 , 0.72482763, 0.8566451 ]), 'test_rmse': array([-0.25368657, -0.26025278, -0.25605628, -0.59163084, -0.35256414]), 'test_mae': array([-0.14332241, -0.1764705 , -0.13324223, -0.27587391, -0.18757356]), 'test_r2': array([0.83317257, 0.80733738, 0.83294731, 0.01194837, 0.73575513]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 64, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0015848722616231376, 'regressor__max_fun': 15000, 'regressor__max_iter': 500, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'fit_time': array([0.36379194, 0.3660109 , 0.35953879, 0.37481856, 0.32525253]), 'score_time': array([0.0084393 , 0.00844288, 0.00847054, 0.00909257, 0.0088563 ]), 'test_pearson_r': array([0.92562796, 0.81025599, 0.80536849, 0.88631162, 0.74574004]), 'test_spearman_r': array([0.89519101, 0.82353946, 0.81057195, 0.87293219, 0.77874064]), 'test_rmse': array([-0.22870262, -0.38350491, -0.36511133, -0.30723249, -0.44055756]), 'test_mae': array([-0.14842762, -0.23145552, -0.2162667 , -0.20520938, -0.22098311]), 'test_r2': array([0.85628667, 0.62312448, 0.58709432, 0.78194444, 0.54573964]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 256, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0010809453191141737, 'regressor__max_fun': 15000, 'regressor__max_iter': 500, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'fit_time': array([0.66257429, 0.57818556, 0.53247809, 0.52740216, 0.4210434 ]), 'score_time': array([0.00953579, 0.00806046, 0.00839925, 0.00886655, 0.00865912]), 'test_pearson_r': array([0.8692139 , 0.94820802, 0.8914618 , 0.83808345, 0.69885704]), 'test_spearman_r': array([0.86890075, 0.92030148, 0.88170253, 0.85096392, 0.72378286]), 'test_rmse': array([-0.30484786, -0.18289409, -0.30606553, -0.36379711, -0.51843693]), 'test_mae': array([-0.18689711, -0.12094574, -0.21135338, -0.21250573, -0.2478578 ]), 'test_r2': array([0.71823171, 0.89886397, 0.76904615, 0.67467944, 0.43564207]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 32, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0019445732766568073, 'regressor__max_fun': 15000, 'regressor__max_iter': 500, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'fit_time': array([0.77486396, 0.77815986, 0.81532717, 0.87650824, 0.96583748]), 'score_time': array([0.00856018, 0.00845695, 0.00796962, 0.0090487 , 0.00871062]), 'test_pearson_r': array([0.76595974, 0.73557159, 0.69648909, 0.94733495, 0.83287648]), 'test_spearman_r': array([0.83738717, 0.75093939, 0.81515637, 0.94483116, 0.77909502]), 'test_rmse': array([-0.4343087 , -0.43281266, -0.52634284, -0.21091986, -0.34783972]), 'test_mae': array([-0.18901591, -0.22674289, -0.2515698 , -0.13110013, -0.21100362]), 'test_r2': array([0.57401399, 0.41938525, 0.1982105 , 0.89286458, 0.67944735]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 32, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0011047816215412642, 'regressor__max_fun': 15000, 'regressor__max_iter': 500, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 'pearson_r_avg': 0.8286912161652015, 'pearson_r_stdev': 0.08963021134515103, 'spearman_r_avg': 0.8394240293579794, 'spearman_r_stdev': 0.06547099119832027, 'rmse_avg': 0.35113041542770423, 'rmse_stdev': 0.09776198689635224, 'mae_avg': 0.1961469463276309, 'mae_stdev': 0.0398749771898694, 'r2_avg': 0.6506791052290771, 'r2_stdev': 0.20385354941541026}
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n11>
Subject: Job 392668: <numerical_MLP_with_feats_on_log Rg (nm)_20250520> in cluster <Hazel> Done

Job <numerical_MLP_with_feats_on_log Rg (nm)_20250520> was submitted from host <c207n11> by user <sdehgha2> in cluster <Hazel> at Wed May 21 17:17:31 2025
Job was executed on host(s) <6*c207n11>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed May 21 17:17:32 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed May 21 17:17:32 2025
Terminated at Wed May 21 17:58:30 2025
Results reported at Wed May 21 17:58:30 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 20:01
#BSUB -x
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "numerical_MLP_with_feats_on_log Rg (nm)_20250520"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "log Rg (nm)"                                   --regressor_type "MLP"                                   --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4173.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.79 GB
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               6.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   2459 sec.
    Turnaround time :                            2459 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.4854104037707156e-07), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 128), ('regressor__regressor__learning_rate_init', 0.0009457758483788338), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 128), ('regressor__regressor__hidden_layer_sizes', 64), ('regressor__regressor__learning_rate_init', 0.002907253560971976), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.0022913227882986626), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.332865665147128e-07), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.0005605981978635558), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.4854104037707156e-07), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 128), ('regressor__regressor__learning_rate_init', 0.0009457758483788338), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 128), ('regressor__regressor__learning_rate_init', 0.0009154185143181923), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 64), ('regressor__regressor__learning_rate_init', 0.0019501401679609845), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.0008616996726832449), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.0006613428923393368), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 256), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.001856225692025344), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.001507536516472985), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.0006409050260065336), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.0009598125410301526), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 64), ('regressor__regressor__learning_rate_init', 0.0008448927852341622), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.0012825044333710331), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 256), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.002048727140160892), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 9.685894334824262e-07), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.0007412688203221942), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 3.5541028936763716e-08), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 64), ('regressor__regressor__learning_rate_init', 0.0009838767933472217), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 3.7067951790036217e-07), ('regressor__regressor__batch_size', 128), ('regressor__regressor__hidden_layer_sizes', 128), ('regressor__regressor__learning_rate_init', 0.013188373050364108), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 64), ('regressor__regressor__learning_rate_init', 0.001693416749964116), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.0004950001433497954), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.335146477818154e-07), ('regressor__regressor__batch_size', 128), ('regressor__regressor__hidden_layer_sizes', 128), ('regressor__regressor__learning_rate_init', 0.0017692348916286827), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 9.697867528582978e-08), ('regressor__regressor__batch_size', 128), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.001907398470654961), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.796765605138327e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.0017120150766208716), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__alpha', 1.335146477818154e-07), ('regressor__regressor__batch_size', 128), ('regressor__regressor__hidden_layer_sizes', 128), ('regressor__regressor__learning_rate_init', 0.0017692348916286827), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.00047843853779244727), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 64), ('regressor__regressor__learning_rate_init', 0.0013749351224011373), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.0013001583827027727), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 64), ('regressor__regressor__learning_rate_init', 0.004981496845399412), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 256), ('regressor__regressor__learning_rate_init', 0.002797269648360528), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-08), ('regressor__regressor__batch_size', 128), ('regressor__regressor__hidden_layer_sizes', 128), ('regressor__regressor__learning_rate_init', 0.008959943758980786), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.0032562019128839536), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 1e-06), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.0008942218392906218), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 2.7781661990175306e-08), ('regressor__regressor__batch_size', 64), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.09872419187398675), ('regressor__regressor__max_iter', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR MLP 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__alpha', 3.980140412909693e-07), ('regressor__regressor__batch_size', 32), ('regressor__regressor__hidden_layer_sizes', 512), ('regressor__regressor__learning_rate_init', 0.00039105360790159287), ('regressor__regressor__max_iter', 200)])


Average scores:	 r: 0.82±0.09	 r2: 0.63±0.2
Filename: (Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_MLP_Standard
{6: {'fit_time': array([1.08664489, 1.04301667, 1.1038847 , 1.0529449 , 0.89786601]), 'score_time': array([0.01239657, 0.01251245, 0.01311779, 0.01305676, 0.01139808]), 'test_pearson_r': array([0.93593451, 0.78890438, 0.73622701, 0.89944546, 0.7616171 ]), 'test_spearman_r': array([0.93612163, 0.85231275, 0.77201896, 0.90711131, 0.76491085]), 'test_rmse': array([-0.23458091, -0.41522316, -0.44463234, -0.27407711, -0.37392857]), 'test_mae': array([-0.14988087, -0.2227919 , -0.22250147, -0.17544302, -0.22355409]), 'test_r2': array([0.87392761, 0.56914173, 0.4981699 , 0.80871902, 0.54189855]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1.332865665147128e-07, 'regressor__batch_size': 32, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__hidden_layer_sizes': 512, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0005605981978635558, 'regressor__max_fun': 15000, 'regressor__max_iter': 200, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'fit_time': array([1.04021764, 1.08637166, 1.09653139, 1.07928872, 0.76577616]), 'score_time': array([0.01292157, 0.0118432 , 0.01715422, 0.00993204, 0.01157165]), 'test_pearson_r': array([0.77983286, 0.904331  , 0.66422681, 0.836797  , 0.85739302]), 'test_spearman_r': array([0.89211982, 0.91169125, 0.72914756, 0.85288532, 0.83572431]), 'test_rmse': array([-0.46109324, -0.29411353, -0.49993167, -0.36055754, -0.29713437]), 'test_mae': array([-0.20968899, -0.16115826, -0.24938044, -0.1943307 , -0.19074957]), 'test_r2': array([0.45954122, 0.79537431, 0.35868777, 0.68641292, 0.72424046]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-06, 'regressor__batch_size': 32, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__hidden_layer_sizes': 512, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0008616996726832449, 'regressor__max_fun': 15000, 'regressor__max_iter': 200, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'fit_time': array([1.18707323, 0.88194776, 0.64781117, 0.89067984, 0.90427613]), 'score_time': array([0.01184511, 0.01190829, 0.0127728 , 0.01300406, 0.01103425]), 'test_pearson_r': array([0.87654246, 0.75407052, 0.68437308, 0.94085229, 0.78635414]), 'test_spearman_r': array([0.84662184, 0.79667022, 0.81995347, 0.93487588, 0.80551688]), 'test_rmse': array([-0.32092692, -0.45907555, -0.4326535 , -0.22214843, -0.4040914 ]), 'test_mae': array([-0.20747383, -0.26526765, -0.21862162, -0.14501878, -0.1906426 ]), 'test_r2': array([0.76797861, 0.51088478, 0.24584181, 0.88022623, 0.60827698]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 32, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__hidden_layer_sizes': 512, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.0012825044333710331, 'regressor__max_fun': 15000, 'regressor__max_iter': 200, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'fit_time': array([0.58402896, 0.56798124, 0.41569448, 0.56586218, 0.53635788]), 'score_time': array([0.01153517, 0.01061702, 0.0114212 , 0.01400113, 0.01295567]), 'test_pearson_r': array([0.90838478, 0.83115205, 0.9148588 , 0.67295741, 0.87207199]), 'test_spearman_r': array([0.91736402, 0.83642367, 0.91653147, 0.75488292, 0.84868094]), 'test_rmse': array([-0.27270554, -0.332967  , -0.25461883, -0.51557119, -0.33811068]), 'test_mae': array([-0.18113159, -0.20654041, -0.16518309, -0.25700258, -0.21024097]), 'test_r2': array([0.80722069, 0.68463821, 0.83481766, 0.24966479, 0.75697662]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 32, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.001693416749964116, 'regressor__max_fun': 15000, 'regressor__max_iter': 200, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'fit_time': array([0.44185305, 0.44259715, 0.45310378, 0.46117258, 0.44490886]), 'score_time': array([0.01278734, 0.01457214, 0.01256609, 0.01302338, 0.01348233]), 'test_pearson_r': array([0.93198406, 0.7810156 , 0.81421984, 0.90099021, 0.75992916]), 'test_spearman_r': array([0.90441626, 0.80334692, 0.85963154, 0.88326325, 0.80254316]), 'test_rmse': array([-0.21911998, -0.40632277, -0.37537881, -0.28966522, -0.43410748]), 'test_mae': array([-0.1474028 , -0.22996382, -0.22336042, -0.19396735, -0.20716209]), 'test_r2': array([0.86807754, 0.57694349, 0.56354472, 0.80616795, 0.55894368]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 9.697867528582978e-08, 'regressor__batch_size': 128, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__hidden_layer_sizes': 256, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.001907398470654961, 'regressor__max_fun': 15000, 'regressor__max_iter': 200, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'fit_time': array([0.28509879, 0.39987803, 0.39460588, 0.28982449, 0.27156901]), 'score_time': array([0.01297069, 0.01682496, 0.01077318, 0.0117259 , 0.01124787]), 'test_pearson_r': array([0.79716577, 0.92766877, 0.8766669 , 0.81686744, 0.71889773]), 'test_spearman_r': array([0.76917823, 0.90633876, 0.86885246, 0.81287763, 0.7694154 ]), 'test_rmse': array([-0.36762014, -0.21858874, -0.31857932, -0.38123959, -0.49549707]), 'test_mae': array([-0.24942511, -0.15455332, -0.21829981, -0.21775846, -0.27592325]), 'test_r2': array([0.59024485, 0.85553517, 0.74977452, 0.64273621, 0.48448067]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-06, 'regressor__batch_size': 64, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__hidden_layer_sizes': 256, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.002797269648360528, 'regressor__max_fun': 15000, 'regressor__max_iter': 200, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'fit_time': array([0.1909256 , 0.20995545, 0.24950504, 0.28028584, 0.16605878]), 'score_time': array([0.01176691, 0.01190519, 0.01261783, 0.0118854 , 0.00998974]), 'test_pearson_r': array([0.77179689, 0.79224397, 0.59982063, 0.95355336, 0.82949839]), 'test_spearman_r': array([0.83854031, 0.80849703, 0.7091045 , 0.95593326, 0.77909502]), 'test_rmse': array([-0.4260803 , -0.36642288, -0.57130936, -0.19681545, -0.35480023]), 'test_mae': array([-0.19849572, -0.20059901, -0.33499762, -0.14402387, -0.22797867]), 'test_r2': array([0.59000251, 0.58384671, 0.05536156, 0.90671399, 0.66649004]), 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__activation': 'relu', 'regressor__alpha': 1e-08, 'regressor__batch_size': 128, 'regressor__beta_1': 0.9, 'regressor__beta_2': 0.999, 'regressor__early_stopping': False, 'regressor__epsilon': 1e-08, 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.008959943758980786, 'regressor__max_fun': 15000, 'regressor__max_iter': 200, 'regressor__momentum': 0.9, 'regressor__n_iter_no_change': 10, 'regressor__nesterovs_momentum': True, 'regressor__power_t': 0.5, 'regressor__random_state': None, 'regressor__shuffle': True, 'regressor__solver': 'adam', 'regressor__tol': 0.0001, 'regressor__validation_fraction': 0.1, 'regressor__verbose': False, 'regressor__warm_start': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 'pearson_r_avg': 0.8193898683610081, 'pearson_r_stdev': 0.08751562595856413, 'spearman_r_avg': 0.8400742512397911, 'spearman_r_stdev': 0.06246603829736393, 'rmse_avg': 0.3608482528635989, 'rmse_stdev': 0.09293002222741996, 'mae_avg': 0.20772896430765694, 'mae_stdev': 0.04030783691322889, 'r2_avg': 0.6331858127329537, 'r2_stdev': 0.19588537233113013}
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n09>
Subject: Job 420410: <numerical_MLP_with_feats_on_log Rg (nm)_20250520> in cluster <Hazel> Done

Job <numerical_MLP_with_feats_on_log Rg (nm)_20250520> was submitted from host <c207n01> by user <sdehgha2> in cluster <Hazel> at Thu May 22 00:03:59 2025
Job was executed on host(s) <6*c201n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu May 22 00:03:59 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu May 22 00:03:59 2025
Terminated at Thu May 22 00:56:35 2025
Results reported at Thu May 22 00:56:35 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 2:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "numerical_MLP_with_feats_on_log Rg (nm)_20250520"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "log Rg (nm)"                                   --regressor_type "MLP"                                   --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5406.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.96 GB
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               6.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   3176 sec.
    Turnaround time :                            3156 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err> for stderr output of this job.

