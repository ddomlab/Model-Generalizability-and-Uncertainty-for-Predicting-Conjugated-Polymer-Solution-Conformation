Fluorene
-------- OOD Parallel --------
Fluorene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
PPV
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Thiophene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Polar
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Filename: (Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH-light exposure-aging time-aging temperature-prep temperature-prep time)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n05>
Subject: Job 634624: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c207n06> by user <sdehgha2> in cluster <Hazel> at Sat May 31 10:42:50 2025
Job was executed on host(s) <4*c202n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat May 31 10:42:52 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat May 31 10:42:52 2025
Terminated at Sat May 31 11:02:05 2025
Results reported at Sat May 31 11:02:05 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' "Dark/light" "Aging time (hour)" "To Aging Temperature (K)" "Sonication/Stirring/heating Temperature (K)" "Merged Stirring /sonication/heating time(min)"                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   12470.45 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.05 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1172 sec.
    Turnaround time :                            1155 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
PPV
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Thiophene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Polar
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Filename: (concentration-temperature-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n09>
Subject: Job 634653: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c203n01> by user <sdehgha2> in cluster <Hazel> at Sat May 31 10:51:04 2025
Job was executed on host(s) <4*c203n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat May 31 10:51:06 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat May 31 10:51:06 2025
Terminated at Sat May 31 11:14:59 2025
Results reported at Sat May 31 11:14:59 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   8437.39 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.47 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1433 sec.
    Turnaround time :                            1435 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

Fluorene
-------- OOD Parallel --------
Fluorene
-------- OOD Parallel --------
Fluorene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
PPV
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Thiophene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Polar
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Filename: (Xn-Mw-PDI)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n07>
Subject: Job 634761: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c205n03> by user <sdehgha2> in cluster <Hazel> at Sat May 31 11:32:48 2025
Job was executed on host(s) <4*c203n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat May 31 11:32:50 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat May 31 11:32:50 2025
Terminated at Sat May 31 11:51:08 2025
Results reported at Sat May 31 11:51:08 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI'                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6476.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.56 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               11.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1123 sec.
    Turnaround time :                            1100 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
PPV
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Thiophene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Polar
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Filename: (concentration-temperature-solvent dP-solvent dD-solvent dH-light exposure-aging time-aging temperature-prep temperature-prep time)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n10>
Subject: Job 634736: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c203n05> by user <sdehgha2> in cluster <Hazel> at Sat May 31 11:24:14 2025
Job was executed on host(s) <4*c203n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat May 31 11:24:15 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat May 31 11:24:15 2025
Terminated at Sat May 31 11:59:43 2025
Results reported at Sat May 31 11:59:43 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' 'solvent dP' 'solvent dD' 'solvent dH' "Dark/light" "Aging time (hour)" "To Aging Temperature (K)" "Sonication/Stirring/heating Temperature (K)" "Merged Stirring /sonication/heating time(min)"                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   9254.26 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.11 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   2133 sec.
    Turnaround time :                            2129 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
PPV
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Thiophene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Polar
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Filename: (Xn-Mw-PDI-polymer dP-polymer dD-polymer dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n06>
Subject: Job 634801: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c203n09> by user <sdehgha2> in cluster <Hazel> at Sat May 31 11:46:27 2025
Job was executed on host(s) <4*c207n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat May 31 11:46:33 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat May 31 11:46:33 2025
Terminated at Sat May 31 12:03:25 2025
Results reported at Sat May 31 12:03:25 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' "polymer dP" "polymer dD" "polymer dH"                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6965.59 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.81 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               11.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1016 sec.
    Turnaround time :                            1018 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

Fluorene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
PPV
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Thiophene
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Polar
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
-------- OOD Parallel --------
-------- IID Parallel --------
Filename: (Xn)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c009n01>
Subject: Job 643374: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c202n14> by user <sdehgha2> in cluster <Hazel> at Mon Jun  2 17:08:11 2025
Job was executed on host(s) <4*c009n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Jun  2 17:08:32 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Jun  2 17:08:32 2025
Terminated at Mon Jun  2 17:12:35 2025
Results reported at Mon Jun  2 17:12:35 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Xn'                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3779.52 sec.
    Max Memory :                                 8 GB
    Average Memory :                             5.50 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               8.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   270 sec.
    Turnaround time :                            264 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

Fluorene
-------- OOD Parallel --------

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n10>
Subject: Job 819454: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c203n04> by user <sdehgha2> in cluster <Hazel> at Tue Jun 17 00:23:22 2025
Job was executed on host(s) <4*c203n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Jun 17 00:36:22 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Jun 17 00:36:22 2025
Terminated at Tue Jun 17 00:36:47 2025
Results reported at Tue Jun 17 00:36:47 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI'  'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' 'abs(solvent dD - polymer dD)' 'abs(solvent dP - polymer dP)' 'abs(solvent dH - polymer dH)' "Dark/light" "Aging time (hour)" "To Aging Temperature (K)" "Sonication/Stirring/heating Temperature (K)" "Merged Stirring /sonication/heating time(min)"                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   61.30 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   25 sec.
    Turnaround time :                            805 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

Fluorene
-------- OOD Parallel --------

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n04>
Subject: Job 819697: <XGBR_log Rg (nm)___substructure cluster_20250531> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)___substructure cluster_20250531> was submitted from host <c205n05> by user <sdehgha2> in cluster <Hazel> at Tue Jun 17 02:30:12 2025
Job was executed on host(s) <4*c200n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Jun 17 02:30:14 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Jun 17 02:30:14 2025
Terminated at Tue Jun 17 03:07:36 2025
Results reported at Tue Jun 17 03:07:36 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 06:00
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)___substructure cluster_20250531"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --regressor_type "XGBR"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI'  'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' 'abs(solvent dD - polymer dD)' 'abs(solvent dP - polymer dP)' 'abs(solvent dH - polymer dH)' "Dark/light" "Aging time (hour)" "To Aging Temperature (K)" "Sonication/Stirring/heating Temperature (K)" "Merged Stirring /sonication/heating time(min)"                                       --clustering_method "substructure cluster" 



------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   29260.00 sec.
    Max Memory :                                 45 GB
    Average Memory :                             23.96 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -29.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   2242 sec.
    Turnaround time :                            2244 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250531/XGBR_log Rg (nm)___substructure cluster_numerical_20250531.err> for stderr output of this job.

