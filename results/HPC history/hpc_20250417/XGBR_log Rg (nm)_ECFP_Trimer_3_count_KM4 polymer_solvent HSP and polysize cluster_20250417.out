
------------------------------------------------------------
Sender: LSF System <lsfadmin@c014n02>
Subject: Job 206523: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> was submitted from host <c202n11> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:18:18 2025
Job was executed on host(s) <4*c014n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:19:03 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:19:03 2025
Terminated at Thu Apr 17 17:19:37 2025
Results reported at Thu Apr 17 17:19:37 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 polymer_solvent HSP and polysize cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   3.44 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   54 sec.
    Turnaround time :                            79 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c014n02>
Subject: Job 206740: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> was submitted from host <c202n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:23:37 2025
Job was executed on host(s) <4*c014n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:24:24 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:24:24 2025
Terminated at Thu Apr 17 17:28:02 2025
Results reported at Thu Apr 17 17:28:02 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 polymer_solvent HSP and polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   61.39 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   219 sec.
    Turnaround time :                            265 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n10>
Subject: Job 208353: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> was submitted from host <c200n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:51:47 2025
Job was executed on host(s) <4*c205n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:52:46 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:52:46 2025
Terminated at Thu Apr 17 17:53:15 2025
Results reported at Thu Apr 17 17:53:15 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 polymer_solvent HSP and polysize cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   3.07 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   52 sec.
    Turnaround time :                            88 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n07>
Subject: Job 209813: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> was submitted from host <c207n12> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:26:24 2025
Job was executed on host(s) <4*c202n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:29:22 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 18:29:22 2025
Terminated at Thu Apr 17 18:42:26 2025
Results reported at Thu Apr 17 18:42:26 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 polymer_solvent HSP and polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   766.13 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   788 sec.
    Turnaround time :                            962 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.060106274145486735), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02872235754997113), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 361), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 583), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003650931474568706), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 707), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006064778220206785), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 510), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.024483401770795898), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1031), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02101229493902693), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 622), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1351), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.046730285688836706), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 921), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03295662030643614), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1071), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006441783644911765), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03473715753698836), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 676), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06740765235356637), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 126), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07190456966549479), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 262), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06483124130945074), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 1748), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05024983629918034), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 542), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03873279577808253), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 140), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03288323560706785), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 471), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 124), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0194947758197775), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 136), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.018150368408364728), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 596), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07093905412651977), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 126), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05110435274898769), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 74), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 60), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02988652686941158), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03988639142620346), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07390686814548807), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 611), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09742919667455353), ('regressor__regressor__max_depth', 8716), ('regressor__regressor__n_estimators', 437), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 606), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003884198378633661), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 816), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018267015369190568), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.023496607323832727), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1199), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015612938007098074), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 314), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.059611912268390965), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1232), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08958575698105219), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 66), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01629728699935032), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1220), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07527510320668386), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 71), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022496406586187965), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04624273993073388), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 242), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05967433304174098), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 483), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03252108800594495), ('regressor__regressor__max_depth', 4466), ('regressor__regressor__n_estimators', 153), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03796348935226763), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 140), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07847500212523906), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1320), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 82), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0034667052474954755), ('regressor__regressor__max_depth', 9085), ('regressor__regressor__n_estimators', 685), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.033206317199631165), ('regressor__regressor__max_depth', 384), ('regressor__regressor__n_estimators', 158), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02256825001011882), ('regressor__regressor__max_depth', 522), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06307172625353798), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 144), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04378197785136113), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0072375780591068355), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 524), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07706098868308885), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007680500558585925), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 451), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 3110), ('regressor__regressor__n_estimators', 255), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06818032904073776), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002352063405105436), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.060577696693666264), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1436), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04776562237192588), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 100), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006060025461799215), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 453), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 279), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08016686144161426), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 68), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 2



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034821849884603503), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1084), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05875459069453165), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 316), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07360225781597989), ('regressor__regressor__max_depth', 31), ('regressor__regressor__n_estimators', 237), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 308), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.039513785613845206), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 205), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07700250672973129), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 348), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1531), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007767027912560548), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06496785890651455), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 156), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006620676229153067), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1662), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 91), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04757122610732569), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.022484495530915093), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1082), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07267273720846974), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 231), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.061411624474773774), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 578), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04490408354303042), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07385374179478922), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 112), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028848359902664236), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 146), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 308), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002079272161566662), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09051443436597122), ('regressor__regressor__max_depth', 4488), ('regressor__regressor__n_estimators', 477), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07158394113391477), ('regressor__regressor__max_depth', 6387), ('regressor__regressor__n_estimators', 482), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06631157031594583), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1121), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05995330553063688), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.013558036239526117), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 250), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.061118503464299215), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 356), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.013950108128827637), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 3



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028491276439735654), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1095), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07192938833202275), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 395), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018373490398805416), ('regressor__regressor__max_depth', 216), ('regressor__regressor__n_estimators', 1510), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00747938617678172), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0633090825732806), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 75), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05867717688232244), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 121), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08299934156161437), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1293), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.045063537000944134), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 568), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 223), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06614433601163947), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.013752336241581072), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1147), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 234), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05095070413838073), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 231), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002424513814484764), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1046), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06645171834283019), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 265), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02256825001011882), ('regressor__regressor__max_depth', 522), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002894694972302011), ('regressor__regressor__max_depth', 2119), ('regressor__regressor__n_estimators', 1147), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05739238905792375), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0021654106986286094), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06372671854842075), ('regressor__regressor__max_depth', 8500), ('regressor__regressor__n_estimators', 261), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03921204133394256), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 558), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03966332401253303), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 828), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00639996078451744), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 374), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 499), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.022530587074048373), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 167), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04108888270678258), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 124), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06131599844034504), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 174), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030924562186255757), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 939), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06611799810717171), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 171), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06510082835635203), ('regressor__regressor__max_depth', 6099), ('regressor__regressor__n_estimators', 1441), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0695585601442802), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 170), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02739515115719073), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05653166210539317), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 71), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0727880237480246), ('regressor__regressor__max_depth', 502), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015490497743708975), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1248), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])


Filename: (ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Standard
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n14>
Subject: Job 233651: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> was submitted from host <c021n03> by user <sdehgha2> in cluster <Hazel> at Fri Apr 18 02:29:55 2025
Job was executed on host(s) <8*c205n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat Apr 19 07:30:32 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat Apr 19 07:30:32 2025
Terminated at Sun Apr 20 00:28:07 2025
Results reported at Sun Apr 20 00:28:07 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 polymer_solvent HSP and polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   239470.23 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.08 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               11.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   61056 sec.
    Turnaround time :                            165492 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06274308355406859), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 246), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.058553884052961476), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 123), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0208329447179998), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 542), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01710683755475168), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 231), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02624177521614131), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 422), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09258732256565452), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 1175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 120), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07327247951966166), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 67), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07470091383037525), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 146), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0718870661754239), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 82), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04424585428514749), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 216), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05023743348082711), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03259750245535606), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 136), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07710543107825665), ('regressor__regressor__max_depth', 7958), ('regressor__regressor__n_estimators', 67), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034769668589043685), ('regressor__regressor__max_depth', 2287), ('regressor__regressor__n_estimators', 1119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016994636371262762), ('regressor__regressor__max_depth', 1525), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0030902789138549007), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0992922593078404), ('regressor__regressor__max_depth', 6270), ('regressor__regressor__n_estimators', 63), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 357), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 493), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04958480243586312), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 756), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004539549056204168), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1757), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n01>
Subject: Job 372776: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> was submitted from host <c200n05> by user <sdehgha2> in cluster <Hazel> at Tue Apr 22 10:01:58 2025
Job was executed on host(s) <6*c203n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Apr 22 10:20:16 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Apr 22 10:20:16 2025
Terminated at Tue Apr 22 12:03:08 2025
Results reported at Tue Apr 22 12:03:08 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 polymer_solvent HSP and polysize cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   24084.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.16 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   6172 sec.
    Turnaround time :                            7270 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n07>
Subject: Job 496392: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417> was submitted from host <c207n07> by user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:48:18 2025
Job was executed on host(s) <8*c207n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:51:49 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Apr 28 11:51:49 2025
Terminated at Mon Apr 28 11:52:09 2025
Results reported at Mon Apr 28 11:52:09 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 polymer_solvent HSP and polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 polymer_solvent HSP and polysize cluster" 



------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   5.58 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   28 sec.
    Turnaround time :                            231 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 polymer_solvent HSP and polysize cluster_20250417.err> for stderr output of this job.

