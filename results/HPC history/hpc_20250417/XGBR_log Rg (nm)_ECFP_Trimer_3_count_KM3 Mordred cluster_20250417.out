
------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n06>
Subject: Job 206521: <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> was submitted from host <c202n11> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:18:17 2025
Job was executed on host(s) <4*c200n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:18:54 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:18:54 2025
Terminated at Thu Apr 17 17:19:38 2025
Results reported at Thu Apr 17 17:19:38 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM3 Mordred cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   2.78 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   44 sec.
    Turnaround time :                            81 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n06>
Subject: Job 206738: <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> was submitted from host <c202n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:23:37 2025
Job was executed on host(s) <4*c200n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:23:39 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:23:39 2025
Terminated at Thu Apr 17 17:27:33 2025
Results reported at Thu Apr 17 17:27:33 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM3 Mordred cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   66.98 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   235 sec.
    Turnaround time :                            236 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n12>
Subject: Job 208349: <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> was submitted from host <c200n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:51:47 2025
Job was executed on host(s) <4*c200n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:52:44 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:52:44 2025
Terminated at Thu Apr 17 17:53:15 2025
Results reported at Thu Apr 17 17:53:15 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM3 Mordred cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   2.16 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   39 sec.
    Turnaround time :                            88 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n02>
Subject: Job 209811: <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> was submitted from host <c207n12> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:26:24 2025
Job was executed on host(s) <4*c023n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:29:01 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 18:29:01 2025
Terminated at Thu Apr 17 18:35:56 2025
Results reported at Thu Apr 17 18:35:56 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM3 Mordred cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   401.51 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   415 sec.
    Turnaround time :                            572 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0037633627051647696), ('regressor__regressor__max_depth', 95), ('regressor__regressor__n_estimators', 1802), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008922390010235524), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07492585568714204), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 94), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002713495309824603), ('regressor__regressor__max_depth', 100), ('regressor__regressor__n_estimators', 1712), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004866083656078861), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 1446), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0838635785626253), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1125), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00572326441431493), ('regressor__regressor__max_depth', 38), ('regressor__regressor__n_estimators', 1015), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004168179613999179), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1154), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026001274366483626), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 212), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 436), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04872690530435609), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01113953227780453), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 187), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057531819683288826), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 128), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040701723660355724), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 173), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03427544220836661), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 484), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03793633495846121), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 180), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 403), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0587088983948905), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 669), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016972844896636877), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06006546229794959), ('regressor__regressor__max_depth', 22), ('regressor__regressor__n_estimators', 1924), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06048574530226919), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 240), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09839503492963116), ('regressor__regressor__max_depth', 7839), ('regressor__regressor__n_estimators', 474), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 353), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 384), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00224225048338329), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03279651592058514), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 100), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07341369551635653), ('regressor__regressor__max_depth', 5486), ('regressor__regressor__n_estimators', 350), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05765479986080695), ('regressor__regressor__max_depth', 6259), ('regressor__regressor__n_estimators', 115), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007214881039251286), ('regressor__regressor__max_depth', 6409), ('regressor__regressor__n_estimators', 1890), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034996655442758436), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014249018759709083), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03298106706391001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 5778), ('regressor__regressor__n_estimators', 66), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028002967083632896), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 326), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07054458382904202), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008818984289510586), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06564913383710246), ('regressor__regressor__max_depth', 7802), ('regressor__regressor__n_estimators', 69), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027516788930821975), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1081), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007896997673782765), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 527), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004231160373687155), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 779), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518378097192), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00408294736977109), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 513), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004629600865244824), ('regressor__regressor__max_depth', 9841), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0017242984490246959), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1658), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028931796468505747), ('regressor__regressor__max_depth', 8188), ('regressor__regressor__n_estimators', 96), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.044435211555199125), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 638), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09162216582089645), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06638413613262747), ('regressor__regressor__max_depth', 7126), ('regressor__regressor__n_estimators', 1975), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035830229184755716), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028183247153004812), ('regressor__regressor__max_depth', 8983), ('regressor__regressor__n_estimators', 164), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05051437569172617), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007456062192354527), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 244), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07848547587965879), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006348301035848299), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 518), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03586578658051549), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 113), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02611668842159466), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014478182740418903), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06110296145215738), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 690), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003974297544878959), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 923), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1353), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006128115832970131), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04378058934283143), ('regressor__regressor__max_depth', 369), ('regressor__regressor__n_estimators', 1345), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004866083656078861), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 1446), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0838635785626253), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1125), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00572326441431493), ('regressor__regressor__max_depth', 38), ('regressor__regressor__n_estimators', 1015), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06991692945397764), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.059954880771886696), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 191), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07318509725870048), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0674196526069194), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0502408167528029), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057531819683288826), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 128), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040701723660355724), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 173), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03427544220836661), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 484), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03793633495846121), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 180), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 403), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07883755320308729), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 112), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.033340484049045584), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07430945423051924), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 156), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.020587278721539527), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 660), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06048574530226919), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 240), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09839503492963116), ('regressor__regressor__max_depth', 7839), ('regressor__regressor__n_estimators', 474), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 353), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 384), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00224225048338329), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02030855584087624), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1016), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004540102074705809), ('regressor__regressor__max_depth', 8931), ('regressor__regressor__n_estimators', 1863), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 396), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02252078462575068), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06073336498681336), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 469), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034996655442758436), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014249018759709083), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03298106706391001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.021370901367168228), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 197), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03946510438829927), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06431342252795764), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 291), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010744618050607705), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__max_depth', 2125), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027516788930821975), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1081), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007896997673782765), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 527), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004231160373687155), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 779), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518378097192), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014044590250285796), ('regressor__regressor__max_depth', 16), ('regressor__regressor__n_estimators', 849), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03183734509541455), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1132), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006693424541199479), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0411127556260327), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 303), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.018225180908565605), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09162216582089645), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06638413613262747), ('regressor__regressor__max_depth', 7126), ('regressor__regressor__n_estimators', 1975), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035830229184755716), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028183247153004812), ('regressor__regressor__max_depth', 8983), ('regressor__regressor__n_estimators', 164), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06052165402420542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 364), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.046061520553729904), ('regressor__regressor__max_depth', 3975), ('regressor__regressor__n_estimators', 101), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 206), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05041408829946739), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 99), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0794557114003219), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02611668842159466), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014478182740418903), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06110296145215738), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 690), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003974297544878959), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 923), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 2



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04740405617774628), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 194), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05441127708224127), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1347), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 144), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.056876713513412946), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06907725087202664), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004866083656078861), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 1446), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0838635785626253), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1125), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00572326441431493), ('regressor__regressor__max_depth', 38), ('regressor__regressor__n_estimators', 1015), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06991692945397764), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.042905823362158174), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 250), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07580345036295748), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 99), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05946125338899562), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057531819683288826), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 128), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040701723660355724), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 173), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03427544220836661), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 484), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03793633495846121), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 180), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 403), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05379512505686901), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05310260245270577), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 697), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 345), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 102), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08295272395355681), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 74), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06048574530226919), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 240), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09839503492963116), ('regressor__regressor__max_depth', 7839), ('regressor__regressor__n_estimators', 474), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 353), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 384), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00224225048338329), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05734002063529617), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02256825001011882), ('regressor__regressor__max_depth', 522), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04568143536571276), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1237), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05847583007804021), ('regressor__regressor__max_depth', 17), ('regressor__regressor__n_estimators', 839), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006681783121626145), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034996655442758436), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014249018759709083), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03298106706391001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 77), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01002325189189055), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 427), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0285618518981639), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 154), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027516788930821975), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1081), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007896997673782765), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 527), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004231160373687155), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 779), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518378097192), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 926), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011890758990740746), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026715543896256785), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0699644496359164), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 163), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07243652792109966), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 748), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09162216582089645), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06638413613262747), ('regressor__regressor__max_depth', 7126), ('regressor__regressor__n_estimators', 1975), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035830229184755716), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028183247153004812), ('regressor__regressor__max_depth', 8983), ('regressor__regressor__n_estimators', 164), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004998548569316488), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0727880237480246), ('regressor__regressor__max_depth', 502), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06035645392574147), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 400), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09711204176767385), ('regressor__regressor__max_depth', 9168), ('regressor__regressor__n_estimators', 1457), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0564901521834508), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 296), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02611668842159466), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014478182740418903), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06110296145215738), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 690), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003974297544878959), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 923), ('regressor__regressor__n_jobs', -2)])


Filename: (ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Standard
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c003n03>
Subject: Job 233649: <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> was submitted from host <c021n03> by user <sdehgha2> in cluster <Hazel> at Fri Apr 18 02:29:55 2025
Job was executed on host(s) <8*c003n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Apr 18 21:08:28 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Apr 18 21:08:28 2025
Terminated at Sat Apr 19 05:31:05 2025
Results reported at Sat Apr 19 05:31:05 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM3 Mordred cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   117829.21 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.70 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   30158 sec.
    Turnaround time :                            97270 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004866083656078861), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 1446), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004427759270669458), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 429), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07171765419782497), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.058042150372589835), ('regressor__regressor__max_depth', 36), ('regressor__regressor__n_estimators', 634), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006625211189551136), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 376), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02624177521614131), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 422), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09258732256565452), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 1175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 120), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0421810924125031), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030995112132009943), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 83), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04474159172895354), ('regressor__regressor__max_depth', 4107), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07116232659231948), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05023743348082711), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03259750245535606), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 136), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07710543107825665), ('regressor__regressor__max_depth', 7958), ('regressor__regressor__n_estimators', 67), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034769668589043685), ('regressor__regressor__max_depth', 2287), ('regressor__regressor__n_estimators', 1119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 746), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009586362410430369), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06083593467097554), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 106), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06453725140529415), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016818852963153635), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04958480243586312), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 756), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004539549056204168), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1757), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n04>
Subject: Job 372774: <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> was submitted from host <c200n05> by user <sdehgha2> in cluster <Hazel> at Tue Apr 22 10:01:58 2025
Job was executed on host(s) <6*c205n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Apr 22 10:19:57 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Apr 22 10:19:57 2025
Terminated at Tue Apr 22 12:03:07 2025
Results reported at Tue Apr 22 12:03:07 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM3 Mordred cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   23989.16 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.76 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   6202 sec.
    Turnaround time :                            7269 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n14>
Subject: Job 496390: <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417> was submitted from host <c207n07> by user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:48:17 2025
Job was executed on host(s) <8*c205n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:48:22 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Apr 28 11:48:22 2025
Terminated at Mon Apr 28 11:51:47 2025
Results reported at Mon Apr 28 11:51:47 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM3 Mordred cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM3 Mordred cluster" 



------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   8.98 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   205 sec.
    Turnaround time :                            210 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM3 Mordred cluster_20250417.err> for stderr output of this job.

