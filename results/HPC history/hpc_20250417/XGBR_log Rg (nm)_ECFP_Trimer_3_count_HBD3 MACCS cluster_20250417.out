
------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n04>
Subject: Job 206520: <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> was submitted from host <c202n11> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:18:17 2025
Job was executed on host(s) <4*c200n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:18:52 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:18:52 2025
Terminated at Thu Apr 17 17:19:37 2025
Results reported at Thu Apr 17 17:19:37 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "HBD3 MACCS cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   2.77 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   45 sec.
    Turnaround time :                            80 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n12>
Subject: Job 206737: <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> was submitted from host <c202n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:23:37 2025
Job was executed on host(s) <4*c200n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:23:39 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:23:39 2025
Terminated at Thu Apr 17 17:27:56 2025
Results reported at Thu Apr 17 17:27:56 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "HBD3 MACCS cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   71.47 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   257 sec.
    Turnaround time :                            259 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 208347: <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> was submitted from host <c200n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:51:47 2025
Job was executed on host(s) <4*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:52:44 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:52:44 2025
Terminated at Thu Apr 17 17:53:15 2025
Results reported at Thu Apr 17 17:53:15 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "HBD3 MACCS cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   2.27 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   42 sec.
    Turnaround time :                            88 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c018n03>
Subject: Job 209810: <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> was submitted from host <c207n12> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:26:24 2025
Job was executed on host(s) <4*c018n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:28:46 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 18:28:46 2025
Terminated at Thu Apr 17 18:35:55 2025
Results reported at Thu Apr 17 18:35:55 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "HBD3 MACCS cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   408.04 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   429 sec.
    Turnaround time :                            571 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON -1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011705732141338692), ('regressor__regressor__max_depth', 63), ('regressor__regressor__n_estimators', 351), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.059231211758690824), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 191), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002805588199070955), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.038385745526028435), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 322), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008330876591366502), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 633), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004866083656078861), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 1446), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0838635785626253), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1125), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00572326441431493), ('regressor__regressor__max_depth', 38), ('regressor__regressor__n_estimators', 1015), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07227468979572932), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1065), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 304), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07773919076932455), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018386379040481076), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057531819683288826), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 128), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040701723660355724), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 173), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03427544220836661), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 484), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03793633495846121), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 180), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 403), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05667595031485473), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 97), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.022468620168040812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 245), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03021991677543778), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06048574530226919), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 240), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09839503492963116), ('regressor__regressor__max_depth', 7839), ('regressor__regressor__n_estimators', 474), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 353), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 384), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00224225048338329), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09939793013929618), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 3250), ('regressor__regressor__n_estimators', 353), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07406245131982615), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0019617731996469314), ('regressor__regressor__max_depth', 7245), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05450944392439182), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034996655442758436), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014249018759709083), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03298106706391001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014798641065097335), ('regressor__regressor__max_depth', 41), ('regressor__regressor__n_estimators', 720), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01130041524333301), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 390), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014798641065097335), ('regressor__regressor__max_depth', 41), ('regressor__regressor__n_estimators', 720), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018310986575811364), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027516788930821975), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1081), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007896997673782765), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 527), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004231160373687155), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 779), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518378097192), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07682256475052597), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 60), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 61), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.043602549637570154), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 95), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0637136598392493), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09162216582089645), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06638413613262747), ('regressor__regressor__max_depth', 7126), ('regressor__regressor__n_estimators', 1975), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035830229184755716), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028183247153004812), ('regressor__regressor__max_depth', 8983), ('regressor__regressor__n_estimators', 164), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.009037370162501578), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1305), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 220), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08192086332664832), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 457), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 256), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02611668842159466), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014478182740418903), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06110296145215738), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 690), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003974297544878959), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 923), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 146), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06473452849469352), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06868290319864502), ('regressor__regressor__max_depth', 2615), ('regressor__regressor__n_estimators', 394), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004866083656078861), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 1446), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0838635785626253), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1125), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00572326441431493), ('regressor__regressor__max_depth', 38), ('regressor__regressor__n_estimators', 1015), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 736), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06650005607009224), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 66), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05341725568234184), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057531819683288826), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 128), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040701723660355724), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 173), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03427544220836661), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 484), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03793633495846121), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 180), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 403), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 115), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.042009242634545974), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 956), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 382), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002456725782347182), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05612060210227508), ('regressor__regressor__max_depth', 9040), ('regressor__regressor__n_estimators', 543), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06048574530226919), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 240), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09839503492963116), ('regressor__regressor__max_depth', 7839), ('regressor__regressor__n_estimators', 474), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 353), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 384), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00224225048338329), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.020533944093645416), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 279), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06965986787706396), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 644), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0020556569190693552), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06815158997920313), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 245), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004540102074705809), ('regressor__regressor__max_depth', 8931), ('regressor__regressor__n_estimators', 1863), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034996655442758436), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014249018759709083), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03298106706391001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00249272222147598), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__max_depth', 2125), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 72), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__max_depth', 2125), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03190541719740462), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 922), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027516788930821975), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1081), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007896997673782765), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 527), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004231160373687155), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 779), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518378097192), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04348476782049988), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.013621429481623775), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 554), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07432416282251335), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 472), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 59), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09162216582089645), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06638413613262747), ('regressor__regressor__max_depth', 7126), ('regressor__regressor__n_estimators', 1975), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035830229184755716), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028183247153004812), ('regressor__regressor__max_depth', 8983), ('regressor__regressor__n_estimators', 164), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06773471193641259), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 558), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004044708924706896), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1110), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008946969178066807), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06501676057141242), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02611668842159466), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014478182740418903), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06110296145215738), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 690), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003974297544878959), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 923), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07610331195026297), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 133), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015536529968568913), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 287), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012823309337280363), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1013), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 51), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004866083656078861), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 1446), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0838635785626253), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1125), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00572326441431493), ('regressor__regressor__max_depth', 38), ('regressor__regressor__n_estimators', 1015), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06765528016583688), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06020051269687166), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08358084326205244), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 68), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002580064554077554), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1512), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002746874203004447), ('regressor__regressor__max_depth', 3150), ('regressor__regressor__n_estimators', 848), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057531819683288826), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 128), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040701723660355724), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 173), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03427544220836661), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 484), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03793633495846121), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 180), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 403), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08081191030929204), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 62), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05032208032197972), ('regressor__regressor__max_depth', 9967), ('regressor__regressor__n_estimators', 393), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1197), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06048574530226919), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 240), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09839503492963116), ('regressor__regressor__max_depth', 7839), ('regressor__regressor__n_estimators', 474), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 353), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 384), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00224225048338329), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 485), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057960672025371834), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06209010685948583), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 1962), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05368026418495971), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005243191566869139), ('regressor__regressor__max_depth', 3871), ('regressor__regressor__n_estimators', 653), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034996655442758436), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014249018759709083), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03298106706391001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 255), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06356791817846508), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 176), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 386), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027516788930821975), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1081), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007896997673782765), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 527), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004231160373687155), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 779), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518378097192), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022101768739566994), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06449854041502759), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 82), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026441524220402263), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 1241), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09162216582089645), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06638413613262747), ('regressor__regressor__max_depth', 7126), ('regressor__regressor__n_estimators', 1975), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035830229184755716), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028183247153004812), ('regressor__regressor__max_depth', 8983), ('regressor__regressor__n_estimators', 164), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 72), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06562471170021157), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 220), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07743469230696515), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 75), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001349979001195419), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005478401038864678), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 930), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02611668842159466), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014478182740418903), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06110296145215738), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 690), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003974297544878959), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 923), ('regressor__regressor__n_jobs', -2)])


Filename: (ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Standard
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c004n02>
Subject: Job 233648: <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> was submitted from host <c021n03> by user <sdehgha2> in cluster <Hazel> at Fri Apr 18 02:29:55 2025
Job was executed on host(s) <8*c004n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Apr 18 18:09:06 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Apr 18 18:09:06 2025
Terminated at Sat Apr 19 02:44:46 2025
Results reported at Sat Apr 19 02:44:46 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "HBD3 MACCS cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   120934.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.87 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   30964 sec.
    Turnaround time :                            87291 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON -1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015780241340764528), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1023), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015201019174817662), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 423), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02624177521614131), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 422), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09258732256565452), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 1175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 120), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0485298338665768), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1042), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03313560446257025), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08174673371298112), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 67), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018076645913389692), ('regressor__regressor__max_depth', 603), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05023743348082711), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03259750245535606), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 136), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07710543107825665), ('regressor__regressor__max_depth', 7958), ('regressor__regressor__n_estimators', 67), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034769668589043685), ('regressor__regressor__max_depth', 2287), ('regressor__regressor__n_estimators', 1119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07799002078361497), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 65), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.059312006530561595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 98), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057086984700346115), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0710350144034648), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 72), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04958480243586312), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 756), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004539549056204168), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1757), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09939793013929618), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 84), ('regressor__regressor__n_jobs', -2)])



------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n12>
Subject: Job 372773: <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> was submitted from host <c200n05> by user <sdehgha2> in cluster <Hazel> at Tue Apr 22 10:01:58 2025
Job was executed on host(s) <6*c200n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Apr 22 10:02:00 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Apr 22 10:02:00 2025
Terminated at Tue Apr 22 12:03:07 2025
Results reported at Tue Apr 22 12:03:07 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "HBD3 MACCS cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   28942.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.51 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   7268 sec.
    Turnaround time :                            7269 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n12>
Subject: Job 496389: <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417> was submitted from host <c207n07> by user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:48:17 2025
Job was executed on host(s) <8*c207n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:48:22 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Apr 28 11:48:22 2025
Terminated at Mon Apr 28 11:51:49 2025
Results reported at Mon Apr 28 11:51:49 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_HBD3 MACCS cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "HBD3 MACCS cluster" 



------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   5.36 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   235 sec.
    Turnaround time :                            212 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_HBD3 MACCS cluster_20250417.err> for stderr output of this job.

