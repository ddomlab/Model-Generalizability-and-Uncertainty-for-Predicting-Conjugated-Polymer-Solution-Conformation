
------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n12>
Subject: Job 206526: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> was submitted from host <c202n11> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:18:18 2025
Job was executed on host(s) <4*c200n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:19:22 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:19:22 2025
Terminated at Thu Apr 17 17:19:36 2025
Results reported at Thu Apr 17 17:19:36 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   1.21 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   14 sec.
    Turnaround time :                            78 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n06>
Subject: Job 206743: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> was submitted from host <c202n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:23:37 2025
Job was executed on host(s) <4*c202n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:24:37 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:24:37 2025
Terminated at Thu Apr 17 17:28:44 2025
Results reported at Thu Apr 17 17:28:44 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   88.21 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   270 sec.
    Turnaround time :                            307 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n04>
Subject: Job 208356: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> was submitted from host <c200n06> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:51:48 2025
Job was executed on host(s) <4*c200n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 17:52:48 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 17:52:48 2025
Terminated at Thu Apr 17 17:53:15 2025
Results reported at Thu Apr 17 17:53:15 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   2.27 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   33 sec.
    Turnaround time :                            87 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err> for stderr output of this job.

Filename: (ECFP3.count.512-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_hypOFF_Standard_lc
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n02>
Subject: Job 209816: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> was submitted from host <c207n12> by user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:26:24 2025
Job was executed on host(s) <4*c023n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Apr 17 18:30:01 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Apr 17 18:30:01 2025
Terminated at Thu Apr 17 18:39:36 2025
Results reported at Thu Apr 17 18:39:36 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 4
#BSUB -W 5:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_learning_curve.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   564.02 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   578 sec.
    Turnaround time :                            792 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05456296665943283), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 502), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 99), ('regressor__regressor__n_estimators', 219), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012802562951779374), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1071), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04495708496722383), ('regressor__regressor__max_depth', 20), ('regressor__regressor__n_estimators', 1976), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08132169084074285), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.061645781727860366), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1066), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.024503281764836665), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1305), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.043146007712648246), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 133), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01680717824664625), ('regressor__regressor__max_depth', 8515), ('regressor__regressor__n_estimators', 232), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 153), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005120132255549926), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1272), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 65), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004453359944531702), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 924), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06133447742428803), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 794), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06497935369042435), ('regressor__regressor__max_depth', 22), ('regressor__regressor__n_estimators', 254), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09939793013929618), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00423829500094727), ('regressor__regressor__max_depth', 8980), ('regressor__regressor__n_estimators', 625), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 386), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.045970035084142935), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 174), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0942969584836029), ('regressor__regressor__max_depth', 6179), ('regressor__regressor__n_estimators', 366), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040085294150451194), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 600), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008880580624732523), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1315), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1359), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07318214628995287), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1252), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07745262735392605), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 1992), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07488492872705071), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 221), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.056933272168655256), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05337327818123036), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 282), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015522321670998039), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04897787555251706), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 965), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06663648399747653), ('regressor__regressor__max_depth', 17), ('regressor__regressor__n_estimators', 993), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03198334877824957), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1547), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.050178197424208315), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1059), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06767421553338765), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 142), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.029693018518887494), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 150), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 125), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03301580203477667), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 430), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022172376842709155), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01742278718175522), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07085551470850027), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1223), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09997403311331204), ('regressor__regressor__max_depth', 897), ('regressor__regressor__n_estimators', 263), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07181492146655581), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 441), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 73), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04516388105203668), ('regressor__regressor__max_depth', 21), ('regressor__regressor__n_estimators', 1249), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03314695489469912), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 413), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03855564718117928), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015782828764734722), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1473), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07386431494821726), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026577521271203827), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 246), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0029903619429966603), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010772414879038662), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 399), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0655487929557134), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 157), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03618946968938528), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 141), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03269392023528494), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 870), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030238086223115246), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 366), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 61), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06600191297636987), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 332), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057442456888728254), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1585), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1248), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02868658826861881), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 122), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.058508838497560035), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 287), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03693499023328491), ('regressor__regressor__max_depth', 28), ('regressor__regressor__n_estimators', 168), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 2



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0925883876990414), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 1175), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05292784742172536), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 87), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__max_depth', 2326), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0764849278940918), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 658), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 144), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0753199566786652), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1402), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06004263137157562), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 340), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007993779239489065), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1113), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01851091815803727), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07507154769236594), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1269), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09634310872554593), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 157), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025041499136197735), ('regressor__regressor__max_depth', 206), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07119234845535184), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 323), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06752698506398944), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 429), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.022852029837257568), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07109468954337901), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 59), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04848707664899251), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 757), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 165), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04389801687602887), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 543), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 72), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07331645576770805), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 440), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06847150929120425), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 155), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040081798054072325), ('regressor__regressor__max_depth', 4547), ('regressor__regressor__n_estimators', 340), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1411), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014044590250285796), ('regressor__regressor__max_depth', 16), ('regressor__regressor__n_estimators', 849), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005134979324498221), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06480138173146102), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1200), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0382409396626383), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 336), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 867), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06826556414440269), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 894), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OOD TEST ON 3



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 213), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008421057369642056), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1318), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05405283029189137), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 103), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02068166175819242), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 243), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03955290735180843), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06741955798572866), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007688688980251576), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 557), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06005353003025671), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 952), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03579795990094447), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 478), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07119142311726538), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 65), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07554960731291961), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 140), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05073633875053041), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07307234715084023), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06803466346183422), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1176), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036269167803041534), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 280), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003566206366522988), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09852929044079586), ('regressor__regressor__max_depth', 6799), ('regressor__regressor__n_estimators', 861), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003160655767063642), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1046), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06181736940533902), ('regressor__regressor__max_depth', 8024), ('regressor__regressor__n_estimators', 496), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06054211506722704), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09881824313473907), ('regressor__regressor__max_depth', 5423), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 318), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 381), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022426793687285126), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02293075553850106), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0025336680426949), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 1189), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011706306082980242), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 359), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03902584250434872), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 109), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002812891612482533), ('regressor__regressor__max_depth', 8510), ('regressor__regressor__n_estimators', 1245), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02908897228917533), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 387), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034824266632942906), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02210581401034014), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1202), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__max_depth', 2125), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.032035339688948304), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.029389948351675493), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003086786577402985), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1306), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008592298307093542), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0044782812874711595), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00826394461079099), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031061518492996078), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 252), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04233102476441256), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 696), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008841507250778171), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 334), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 158), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.061635438579833654), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036883359898655856), ('regressor__regressor__max_depth', 4779), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06263244299043501), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005419734705578945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 745), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04641978787060013), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0015450891536052543), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09012463346115321), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05244220890158476), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 254), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007521274684171438), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 358), ('regressor__regressor__n_jobs', -2)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005096467285945195), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026164491508259797), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 112), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001650968657079566), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1735), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06394149861588812), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 371), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006480422629316279), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 545), ('regressor__regressor__n_jobs', -2)])


Filename: (ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Standard
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n05>
Subject: Job 233654: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> in cluster <Hazel> Done

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> was submitted from host <c021n03> by user <sdehgha2> in cluster <Hazel> at Fri Apr 18 02:29:55 2025
Job was executed on host(s) <8*c203n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat Apr 19 07:44:43 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat Apr 19 07:44:43 2025
Terminated at Sat Apr 19 22:59:57 2025
Results reported at Sat Apr 19 22:59:57 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   220705.66 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.91 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   54940 sec.
    Turnaround time :                            160202 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n01>
Subject: Job 496395: <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> in cluster <Hazel> Exited

Job <XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417> was submitted from host <c207n07> by user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:48:20 2025
Job was executed on host(s) <8*c200n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Apr 28 11:51:49 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Apr 28 11:51:49 2025
Terminated at Mon Apr 28 11:52:01 2025
Results reported at Mon Apr 28 11:52:01 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Rg (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250417"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   4.98 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   24 sec.
    Turnaround time :                            221 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250417/XGBR_log Rg (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250417.err> for stderr output of this job.

