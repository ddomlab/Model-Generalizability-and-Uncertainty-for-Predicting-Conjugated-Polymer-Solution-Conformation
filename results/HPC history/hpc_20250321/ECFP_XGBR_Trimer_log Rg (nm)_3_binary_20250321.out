


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0024113907226996746), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 961), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008231907291836546), ('regressor__regressor__max_depth', 148), ('regressor__regressor__n_estimators', 175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0010100876402038682), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0030044432055519664), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1003), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018373490398805416), ('regressor__regressor__max_depth', 216), ('regressor__regressor__n_estimators', 1510), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06359610187798741), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 71), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0054961351617136365), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 853), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0447707722666728), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09984963351165313), ('regressor__regressor__max_depth', 6661), ('regressor__regressor__n_estimators', 423), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004660566900199063), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 755), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0037979233426242267), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1021), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02925395563705315), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 86), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0028520524866517457), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01609662655909613), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 178), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0056994238254731815), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 815), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 7574), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0012065069578280638), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0989721181450907), ('regressor__regressor__max_depth', 5813), ('regressor__regressor__n_estimators', 598), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 2798), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007537142642572274), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 485), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0023266590176560134), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1412), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.024350812493704875), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 167), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035977242854707374), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 136), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 742), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02027333939521729), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 213), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002390305552331574), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1481), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06119245862471386), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09938172047537026), ('regressor__regressor__max_depth', 22), ('regressor__regressor__n_estimators', 1013), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006683571962168213), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 337), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09910196369287054), ('regressor__regressor__max_depth', 2021), ('regressor__regressor__n_estimators', 100), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027067044285405163), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 137), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0020165217532515443), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01213783122385391), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 309), ('regressor__regressor__n_jobs', -2)])


Average scores:	 r: 0.48±0.12	 r2: 0.2±0.13
Filename: (ECFP3.binary.512)_XGBR_Standard
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c019n03>
Subject: Job 781579: <ECFP_XGBR_Trimer_log Rg (nm)_3_binary_20250321> in cluster <Hazel> Done

Job <ECFP_XGBR_Trimer_log Rg (nm)_3_binary_20250321> was submitted from host <c005n01> by user <sdehgha2> in cluster <Hazel> at Mon Apr  7 09:11:50 2025
Job was executed on host(s) <6*c019n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Apr  7 09:11:51 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Apr  7 09:11:51 2025
Terminated at Mon Apr  7 10:12:52 2025
Results reported at Mon Apr  7 10:12:52 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 30:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "ECFP_XGBR_Trimer_log Rg (nm)_3_binary_20250321"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250321/ECFP_XGBR_Trimer_log Rg (nm)_3_binary_20250321.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250321/ECFP_XGBR_Trimer_log Rg (nm)_3_binary_20250321.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py --target_features "log Rg (nm)"                                   --representation "ECFP"                                   --regressor_type "XGBR"                                   --oligomer_representation "Trimer"                                   --radius "3"                                   --vector "binary" 

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   11055.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             2.92 GB
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               4.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   3680 sec.
    Turnaround time :                            3662 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250321/ECFP_XGBR_Trimer_log Rg (nm)_3_binary_20250321.err> for stderr output of this job.

