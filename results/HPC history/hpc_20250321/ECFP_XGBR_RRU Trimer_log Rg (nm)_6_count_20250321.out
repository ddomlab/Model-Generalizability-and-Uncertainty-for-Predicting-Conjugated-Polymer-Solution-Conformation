


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03790946827495257), ('regressor__regressor__max_depth', 558), ('regressor__regressor__n_estimators', 51), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002851345347046383), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 641), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04144415119081405), ('regressor__regressor__max_depth', 1685), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0013425154878906565), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005286312871449168), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 538), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005009721213131051), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 680), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006077428327985459), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 484), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.036246335509838475), ('regressor__regressor__max_depth', 1784), ('regressor__regressor__n_estimators', 83), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017391485016234557), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 183), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0032986477087757274), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1066), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.059911270194018026), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 107), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026715078093594465), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 91), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0030295233591573828), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1379), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0020325252393098405), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06535674992413473), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05560794339240895), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02256825001011882), ('regressor__regressor__max_depth', 522), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010577413380542865), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 534), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00624320756857731), ('regressor__regressor__max_depth', 9967), ('regressor__regressor__n_estimators', 989), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002346344821291157), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1389), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0172842129922489), ('regressor__regressor__max_depth', 8154), ('regressor__regressor__n_estimators', 265), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09905002184460181), ('regressor__regressor__max_depth', 4770), ('regressor__regressor__n_estimators', 59), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00789686165945836), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 476), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03496101199836055), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03194664380574536), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 109), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007438040115508347), ('regressor__regressor__max_depth', 32), ('regressor__regressor__n_estimators', 326), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0028218835779476367), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1404), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002109323408597636), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.018596608299181056), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 179), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03434717693977727), ('regressor__regressor__max_depth', 20), ('regressor__regressor__n_estimators', 87), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004883277495112191), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 666), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0049123819885996955), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 927), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])


Average scores:	 r: 0.48±0.12	 r2: 0.2±0.13
Filename: (ECFP6.count.4096)_XGBR_Standard
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n02>
Subject: Job 741689: <ECFP_XGBR_RRU Trimer_log Rg (nm)_6_count_20250321> in cluster <Hazel> Done

Job <ECFP_XGBR_RRU Trimer_log Rg (nm)_6_count_20250321> was submitted from host <c038n03> by user <sdehgha2> in cluster <Hazel> at Sat Apr  5 16:01:44 2025
Job was executed on host(s) <6*c201n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat Apr  5 20:23:03 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat Apr  5 20:23:03 2025
Terminated at Sun Apr  6 02:53:21 2025
Results reported at Sun Apr  6 02:53:21 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 30:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "ECFP_XGBR_RRU Trimer_log Rg (nm)_6_count_20250321"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250321/ECFP_XGBR_RRU Trimer_log Rg (nm)_6_count_20250321.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250321/ECFP_XGBR_RRU Trimer_log Rg (nm)_6_count_20250321.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py --target_features "log Rg (nm)"                                   --representation "ECFP"                                   --regressor_type "XGBR"                                   --oligomer_representation "RRU Trimer"                                   --radius "6"                                   --vector "count" 

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   107837.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.72 GB
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               4.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   23418 sec.
    Turnaround time :                            39097 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250321/ECFP_XGBR_RRU Trimer_log Rg (nm)_6_count_20250321.err> for stderr output of this job.

