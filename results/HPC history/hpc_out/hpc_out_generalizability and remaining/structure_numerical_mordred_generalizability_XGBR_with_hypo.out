polymer representation: RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
polymer representation: RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
polymer representation: RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
polymer representation: Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
polymer representation: Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
polymer representation: Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018477615885138378), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 615), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0024228024617774188), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 461), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02086656645169091), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 53), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002433674591893196), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 458), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017126471380593825), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 67), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019012372808588238), ('regressor__regressor__max_depth', 1912), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019030089195516044), ('regressor__regressor__max_depth', 1909), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01901891250040198), ('regressor__regressor__max_depth', 1914), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019406123961483245), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003172060456947136), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 324), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014630650415646108), ('regressor__regressor__max_depth', 36), ('regressor__regressor__n_estimators', 193), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0019017192150021303), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 221), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002213241823188217), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 964), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016620699198080975), ('regressor__regressor__max_depth', 889), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.033819657555193124), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 61), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0015142910976516347), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1049), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04704380920774926), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.009639708415587764), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 383), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 9541), ('regressor__regressor__n_estimators', 236), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.031185832391321836), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 112), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008817881477741348), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 121), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0013555564790294558), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1055), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0692196227616104), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015121951943601417), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 80), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.060047062958984196), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004647985927451744), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 312), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03155545436991884), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02174844243936578), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05475211878854835), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0034909470148655024), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1097), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01240706162843621), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006927114513976712), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 146), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006666297530720521), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 325), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04905836645087207), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 59), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026002525099610124), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 96), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.032165864201428425), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 97), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004075204295105206), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 303), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006555615838338001), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 504), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010232285773184517), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006106704304557553), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 550), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025121115158077655), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 128), ('regressor__regressor__n_jobs', -2)])


Trimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c014n02>
Subject: Job 856564: <structure_numerical_mordred_NGB_generalizibility_with_hypo> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility_with_hypo> was submitted from host <c022n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:37 2024
Job was executed on host(s) <4*c014n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:18:18 2024
                            <4*c019n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:18:18 2024
Terminated at Wed Oct 23 15:49:40 2024
Results reported at Wed Oct 23 15:49:40 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility_with_hypo"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type XGBR --target "Rg1 (nm)" --oligo_type "Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   36739.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             4.18 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               58.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   12699 sec.
    Turnaround time :                            12723 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01430529118455623), ('regressor__regressor__max_depth', 20), ('regressor__regressor__n_estimators', 79), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019072281174117627), ('regressor__regressor__max_depth', 1904), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008540185281656983), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 270), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002603842840978718), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 392), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010270362938541056), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 256), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0025988842127393445), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 163), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022144938375607435), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 962), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022453036608347555), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1547), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.021396505042840134), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 97), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014850622702072358), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1060), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.023220759406062788), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030340774542420006), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 130), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03249104530636686), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00783660766345155), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 393), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1066), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0019712461999166994), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 713), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06749703097328429), ('regressor__regressor__max_depth', 468), ('regressor__regressor__n_estimators', 1230), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015147879514261818), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 80), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01925381696724183), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 158), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006486184023173054), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 222), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0035428807151259806), ('regressor__regressor__max_depth', 1781), ('regressor__regressor__n_estimators', 462), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005330687259365276), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 184), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05326344736142681), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005179973338393859), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 753), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012330203256152496), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 118), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014327589132414357), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 69), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0064032458994905984), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05149511600840251), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 59), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04098492721571369), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 57), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006324591116217399), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 461), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004055284976921472), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 304), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09386253595756698), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018636892683183879), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005947921235979719), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 573), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016666829238873877), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])


Monomer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c022n01>
Subject: Job 856562: <structure_numerical_mordred_NGB_generalizibility_with_hypo> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility_with_hypo> was submitted from host <c022n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:30 2024
Job was executed on host(s) <4*c022n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:54 2024
                            <4*c020n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:17:54 2024
Terminated at Wed Oct 23 15:54:11 2024
Results reported at Wed Oct 23 15:54:11 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility_with_hypo"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type XGBR --target "Rg1 (nm)" --oligo_type "Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   37595.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             4.14 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               58.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   12977 sec.
    Turnaround time :                            13001 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014574007602898447), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1625), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0024852428080755127), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 405), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014630650415646108), ('regressor__regressor__max_depth', 36), ('regressor__regressor__n_estimators', 193), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002773624242228381), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 153), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0409156905846737), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011514811577243881), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 273), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026736085985076527), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 79), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0031002705818281985), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 510), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.029380287142759306), ('regressor__regressor__max_depth', 6578), ('regressor__regressor__n_estimators', 91), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027486636501129258), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 137), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 186), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0015519052911467995), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014474237476909105), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 73), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1469), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06831821865723577), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 120), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014999420668426832), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 80), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02913047667584373), ('regressor__regressor__max_depth', 8958), ('regressor__regressor__n_estimators', 102), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0035116832740584216), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 408), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0021199201537878067), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 755), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.021732371137643713), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05318041882828061), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006635702201871247), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 560), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01239961175344567), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006928103326652361), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 146), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007247866681953102), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 300), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05128494870038974), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026625296785097938), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 95), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0067187567051895805), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 438), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004083411220888904), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 303), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010597024364775854), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 311), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02374832291448954), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 157), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0057483804384099255), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 600), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025074214867489602), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 129), ('regressor__regressor__n_jobs', -2)])


Dimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c027n04>
Subject: Job 856563: <structure_numerical_mordred_NGB_generalizibility_with_hypo> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility_with_hypo> was submitted from host <c022n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:34 2024
Job was executed on host(s) <4*c027n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:56 2024
                            <4*c030n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:17:56 2024
Terminated at Wed Oct 23 16:19:10 2024
Results reported at Wed Oct 23 16:19:10 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility_with_hypo"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type XGBR --target "Rg1 (nm)" --oligo_type "Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   45576.21 sec.
    Max Memory :                                 6 GB
    Average Memory :                             4.53 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               58.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   14489 sec.
    Turnaround time :                            14496 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005698760075980067), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 422), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017745305888533118), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010161426675310765), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 259), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0025785738405661334), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 167), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002213693658085017), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 958), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06711494329093452), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02711385805650875), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 78), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1572), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017145838038053692), ('regressor__regressor__max_depth', 2119), ('regressor__regressor__n_estimators', 188), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005058656830430296), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 724), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0439805943177111), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1564), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.022884770110433408), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 129), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.016977281453446978), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 62), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0013403571950495832), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1106), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09959821624674509), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015175084351225079), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 80), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019257608917241244), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 158), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00462623159058237), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 313), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0035428807151259806), ('regressor__regressor__max_depth', 1781), ('regressor__regressor__n_estimators', 462), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019338142945868917), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05322368457154741), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0018091615546582606), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012259226196711645), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 120), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004863140631508795), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 206), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006483337990771034), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 327), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0639781210238089), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.026493319451183977), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 94), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034264211364826554), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 92), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004052602633043923), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 305), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015703340727750034), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 229), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007447303397508388), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 444), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016661489841611503), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])


RRU Monomer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c022n03>
Subject: Job 856565: <structure_numerical_mordred_NGB_generalizibility_with_hypo> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility_with_hypo> was submitted from host <c022n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:43 2024
Job was executed on host(s) <4*c022n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:20:55 2024
                            <4*c017n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:20:55 2024
Terminated at Wed Oct 23 17:45:30 2024
Results reported at Wed Oct 23 17:45:30 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility_with_hypo"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type XGBR --target "Rg1 (nm)" --oligo_type "RRU Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   72126.00 sec.
    Max Memory :                                 7 GB
    Average Memory :                             5.73 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               57.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   19479 sec.
    Turnaround time :                            19667 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019015234486709012), ('regressor__regressor__max_depth', 1913), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004381464514571615), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 555), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01703711142141521), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 58), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05671516338520522), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004186167876216837), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 101), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040784854057874805), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0035223470862579577), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 851), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0272389786833969), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 78), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014945663047756486), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1051), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02410395528126499), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 113), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0017861007088111624), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04896903246053012), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1053), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04123483619265488), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 82), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014462439557500787), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 73), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004259540832569038), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 346), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06016739554335091), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 697), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0236989752438689), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012057969963355451), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 246), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00427778424567497), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 335), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0035428807151259806), ('regressor__regressor__max_depth', 1781), ('regressor__regressor__n_estimators', 462), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0024263613662962084), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 425), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05066534547748341), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02477461812364624), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 153), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012387417953010937), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005061754324556416), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 202), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006933139512695659), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 306), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05131346503075505), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 59), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040881568845424286), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 57), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005505701534244786), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 548), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001514579334370685), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 853), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0017072214294163314), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03282025857068679), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006146663074459662), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 546), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025390283379234862), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__n_jobs', -2)])


RRU Dimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n12>
Subject: Job 856566: <structure_numerical_mordred_NGB_generalizibility_with_hypo> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility_with_hypo> was submitted from host <c022n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:48 2024
Job was executed on host(s) <4*c207n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:21:06 2024
                            <4*c207n11>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:21:06 2024
Terminated at Wed Oct 23 20:23:36 2024
Results reported at Wed Oct 23 20:23:36 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility_with_hypo"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type XGBR --target "Rg1 (nm)" --oligo_type "RRU Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   99597.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.70 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               59.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   28951 sec.
    Turnaround time :                            29148 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019000815525123827), ('regressor__regressor__max_depth', 1916), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017303431620072637), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 124), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002637089826955851), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 388), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05663096661048638), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002299288604701191), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 185), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04072874625217428), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0020132798865771114), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1457), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027247325506463384), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 78), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0015082638399830466), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1048), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04047250573721932), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 73), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027665857694957895), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 138), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08146216961026964), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0388633317860296), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 79), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017177452535583754), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 61), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 1445), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06523941902391797), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 218), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015122874236666093), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 80), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.037383771156723734), ('regressor__regressor__max_depth', 7025), ('regressor__regressor__n_estimators', 77), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003928248846205098), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 370), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0035428807151259806), ('regressor__regressor__max_depth', 1781), ('regressor__regressor__n_estimators', 462), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00368301660649039), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 290), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05466307382244895), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0032141325252137316), ('regressor__regressor__max_depth', 3663), ('regressor__regressor__n_estimators', 1190), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012467348926447205), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 116), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014836083597693887), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 68), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006812782622859905), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 340), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0639486051499749), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015905747212626456), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 164), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002377187058782611), ('regressor__regressor__max_depth', 5355), ('regressor__regressor__n_estimators', 1334), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014834160552610013), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 840), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02570707191646482), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 134), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004347274243198239), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 922), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005669276030601177), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 606), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027252986818078237), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 120), ('regressor__regressor__n_jobs', -2)])


RRU Trimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_XGBR_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n09>
Subject: Job 856567: <structure_numerical_mordred_NGB_generalizibility_with_hypo> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility_with_hypo> was submitted from host <c022n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:17:53 2024
Job was executed on host(s) <4*c201n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:21:55 2024
                            <4*c201n11>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:21:55 2024
Terminated at Wed Oct 23 20:47:04 2024
Results reported at Wed Oct 23 20:47:04 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility_with_hypo"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type XGBR --target "Rg1 (nm)" --oligo_type "RRU Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   102248.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.40 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               59.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   30339 sec.
    Turnaround time :                            30551 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_XGBR_with_hypo.err> for stderr output of this job.

