polymer representation: RRU Dimer
polymer representation: Trimer
polymer representation: RRU Monomer
polymer representation: RRU Trimer
Trimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3355 val_loss=0.0000 scale=2.0000 norm=1.0259
[iter 200] loss=-0.3004 val_loss=0.0000 scale=2.0000 norm=0.8869
[iter 300] loss=-0.6963 val_loss=0.0000 scale=2.0000 norm=0.8296
[iter 400] loss=-0.9926 val_loss=0.0000 scale=1.0000 norm=0.4031
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2593 val_loss=0.0000 scale=2.0000 norm=1.0020
[iter 200] loss=-0.4175 val_loss=0.0000 scale=1.0000 norm=0.4292
[iter 300] loss=-0.8701 val_loss=0.0000 scale=2.0000 norm=0.7744
[iter 400] loss=-1.2019 val_loss=0.0000 scale=2.0000 norm=0.7484
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3148 val_loss=0.0000 scale=2.0000 norm=1.0245
[iter 200] loss=-0.2832 val_loss=0.0000 scale=1.0000 norm=0.4458
[iter 300] loss=-0.6422 val_loss=0.0000 scale=1.0000 norm=0.4059
[iter 400] loss=-0.8903 val_loss=0.0000 scale=0.5000 norm=0.1982
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3485 val_loss=0.0000 scale=2.0000 norm=0.9975
[iter 200] loss=-0.5725 val_loss=0.0000 scale=2.0000 norm=0.9273
[iter 300] loss=-1.4290 val_loss=0.0000 scale=2.0000 norm=0.8650
[iter 400] loss=-2.1575 val_loss=0.0000 scale=2.0000 norm=0.7766
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3277 val_loss=0.0000 scale=2.0000 norm=0.9712
[iter 200] loss=-0.6487 val_loss=0.0000 scale=2.0000 norm=0.9701
[iter 300] loss=-1.6413 val_loss=0.0000 scale=2.0000 norm=0.9804
[iter 400] loss=-2.7547 val_loss=0.0000 scale=2.0000 norm=0.9743
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6675 val_loss=0.0000 scale=2.0000 norm=1.1429
[iter 200] loss=-0.1093 val_loss=0.0000 scale=2.0000 norm=0.9110
[iter 300] loss=-0.6482 val_loss=0.0000 scale=2.0000 norm=0.8382
[iter 400] loss=-1.1159 val_loss=0.0000 scale=2.0000 norm=0.7768
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2519 val_loss=0.0000 scale=2.0000 norm=0.9951
[iter 200] loss=-0.4887 val_loss=0.0000 scale=2.0000 norm=0.8681
[iter 300] loss=-1.1734 val_loss=0.0000 scale=2.0000 norm=0.7688
[iter 400] loss=-1.5363 val_loss=0.0000 scale=1.0000 norm=0.3489
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3638 val_loss=0.0000 scale=2.0000 norm=1.0393
[iter 200] loss=-0.2516 val_loss=0.0000 scale=2.0000 norm=0.8923
[iter 300] loss=-0.6607 val_loss=0.0000 scale=1.0000 norm=0.4153
[iter 400] loss=-0.9043 val_loss=0.0000 scale=2.0000 norm=0.8077
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1722 val_loss=0.0000 scale=2.0000 norm=0.9692
[iter 200] loss=-0.7254 val_loss=0.0000 scale=2.0000 norm=0.9096
[iter 300] loss=-1.5356 val_loss=0.0000 scale=2.0000 norm=0.8084
[iter 400] loss=-2.1896 val_loss=0.0000 scale=2.0000 norm=0.7521
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2644 val_loss=0.0000 scale=2.0000 norm=1.0167
[iter 200] loss=-0.3205 val_loss=0.0000 scale=1.0000 norm=0.4526
[iter 300] loss=-0.7254 val_loss=0.0000 scale=2.0000 norm=0.8339
[iter 400] loss=-1.0322 val_loss=0.0000 scale=2.0000 norm=0.8052
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3526 val_loss=0.0000 scale=2.0000 norm=1.0301
[iter 200] loss=-0.1933 val_loss=0.0000 scale=1.0000 norm=0.4464
[iter 300] loss=-0.5829 val_loss=0.0000 scale=1.0000 norm=0.4202
[iter 400] loss=-0.8653 val_loss=0.0000 scale=0.5000 norm=0.1982
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4817 val_loss=0.0000 scale=1.0000 norm=0.5395
[iter 200] loss=-0.1351 val_loss=0.0000 scale=2.0000 norm=0.9334
[iter 300] loss=-0.6247 val_loss=0.0000 scale=1.0000 norm=0.4253
[iter 400] loss=-0.9419 val_loss=0.0000 scale=1.0000 norm=0.3958
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2118 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 200] loss=-0.5527 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 300] loss=-1.1202 val_loss=0.0000 scale=2.0000 norm=0.7649
[iter 400] loss=-1.5023 val_loss=0.0000 scale=2.0000 norm=0.7123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1021 val_loss=0.0000 scale=2.0000 norm=0.9845
[iter 200] loss=-0.8019 val_loss=0.0000 scale=2.0000 norm=0.9131
[iter 300] loss=-1.6674 val_loss=0.0000 scale=2.0000 norm=0.8688
[iter 400] loss=-2.4453 val_loss=0.0000 scale=2.0000 norm=0.8381
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3638 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2901 val_loss=0.0000 scale=2.0000 norm=0.8703
[iter 300] loss=-0.7098 val_loss=0.0000 scale=1.0000 norm=0.4021
[iter 400] loss=-0.9871 val_loss=0.0000 scale=2.0000 norm=0.7780
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2766 val_loss=0.0000 scale=2.0000 norm=1.0067
[iter 200] loss=-0.3454 val_loss=0.0000 scale=2.0000 norm=0.8778
[iter 300] loss=-0.7433 val_loss=0.0000 scale=1.0000 norm=0.4073
[iter 400] loss=-0.9754 val_loss=0.0000 scale=1.0000 norm=0.4002
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2891 val_loss=0.0000 scale=1.0000 norm=0.5123
[iter 200] loss=-0.2770 val_loss=0.0000 scale=1.0000 norm=0.4541
[iter 300] loss=-0.7251 val_loss=0.0000 scale=1.0000 norm=0.4206
[iter 400] loss=-1.0648 val_loss=0.0000 scale=1.0000 norm=0.3964
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2667 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-0.4685 val_loss=0.0000 scale=2.0000 norm=0.8875
[iter 300] loss=-0.9352 val_loss=0.0000 scale=2.0000 norm=0.8161
[iter 400] loss=-1.2515 val_loss=0.0000 scale=1.0000 norm=0.3836
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6171 val_loss=0.0000 scale=1.0000 norm=0.5758
[iter 200] loss=0.0137 val_loss=0.0000 scale=1.0000 norm=0.4769
[iter 300] loss=-0.6407 val_loss=0.0000 scale=2.0000 norm=0.8245
[iter 400] loss=-1.2117 val_loss=0.0000 scale=1.0000 norm=0.3725
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2818 val_loss=0.0000 scale=2.0000 norm=1.0063
[iter 200] loss=-0.3105 val_loss=0.0000 scale=2.0000 norm=0.8785
[iter 300] loss=-0.7621 val_loss=0.0000 scale=2.0000 norm=0.8103
[iter 400] loss=-1.0600 val_loss=0.0000 scale=0.5000 norm=0.1916
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2518 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 200] loss=-0.3770 val_loss=0.0000 scale=2.0000 norm=0.9001
[iter 300] loss=-0.7974 val_loss=0.0000 scale=1.0000 norm=0.4190
[iter 400] loss=-1.0541 val_loss=0.0000 scale=1.0000 norm=0.4026
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3421 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 200] loss=-0.2623 val_loss=0.0000 scale=1.0000 norm=0.4452
[iter 300] loss=-0.6685 val_loss=0.0000 scale=1.0000 norm=0.4154
[iter 400] loss=-0.9371 val_loss=0.0000 scale=0.5000 norm=0.2045
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2475 val_loss=0.0000 scale=2.0000 norm=0.9810
[iter 200] loss=-0.6666 val_loss=0.0000 scale=2.0000 norm=0.9181
[iter 300] loss=-1.4968 val_loss=0.0000 scale=2.0000 norm=0.8551
[iter 400] loss=-2.1652 val_loss=0.0000 scale=2.0000 norm=0.7758
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1018 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.8851 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 300] loss=-2.2926 val_loss=0.0000 scale=4.0000 norm=1.9800
[iter 400] loss=-4.1853 val_loss=0.0000 scale=2.0000 norm=0.9843
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2921 val_loss=0.0000 scale=2.0000 norm=1.0078
[iter 200] loss=-0.2804 val_loss=0.0000 scale=2.0000 norm=0.8810
[iter 300] loss=-0.6723 val_loss=0.0000 scale=2.0000 norm=0.8003
[iter 400] loss=-0.9258 val_loss=0.0000 scale=1.0000 norm=0.3777
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2690 val_loss=0.0000 scale=2.0000 norm=1.0009
[iter 200] loss=-0.3222 val_loss=0.0000 scale=1.0000 norm=0.4427
[iter 300] loss=-0.6908 val_loss=0.0000 scale=1.0000 norm=0.4071
[iter 400] loss=-1.0004 val_loss=0.0000 scale=2.0000 norm=0.7497
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4332 val_loss=0.0000 scale=2.0000 norm=1.0634
[iter 200] loss=-0.2074 val_loss=0.0000 scale=1.0000 norm=0.4559
[iter 300] loss=-0.6739 val_loss=0.0000 scale=2.0000 norm=0.8174
[iter 400] loss=-1.0199 val_loss=0.0000 scale=2.0000 norm=0.7680
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2110 val_loss=0.0000 scale=2.0000 norm=0.9674
[iter 200] loss=-0.6982 val_loss=0.0000 scale=2.0000 norm=0.9097
[iter 300] loss=-1.5274 val_loss=0.0000 scale=2.0000 norm=0.8257
[iter 400] loss=-2.2516 val_loss=0.0000 scale=2.0000 norm=0.7433
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5405 val_loss=0.0000 scale=2.0000 norm=1.1270
[iter 200] loss=-0.0986 val_loss=0.0000 scale=1.0000 norm=0.4831
[iter 300] loss=-0.5652 val_loss=0.0000 scale=1.0000 norm=0.4424
[iter 400] loss=-0.9340 val_loss=0.0000 scale=1.0000 norm=0.4159
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3062 val_loss=0.0000 scale=1.0000 norm=0.5089
[iter 200] loss=-0.2252 val_loss=0.0000 scale=1.0000 norm=0.4467
[iter 300] loss=-0.6260 val_loss=0.0000 scale=2.0000 norm=0.8346
[iter 400] loss=-0.9085 val_loss=0.0000 scale=2.0000 norm=0.8044
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2390 val_loss=0.0000 scale=2.0000 norm=0.9928
[iter 200] loss=-0.4664 val_loss=0.0000 scale=1.0000 norm=0.4377
[iter 300] loss=-0.8640 val_loss=0.0000 scale=1.0000 norm=0.4118
[iter 400] loss=-1.1155 val_loss=0.0000 scale=1.0000 norm=0.3816
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3123 val_loss=0.0000 scale=2.0000 norm=1.0243
[iter 200] loss=-0.2469 val_loss=0.0000 scale=1.0000 norm=0.4486
[iter 300] loss=-0.6031 val_loss=0.0000 scale=1.0000 norm=0.4099
[iter 400] loss=-0.8552 val_loss=0.0000 scale=1.0000 norm=0.3930
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6482 val_loss=0.0000 scale=2.0000 norm=1.1646
[iter 200] loss=0.1506 val_loss=0.0000 scale=2.0000 norm=0.9648
[iter 300] loss=-0.2759 val_loss=0.0000 scale=1.0000 norm=0.4392
[iter 400] loss=-0.6147 val_loss=0.0000 scale=1.0000 norm=0.4123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2949 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 200] loss=-0.3390 val_loss=0.0000 scale=2.0000 norm=0.8998
[iter 300] loss=-0.7994 val_loss=0.0000 scale=2.0000 norm=0.8363
[iter 400] loss=-1.1680 val_loss=0.0000 scale=1.0000 norm=0.3973
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2742 val_loss=0.0000 scale=2.0000 norm=0.9959
[iter 200] loss=-0.2899 val_loss=0.0000 scale=2.0000 norm=0.8971
[iter 300] loss=-0.7763 val_loss=0.0000 scale=1.0000 norm=0.4135
[iter 400] loss=-1.1249 val_loss=0.0000 scale=1.0000 norm=0.3981
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2060 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 200] loss=-0.7315 val_loss=0.0000 scale=2.0000 norm=0.9443
[iter 300] loss=-1.6778 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 400] loss=-2.6070 val_loss=0.0000 scale=2.0000 norm=0.9356
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3857 val_loss=0.0000 scale=2.0000 norm=1.0347
[iter 200] loss=-0.1482 val_loss=0.0000 scale=1.0000 norm=0.4548
[iter 300] loss=-0.4571 val_loss=0.0000 scale=1.0000 norm=0.4248
[iter 400] loss=-0.7018 val_loss=0.0000 scale=1.0000 norm=0.4130
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2499 val_loss=0.0000 scale=2.0000 norm=0.9980
[iter 200] loss=-0.3823 val_loss=0.0000 scale=2.0000 norm=0.8744
[iter 300] loss=-0.8026 val_loss=0.0000 scale=1.0000 norm=0.4062
[iter 400] loss=-1.0933 val_loss=0.0000 scale=1.0000 norm=0.3921
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5205 val_loss=0.0000 scale=2.0000 norm=1.1258
[iter 200] loss=0.0582 val_loss=0.0000 scale=1.0000 norm=0.4895
[iter 300] loss=-0.2484 val_loss=0.0000 scale=1.0000 norm=0.4461
[iter 400] loss=-0.4855 val_loss=0.0000 scale=0.5000 norm=0.2090
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2697 val_loss=0.0000 scale=2.0000 norm=0.9969
[iter 200] loss=-0.6790 val_loss=0.0000 scale=2.0000 norm=0.9503
[iter 300] loss=-1.6257 val_loss=0.0000 scale=2.0000 norm=0.9456
[iter 400] loss=-2.5624 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3361 val_loss=0.0000 scale=1.0000 norm=0.5078
[iter 200] loss=-0.3380 val_loss=0.0000 scale=2.0000 norm=0.8716
[iter 300] loss=-0.7261 val_loss=0.0000 scale=1.0000 norm=0.4086
[iter 400] loss=-0.9976 val_loss=0.0000 scale=1.0000 norm=0.3952
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2410 val_loss=0.0000 scale=2.0000 norm=0.9960
[iter 200] loss=-0.4427 val_loss=0.0000 scale=1.0000 norm=0.4289
[iter 300] loss=-0.8778 val_loss=0.0000 scale=2.0000 norm=0.7859
[iter 400] loss=-1.1411 val_loss=0.0000 scale=1.0000 norm=0.3743
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3007 val_loss=0.0000 scale=2.0000 norm=1.0256
[iter 200] loss=-0.3512 val_loss=0.0000 scale=2.0000 norm=0.8937
[iter 300] loss=-1.0230 val_loss=0.0000 scale=2.0000 norm=0.7575
[iter 400] loss=-1.4706 val_loss=0.0000 scale=1.0000 norm=0.3285
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1888 val_loss=0.0000 scale=2.0000 norm=1.0003
[iter 200] loss=-0.5416 val_loss=0.0000 scale=2.0000 norm=0.8678
[iter 300] loss=-1.0271 val_loss=0.0000 scale=1.0000 norm=0.3893
[iter 400] loss=-1.3452 val_loss=0.0000 scale=0.5000 norm=0.1838
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1752 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.8281 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-2.7237 val_loss=0.0000 scale=4.0000 norm=1.9876
[iter 400] loss=-4.5911 val_loss=0.0000 scale=2.0000 norm=0.9841
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1477 val_loss=0.0000 scale=2.0000 norm=0.9742
[iter 200] loss=-0.7397 val_loss=0.0000 scale=2.0000 norm=0.9034
[iter 300] loss=-1.5738 val_loss=0.0000 scale=2.0000 norm=0.8439
[iter 400] loss=-2.3407 val_loss=0.0000 scale=2.0000 norm=0.7852
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3687 val_loss=0.0000 scale=2.0000 norm=1.0445
[iter 200] loss=-0.2213 val_loss=0.0000 scale=2.0000 norm=0.8985
[iter 300] loss=-0.7045 val_loss=0.0000 scale=2.0000 norm=0.8134
[iter 400] loss=-1.0515 val_loss=0.0000 scale=1.0000 norm=0.3671
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5432 val_loss=0.0000 scale=2.0000 norm=1.0808
[iter 200] loss=-0.1569 val_loss=0.0000 scale=2.0000 norm=0.9210
[iter 300] loss=-0.6904 val_loss=0.0000 scale=2.0000 norm=0.8269
[iter 400] loss=-1.1557 val_loss=0.0000 scale=1.0000 norm=0.3676
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2751 val_loss=0.0000 scale=2.0000 norm=1.0154
[iter 200] loss=-0.2988 val_loss=0.0000 scale=2.0000 norm=0.8978
[iter 300] loss=-0.6687 val_loss=0.0000 scale=1.0000 norm=0.4147
[iter 400] loss=-0.9643 val_loss=0.0000 scale=1.0000 norm=0.3886
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3167 val_loss=0.0000 scale=2.0000 norm=1.0377
[iter 200] loss=-0.2452 val_loss=0.0000 scale=1.0000 norm=0.4610
[iter 300] loss=-0.6284 val_loss=0.0000 scale=1.0000 norm=0.4190
[iter 400] loss=-0.9003 val_loss=0.0000 scale=1.0000 norm=0.3922
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3344 val_loss=0.0000 scale=2.0000 norm=1.0487
[iter 200] loss=-0.0816 val_loss=0.0000 scale=1.0000 norm=0.4790
[iter 300] loss=-0.4634 val_loss=0.0000 scale=1.0000 norm=0.4533
[iter 400] loss=-0.7382 val_loss=0.0000 scale=1.0000 norm=0.4417
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4321 val_loss=0.0000 scale=1.0000 norm=0.5404
[iter 200] loss=-0.0435 val_loss=0.0000 scale=1.0000 norm=0.4739
[iter 300] loss=-0.4258 val_loss=0.0000 scale=1.0000 norm=0.4452
[iter 400] loss=-0.7369 val_loss=0.0000 scale=1.0000 norm=0.4185
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2760 val_loss=0.0000 scale=1.0000 norm=0.5050
[iter 200] loss=-0.3998 val_loss=0.0000 scale=1.0000 norm=0.4439
[iter 300] loss=-0.8108 val_loss=0.0000 scale=1.0000 norm=0.4102
[iter 400] loss=-1.1131 val_loss=0.0000 scale=1.0000 norm=0.3881
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4141 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 200] loss=-0.1696 val_loss=0.0000 scale=2.0000 norm=0.9243
[iter 300] loss=-0.5846 val_loss=0.0000 scale=1.0000 norm=0.4260
[iter 400] loss=-0.8958 val_loss=0.0000 scale=1.0000 norm=0.4036
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3986 val_loss=0.0000 scale=2.0000 norm=1.0402
[iter 200] loss=-0.1801 val_loss=0.0000 scale=2.0000 norm=0.9217
[iter 300] loss=-0.5814 val_loss=0.0000 scale=1.0000 norm=0.4223
[iter 400] loss=-0.8843 val_loss=0.0000 scale=1.0000 norm=0.3948
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2863 val_loss=0.0000 scale=2.0000 norm=1.0074
[iter 200] loss=-0.3540 val_loss=0.0000 scale=2.0000 norm=0.8827
[iter 300] loss=-0.7461 val_loss=0.0000 scale=1.0000 norm=0.3977
[iter 400] loss=-0.9996 val_loss=0.0000 scale=1.0000 norm=0.3811
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3990 val_loss=0.0000 scale=2.0000 norm=1.0153
[iter 200] loss=-0.5452 val_loss=0.0000 scale=2.0000 norm=0.9433
[iter 300] loss=-1.4905 val_loss=0.0000 scale=2.0000 norm=0.9462
[iter 400] loss=-2.4352 val_loss=0.0000 scale=2.0000 norm=0.9405
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2703 val_loss=0.0000 scale=2.0000 norm=1.0109
[iter 200] loss=-0.3807 val_loss=0.0000 scale=2.0000 norm=0.8770
[iter 300] loss=-0.7933 val_loss=0.0000 scale=1.0000 norm=0.4019
[iter 400] loss=-1.1268 val_loss=0.0000 scale=1.0000 norm=0.3844
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3312 val_loss=0.0000 scale=1.0000 norm=0.5142
[iter 200] loss=-0.3155 val_loss=0.0000 scale=1.0000 norm=0.4416
[iter 300] loss=-0.7089 val_loss=0.0000 scale=1.0000 norm=0.4075
[iter 400] loss=-1.0404 val_loss=0.0000 scale=1.0000 norm=0.3836
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1885 val_loss=0.0000 scale=2.0000 norm=0.9847
[iter 200] loss=-0.6922 val_loss=0.0000 scale=2.0000 norm=0.8996
[iter 300] loss=-1.4856 val_loss=0.0000 scale=2.0000 norm=0.7976
[iter 400] loss=-2.0481 val_loss=0.0000 scale=1.0000 norm=0.3290
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3768 val_loss=0.0000 scale=1.0000 norm=0.5108
[iter 200] loss=-0.1084 val_loss=0.0000 scale=2.0000 norm=0.8950
[iter 300] loss=-0.4466 val_loss=0.0000 scale=1.0000 norm=0.4147
[iter 400] loss=-0.7705 val_loss=0.0000 scale=1.0000 norm=0.3716
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3014 val_loss=0.0000 scale=2.0000 norm=1.0363
[iter 200] loss=-0.1774 val_loss=0.0000 scale=1.0000 norm=0.4676
[iter 300] loss=-0.5905 val_loss=0.0000 scale=1.0000 norm=0.4423
[iter 400] loss=-0.8888 val_loss=0.0000 scale=1.0000 norm=0.4207
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2661 val_loss=0.0000 scale=2.0000 norm=1.0065
[iter 200] loss=-0.3073 val_loss=0.0000 scale=1.0000 norm=0.4512
[iter 300] loss=-0.7064 val_loss=0.0000 scale=1.0000 norm=0.4200
[iter 400] loss=-0.9982 val_loss=0.0000 scale=1.0000 norm=0.4112
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5627 val_loss=0.0000 scale=1.0000 norm=0.5754
[iter 200] loss=0.0596 val_loss=0.0000 scale=1.0000 norm=0.4936
[iter 300] loss=-0.3123 val_loss=0.0000 scale=1.0000 norm=0.4569
[iter 400] loss=-0.5975 val_loss=0.0000 scale=1.0000 norm=0.4314
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2981 val_loss=0.0000 scale=2.0000 norm=1.0142
[iter 200] loss=-0.3988 val_loss=0.0000 scale=2.0000 norm=0.8810
[iter 300] loss=-0.8518 val_loss=0.0000 scale=1.0000 norm=0.4028
[iter 400] loss=-1.1484 val_loss=0.0000 scale=2.0000 norm=0.7752
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0984 val_loss=0.0000 scale=2.0000 norm=0.9993
[iter 200] loss=-0.8797 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 300] loss=-1.8909 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9989 val_loss=0.0000 scale=2.0000 norm=0.9816
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4021 val_loss=0.0000 scale=2.0000 norm=1.0548
[iter 200] loss=-0.2239 val_loss=0.0000 scale=2.0000 norm=0.9231
[iter 300] loss=-0.6706 val_loss=0.0000 scale=2.0000 norm=0.8408
[iter 400] loss=-1.0604 val_loss=0.0000 scale=1.0000 norm=0.3891
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2786 val_loss=0.0000 scale=1.0000 norm=0.5092
[iter 200] loss=-0.1754 val_loss=0.0000 scale=2.0000 norm=0.9187
[iter 300] loss=-0.6292 val_loss=0.0000 scale=2.0000 norm=0.8424
[iter 400] loss=-0.9292 val_loss=0.0000 scale=1.0000 norm=0.4091
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2870 val_loss=0.0000 scale=2.0000 norm=1.0233
[iter 200] loss=-0.3635 val_loss=0.0000 scale=2.0000 norm=0.8973
[iter 300] loss=-0.7704 val_loss=0.0000 scale=1.0000 norm=0.4229
[iter 400] loss=-1.1154 val_loss=0.0000 scale=1.0000 norm=0.3882
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6570 val_loss=0.0000 scale=1.0000 norm=0.5834
[iter 200] loss=0.1047 val_loss=0.0000 scale=1.0000 norm=0.4750
[iter 300] loss=-0.4521 val_loss=0.0000 scale=2.0000 norm=0.8337
[iter 400] loss=-0.8778 val_loss=0.0000 scale=1.0000 norm=0.3947
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3435 val_loss=0.0000 scale=2.0000 norm=1.0347
[iter 200] loss=-0.1024 val_loss=0.0000 scale=1.0000 norm=0.4561
[iter 300] loss=-0.4503 val_loss=0.0000 scale=2.0000 norm=0.8284
[iter 400] loss=-0.7553 val_loss=0.0000 scale=1.0000 norm=0.3934
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1068 val_loss=0.0000 scale=2.0000 norm=1.0019
[iter 200] loss=-0.9461 val_loss=0.0000 scale=4.0000 norm=1.9817
[iter 300] loss=-2.9413 val_loss=0.0000 scale=4.0000 norm=1.9968
[iter 400] loss=-4.9374 val_loss=0.0000 scale=4.0000 norm=1.9950
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3063 val_loss=0.0000 scale=2.0000 norm=1.0162
[iter 200] loss=-0.2862 val_loss=0.0000 scale=2.0000 norm=0.9118
[iter 300] loss=-0.6662 val_loss=0.0000 scale=1.0000 norm=0.4238
[iter 400] loss=-0.9749 val_loss=0.0000 scale=1.0000 norm=0.4132
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5505 val_loss=0.0000 scale=2.0000 norm=1.0938
[iter 200] loss=-0.2825 val_loss=0.0000 scale=1.0000 norm=0.4521
[iter 300] loss=-1.0637 val_loss=0.0000 scale=2.0000 norm=0.8263
[iter 400] loss=-1.6443 val_loss=0.0000 scale=2.0000 norm=0.7593
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3049 val_loss=0.0000 scale=2.0000 norm=1.0070
[iter 200] loss=-0.4325 val_loss=0.0000 scale=2.0000 norm=0.8886
[iter 300] loss=-0.9666 val_loss=0.0000 scale=2.0000 norm=0.8159
[iter 400] loss=-1.2983 val_loss=0.0000 scale=1.0000 norm=0.3781
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2067 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 200] loss=-0.6757 val_loss=0.0000 scale=2.0000 norm=0.9091
[iter 300] loss=-1.3046 val_loss=0.0000 scale=2.0000 norm=0.8123
[iter 400] loss=-1.7730 val_loss=0.0000 scale=1.0000 norm=0.3544
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2945 val_loss=0.0000 scale=2.0000 norm=1.0200
[iter 200] loss=-0.3579 val_loss=0.0000 scale=1.0000 norm=0.4330
[iter 300] loss=-0.8398 val_loss=0.0000 scale=2.0000 norm=0.7455
[iter 400] loss=-1.1760 val_loss=0.0000 scale=1.0000 norm=0.3320
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3283 val_loss=0.0000 scale=1.0000 norm=0.5028
[iter 200] loss=-0.1930 val_loss=0.0000 scale=1.0000 norm=0.4385
[iter 300] loss=-0.6243 val_loss=0.0000 scale=1.0000 norm=0.4007
[iter 400] loss=-0.9064 val_loss=0.0000 scale=1.0000 norm=0.3837
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3096 val_loss=0.0000 scale=2.0000 norm=1.0114
[iter 200] loss=-0.1940 val_loss=0.0000 scale=2.0000 norm=0.8799
[iter 300] loss=-0.6167 val_loss=0.0000 scale=1.0000 norm=0.4007
[iter 400] loss=-0.9080 val_loss=0.0000 scale=0.5000 norm=0.1929
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3164 val_loss=0.0000 scale=2.0000 norm=1.0054
[iter 200] loss=-0.4280 val_loss=0.0000 scale=2.0000 norm=0.8397
[iter 300] loss=-0.9644 val_loss=0.0000 scale=1.0000 norm=0.3807
[iter 400] loss=-1.3543 val_loss=0.0000 scale=1.0000 norm=0.3615
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3330 val_loss=0.0000 scale=2.0000 norm=1.0587
[iter 200] loss=-0.2119 val_loss=0.0000 scale=1.0000 norm=0.4657
[iter 300] loss=-0.6073 val_loss=0.0000 scale=1.0000 norm=0.4338
[iter 400] loss=-0.9042 val_loss=0.0000 scale=2.0000 norm=0.8360
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4617 val_loss=0.0000 scale=2.0000 norm=1.0549
[iter 200] loss=-0.1658 val_loss=0.0000 scale=2.0000 norm=0.8849
[iter 300] loss=-0.7406 val_loss=0.0000 scale=2.0000 norm=0.7882
[iter 400] loss=-1.1018 val_loss=0.0000 scale=2.0000 norm=0.7256
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3250 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.5737 val_loss=0.0000 scale=2.0000 norm=0.9285
[iter 300] loss=-1.4450 val_loss=0.0000 scale=2.0000 norm=0.8670
[iter 400] loss=-2.1647 val_loss=0.0000 scale=2.0000 norm=0.7283
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4245 val_loss=0.0000 scale=2.0000 norm=1.0046
[iter 200] loss=-0.4443 val_loss=0.0000 scale=2.0000 norm=0.8820
[iter 300] loss=-1.2001 val_loss=0.0000 scale=2.0000 norm=0.7774
[iter 400] loss=-1.7873 val_loss=0.0000 scale=2.0000 norm=0.6613
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=0.9788
[iter 200] loss=-0.5862 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 300] loss=-1.5311 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 400] loss=-2.4801 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2240 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 200] loss=-0.6141 val_loss=0.0000 scale=2.0000 norm=0.8772
[iter 300] loss=-1.2439 val_loss=0.0000 scale=1.0000 norm=0.3868
[iter 400] loss=-1.6155 val_loss=0.0000 scale=1.0000 norm=0.3449
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3342 val_loss=0.0000 scale=2.0000 norm=1.0286
[iter 200] loss=-0.2711 val_loss=0.0000 scale=1.0000 norm=0.4472
[iter 300] loss=-0.6367 val_loss=0.0000 scale=1.0000 norm=0.4183
[iter 400] loss=-0.9053 val_loss=0.0000 scale=1.0000 norm=0.3940
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2346 val_loss=0.0000 scale=2.0000 norm=0.9781
[iter 200] loss=-0.6004 val_loss=0.0000 scale=2.0000 norm=0.8723
[iter 300] loss=-1.3574 val_loss=0.0000 scale=2.0000 norm=0.8098
[iter 400] loss=-1.9670 val_loss=0.0000 scale=2.0000 norm=0.7473
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1429 val_loss=0.0000 scale=2.0000 norm=0.9723
[iter 200] loss=-0.7723 val_loss=0.0000 scale=2.0000 norm=0.9256
[iter 300] loss=-1.6378 val_loss=0.0000 scale=2.0000 norm=0.8628
[iter 400] loss=-2.3992 val_loss=0.0000 scale=2.0000 norm=0.7705
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2550 val_loss=0.0000 scale=2.0000 norm=0.9977
[iter 200] loss=-0.4750 val_loss=0.0000 scale=2.0000 norm=0.8459
[iter 300] loss=-0.9129 val_loss=0.0000 scale=1.0000 norm=0.3851
[iter 400] loss=-1.2046 val_loss=0.0000 scale=1.0000 norm=0.3706
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2879 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3116 val_loss=0.0000 scale=2.0000 norm=0.8946
[iter 300] loss=-0.6711 val_loss=0.0000 scale=2.0000 norm=0.8175
[iter 400] loss=-0.9128 val_loss=0.0000 scale=1.0000 norm=0.3832
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1414 val_loss=0.0000 scale=2.0000 norm=0.9859
[iter 200] loss=-0.7546 val_loss=0.0000 scale=2.0000 norm=0.9052
[iter 300] loss=-1.5436 val_loss=0.0000 scale=2.0000 norm=0.7926
[iter 400] loss=-2.0946 val_loss=0.0000 scale=1.0000 norm=0.3408
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3182 val_loss=0.0000 scale=1.0000 norm=0.5115
[iter 200] loss=-0.3088 val_loss=0.0000 scale=2.0000 norm=0.9019
[iter 300] loss=-0.8109 val_loss=0.0000 scale=1.0000 norm=0.4081
[iter 400] loss=-1.1745 val_loss=0.0000 scale=1.0000 norm=0.3803
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2870 val_loss=0.0000 scale=2.0000 norm=1.0121
[iter 200] loss=-0.6010 val_loss=0.0000 scale=2.0000 norm=0.9058
[iter 300] loss=-1.4240 val_loss=0.0000 scale=2.0000 norm=0.8426
[iter 400] loss=-2.0582 val_loss=0.0000 scale=2.0000 norm=0.7612
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4919 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 200] loss=-0.3404 val_loss=0.0000 scale=2.0000 norm=0.8908
[iter 300] loss=-1.0465 val_loss=0.0000 scale=2.0000 norm=0.7866
[iter 400] loss=-1.6085 val_loss=0.0000 scale=2.0000 norm=0.7166
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5730 val_loss=0.0000 scale=1.0000 norm=0.5690
[iter 200] loss=-0.0081 val_loss=0.0000 scale=1.0000 norm=0.4804
[iter 300] loss=-0.3856 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 400] loss=-0.6896 val_loss=0.0000 scale=1.0000 norm=0.4355
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3193 val_loss=0.0000 scale=2.0000 norm=1.0285
[iter 200] loss=-0.2621 val_loss=0.0000 scale=2.0000 norm=0.9036
[iter 300] loss=-0.6703 val_loss=0.0000 scale=1.0000 norm=0.4209
[iter 400] loss=-0.9463 val_loss=0.0000 scale=1.0000 norm=0.3968
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7716 val_loss=0.0000 scale=2.0000 norm=1.2026
[iter 200] loss=0.1588 val_loss=0.0000 scale=2.0000 norm=0.9470
[iter 300] loss=-0.3944 val_loss=0.0000 scale=2.0000 norm=0.8496
[iter 400] loss=-0.8615 val_loss=0.0000 scale=1.0000 norm=0.3993
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1976 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 200] loss=-0.5789 val_loss=0.0000 scale=2.0000 norm=0.8620
[iter 300] loss=-1.1456 val_loss=0.0000 scale=2.0000 norm=0.7640
[iter 400] loss=-1.5163 val_loss=0.0000 scale=1.0000 norm=0.3398
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1302 val_loss=0.0000 scale=2.0000 norm=0.9725
[iter 200] loss=-0.7246 val_loss=0.0000 scale=2.0000 norm=0.8697
[iter 300] loss=-1.4600 val_loss=0.0000 scale=2.0000 norm=0.7528
[iter 400] loss=-1.9543 val_loss=0.0000 scale=2.0000 norm=0.6718
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2884 val_loss=0.0000 scale=2.0000 norm=1.0160
[iter 200] loss=-0.2077 val_loss=0.0000 scale=1.0000 norm=0.4532
[iter 300] loss=-0.6146 val_loss=0.0000 scale=1.0000 norm=0.4188
[iter 400] loss=-0.9026 val_loss=0.0000 scale=2.0000 norm=0.8236
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2199 val_loss=0.0000 scale=1.0000 norm=0.5059
[iter 200] loss=-0.4805 val_loss=0.0000 scale=2.0000 norm=0.8974
[iter 300] loss=-1.0945 val_loss=0.0000 scale=2.0000 norm=0.8160
[iter 400] loss=-1.4530 val_loss=0.0000 scale=1.0000 norm=0.3766
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2487 val_loss=0.0000 scale=2.0000 norm=1.0048
[iter 200] loss=-0.3530 val_loss=0.0000 scale=1.0000 norm=0.4517
[iter 300] loss=-0.7913 val_loss=0.0000 scale=1.0000 norm=0.4181
[iter 400] loss=-1.0679 val_loss=0.0000 scale=1.0000 norm=0.3928
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4221 val_loss=0.0000 scale=2.0000 norm=1.0496
[iter 200] loss=-0.2573 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 300] loss=-0.7234 val_loss=0.0000 scale=1.0000 norm=0.4044
[iter 400] loss=-1.0415 val_loss=0.0000 scale=1.0000 norm=0.3888
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3719 val_loss=0.0000 scale=1.0000 norm=0.5258
[iter 200] loss=-0.1438 val_loss=0.0000 scale=1.0000 norm=0.4618
[iter 300] loss=-0.5365 val_loss=0.0000 scale=2.0000 norm=0.8334
[iter 400] loss=-0.8216 val_loss=0.0000 scale=1.0000 norm=0.3944
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4062 val_loss=0.0000 scale=1.0000 norm=0.5216
[iter 200] loss=-0.2842 val_loss=0.0000 scale=2.0000 norm=0.8983
[iter 300] loss=-0.8555 val_loss=0.0000 scale=1.0000 norm=0.4008
[iter 400] loss=-1.1804 val_loss=0.0000 scale=1.0000 norm=0.3752
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2889 val_loss=0.0000 scale=2.0000 norm=1.0074
[iter 200] loss=-0.3659 val_loss=0.0000 scale=2.0000 norm=0.8807
[iter 300] loss=-0.7829 val_loss=0.0000 scale=2.0000 norm=0.7832
[iter 400] loss=-1.0631 val_loss=0.0000 scale=0.5000 norm=0.1780
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1989 val_loss=0.0000 scale=2.0000 norm=0.9811
[iter 200] loss=-0.7871 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 300] loss=-1.7701 val_loss=0.0000 scale=2.0000 norm=0.9822
[iter 400] loss=-2.9153 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4250 val_loss=0.0000 scale=1.0000 norm=0.5352
[iter 200] loss=-0.0397 val_loss=0.0000 scale=1.0000 norm=0.4686
[iter 300] loss=-0.4161 val_loss=0.0000 scale=1.0000 norm=0.4265
[iter 400] loss=-0.6848 val_loss=0.0000 scale=1.0000 norm=0.3903
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3326 val_loss=0.0000 scale=2.0000 norm=1.0343
[iter 200] loss=-0.1318 val_loss=0.0000 scale=2.0000 norm=0.9325
[iter 300] loss=-0.5749 val_loss=0.0000 scale=1.0000 norm=0.4405
[iter 400] loss=-0.9439 val_loss=0.0000 scale=2.0000 norm=0.8566
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4054 val_loss=0.0000 scale=1.0000 norm=0.5218
[iter 200] loss=-0.1101 val_loss=0.0000 scale=2.0000 norm=0.9161
[iter 300] loss=-0.5469 val_loss=0.0000 scale=1.0000 norm=0.4176
[iter 400] loss=-0.8576 val_loss=0.0000 scale=1.0000 norm=0.3931
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4667 val_loss=0.0000 scale=2.0000 norm=1.0798
[iter 200] loss=-0.0861 val_loss=0.0000 scale=1.0000 norm=0.4565
[iter 300] loss=-0.4159 val_loss=0.0000 scale=1.0000 norm=0.4206
[iter 400] loss=-0.6553 val_loss=0.0000 scale=1.0000 norm=0.4017
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2927 val_loss=0.0000 scale=2.0000 norm=1.0208
[iter 200] loss=-0.3474 val_loss=0.0000 scale=2.0000 norm=0.8941
[iter 300] loss=-0.7737 val_loss=0.0000 scale=1.0000 norm=0.4170
[iter 400] loss=-1.0730 val_loss=0.0000 scale=0.5000 norm=0.1991
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2915 val_loss=0.0000 scale=1.0000 norm=0.5077
[iter 200] loss=-0.3576 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 300] loss=-0.7946 val_loss=0.0000 scale=1.0000 norm=0.4117
[iter 400] loss=-1.1464 val_loss=0.0000 scale=2.0000 norm=0.7931
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3262 val_loss=0.0000 scale=2.0000 norm=1.0458
[iter 200] loss=-0.2098 val_loss=0.0000 scale=2.0000 norm=0.9339
[iter 300] loss=-0.5520 val_loss=0.0000 scale=1.0000 norm=0.4327
[iter 400] loss=-0.8866 val_loss=0.0000 scale=1.0000 norm=0.4184
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3975 val_loss=0.0000 scale=2.0000 norm=1.0571
[iter 200] loss=-0.0606 val_loss=0.0000 scale=1.0000 norm=0.4547
[iter 300] loss=-0.4557 val_loss=0.0000 scale=1.0000 norm=0.4161
[iter 400] loss=-0.7275 val_loss=0.0000 scale=1.0000 norm=0.4081
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3636 val_loss=0.0000 scale=2.0000 norm=1.0231
[iter 200] loss=-0.3948 val_loss=0.0000 scale=1.0000 norm=0.4341
[iter 300] loss=-0.9170 val_loss=0.0000 scale=1.0000 norm=0.3893
[iter 400] loss=-1.2989 val_loss=0.0000 scale=1.0000 norm=0.3644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4174 val_loss=0.0000 scale=2.0000 norm=1.0561
[iter 200] loss=-0.2327 val_loss=0.0000 scale=1.0000 norm=0.4501
[iter 300] loss=-0.7423 val_loss=0.0000 scale=1.0000 norm=0.3957
[iter 400] loss=-1.0526 val_loss=0.0000 scale=1.0000 norm=0.3468
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3159 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.2927 val_loss=0.0000 scale=1.0000 norm=0.4446
[iter 300] loss=-0.6799 val_loss=0.0000 scale=2.0000 norm=0.7987
[iter 400] loss=-0.9600 val_loss=0.0000 scale=1.0000 norm=0.3736
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1841 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 200] loss=-0.7878 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 300] loss=-1.7623 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 400] loss=-2.8661 val_loss=0.0000 scale=2.0000 norm=0.9847
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4058 val_loss=0.0000 scale=2.0000 norm=1.0597
[iter 200] loss=-0.1401 val_loss=0.0000 scale=1.0000 norm=0.4571
[iter 300] loss=-0.4759 val_loss=0.0000 scale=1.0000 norm=0.4204
[iter 400] loss=-0.7579 val_loss=0.0000 scale=2.0000 norm=0.8020
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3438 val_loss=0.0000 scale=2.0000 norm=1.0380
[iter 200] loss=-0.1966 val_loss=0.0000 scale=1.0000 norm=0.4487
[iter 300] loss=-0.5684 val_loss=0.0000 scale=1.0000 norm=0.4139
[iter 400] loss=-0.8428 val_loss=0.0000 scale=1.0000 norm=0.3988
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4598 val_loss=0.0000 scale=1.0000 norm=0.5334
[iter 200] loss=-0.1059 val_loss=0.0000 scale=1.0000 norm=0.4666
[iter 300] loss=-0.5064 val_loss=0.0000 scale=1.0000 norm=0.4288
[iter 400] loss=-0.8747 val_loss=0.0000 scale=1.0000 norm=0.4014
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2746 val_loss=0.0000 scale=2.0000 norm=0.9653
[iter 200] loss=-0.6147 val_loss=0.0000 scale=2.0000 norm=0.9017
[iter 300] loss=-1.4383 val_loss=0.0000 scale=2.0000 norm=0.8365
[iter 400] loss=-2.1699 val_loss=0.0000 scale=2.0000 norm=0.7484
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1082 val_loss=0.0000 scale=2.0000 norm=0.9844
[iter 200] loss=-0.7844 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 300] loss=-1.5795 val_loss=0.0000 scale=2.0000 norm=0.8370
[iter 400] loss=-2.3034 val_loss=0.0000 scale=1.0000 norm=0.3885
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2519 val_loss=0.0000 scale=2.0000 norm=0.9980
[iter 200] loss=-0.4852 val_loss=0.0000 scale=2.0000 norm=0.8772
[iter 300] loss=-0.9851 val_loss=0.0000 scale=2.0000 norm=0.8009
[iter 400] loss=-1.2791 val_loss=0.0000 scale=1.0000 norm=0.3821
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3429 val_loss=0.0000 scale=2.0000 norm=1.0162
[iter 200] loss=-0.3955 val_loss=0.0000 scale=2.0000 norm=0.8948
[iter 300] loss=-0.9871 val_loss=0.0000 scale=2.0000 norm=0.8215
[iter 400] loss=-1.4363 val_loss=0.0000 scale=1.0000 norm=0.3869
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3986 val_loss=0.0000 scale=1.0000 norm=0.5181
[iter 200] loss=-0.1790 val_loss=0.0000 scale=1.0000 norm=0.4457
[iter 300] loss=-0.6342 val_loss=0.0000 scale=2.0000 norm=0.7992
[iter 400] loss=-0.9846 val_loss=0.0000 scale=2.0000 norm=0.7245
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2731 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 200] loss=-0.4992 val_loss=0.0000 scale=2.0000 norm=0.8310
[iter 300] loss=-1.1697 val_loss=0.0000 scale=1.0000 norm=0.3855
[iter 400] loss=-1.6819 val_loss=0.0000 scale=2.0000 norm=0.6693
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1727 val_loss=0.0000 scale=2.0000 norm=0.9677
[iter 200] loss=-0.7643 val_loss=0.0000 scale=2.0000 norm=0.9510
[iter 300] loss=-1.7335 val_loss=0.0000 scale=2.0000 norm=0.9625
[iter 400] loss=-2.6665 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2635 val_loss=0.0000 scale=2.0000 norm=1.0142
[iter 200] loss=-0.5780 val_loss=0.0000 scale=2.0000 norm=0.8860
[iter 300] loss=-1.2763 val_loss=0.0000 scale=2.0000 norm=0.7788
[iter 400] loss=-1.7413 val_loss=0.0000 scale=2.0000 norm=0.7112
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1459 val_loss=0.0000 scale=2.0000 norm=0.9922
[iter 200] loss=-0.8550 val_loss=0.0000 scale=4.0000 norm=1.9724
[iter 300] loss=-2.3651 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 400] loss=-3.8952 val_loss=0.0000 scale=4.0000 norm=1.9744
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2369 val_loss=0.0000 scale=2.0000 norm=1.0177
[iter 200] loss=-0.4574 val_loss=0.0000 scale=2.0000 norm=0.9157
[iter 300] loss=-0.9544 val_loss=0.0000 scale=2.0000 norm=0.8402
[iter 400] loss=-1.3312 val_loss=0.0000 scale=1.0000 norm=0.3785
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1410 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.7518 val_loss=0.0000 scale=2.0000 norm=0.9075
[iter 300] loss=-1.5806 val_loss=0.0000 scale=2.0000 norm=0.8407
[iter 400] loss=-2.3084 val_loss=0.0000 scale=2.0000 norm=0.7937
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3309 val_loss=0.0000 scale=2.0000 norm=0.9929
[iter 200] loss=-0.5721 val_loss=0.0000 scale=2.0000 norm=0.9207
[iter 300] loss=-1.4766 val_loss=0.0000 scale=2.0000 norm=0.9022
[iter 400] loss=-2.2790 val_loss=0.0000 scale=2.0000 norm=0.8279
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4383 val_loss=0.0000 scale=1.0000 norm=0.5377
[iter 200] loss=-0.0426 val_loss=0.0000 scale=1.0000 norm=0.4743
[iter 300] loss=-0.4570 val_loss=0.0000 scale=2.0000 norm=0.8455
[iter 400] loss=-0.8087 val_loss=0.0000 scale=2.0000 norm=0.7696
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2241 val_loss=0.0000 scale=2.0000 norm=0.9728
[iter 200] loss=-0.7407 val_loss=0.0000 scale=2.0000 norm=0.9573
[iter 300] loss=-1.6618 val_loss=0.0000 scale=2.0000 norm=0.9200
[iter 400] loss=-2.6667 val_loss=0.0000 scale=2.0000 norm=0.8714
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5767 val_loss=0.0000 scale=2.0000 norm=1.1478
[iter 200] loss=0.0379 val_loss=0.0000 scale=2.0000 norm=0.9780
[iter 300] loss=-0.2345 val_loss=0.0000 scale=2.0000 norm=0.9131
[iter 400] loss=-0.4778 val_loss=0.0000 scale=1.0000 norm=0.4447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1596 val_loss=0.0000 scale=2.0000 norm=0.9790
[iter 200] loss=-0.7185 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 300] loss=-1.4815 val_loss=0.0000 scale=2.0000 norm=0.8002
[iter 400] loss=-2.1283 val_loss=0.0000 scale=2.0000 norm=0.7408
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1450 val_loss=0.0000 scale=2.0000 norm=0.9996
[iter 200] loss=-0.8429 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-2.3452 val_loss=0.0000 scale=4.0000 norm=1.9717
[iter 400] loss=-3.7202 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2892 val_loss=0.0000 scale=2.0000 norm=0.9897
[iter 200] loss=-0.4810 val_loss=0.0000 scale=2.0000 norm=0.8678
[iter 300] loss=-1.0997 val_loss=0.0000 scale=2.0000 norm=0.7663
[iter 400] loss=-1.4375 val_loss=0.0000 scale=1.0000 norm=0.3584
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2598 val_loss=0.0000 scale=2.0000 norm=0.9799
[iter 200] loss=-0.7165 val_loss=0.0000 scale=2.0000 norm=0.9748
[iter 300] loss=-1.9868 val_loss=0.0000 scale=4.0000 norm=1.9636
[iter 400] loss=-3.2291 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1047 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 200] loss=-0.8756 val_loss=0.0000 scale=2.0000 norm=0.9785
[iter 300] loss=-1.8577 val_loss=0.0000 scale=2.0000 norm=0.9818
[iter 400] loss=-2.8487 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3254 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.2592 val_loss=0.0000 scale=2.0000 norm=0.8955
[iter 300] loss=-0.6932 val_loss=0.0000 scale=1.0000 norm=0.4134
[iter 400] loss=-0.9873 val_loss=0.0000 scale=2.0000 norm=0.8002
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1889 val_loss=0.0000 scale=2.0000 norm=0.9820
[iter 200] loss=-0.6068 val_loss=0.0000 scale=2.0000 norm=0.8468
[iter 300] loss=-1.2370 val_loss=0.0000 scale=2.0000 norm=0.7467
[iter 400] loss=-1.6570 val_loss=0.0000 scale=2.0000 norm=0.6816
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6867 val_loss=0.0000 scale=2.0000 norm=1.1621
[iter 200] loss=-0.0196 val_loss=0.0000 scale=2.0000 norm=0.9474
[iter 300] loss=-0.6960 val_loss=0.0000 scale=1.0000 norm=0.4260
[iter 400] loss=-1.1072 val_loss=0.0000 scale=1.0000 norm=0.3973
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3334 val_loss=0.0000 scale=2.0000 norm=1.0407
[iter 200] loss=-0.3823 val_loss=0.0000 scale=1.0000 norm=0.4482
[iter 300] loss=-0.8357 val_loss=0.0000 scale=2.0000 norm=0.8157
[iter 400] loss=-1.2155 val_loss=0.0000 scale=1.0000 norm=0.3768
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1668 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 200] loss=-0.5588 val_loss=0.0000 scale=2.0000 norm=0.9006
[iter 300] loss=-1.3087 val_loss=0.0000 scale=2.0000 norm=0.7946
[iter 400] loss=-1.8489 val_loss=0.0000 scale=1.0000 norm=0.3874
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3950 val_loss=0.0000 scale=2.0000 norm=1.0670
[iter 200] loss=-0.1849 val_loss=0.0000 scale=1.0000 norm=0.4546
[iter 300] loss=-0.5475 val_loss=0.0000 scale=1.0000 norm=0.4135
[iter 400] loss=-0.8231 val_loss=0.0000 scale=1.0000 norm=0.3884
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2920 val_loss=0.0000 scale=2.0000 norm=1.0300
[iter 200] loss=-0.3062 val_loss=0.0000 scale=1.0000 norm=0.4510
[iter 300] loss=-0.7157 val_loss=0.0000 scale=2.0000 norm=0.8223
[iter 400] loss=-0.9975 val_loss=0.0000 scale=1.0000 norm=0.3960
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2482 val_loss=0.0000 scale=2.0000 norm=0.9712
[iter 200] loss=-0.7127 val_loss=0.0000 scale=2.0000 norm=0.9601
[iter 300] loss=-1.6799 val_loss=0.0000 scale=2.0000 norm=0.9664
[iter 400] loss=-2.6411 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4833 val_loss=0.0000 scale=1.0000 norm=0.5482
[iter 200] loss=0.0271 val_loss=0.0000 scale=1.0000 norm=0.4768
[iter 300] loss=-0.2938 val_loss=0.0000 scale=1.0000 norm=0.4413
[iter 400] loss=-0.5648 val_loss=0.0000 scale=1.0000 norm=0.4208
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3297 val_loss=0.0000 scale=1.0000 norm=0.5139
[iter 200] loss=-0.2811 val_loss=0.0000 scale=2.0000 norm=0.9050
[iter 300] loss=-0.7626 val_loss=0.0000 scale=2.0000 norm=0.8194
[iter 400] loss=-1.1061 val_loss=0.0000 scale=1.0000 norm=0.3892
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1899 val_loss=0.0000 scale=2.0000 norm=0.9760
[iter 200] loss=-0.6498 val_loss=0.0000 scale=2.0000 norm=0.8792
[iter 300] loss=-1.4094 val_loss=0.0000 scale=2.0000 norm=0.8044
[iter 400] loss=-1.9107 val_loss=0.0000 scale=1.0000 norm=0.3867
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2405 val_loss=0.0000 scale=2.0000 norm=0.9784
[iter 200] loss=-0.7571 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 300] loss=-2.6002 val_loss=0.0000 scale=4.0000 norm=1.9920
[iter 400] loss=-4.5862 val_loss=0.0000 scale=4.0000 norm=1.9821
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3425 val_loss=0.0000 scale=2.0000 norm=1.0399
[iter 200] loss=-0.3088 val_loss=0.0000 scale=1.0000 norm=0.4350
[iter 300] loss=-0.7300 val_loss=0.0000 scale=2.0000 norm=0.7820
[iter 400] loss=-1.0101 val_loss=0.0000 scale=1.0000 norm=0.3854
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2972 val_loss=0.0000 scale=2.0000 norm=1.0037
[iter 200] loss=-0.3717 val_loss=0.0000 scale=1.0000 norm=0.4366
[iter 300] loss=-0.8466 val_loss=0.0000 scale=1.0000 norm=0.4003
[iter 400] loss=-1.1784 val_loss=0.0000 scale=1.0000 norm=0.3853
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1766 val_loss=0.0000 scale=2.0000 norm=1.0054
[iter 200] loss=-0.6840 val_loss=0.0000 scale=2.0000 norm=0.8978
[iter 300] loss=-1.4574 val_loss=0.0000 scale=1.0000 norm=0.4037
[iter 400] loss=-2.0196 val_loss=0.0000 scale=1.0000 norm=0.3638
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2371 val_loss=0.0000 scale=1.0000 norm=0.5089
[iter 200] loss=-0.3674 val_loss=0.0000 scale=2.0000 norm=0.9124
[iter 300] loss=-0.9419 val_loss=0.0000 scale=2.0000 norm=0.8272
[iter 400] loss=-1.2881 val_loss=0.0000 scale=0.5000 norm=0.1906
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5175 val_loss=0.0000 scale=2.0000 norm=1.0634
[iter 200] loss=-0.2878 val_loss=0.0000 scale=2.0000 norm=0.8941
[iter 300] loss=-0.8804 val_loss=0.0000 scale=1.0000 norm=0.4017
[iter 400] loss=-1.2710 val_loss=0.0000 scale=2.0000 norm=0.7425
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2883 val_loss=0.0000 scale=2.0000 norm=1.0215
[iter 200] loss=-0.3610 val_loss=0.0000 scale=2.0000 norm=0.8846
[iter 300] loss=-0.8215 val_loss=0.0000 scale=2.0000 norm=0.8070
[iter 400] loss=-1.1888 val_loss=0.0000 scale=1.0000 norm=0.3676
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2858 val_loss=0.0000 scale=2.0000 norm=1.0140
[iter 200] loss=-0.2391 val_loss=0.0000 scale=1.0000 norm=0.4469
[iter 300] loss=-0.6215 val_loss=0.0000 scale=2.0000 norm=0.8275
[iter 400] loss=-0.9125 val_loss=0.0000 scale=1.0000 norm=0.3888
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2894 val_loss=0.0000 scale=1.0000 norm=0.5054
[iter 200] loss=-0.2736 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 300] loss=-0.7262 val_loss=0.0000 scale=1.0000 norm=0.4117
[iter 400] loss=-1.0350 val_loss=0.0000 scale=0.5000 norm=0.1963
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8149 val_loss=0.0000 scale=2.0000 norm=1.2576
[iter 200] loss=0.3206 val_loss=0.0000 scale=1.0000 norm=0.5082
[iter 300] loss=-0.1895 val_loss=0.0000 scale=1.0000 norm=0.4450
[iter 400] loss=-0.6592 val_loss=0.0000 scale=1.0000 norm=0.4168
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2968 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 200] loss=-0.5845 val_loss=0.0000 scale=2.0000 norm=0.9055
[iter 300] loss=-1.3109 val_loss=0.0000 scale=2.0000 norm=0.8293
[iter 400] loss=-1.8985 val_loss=0.0000 scale=1.0000 norm=0.3778
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1371 val_loss=0.0000 scale=2.0000 norm=0.9839
[iter 200] loss=-0.8534 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 300] loss=-2.3051 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 400] loss=-3.7613 val_loss=0.0000 scale=2.0000 norm=0.9837
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2765 val_loss=0.0000 scale=2.0000 norm=0.9945
[iter 200] loss=-0.4062 val_loss=0.0000 scale=2.0000 norm=0.8582
[iter 300] loss=-0.8555 val_loss=0.0000 scale=1.0000 norm=0.3800
[iter 400] loss=-1.1541 val_loss=0.0000 scale=1.0000 norm=0.3410
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5637 val_loss=0.0000 scale=2.0000 norm=1.1130
[iter 200] loss=-0.0532 val_loss=0.0000 scale=2.0000 norm=0.9336
[iter 300] loss=-0.5458 val_loss=0.0000 scale=1.0000 norm=0.4218
[iter 400] loss=-0.8443 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2400 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-0.3534 val_loss=0.0000 scale=1.0000 norm=0.4464
[iter 300] loss=-0.7291 val_loss=0.0000 scale=2.0000 norm=0.8140
[iter 400] loss=-1.0145 val_loss=0.0000 scale=1.0000 norm=0.3915
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3542 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 200] loss=-0.4978 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 300] loss=-1.2283 val_loss=0.0000 scale=2.0000 norm=0.9099
[iter 400] loss=-2.0764 val_loss=0.0000 scale=2.0000 norm=0.8862
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3128 val_loss=0.0000 scale=2.0000 norm=1.0083
[iter 200] loss=-0.3207 val_loss=0.0000 scale=2.0000 norm=0.8768
[iter 300] loss=-0.7280 val_loss=0.0000 scale=1.0000 norm=0.3979
[iter 400] loss=-0.9372 val_loss=0.0000 scale=1.0000 norm=0.3717
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1293 val_loss=0.0000 scale=2.0000 norm=0.9914
[iter 200] loss=-0.8581 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 300] loss=-2.4725 val_loss=0.0000 scale=4.0000 norm=1.9772
[iter 400] loss=-4.1079 val_loss=0.0000 scale=4.0000 norm=1.9528
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3603 val_loss=0.0000 scale=2.0000 norm=1.0402
[iter 200] loss=-0.1021 val_loss=0.0000 scale=1.0000 norm=0.4638
[iter 300] loss=-0.4806 val_loss=0.0000 scale=1.0000 norm=0.4312
[iter 400] loss=-0.7589 val_loss=0.0000 scale=1.0000 norm=0.4132
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3153 val_loss=0.0000 scale=2.0000 norm=1.0098
[iter 200] loss=-0.2662 val_loss=0.0000 scale=1.0000 norm=0.4377
[iter 300] loss=-0.6720 val_loss=0.0000 scale=1.0000 norm=0.3964
[iter 400] loss=-0.9661 val_loss=0.0000 scale=1.0000 norm=0.3731
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2255 val_loss=0.0000 scale=2.0000 norm=0.9985
[iter 200] loss=-0.4374 val_loss=0.0000 scale=1.0000 norm=0.4345
[iter 300] loss=-0.8130 val_loss=0.0000 scale=1.0000 norm=0.4099
[iter 400] loss=-1.1177 val_loss=0.0000 scale=1.0000 norm=0.3880
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3793 val_loss=0.0000 scale=2.0000 norm=1.0052
[iter 200] loss=-0.5314 val_loss=0.0000 scale=2.0000 norm=0.9202
[iter 300] loss=-1.3983 val_loss=0.0000 scale=2.0000 norm=0.8727
[iter 400] loss=-2.1753 val_loss=0.0000 scale=2.0000 norm=0.7812
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4154 val_loss=0.0000 scale=2.0000 norm=1.0627
[iter 200] loss=-0.1476 val_loss=0.0000 scale=1.0000 norm=0.4612
[iter 300] loss=-0.6034 val_loss=0.0000 scale=1.0000 norm=0.4143
[iter 400] loss=-0.9015 val_loss=0.0000 scale=1.0000 norm=0.3988
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1221 val_loss=0.0000 scale=2.0000 norm=0.9884
[iter 200] loss=-0.7208 val_loss=0.0000 scale=2.0000 norm=0.8790
[iter 300] loss=-1.3139 val_loss=0.0000 scale=1.0000 norm=0.3983
[iter 400] loss=-1.7873 val_loss=0.0000 scale=1.0000 norm=0.3300
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3069 val_loss=0.0000 scale=2.0000 norm=1.0223
[iter 200] loss=-0.3252 val_loss=0.0000 scale=1.0000 norm=0.4565
[iter 300] loss=-0.7325 val_loss=0.0000 scale=1.0000 norm=0.4240
[iter 400] loss=-1.0636 val_loss=0.0000 scale=1.0000 norm=0.4022
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1086 val_loss=0.0000 scale=2.0000 norm=0.9823
[iter 200] loss=-0.8361 val_loss=0.0000 scale=2.0000 norm=0.9454
[iter 300] loss=-1.7393 val_loss=0.0000 scale=2.0000 norm=0.9000
[iter 400] loss=-2.5530 val_loss=0.0000 scale=2.0000 norm=0.8153
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4419 val_loss=0.0000 scale=2.0000 norm=1.0582
[iter 200] loss=-0.0831 val_loss=0.0000 scale=1.0000 norm=0.4585
[iter 300] loss=-0.4950 val_loss=0.0000 scale=1.0000 norm=0.4247
[iter 400] loss=-0.7925 val_loss=0.0000 scale=2.0000 norm=0.7938
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2396 val_loss=0.0000 scale=1.0000 norm=0.5090
[iter 200] loss=-0.3942 val_loss=0.0000 scale=2.0000 norm=0.9118
[iter 300] loss=-1.0142 val_loss=0.0000 scale=2.0000 norm=0.8270
[iter 400] loss=-1.4615 val_loss=0.0000 scale=1.0000 norm=0.3807
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=0.9863
[iter 200] loss=-0.5277 val_loss=0.0000 scale=2.0000 norm=0.9175
[iter 300] loss=-1.3767 val_loss=0.0000 scale=2.0000 norm=0.8549
[iter 400] loss=-2.1072 val_loss=0.0000 scale=2.0000 norm=0.7890
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3022 val_loss=0.0000 scale=2.0000 norm=1.0091
[iter 200] loss=-0.5470 val_loss=0.0000 scale=2.0000 norm=0.8986
[iter 300] loss=-1.2535 val_loss=0.0000 scale=2.0000 norm=0.8112
[iter 400] loss=-1.8276 val_loss=0.0000 scale=2.0000 norm=0.7292
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3383 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.2192 val_loss=0.0000 scale=1.0000 norm=0.4471
[iter 300] loss=-0.6397 val_loss=0.0000 scale=2.0000 norm=0.8111
[iter 400] loss=-0.9577 val_loss=0.0000 scale=2.0000 norm=0.7651
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1009 val_loss=0.0000 scale=2.0000 norm=0.9932
[iter 200] loss=-0.8775 val_loss=0.0000 scale=2.0000 norm=0.9750
[iter 300] loss=-1.8561 val_loss=0.0000 scale=4.0000 norm=1.9622
[iter 400] loss=-2.9791 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4048 val_loss=0.0000 scale=2.0000 norm=1.0521
[iter 200] loss=-0.1285 val_loss=0.0000 scale=1.0000 norm=0.4668
[iter 300] loss=-0.5354 val_loss=0.0000 scale=1.0000 norm=0.4333
[iter 400] loss=-0.8702 val_loss=0.0000 scale=2.0000 norm=0.8188
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3100 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.2645 val_loss=0.0000 scale=2.0000 norm=0.8972
[iter 300] loss=-0.6851 val_loss=0.0000 scale=2.0000 norm=0.8304
[iter 400] loss=-1.0037 val_loss=0.0000 scale=1.0000 norm=0.3958
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4284 val_loss=0.0000 scale=2.0000 norm=1.0288
[iter 200] loss=-0.4033 val_loss=0.0000 scale=2.0000 norm=0.8878
[iter 300] loss=-1.1039 val_loss=0.0000 scale=2.0000 norm=0.7975
[iter 400] loss=-1.5777 val_loss=0.0000 scale=1.0000 norm=0.3709
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3896 val_loss=0.0000 scale=1.0000 norm=0.5330
[iter 200] loss=-0.1241 val_loss=0.0000 scale=1.0000 norm=0.4649
[iter 300] loss=-0.4996 val_loss=0.0000 scale=1.0000 norm=0.4247
[iter 400] loss=-0.7890 val_loss=0.0000 scale=1.0000 norm=0.4026
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3178 val_loss=0.0000 scale=2.0000 norm=1.0150
[iter 200] loss=-0.2399 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 300] loss=-0.5977 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 400] loss=-0.9029 val_loss=0.0000 scale=1.0000 norm=0.3772
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5159 val_loss=0.0000 scale=2.0000 norm=1.1107
[iter 200] loss=-0.0128 val_loss=0.0000 scale=2.0000 norm=0.9749
[iter 300] loss=-0.3568 val_loss=0.0000 scale=1.0000 norm=0.4563
[iter 400] loss=-0.6227 val_loss=0.0000 scale=1.0000 norm=0.4280
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2417 val_loss=0.0000 scale=2.0000 norm=0.9875
[iter 200] loss=-0.3629 val_loss=0.0000 scale=2.0000 norm=0.8739
[iter 300] loss=-0.8543 val_loss=0.0000 scale=1.0000 norm=0.3927
[iter 400] loss=-1.2160 val_loss=0.0000 scale=1.0000 norm=0.3717
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3653 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.2332 val_loss=0.0000 scale=2.0000 norm=0.8930
[iter 300] loss=-0.6056 val_loss=0.0000 scale=1.0000 norm=0.4145
[iter 400] loss=-0.8810 val_loss=0.0000 scale=1.0000 norm=0.3931
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0972 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.8449 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-1.8387 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9335 val_loss=0.0000 scale=2.0000 norm=0.9864
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3935 val_loss=0.0000 scale=1.0000 norm=0.5281
[iter 200] loss=-0.0714 val_loss=0.0000 scale=2.0000 norm=0.9233
[iter 300] loss=-0.4504 val_loss=0.0000 scale=2.0000 norm=0.8389
[iter 400] loss=-0.7398 val_loss=0.0000 scale=1.0000 norm=0.4034
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3696 val_loss=0.0000 scale=2.0000 norm=0.9918
[iter 200] loss=-0.5889 val_loss=0.0000 scale=2.0000 norm=0.9513
[iter 300] loss=-1.5095 val_loss=0.0000 scale=2.0000 norm=0.9202
[iter 400] loss=-2.3266 val_loss=0.0000 scale=2.0000 norm=0.8119
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3871 val_loss=0.0000 scale=2.0000 norm=1.0500
[iter 200] loss=-0.2153 val_loss=0.0000 scale=2.0000 norm=0.8949
[iter 300] loss=-0.6392 val_loss=0.0000 scale=2.0000 norm=0.8009
[iter 400] loss=-0.9087 val_loss=0.0000 scale=1.0000 norm=0.3741
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2438 val_loss=0.0000 scale=2.0000 norm=1.0053
[iter 200] loss=-0.4468 val_loss=0.0000 scale=2.0000 norm=0.8827
[iter 300] loss=-0.8593 val_loss=0.0000 scale=2.0000 norm=0.8027
[iter 400] loss=-1.1823 val_loss=0.0000 scale=1.0000 norm=0.3765
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4035 val_loss=0.0000 scale=2.0000 norm=1.0451
[iter 200] loss=-0.2954 val_loss=0.0000 scale=1.0000 norm=0.4452
[iter 300] loss=-0.6713 val_loss=0.0000 scale=1.0000 norm=0.3843
[iter 400] loss=-0.9328 val_loss=0.0000 scale=1.0000 norm=0.3421
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3285 val_loss=0.0000 scale=1.0000 norm=0.5135
[iter 200] loss=-0.2041 val_loss=0.0000 scale=1.0000 norm=0.4500
[iter 300] loss=-0.6327 val_loss=0.0000 scale=1.0000 norm=0.4082
[iter 400] loss=-0.9481 val_loss=0.0000 scale=1.0000 norm=0.3889
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3327 val_loss=0.0000 scale=2.0000 norm=1.0423
[iter 200] loss=-0.2037 val_loss=0.0000 scale=2.0000 norm=0.9094
[iter 300] loss=-0.5384 val_loss=0.0000 scale=2.0000 norm=0.8310
[iter 400] loss=-0.7797 val_loss=0.0000 scale=2.0000 norm=0.7944
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5459 val_loss=0.0000 scale=2.0000 norm=1.0708
[iter 200] loss=-0.2366 val_loss=0.0000 scale=2.0000 norm=0.9077
[iter 300] loss=-0.7888 val_loss=0.0000 scale=1.0000 norm=0.3988
[iter 400] loss=-1.1475 val_loss=0.0000 scale=2.0000 norm=0.7170
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2959 val_loss=0.0000 scale=2.0000 norm=1.0271
[iter 200] loss=-0.2666 val_loss=0.0000 scale=2.0000 norm=0.8982
[iter 300] loss=-0.6759 val_loss=0.0000 scale=1.0000 norm=0.4177
[iter 400] loss=-0.9565 val_loss=0.0000 scale=1.0000 norm=0.4118
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4382 val_loss=0.0000 scale=2.0000 norm=1.0100
[iter 200] loss=-0.3900 val_loss=0.0000 scale=2.0000 norm=0.8817
[iter 300] loss=-1.0926 val_loss=0.0000 scale=2.0000 norm=0.8140
[iter 400] loss=-1.5681 val_loss=0.0000 scale=1.0000 norm=0.3898
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2161 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 200] loss=-0.5894 val_loss=0.0000 scale=2.0000 norm=0.8582
[iter 300] loss=-1.2435 val_loss=0.0000 scale=1.0000 norm=0.3767
[iter 400] loss=-1.7270 val_loss=0.0000 scale=1.0000 norm=0.3622
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2682 val_loss=0.0000 scale=1.0000 norm=0.5037
[iter 200] loss=-0.3960 val_loss=0.0000 scale=2.0000 norm=0.8991
[iter 300] loss=-0.9047 val_loss=0.0000 scale=2.0000 norm=0.8219
[iter 400] loss=-1.2447 val_loss=0.0000 scale=1.0000 norm=0.3813
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3588 val_loss=0.0000 scale=2.0000 norm=1.0202
[iter 200] loss=-0.1637 val_loss=0.0000 scale=1.0000 norm=0.4454
[iter 300] loss=-0.5460 val_loss=0.0000 scale=1.0000 norm=0.4096
[iter 400] loss=-0.8194 val_loss=0.0000 scale=1.0000 norm=0.3843
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4822 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.1726 val_loss=0.0000 scale=2.0000 norm=0.9073
[iter 300] loss=-0.6031 val_loss=0.0000 scale=1.0000 norm=0.4131
[iter 400] loss=-0.9956 val_loss=0.0000 scale=1.0000 norm=0.3793
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4442 val_loss=0.0000 scale=1.0000 norm=0.5343
[iter 200] loss=-0.0611 val_loss=0.0000 scale=1.0000 norm=0.4709
[iter 300] loss=-0.5078 val_loss=0.0000 scale=2.0000 norm=0.8397
[iter 400] loss=-0.8603 val_loss=0.0000 scale=1.0000 norm=0.3814
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2437 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 200] loss=-0.7503 val_loss=0.0000 scale=2.0000 norm=0.9853
[iter 300] loss=-2.1994 val_loss=0.0000 scale=4.0000 norm=1.9752
[iter 400] loss=-4.1723 val_loss=0.0000 scale=4.0000 norm=1.9644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3023 val_loss=0.0000 scale=2.0000 norm=1.0032
[iter 200] loss=-0.3304 val_loss=0.0000 scale=2.0000 norm=0.8825
[iter 300] loss=-0.8089 val_loss=0.0000 scale=1.0000 norm=0.3970
[iter 400] loss=-1.1227 val_loss=0.0000 scale=2.0000 norm=0.7471
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3559 val_loss=0.0000 scale=2.0000 norm=1.0249
[iter 200] loss=-0.1874 val_loss=0.0000 scale=2.0000 norm=0.8878
[iter 300] loss=-0.5872 val_loss=0.0000 scale=1.0000 norm=0.4040
[iter 400] loss=-0.8939 val_loss=0.0000 scale=1.0000 norm=0.3963
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3035 val_loss=0.0000 scale=2.0000 norm=1.0163
[iter 200] loss=-0.4747 val_loss=0.0000 scale=1.0000 norm=0.4420
[iter 300] loss=-0.9330 val_loss=0.0000 scale=2.0000 norm=0.7661
[iter 400] loss=-1.2216 val_loss=0.0000 scale=1.0000 norm=0.3558
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1477 val_loss=0.0000 scale=2.0000 norm=0.9896
[iter 200] loss=-0.8290 val_loss=0.0000 scale=2.0000 norm=0.9783
[iter 300] loss=-2.3012 val_loss=0.0000 scale=4.0000 norm=1.9895
[iter 400] loss=-4.2982 val_loss=0.0000 scale=4.0000 norm=1.9964
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2667 val_loss=0.0000 scale=2.0000 norm=0.9678
[iter 200] loss=-0.6591 val_loss=0.0000 scale=2.0000 norm=0.9288
[iter 300] loss=-1.5344 val_loss=0.0000 scale=2.0000 norm=0.8785
[iter 400] loss=-2.2963 val_loss=0.0000 scale=2.0000 norm=0.8129
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5782 val_loss=0.0000 scale=2.0000 norm=1.1656
[iter 200] loss=-0.0795 val_loss=0.0000 scale=2.0000 norm=0.9430
[iter 300] loss=-0.6751 val_loss=0.0000 scale=2.0000 norm=0.8238
[iter 400] loss=-1.0209 val_loss=0.0000 scale=1.0000 norm=0.4008
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2612 val_loss=0.0000 scale=2.0000 norm=0.9531
[iter 200] loss=-0.6809 val_loss=0.0000 scale=2.0000 norm=0.9436
[iter 300] loss=-1.6199 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-2.5472 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4190 val_loss=0.0000 scale=2.0000 norm=1.0650
[iter 200] loss=-0.1547 val_loss=0.0000 scale=2.0000 norm=0.9196
[iter 300] loss=-0.6387 val_loss=0.0000 scale=1.0000 norm=0.4259
[iter 400] loss=-0.9799 val_loss=0.0000 scale=1.0000 norm=0.3942
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5832 val_loss=0.0000 scale=2.0000 norm=1.1717
[iter 200] loss=0.0700 val_loss=0.0000 scale=1.0000 norm=0.5060
[iter 300] loss=-0.2567 val_loss=0.0000 scale=2.0000 norm=0.9274
[iter 400] loss=-0.5261 val_loss=0.0000 scale=1.0000 norm=0.4353
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0427 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-1.0293 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 300] loss=-2.3716 val_loss=0.0000 scale=2.0000 norm=0.9769
[iter 400] loss=-3.4761 val_loss=0.0000 scale=2.0000 norm=0.9691
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3439 val_loss=0.0000 scale=2.0000 norm=1.0054
[iter 200] loss=-0.4629 val_loss=0.0000 scale=2.0000 norm=0.8743
[iter 300] loss=-1.0489 val_loss=0.0000 scale=2.0000 norm=0.7985
[iter 400] loss=-1.4903 val_loss=0.0000 scale=2.0000 norm=0.6976
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3270 val_loss=0.0000 scale=2.0000 norm=1.0030
[iter 200] loss=-0.4038 val_loss=0.0000 scale=2.0000 norm=0.8592
[iter 300] loss=-0.9169 val_loss=0.0000 scale=1.0000 norm=0.3962
[iter 400] loss=-1.2362 val_loss=0.0000 scale=1.0000 norm=0.3779
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5470 val_loss=0.0000 scale=2.0000 norm=1.0684
[iter 200] loss=-0.3183 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 300] loss=-1.0990 val_loss=0.0000 scale=2.0000 norm=0.8239
[iter 400] loss=-1.7276 val_loss=0.0000 scale=2.0000 norm=0.7155
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2904 val_loss=0.0000 scale=2.0000 norm=1.0180
[iter 200] loss=-0.2699 val_loss=0.0000 scale=1.0000 norm=0.4572
[iter 300] loss=-0.6250 val_loss=0.0000 scale=1.0000 norm=0.4209
[iter 400] loss=-0.8909 val_loss=0.0000 scale=1.0000 norm=0.4063
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3354 val_loss=0.0000 scale=1.0000 norm=0.5030
[iter 200] loss=-0.2012 val_loss=0.0000 scale=2.0000 norm=0.8758
[iter 300] loss=-0.5644 val_loss=0.0000 scale=1.0000 norm=0.4018
[iter 400] loss=-0.8613 val_loss=0.0000 scale=1.0000 norm=0.3708
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3112 val_loss=0.0000 scale=2.0000 norm=1.0230
[iter 200] loss=-0.2570 val_loss=0.0000 scale=1.0000 norm=0.4446
[iter 300] loss=-0.6274 val_loss=0.0000 scale=2.0000 norm=0.8159
[iter 400] loss=-0.9000 val_loss=0.0000 scale=1.0000 norm=0.3851
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2153 val_loss=0.0000 scale=2.0000 norm=0.9750
[iter 200] loss=-0.7325 val_loss=0.0000 scale=2.0000 norm=0.9449
[iter 300] loss=-1.6326 val_loss=0.0000 scale=2.0000 norm=0.8978
[iter 400] loss=-2.4360 val_loss=0.0000 scale=2.0000 norm=0.7973
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4053 val_loss=0.0000 scale=2.0000 norm=1.0550
[iter 200] loss=-0.1839 val_loss=0.0000 scale=2.0000 norm=0.9091
[iter 300] loss=-0.6045 val_loss=0.0000 scale=2.0000 norm=0.8255
[iter 400] loss=-0.9206 val_loss=0.0000 scale=1.0000 norm=0.3927
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5368 val_loss=0.0000 scale=2.0000 norm=1.0673
[iter 200] loss=-0.0735 val_loss=0.0000 scale=2.0000 norm=0.9202
[iter 300] loss=-0.5980 val_loss=0.0000 scale=1.0000 norm=0.4049
[iter 400] loss=-0.9988 val_loss=0.0000 scale=1.0000 norm=0.3945
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3075 val_loss=0.0000 scale=2.0000 norm=1.0163
[iter 200] loss=-0.2485 val_loss=0.0000 scale=2.0000 norm=0.8944
[iter 300] loss=-0.6274 val_loss=0.0000 scale=1.0000 norm=0.4360
[iter 400] loss=-0.9297 val_loss=0.0000 scale=2.0000 norm=0.8527
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2537 val_loss=0.0000 scale=2.0000 norm=1.0222
[iter 200] loss=-0.4668 val_loss=0.0000 scale=2.0000 norm=0.8861
[iter 300] loss=-0.9499 val_loss=0.0000 scale=1.0000 norm=0.4046
[iter 400] loss=-1.3277 val_loss=0.0000 scale=2.0000 norm=0.7383
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1998 val_loss=0.0000 scale=2.0000 norm=0.9848
[iter 200] loss=-0.6092 val_loss=0.0000 scale=2.0000 norm=0.8835
[iter 300] loss=-1.1632 val_loss=0.0000 scale=2.0000 norm=0.7973
[iter 400] loss=-1.5290 val_loss=0.0000 scale=2.0000 norm=0.7566
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2955 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.2756 val_loss=0.0000 scale=2.0000 norm=0.8944
[iter 300] loss=-0.7346 val_loss=0.0000 scale=2.0000 norm=0.8455
[iter 400] loss=-1.1179 val_loss=0.0000 scale=1.0000 norm=0.4046
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1947 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 200] loss=-0.7912 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 300] loss=-1.9578 val_loss=0.0000 scale=4.0000 norm=1.9616
[iter 400] loss=-3.4037 val_loss=0.0000 scale=4.0000 norm=1.9813
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4502 val_loss=0.0000 scale=2.0000 norm=1.0897
[iter 200] loss=-0.1189 val_loss=0.0000 scale=1.0000 norm=0.4604
[iter 300] loss=-0.4630 val_loss=0.0000 scale=1.0000 norm=0.4224
[iter 400] loss=-0.6699 val_loss=0.0000 scale=0.5000 norm=0.2068
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2839 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.3562 val_loss=0.0000 scale=1.0000 norm=0.4486
[iter 300] loss=-0.9526 val_loss=0.0000 scale=1.0000 norm=0.4123
[iter 400] loss=-1.3689 val_loss=0.0000 scale=2.0000 norm=0.7702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2787 val_loss=0.0000 scale=2.0000 norm=1.0075
[iter 200] loss=-0.5175 val_loss=0.0000 scale=2.0000 norm=0.8698
[iter 300] loss=-1.1014 val_loss=0.0000 scale=2.0000 norm=0.7467
[iter 400] loss=-1.4552 val_loss=0.0000 scale=2.0000 norm=0.6744
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2340 val_loss=0.0000 scale=2.0000 norm=1.0068
[iter 200] loss=-0.4479 val_loss=0.0000 scale=1.0000 norm=0.4312
[iter 300] loss=-0.9605 val_loss=0.0000 scale=2.0000 norm=0.7940
[iter 400] loss=-1.3522 val_loss=0.0000 scale=1.0000 norm=0.3749
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3063 val_loss=0.0000 scale=2.0000 norm=1.0221
[iter 200] loss=-0.2613 val_loss=0.0000 scale=1.0000 norm=0.4479
[iter 300] loss=-0.6734 val_loss=0.0000 scale=2.0000 norm=0.8313
[iter 400] loss=-0.9868 val_loss=0.0000 scale=1.0000 norm=0.3983
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4587 val_loss=0.0000 scale=1.0000 norm=0.5356
[iter 200] loss=-0.1002 val_loss=0.0000 scale=2.0000 norm=0.9004
[iter 300] loss=-0.5610 val_loss=0.0000 scale=1.0000 norm=0.3860
[iter 400] loss=-0.8541 val_loss=0.0000 scale=1.0000 norm=0.3655
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2948 val_loss=0.0000 scale=2.0000 norm=1.0293
[iter 200] loss=-0.2243 val_loss=0.0000 scale=1.0000 norm=0.4592
[iter 300] loss=-0.6447 val_loss=0.0000 scale=1.0000 norm=0.4116
[iter 400] loss=-0.9179 val_loss=0.0000 scale=2.0000 norm=0.7765
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3181 val_loss=0.0000 scale=2.0000 norm=1.0246
[iter 200] loss=-0.2775 val_loss=0.0000 scale=1.0000 norm=0.4467
[iter 300] loss=-0.6750 val_loss=0.0000 scale=2.0000 norm=0.8244
[iter 400] loss=-0.9288 val_loss=0.0000 scale=1.0000 norm=0.3990
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2976 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6129 val_loss=0.0000 scale=2.0000 norm=0.9203
[iter 300] loss=-1.5383 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 400] loss=-2.4572 val_loss=0.0000 scale=2.0000 norm=0.9171
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3862 val_loss=0.0000 scale=1.0000 norm=0.5314
[iter 200] loss=-0.1932 val_loss=0.0000 scale=1.0000 norm=0.4583
[iter 300] loss=-0.5544 val_loss=0.0000 scale=1.0000 norm=0.4189
[iter 400] loss=-0.7983 val_loss=0.0000 scale=1.0000 norm=0.3963
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2547 val_loss=0.0000 scale=2.0000 norm=0.9941
[iter 200] loss=-0.4212 val_loss=0.0000 scale=2.0000 norm=0.8659
[iter 300] loss=-0.8470 val_loss=0.0000 scale=1.0000 norm=0.3950
[iter 400] loss=-1.1417 val_loss=0.0000 scale=0.5000 norm=0.1825
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2641 val_loss=0.0000 scale=2.0000 norm=1.0036
[iter 200] loss=-0.4553 val_loss=0.0000 scale=2.0000 norm=0.9037
[iter 300] loss=-0.9307 val_loss=0.0000 scale=2.0000 norm=0.8185
[iter 400] loss=-1.2182 val_loss=0.0000 scale=1.0000 norm=0.3832
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2322 val_loss=0.0000 scale=2.0000 norm=1.0201
[iter 200] loss=-0.4862 val_loss=0.0000 scale=2.0000 norm=0.9212
[iter 300] loss=-1.0956 val_loss=0.0000 scale=2.0000 norm=0.8189
[iter 400] loss=-1.4639 val_loss=0.0000 scale=2.0000 norm=0.7288
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4039 val_loss=0.0000 scale=2.0000 norm=1.0672
[iter 200] loss=0.0062 val_loss=0.0000 scale=1.0000 norm=0.4842
[iter 300] loss=-0.3844 val_loss=0.0000 scale=2.0000 norm=0.8693
[iter 400] loss=-0.6565 val_loss=0.0000 scale=1.0000 norm=0.4084
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3427 val_loss=0.0000 scale=2.0000 norm=1.0302
[iter 200] loss=-0.2624 val_loss=0.0000 scale=2.0000 norm=0.9129
[iter 300] loss=-0.7940 val_loss=0.0000 scale=1.0000 norm=0.4090
[iter 400] loss=-1.1537 val_loss=0.0000 scale=1.0000 norm=0.3833
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2997 val_loss=0.0000 scale=2.0000 norm=1.0092
[iter 200] loss=-0.1928 val_loss=0.0000 scale=1.0000 norm=0.4505
[iter 300] loss=-0.5314 val_loss=0.0000 scale=1.0000 norm=0.4106
[iter 400] loss=-0.7991 val_loss=0.0000 scale=1.0000 norm=0.3829
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1786 val_loss=0.0000 scale=2.0000 norm=0.9804
[iter 200] loss=-0.6303 val_loss=0.0000 scale=2.0000 norm=0.8575
[iter 300] loss=-1.1978 val_loss=0.0000 scale=2.0000 norm=0.7412
[iter 400] loss=-1.5463 val_loss=0.0000 scale=1.0000 norm=0.3347
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3213 val_loss=0.0000 scale=2.0000 norm=1.0105
[iter 200] loss=-0.5753 val_loss=0.0000 scale=2.0000 norm=0.9089
[iter 300] loss=-1.4201 val_loss=0.0000 scale=2.0000 norm=0.8621
[iter 400] loss=-2.1921 val_loss=0.0000 scale=2.0000 norm=0.7766
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4576 val_loss=0.0000 scale=1.0000 norm=0.5508
[iter 200] loss=-0.1560 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 300] loss=-0.5858 val_loss=0.0000 scale=1.0000 norm=0.4420
[iter 400] loss=-0.9143 val_loss=0.0000 scale=1.0000 norm=0.4146
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3406 val_loss=0.0000 scale=1.0000 norm=0.5228
[iter 200] loss=-0.1878 val_loss=0.0000 scale=2.0000 norm=0.9080
[iter 300] loss=-0.6543 val_loss=0.0000 scale=1.0000 norm=0.4031
[iter 400] loss=-0.9399 val_loss=0.0000 scale=1.0000 norm=0.3893
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5387 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.4141 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 300] loss=-1.3785 val_loss=0.0000 scale=2.0000 norm=0.9609
[iter 400] loss=-2.3169 val_loss=0.0000 scale=2.0000 norm=0.9379
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1914 val_loss=0.0000 scale=2.0000 norm=0.9834
[iter 200] loss=-0.7888 val_loss=0.0000 scale=2.0000 norm=0.9744
[iter 300] loss=-1.7596 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 400] loss=-2.7381 val_loss=0.0000 scale=2.0000 norm=0.9777
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3554 val_loss=0.0000 scale=2.0000 norm=1.0353
[iter 200] loss=-0.3658 val_loss=0.0000 scale=2.0000 norm=0.8859
[iter 300] loss=-0.8582 val_loss=0.0000 scale=1.0000 norm=0.3978
[iter 400] loss=-1.1832 val_loss=0.0000 scale=1.0000 norm=0.3604
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4767 val_loss=0.0000 scale=2.0000 norm=1.0742
[iter 200] loss=-0.2622 val_loss=0.0000 scale=1.0000 norm=0.4556
[iter 300] loss=-0.8742 val_loss=0.0000 scale=2.0000 norm=0.8345
[iter 400] loss=-1.3842 val_loss=0.0000 scale=1.0000 norm=0.3821
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2438 val_loss=0.0000 scale=2.0000 norm=1.0078
[iter 200] loss=-0.4106 val_loss=0.0000 scale=1.0000 norm=0.4474
[iter 300] loss=-0.8685 val_loss=0.0000 scale=1.0000 norm=0.4060
[iter 400] loss=-1.1821 val_loss=0.0000 scale=1.0000 norm=0.3835
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.6414 val_loss=0.0000 scale=2.0000 norm=1.1472
[iter 200] loss=0.0700 val_loss=0.0000 scale=1.0000 norm=0.4816
[iter 300] loss=-0.3214 val_loss=0.0000 scale=1.0000 norm=0.4462
[iter 400] loss=-0.6355 val_loss=0.0000 scale=1.0000 norm=0.4018
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6764 val_loss=0.0000 scale=1.0000 norm=0.5986
[iter 200] loss=0.0983 val_loss=0.0000 scale=2.0000 norm=0.9840
[iter 300] loss=-0.2283 val_loss=0.0000 scale=1.0000 norm=0.4552
[iter 400] loss=-0.5133 val_loss=0.0000 scale=2.0000 norm=0.8699
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5584 val_loss=0.0000 scale=2.0000 norm=1.0879
[iter 200] loss=-0.1211 val_loss=0.0000 scale=1.0000 norm=0.4622
[iter 300] loss=-0.6467 val_loss=0.0000 scale=2.0000 norm=0.8335
[iter 400] loss=-1.0417 val_loss=0.0000 scale=1.0000 norm=0.3782
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3133 val_loss=0.0000 scale=2.0000 norm=1.0192
[iter 200] loss=-0.2061 val_loss=0.0000 scale=1.0000 norm=0.4590
[iter 300] loss=-0.6258 val_loss=0.0000 scale=2.0000 norm=0.8503
[iter 400] loss=-0.9642 val_loss=0.0000 scale=1.0000 norm=0.4081
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2063 val_loss=0.0000 scale=2.0000 norm=0.9554
[iter 200] loss=-0.7452 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 300] loss=-1.7049 val_loss=0.0000 scale=2.0000 norm=0.9596
[iter 400] loss=-2.6586 val_loss=0.0000 scale=2.0000 norm=0.9531
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3993 val_loss=0.0000 scale=2.0000 norm=1.0549
[iter 200] loss=-0.1889 val_loss=0.0000 scale=1.0000 norm=0.4575
[iter 300] loss=-0.5214 val_loss=0.0000 scale=1.0000 norm=0.4272
[iter 400] loss=-0.8099 val_loss=0.0000 scale=1.0000 norm=0.4166
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3491 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 200] loss=-0.2940 val_loss=0.0000 scale=1.0000 norm=0.4402
[iter 300] loss=-0.7056 val_loss=0.0000 scale=1.0000 norm=0.3962
[iter 400] loss=-1.0268 val_loss=0.0000 scale=1.0000 norm=0.3702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1304 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.8485 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 300] loss=-1.8290 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 400] loss=-2.9140 val_loss=0.0000 scale=2.0000 norm=0.9778
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3181 val_loss=0.0000 scale=1.0000 norm=0.5166
[iter 200] loss=-0.2381 val_loss=0.0000 scale=2.0000 norm=0.9201
[iter 300] loss=-0.6899 val_loss=0.0000 scale=2.0000 norm=0.8598
[iter 400] loss=-0.9984 val_loss=0.0000 scale=1.0000 norm=0.4164
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2235 val_loss=0.0000 scale=2.0000 norm=0.9897
[iter 200] loss=-0.5944 val_loss=0.0000 scale=2.0000 norm=0.8590
[iter 300] loss=-1.2221 val_loss=0.0000 scale=1.0000 norm=0.3617
[iter 400] loss=-1.5894 val_loss=0.0000 scale=2.0000 norm=0.6676
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2193 val_loss=0.0000 scale=2.0000 norm=0.9894
[iter 200] loss=-0.5191 val_loss=0.0000 scale=2.0000 norm=0.8687
[iter 300] loss=-1.0365 val_loss=0.0000 scale=1.0000 norm=0.3843
[iter 400] loss=-1.3709 val_loss=0.0000 scale=2.0000 norm=0.7331
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2776 val_loss=0.0000 scale=2.0000 norm=1.0110
[iter 200] loss=-0.2342 val_loss=0.0000 scale=2.0000 norm=0.8876
[iter 300] loss=-0.5984 val_loss=0.0000 scale=1.0000 norm=0.4101
[iter 400] loss=-0.8232 val_loss=0.0000 scale=1.0000 norm=0.3847
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3291 val_loss=0.0000 scale=2.0000 norm=1.0390
[iter 200] loss=-0.2265 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 300] loss=-0.5875 val_loss=0.0000 scale=1.0000 norm=0.4278
[iter 400] loss=-0.8596 val_loss=0.0000 scale=1.0000 norm=0.4121
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4478 val_loss=0.0000 scale=2.0000 norm=1.0637
[iter 200] loss=-0.0479 val_loss=0.0000 scale=1.0000 norm=0.4714
[iter 300] loss=-0.5160 val_loss=0.0000 scale=1.0000 norm=0.4236
[iter 400] loss=-0.8629 val_loss=0.0000 scale=2.0000 norm=0.7795
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3731 val_loss=0.0000 scale=1.0000 norm=0.5264
[iter 200] loss=-0.0295 val_loss=0.0000 scale=1.0000 norm=0.4774
[iter 300] loss=-0.4411 val_loss=0.0000 scale=2.0000 norm=0.8463
[iter 400] loss=-0.7661 val_loss=0.0000 scale=2.0000 norm=0.8075
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2690 val_loss=0.0000 scale=2.0000 norm=1.0021
[iter 200] loss=-0.4047 val_loss=0.0000 scale=2.0000 norm=0.9027
[iter 300] loss=-1.1357 val_loss=0.0000 scale=2.0000 norm=0.8252
[iter 400] loss=-1.6107 val_loss=0.0000 scale=1.0000 norm=0.3834
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3070 val_loss=0.0000 scale=1.0000 norm=0.5134
[iter 200] loss=-0.2732 val_loss=0.0000 scale=2.0000 norm=0.8891
[iter 300] loss=-0.6757 val_loss=0.0000 scale=1.0000 norm=0.4056
[iter 400] loss=-0.9749 val_loss=0.0000 scale=1.0000 norm=0.3832
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2767 val_loss=0.0000 scale=2.0000 norm=1.0284
[iter 200] loss=-0.3166 val_loss=0.0000 scale=2.0000 norm=0.8866
[iter 300] loss=-0.8282 val_loss=0.0000 scale=2.0000 norm=0.7963
[iter 400] loss=-1.1091 val_loss=0.0000 scale=1.0000 norm=0.3661
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3067 val_loss=0.0000 scale=1.0000 norm=0.5097
[iter 200] loss=-0.2210 val_loss=0.0000 scale=1.0000 norm=0.4549
[iter 300] loss=-0.6384 val_loss=0.0000 scale=1.0000 norm=0.4159
[iter 400] loss=-0.9749 val_loss=0.0000 scale=1.0000 norm=0.3841
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4963 val_loss=0.0000 scale=1.0000 norm=0.5417
[iter 200] loss=-0.1429 val_loss=0.0000 scale=2.0000 norm=0.9040
[iter 300] loss=-0.6747 val_loss=0.0000 scale=2.0000 norm=0.7820
[iter 400] loss=-1.0206 val_loss=0.0000 scale=2.0000 norm=0.7482
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2768 val_loss=0.0000 scale=2.0000 norm=1.0182
[iter 200] loss=-0.2389 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 300] loss=-0.6791 val_loss=0.0000 scale=2.0000 norm=0.8030
[iter 400] loss=-0.9766 val_loss=0.0000 scale=2.0000 norm=0.7389
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5426 val_loss=0.0000 scale=2.0000 norm=1.0716
[iter 200] loss=-0.2022 val_loss=0.0000 scale=2.0000 norm=0.8810
[iter 300] loss=-0.8214 val_loss=0.0000 scale=2.0000 norm=0.7786
[iter 400] loss=-1.2373 val_loss=0.0000 scale=1.0000 norm=0.3733
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3225 val_loss=0.0000 scale=1.0000 norm=0.5126
[iter 200] loss=-0.3048 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 300] loss=-0.8289 val_loss=0.0000 scale=1.0000 norm=0.3974
[iter 400] loss=-1.1691 val_loss=0.0000 scale=1.0000 norm=0.3760
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3279 val_loss=0.0000 scale=2.0000 norm=1.0198
[iter 200] loss=-0.3342 val_loss=0.0000 scale=2.0000 norm=0.8643
[iter 300] loss=-0.8303 val_loss=0.0000 scale=1.0000 norm=0.3957
[iter 400] loss=-1.0886 val_loss=0.0000 scale=1.0000 norm=0.3660
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5532 val_loss=0.0000 scale=2.0000 norm=1.1288
[iter 200] loss=0.0344 val_loss=0.0000 scale=1.0000 norm=0.4935
[iter 300] loss=-0.4333 val_loss=0.0000 scale=2.0000 norm=0.8909
[iter 400] loss=-0.8231 val_loss=0.0000 scale=1.0000 norm=0.4096
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2969 val_loss=0.0000 scale=1.0000 norm=0.5111
[iter 200] loss=-0.2979 val_loss=0.0000 scale=1.0000 norm=0.4471
[iter 300] loss=-0.6364 val_loss=0.0000 scale=1.0000 norm=0.4138
[iter 400] loss=-0.9169 val_loss=0.0000 scale=1.0000 norm=0.3918
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3028 val_loss=0.0000 scale=1.0000 norm=0.5145
[iter 200] loss=-0.2650 val_loss=0.0000 scale=1.0000 norm=0.4502
[iter 300] loss=-0.6712 val_loss=0.0000 scale=2.0000 norm=0.8631
[iter 400] loss=-0.9838 val_loss=0.0000 scale=1.0000 norm=0.4356
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3904 val_loss=0.0000 scale=2.0000 norm=1.0516
[iter 200] loss=-0.0623 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 300] loss=-0.4134 val_loss=0.0000 scale=1.0000 norm=0.4311
[iter 400] loss=-0.7256 val_loss=0.0000 scale=1.0000 norm=0.4065
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3162 val_loss=0.0000 scale=1.0000 norm=0.5186
[iter 200] loss=-0.1819 val_loss=0.0000 scale=2.0000 norm=0.9061
[iter 300] loss=-0.6213 val_loss=0.0000 scale=1.0000 norm=0.4214
[iter 400] loss=-0.8997 val_loss=0.0000 scale=1.0000 norm=0.4055
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3235 val_loss=0.0000 scale=2.0000 norm=1.0164
[iter 200] loss=-0.4479 val_loss=0.0000 scale=2.0000 norm=0.8762
[iter 300] loss=-1.0558 val_loss=0.0000 scale=2.0000 norm=0.7765
[iter 400] loss=-1.5036 val_loss=0.0000 scale=2.0000 norm=0.7083
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3244 val_loss=0.0000 scale=2.0000 norm=0.9869
[iter 200] loss=-0.4997 val_loss=0.0000 scale=2.0000 norm=0.8702
[iter 300] loss=-1.1838 val_loss=0.0000 scale=2.0000 norm=0.7704
[iter 400] loss=-1.7553 val_loss=0.0000 scale=1.0000 norm=0.3245
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3771 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.3453 val_loss=0.0000 scale=2.0000 norm=0.8963
[iter 300] loss=-0.9561 val_loss=0.0000 scale=2.0000 norm=0.8199
[iter 400] loss=-1.3549 val_loss=0.0000 scale=1.0000 norm=0.3796
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3150 val_loss=0.0000 scale=2.0000 norm=1.0135
[iter 200] loss=-0.3773 val_loss=0.0000 scale=2.0000 norm=0.8612
[iter 300] loss=-0.8468 val_loss=0.0000 scale=1.0000 norm=0.3978
[iter 400] loss=-1.1257 val_loss=0.0000 scale=0.5000 norm=0.1953
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2913 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 200] loss=-0.3589 val_loss=0.0000 scale=2.0000 norm=0.8636
[iter 300] loss=-0.7465 val_loss=0.0000 scale=1.0000 norm=0.3836
[iter 400] loss=-0.9738 val_loss=0.0000 scale=1.0000 norm=0.3662
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2037 val_loss=0.0000 scale=2.0000 norm=0.9852
[iter 200] loss=-0.7354 val_loss=0.0000 scale=2.0000 norm=0.9367
[iter 300] loss=-1.6097 val_loss=0.0000 scale=2.0000 norm=0.8748
[iter 400] loss=-2.3698 val_loss=0.0000 scale=2.0000 norm=0.7786
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2881 val_loss=0.0000 scale=2.0000 norm=1.0055
[iter 200] loss=-0.3477 val_loss=0.0000 scale=1.0000 norm=0.4397
[iter 300] loss=-0.7987 val_loss=0.0000 scale=1.0000 norm=0.4065
[iter 400] loss=-1.0800 val_loss=0.0000 scale=1.0000 norm=0.3852
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2902 val_loss=0.0000 scale=2.0000 norm=1.0173
[iter 200] loss=-0.3975 val_loss=0.0000 scale=2.0000 norm=0.8521
[iter 300] loss=-0.7941 val_loss=0.0000 scale=1.0000 norm=0.3830
[iter 400] loss=-1.0547 val_loss=0.0000 scale=1.0000 norm=0.3587
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1834 val_loss=0.0000 scale=2.0000 norm=0.9883
[iter 200] loss=-0.9052 val_loss=0.0000 scale=4.0000 norm=1.9871
[iter 300] loss=-2.8988 val_loss=0.0000 scale=4.0000 norm=1.9880
[iter 400] loss=-4.7617 val_loss=0.0000 scale=4.0000 norm=1.8447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2515 val_loss=0.0000 scale=2.0000 norm=0.9937
[iter 200] loss=-0.4832 val_loss=0.0000 scale=2.0000 norm=0.8817
[iter 300] loss=-0.9584 val_loss=0.0000 scale=2.0000 norm=0.7950
[iter 400] loss=-1.2923 val_loss=0.0000 scale=1.0000 norm=0.3659
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3704 val_loss=0.0000 scale=2.0000 norm=1.0388
[iter 200] loss=-0.2208 val_loss=0.0000 scale=2.0000 norm=0.9258
[iter 300] loss=-0.6965 val_loss=0.0000 scale=2.0000 norm=0.8618
[iter 400] loss=-1.0094 val_loss=0.0000 scale=1.0000 norm=0.4100
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2729 val_loss=0.0000 scale=2.0000 norm=1.0339
[iter 200] loss=-0.2001 val_loss=0.0000 scale=2.0000 norm=0.9224
[iter 300] loss=-0.6405 val_loss=0.0000 scale=1.0000 norm=0.4250
[iter 400] loss=-0.9148 val_loss=0.0000 scale=1.0000 norm=0.4034
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3216 val_loss=0.0000 scale=2.0000 norm=1.0259
[iter 200] loss=-0.1181 val_loss=0.0000 scale=2.0000 norm=0.9119
[iter 300] loss=-0.5130 val_loss=0.0000 scale=1.0000 norm=0.4185
[iter 400] loss=-0.8094 val_loss=0.0000 scale=1.0000 norm=0.3994
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2177 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.5821 val_loss=0.0000 scale=1.0000 norm=0.4353
[iter 300] loss=-1.0603 val_loss=0.0000 scale=2.0000 norm=0.7790
[iter 400] loss=-1.4088 val_loss=0.0000 scale=2.0000 norm=0.7664
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3372 val_loss=0.0000 scale=1.0000 norm=0.5190
[iter 200] loss=-0.2037 val_loss=0.0000 scale=2.0000 norm=0.9080
[iter 300] loss=-0.5904 val_loss=0.0000 scale=0.5000 norm=0.2065
[iter 400] loss=-0.7923 val_loss=0.0000 scale=1.0000 norm=0.3976
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3136 val_loss=0.0000 scale=2.0000 norm=1.0220
[iter 200] loss=-0.1845 val_loss=0.0000 scale=2.0000 norm=0.8936
[iter 300] loss=-0.5806 val_loss=0.0000 scale=1.0000 norm=0.4129
[iter 400] loss=-0.8242 val_loss=0.0000 scale=0.5000 norm=0.1984
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3160 val_loss=0.0000 scale=2.0000 norm=1.0266
[iter 200] loss=-0.2884 val_loss=0.0000 scale=2.0000 norm=0.8986
[iter 300] loss=-0.7834 val_loss=0.0000 scale=1.0000 norm=0.4130
[iter 400] loss=-1.0716 val_loss=0.0000 scale=0.5000 norm=0.1967
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4114 val_loss=0.0000 scale=2.0000 norm=1.0752
[iter 200] loss=-0.1033 val_loss=0.0000 scale=1.0000 norm=0.4604
[iter 300] loss=-0.4539 val_loss=0.0000 scale=2.0000 norm=0.8306
[iter 400] loss=-0.7595 val_loss=0.0000 scale=1.0000 norm=0.3831
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3137 val_loss=0.0000 scale=2.0000 norm=1.0367
[iter 200] loss=-0.1821 val_loss=0.0000 scale=1.0000 norm=0.4655
[iter 300] loss=-0.5745 val_loss=0.0000 scale=2.0000 norm=0.8542
[iter 400] loss=-0.8609 val_loss=0.0000 scale=1.0000 norm=0.4025
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3426 val_loss=0.0000 scale=2.0000 norm=1.0390
[iter 200] loss=-0.3482 val_loss=0.0000 scale=2.0000 norm=0.8819
[iter 300] loss=-0.7493 val_loss=0.0000 scale=2.0000 norm=0.8221
[iter 400] loss=-0.9768 val_loss=0.0000 scale=2.0000 norm=0.8056
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1987 val_loss=0.0000 scale=2.0000 norm=1.0027
[iter 200] loss=-0.7046 val_loss=0.0000 scale=2.0000 norm=0.9157
[iter 300] loss=-1.5354 val_loss=0.0000 scale=2.0000 norm=0.8347
[iter 400] loss=-2.1520 val_loss=0.0000 scale=2.0000 norm=0.7367
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2750 val_loss=0.0000 scale=2.0000 norm=1.0232
[iter 200] loss=-0.2924 val_loss=0.0000 scale=1.0000 norm=0.4516
[iter 300] loss=-0.7386 val_loss=0.0000 scale=2.0000 norm=0.8402
[iter 400] loss=-1.0090 val_loss=0.0000 scale=2.0000 norm=0.8130
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1677 val_loss=0.0000 scale=2.0000 norm=0.9776
[iter 200] loss=-0.6672 val_loss=0.0000 scale=2.0000 norm=0.8581
[iter 300] loss=-1.2965 val_loss=0.0000 scale=2.0000 norm=0.7516
[iter 400] loss=-1.6973 val_loss=0.0000 scale=2.0000 norm=0.7168
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3871 val_loss=0.0000 scale=2.0000 norm=1.0470
[iter 200] loss=-0.1891 val_loss=0.0000 scale=1.0000 norm=0.4669
[iter 300] loss=-0.5970 val_loss=0.0000 scale=1.0000 norm=0.4245
[iter 400] loss=-0.9182 val_loss=0.0000 scale=1.0000 norm=0.4005
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3440 val_loss=0.0000 scale=1.0000 norm=0.5228
[iter 200] loss=-0.1330 val_loss=0.0000 scale=1.0000 norm=0.4666
[iter 300] loss=-0.5830 val_loss=0.0000 scale=1.0000 norm=0.4341
[iter 400] loss=-0.8862 val_loss=0.0000 scale=1.0000 norm=0.4201
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3438 val_loss=0.0000 scale=2.0000 norm=1.0484
[iter 200] loss=-0.2176 val_loss=0.0000 scale=1.0000 norm=0.4663
[iter 300] loss=-0.6554 val_loss=0.0000 scale=1.0000 norm=0.4359
[iter 400] loss=-0.9688 val_loss=0.0000 scale=1.0000 norm=0.4118

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n13>
Subject: Job 856541: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:24 2024
Job was executed on host(s) <4*c205n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:26 2024
                            <4*c205n14>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:11:26 2024
Terminated at Wed Oct 23 12:35:51 2024
Results reported at Wed Oct 23 12:35:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3011.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.06 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1479 sec.
    Turnaround time :                            1467 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err> for stderr output of this job.

RRU Monomer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4057 val_loss=0.0000 scale=2.0000 norm=1.0405
[iter 200] loss=-0.3106 val_loss=0.0000 scale=1.0000 norm=0.4403
[iter 300] loss=-0.7653 val_loss=0.0000 scale=1.0000 norm=0.4015
[iter 400] loss=-1.0983 val_loss=0.0000 scale=1.0000 norm=0.3757
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2931 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 200] loss=-0.3742 val_loss=0.0000 scale=1.0000 norm=0.4313
[iter 300] loss=-0.8868 val_loss=0.0000 scale=2.0000 norm=0.7519
[iter 400] loss=-1.2301 val_loss=0.0000 scale=1.0000 norm=0.3477
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2993 val_loss=0.0000 scale=2.0000 norm=1.0051
[iter 200] loss=-0.2625 val_loss=0.0000 scale=1.0000 norm=0.4431
[iter 300] loss=-0.5948 val_loss=0.0000 scale=1.0000 norm=0.4080
[iter 400] loss=-0.8670 val_loss=0.0000 scale=1.0000 norm=0.3885
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3357 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.2812 val_loss=0.0000 scale=2.0000 norm=0.8931
[iter 300] loss=-0.6470 val_loss=0.0000 scale=1.0000 norm=0.4073
[iter 400] loss=-0.9022 val_loss=0.0000 scale=1.0000 norm=0.3963
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4074 val_loss=0.0000 scale=2.0000 norm=1.0463
[iter 200] loss=-0.2965 val_loss=0.0000 scale=2.0000 norm=0.8916
[iter 300] loss=-0.8006 val_loss=0.0000 scale=2.0000 norm=0.7468
[iter 400] loss=-1.0690 val_loss=0.0000 scale=1.0000 norm=0.3375
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1477 val_loss=0.0000 scale=2.0000 norm=0.9896
[iter 200] loss=-0.8282 val_loss=0.0000 scale=2.0000 norm=0.9773
[iter 300] loss=-2.1911 val_loss=0.0000 scale=4.0000 norm=1.9918
[iter 400] loss=-4.1887 val_loss=0.0000 scale=4.0000 norm=1.9971
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4506 val_loss=0.0000 scale=2.0000 norm=1.0660
[iter 200] loss=-0.1621 val_loss=0.0000 scale=2.0000 norm=0.8878
[iter 300] loss=-0.6115 val_loss=0.0000 scale=1.0000 norm=0.3922
[iter 400] loss=-0.9160 val_loss=0.0000 scale=1.0000 norm=0.3673
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2865 val_loss=0.0000 scale=1.0000 norm=0.5133
[iter 200] loss=-0.2985 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 300] loss=-0.7522 val_loss=0.0000 scale=1.0000 norm=0.4234
[iter 400] loss=-1.1155 val_loss=0.0000 scale=2.0000 norm=0.7866
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3121 val_loss=0.0000 scale=2.0000 norm=1.0277
[iter 200] loss=-0.2107 val_loss=0.0000 scale=2.0000 norm=0.9086
[iter 300] loss=-0.5770 val_loss=0.0000 scale=2.0000 norm=0.8342
[iter 400] loss=-0.8613 val_loss=0.0000 scale=2.0000 norm=0.8100
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2612 val_loss=0.0000 scale=2.0000 norm=0.9531
[iter 200] loss=-0.6809 val_loss=0.0000 scale=2.0000 norm=0.9436
[iter 300] loss=-1.6199 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-2.5472 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3172 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.2332 val_loss=0.0000 scale=1.0000 norm=0.4470
[iter 300] loss=-0.6072 val_loss=0.0000 scale=1.0000 norm=0.4064
[iter 400] loss=-0.8459 val_loss=0.0000 scale=0.5000 norm=0.1919
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2786 val_loss=0.0000 scale=2.0000 norm=0.9642
[iter 200] loss=-0.6058 val_loss=0.0000 scale=2.0000 norm=0.8955
[iter 300] loss=-1.4206 val_loss=0.0000 scale=2.0000 norm=0.8239
[iter 400] loss=-2.1773 val_loss=0.0000 scale=2.0000 norm=0.7743
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4890 val_loss=0.0000 scale=1.0000 norm=0.5493
[iter 200] loss=-0.0254 val_loss=0.0000 scale=1.0000 norm=0.4724
[iter 300] loss=-0.4446 val_loss=0.0000 scale=1.0000 norm=0.4238
[iter 400] loss=-0.7064 val_loss=0.0000 scale=1.0000 norm=0.4098
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1877 val_loss=0.0000 scale=2.0000 norm=0.9862
[iter 200] loss=-0.6874 val_loss=0.0000 scale=2.0000 norm=0.8935
[iter 300] loss=-1.4810 val_loss=0.0000 scale=2.0000 norm=0.8033
[iter 400] loss=-2.1003 val_loss=0.0000 scale=2.0000 norm=0.6786
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2685 val_loss=0.0000 scale=2.0000 norm=1.0043
[iter 200] loss=-0.3305 val_loss=0.0000 scale=1.0000 norm=0.4536
[iter 300] loss=-0.7071 val_loss=0.0000 scale=2.0000 norm=0.8723
[iter 400] loss=-1.0216 val_loss=0.0000 scale=1.0000 norm=0.4238
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3369 val_loss=0.0000 scale=2.0000 norm=1.0047
[iter 200] loss=-0.3903 val_loss=0.0000 scale=2.0000 norm=0.8600
[iter 300] loss=-0.8755 val_loss=0.0000 scale=1.0000 norm=0.3953
[iter 400] loss=-1.2271 val_loss=0.0000 scale=1.0000 norm=0.3725
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3049 val_loss=0.0000 scale=2.0000 norm=1.0070
[iter 200] loss=-0.4436 val_loss=0.0000 scale=2.0000 norm=0.8847
[iter 300] loss=-0.9831 val_loss=0.0000 scale=1.0000 norm=0.4077
[iter 400] loss=-1.3177 val_loss=0.0000 scale=1.0000 norm=0.3779
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2731 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 200] loss=-0.4992 val_loss=0.0000 scale=2.0000 norm=0.8310
[iter 300] loss=-1.1697 val_loss=0.0000 scale=1.0000 norm=0.3855
[iter 400] loss=-1.6818 val_loss=0.0000 scale=2.0000 norm=0.6684
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4088 val_loss=0.0000 scale=1.0000 norm=0.5273
[iter 200] loss=-0.2966 val_loss=0.0000 scale=2.0000 norm=0.8859
[iter 300] loss=-0.7868 val_loss=0.0000 scale=1.0000 norm=0.3929
[iter 400] loss=-1.1111 val_loss=0.0000 scale=1.0000 norm=0.3741
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1848 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 200] loss=-0.6337 val_loss=0.0000 scale=2.0000 norm=0.8759
[iter 300] loss=-1.3379 val_loss=0.0000 scale=2.0000 norm=0.7713
[iter 400] loss=-1.8554 val_loss=0.0000 scale=2.0000 norm=0.6921
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3205 val_loss=0.0000 scale=2.0000 norm=1.0098
[iter 200] loss=-0.5737 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 300] loss=-1.4117 val_loss=0.0000 scale=2.0000 norm=0.8517
[iter 400] loss=-2.1505 val_loss=0.0000 scale=2.0000 norm=0.7987
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3019 val_loss=0.0000 scale=2.0000 norm=1.0183
[iter 200] loss=-0.2391 val_loss=0.0000 scale=1.0000 norm=0.4564
[iter 300] loss=-0.6818 val_loss=0.0000 scale=2.0000 norm=0.8352
[iter 400] loss=-1.0003 val_loss=0.0000 scale=1.0000 norm=0.3748
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1989 val_loss=0.0000 scale=2.0000 norm=0.9811
[iter 200] loss=-0.7871 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 300] loss=-1.7701 val_loss=0.0000 scale=2.0000 norm=0.9822
[iter 400] loss=-2.9153 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5076 val_loss=0.0000 scale=1.0000 norm=0.5436
[iter 200] loss=-0.1247 val_loss=0.0000 scale=2.0000 norm=0.9090
[iter 300] loss=-0.7032 val_loss=0.0000 scale=1.0000 norm=0.3905
[iter 400] loss=-1.0751 val_loss=0.0000 scale=1.0000 norm=0.3746
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3128 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.1879 val_loss=0.0000 scale=1.0000 norm=0.4660
[iter 300] loss=-0.5766 val_loss=0.0000 scale=2.0000 norm=0.8560
[iter 400] loss=-0.8734 val_loss=0.0000 scale=2.0000 norm=0.8163
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4771 val_loss=0.0000 scale=2.0000 norm=1.0714
[iter 200] loss=-0.0468 val_loss=0.0000 scale=1.0000 norm=0.4589
[iter 300] loss=-0.5811 val_loss=0.0000 scale=2.0000 norm=0.8323
[iter 400] loss=-0.9244 val_loss=0.0000 scale=2.0000 norm=0.7797
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2594 val_loss=0.0000 scale=2.0000 norm=1.0009
[iter 200] loss=-0.4004 val_loss=0.0000 scale=2.0000 norm=0.8779
[iter 300] loss=-0.8430 val_loss=0.0000 scale=1.0000 norm=0.4087
[iter 400] loss=-1.1360 val_loss=0.0000 scale=0.5000 norm=0.1931
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2479 val_loss=0.0000 scale=2.0000 norm=0.9716
[iter 200] loss=-0.7137 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 300] loss=-1.6894 val_loss=0.0000 scale=2.0000 norm=0.9765
[iter 400] loss=-2.8885 val_loss=0.0000 scale=4.0000 norm=1.9606
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5990 val_loss=0.0000 scale=2.0000 norm=1.1399
[iter 200] loss=0.0955 val_loss=0.0000 scale=1.0000 norm=0.4740
[iter 300] loss=-0.2369 val_loss=0.0000 scale=1.0000 norm=0.4379
[iter 400] loss=-0.5942 val_loss=0.0000 scale=1.0000 norm=0.4130
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1068 val_loss=0.0000 scale=2.0000 norm=1.0019
[iter 200] loss=-0.9461 val_loss=0.0000 scale=4.0000 norm=1.9817
[iter 300] loss=-2.9412 val_loss=0.0000 scale=4.0000 norm=1.9970
[iter 400] loss=-4.9391 val_loss=0.0000 scale=4.0000 norm=1.9975
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2559 val_loss=0.0000 scale=1.0000 norm=0.4958
[iter 200] loss=-0.3505 val_loss=0.0000 scale=1.0000 norm=0.4390
[iter 300] loss=-0.8362 val_loss=0.0000 scale=1.0000 norm=0.3929
[iter 400] loss=-1.1812 val_loss=0.0000 scale=1.0000 norm=0.3680
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3686 val_loss=0.0000 scale=1.0000 norm=0.5226
[iter 200] loss=-0.2392 val_loss=0.0000 scale=2.0000 norm=0.9160
[iter 300] loss=-0.6646 val_loss=0.0000 scale=2.0000 norm=0.8324
[iter 400] loss=-0.9955 val_loss=0.0000 scale=1.0000 norm=0.3904
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3000 val_loss=0.0000 scale=2.0000 norm=1.0336
[iter 200] loss=-0.2047 val_loss=0.0000 scale=2.0000 norm=0.9255
[iter 300] loss=-0.6046 val_loss=0.0000 scale=2.0000 norm=0.8716
[iter 400] loss=-0.9143 val_loss=0.0000 scale=1.0000 norm=0.4184
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2598 val_loss=0.0000 scale=2.0000 norm=0.9799
[iter 200] loss=-0.7165 val_loss=0.0000 scale=2.0000 norm=0.9748
[iter 300] loss=-1.9868 val_loss=0.0000 scale=4.0000 norm=1.9636
[iter 400] loss=-3.2291 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3636 val_loss=0.0000 scale=2.0000 norm=1.0231
[iter 200] loss=-0.3948 val_loss=0.0000 scale=1.0000 norm=0.4341
[iter 300] loss=-0.9170 val_loss=0.0000 scale=1.0000 norm=0.3893
[iter 400] loss=-1.2989 val_loss=0.0000 scale=1.0000 norm=0.3644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3116 val_loss=0.0000 scale=2.0000 norm=1.0115
[iter 200] loss=-0.2414 val_loss=0.0000 scale=1.0000 norm=0.4483
[iter 300] loss=-0.6854 val_loss=0.0000 scale=1.0000 norm=0.4108
[iter 400] loss=-0.9910 val_loss=0.0000 scale=1.0000 norm=0.3797
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2054 val_loss=0.0000 scale=2.0000 norm=0.9562
[iter 200] loss=-0.7475 val_loss=0.0000 scale=2.0000 norm=0.9485
[iter 300] loss=-1.6954 val_loss=0.0000 scale=2.0000 norm=0.9461
[iter 400] loss=-2.6246 val_loss=0.0000 scale=2.0000 norm=0.9291
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1758 val_loss=0.0000 scale=2.0000 norm=0.9814
[iter 200] loss=-0.6331 val_loss=0.0000 scale=2.0000 norm=0.8679
[iter 300] loss=-1.2017 val_loss=0.0000 scale=1.0000 norm=0.3807
[iter 400] loss=-1.5585 val_loss=0.0000 scale=1.0000 norm=0.3372
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3037 val_loss=0.0000 scale=2.0000 norm=1.0164
[iter 200] loss=-0.4744 val_loss=0.0000 scale=1.0000 norm=0.4421
[iter 300] loss=-0.9376 val_loss=0.0000 scale=1.0000 norm=0.3826
[iter 400] loss=-1.2260 val_loss=0.0000 scale=0.5000 norm=0.1773
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3973 val_loss=0.0000 scale=2.0000 norm=1.0528
[iter 200] loss=-0.1956 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 300] loss=-0.6416 val_loss=0.0000 scale=1.0000 norm=0.4262
[iter 400] loss=-0.9744 val_loss=0.0000 scale=1.0000 norm=0.4000
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1304 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.8485 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 300] loss=-1.8290 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 400] loss=-2.9139 val_loss=0.0000 scale=2.0000 norm=0.9778
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5546 val_loss=0.0000 scale=2.0000 norm=1.1241
[iter 200] loss=0.0048 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 300] loss=-0.5202 val_loss=0.0000 scale=2.0000 norm=0.8829
[iter 400] loss=-0.8725 val_loss=0.0000 scale=2.0000 norm=0.8300
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3898 val_loss=0.0000 scale=2.0000 norm=1.0558
[iter 200] loss=-0.2457 val_loss=0.0000 scale=2.0000 norm=0.9009
[iter 300] loss=-0.6173 val_loss=0.0000 scale=1.0000 norm=0.4044
[iter 400] loss=-0.8947 val_loss=0.0000 scale=1.0000 norm=0.3807
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2241 val_loss=0.0000 scale=2.0000 norm=0.9728
[iter 200] loss=-0.7407 val_loss=0.0000 scale=2.0000 norm=0.9573
[iter 300] loss=-1.6618 val_loss=0.0000 scale=2.0000 norm=0.9200
[iter 400] loss=-2.6667 val_loss=0.0000 scale=2.0000 norm=0.8714
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7966 val_loss=0.0000 scale=2.0000 norm=1.2219
[iter 200] loss=0.1881 val_loss=0.0000 scale=2.0000 norm=0.9577
[iter 300] loss=-0.3517 val_loss=0.0000 scale=2.0000 norm=0.8594
[iter 400] loss=-0.8987 val_loss=0.0000 scale=1.0000 norm=0.4008
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2935 val_loss=0.0000 scale=2.0000 norm=1.0314
[iter 200] loss=-0.3551 val_loss=0.0000 scale=1.0000 norm=0.4488
[iter 300] loss=-0.7421 val_loss=0.0000 scale=1.0000 norm=0.4184
[iter 400] loss=-1.0278 val_loss=0.0000 scale=2.0000 norm=0.7989
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0427 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-1.0293 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 300] loss=-2.3712 val_loss=0.0000 scale=2.0000 norm=0.9762
[iter 400] loss=-3.4236 val_loss=0.0000 scale=2.0000 norm=0.9644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2762 val_loss=0.0000 scale=2.0000 norm=0.9964
[iter 200] loss=-0.2596 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 300] loss=-0.8142 val_loss=0.0000 scale=1.0000 norm=0.4124
[iter 400] loss=-1.1034 val_loss=0.0000 scale=2.0000 norm=0.7701
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3105 val_loss=0.0000 scale=2.0000 norm=1.0280
[iter 200] loss=-0.2159 val_loss=0.0000 scale=1.0000 norm=0.4548
[iter 300] loss=-0.6390 val_loss=0.0000 scale=1.0000 norm=0.4269
[iter 400] loss=-0.9236 val_loss=0.0000 scale=1.0000 norm=0.4203
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2346 val_loss=0.0000 scale=2.0000 norm=0.9781
[iter 200] loss=-0.6004 val_loss=0.0000 scale=2.0000 norm=0.8724
[iter 300] loss=-1.3427 val_loss=0.0000 scale=2.0000 norm=0.8050
[iter 400] loss=-1.9717 val_loss=0.0000 scale=1.0000 norm=0.3675
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3903 val_loss=0.0000 scale=1.0000 norm=0.5274
[iter 200] loss=-0.0808 val_loss=0.0000 scale=1.0000 norm=0.4628
[iter 300] loss=-0.4610 val_loss=0.0000 scale=1.0000 norm=0.4233
[iter 400] loss=-0.7793 val_loss=0.0000 scale=1.0000 norm=0.3985
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2902 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.4504 val_loss=0.0000 scale=2.0000 norm=0.8632
[iter 300] loss=-0.9724 val_loss=0.0000 scale=1.0000 norm=0.3990
[iter 400] loss=-1.3134 val_loss=0.0000 scale=2.0000 norm=0.7562
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1727 val_loss=0.0000 scale=2.0000 norm=0.9677
[iter 200] loss=-0.7643 val_loss=0.0000 scale=2.0000 norm=0.9510
[iter 300] loss=-1.7335 val_loss=0.0000 scale=2.0000 norm=0.9625
[iter 400] loss=-2.6665 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2697 val_loss=0.0000 scale=2.0000 norm=0.9969
[iter 200] loss=-0.6790 val_loss=0.0000 scale=2.0000 norm=0.9503
[iter 300] loss=-1.6257 val_loss=0.0000 scale=2.0000 norm=0.9456
[iter 400] loss=-2.5624 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3773 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.3489 val_loss=0.0000 scale=1.0000 norm=0.4480
[iter 300] loss=-0.9429 val_loss=0.0000 scale=2.0000 norm=0.8323
[iter 400] loss=-1.3475 val_loss=0.0000 scale=1.0000 norm=0.3923
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1459 val_loss=0.0000 scale=2.0000 norm=0.9922
[iter 200] loss=-0.8550 val_loss=0.0000 scale=4.0000 norm=1.9724
[iter 300] loss=-2.3651 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 400] loss=-4.0052 val_loss=0.0000 scale=4.0000 norm=1.9767
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2905 val_loss=0.0000 scale=2.0000 norm=1.0099
[iter 200] loss=-0.3632 val_loss=0.0000 scale=2.0000 norm=0.8738
[iter 300] loss=-0.8087 val_loss=0.0000 scale=1.0000 norm=0.3871
[iter 400] loss=-1.0497 val_loss=0.0000 scale=1.0000 norm=0.3570
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3170 val_loss=0.0000 scale=2.0000 norm=1.0097
[iter 200] loss=-0.2011 val_loss=0.0000 scale=1.0000 norm=0.4465
[iter 300] loss=-0.5928 val_loss=0.0000 scale=2.0000 norm=0.8056
[iter 400] loss=-0.9316 val_loss=0.0000 scale=1.0000 norm=0.3806
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2733 val_loss=0.0000 scale=2.0000 norm=1.0168
[iter 200] loss=-0.3611 val_loss=0.0000 scale=2.0000 norm=0.8741
[iter 300] loss=-0.7429 val_loss=0.0000 scale=1.0000 norm=0.3884
[iter 400] loss=-0.9892 val_loss=0.0000 scale=1.0000 norm=0.3599
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1752 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.8281 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-2.7237 val_loss=0.0000 scale=4.0000 norm=1.9876
[iter 400] loss=-4.5911 val_loss=0.0000 scale=2.0000 norm=0.9841
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2632 val_loss=0.0000 scale=2.0000 norm=1.0040
[iter 200] loss=-0.4939 val_loss=0.0000 scale=1.0000 norm=0.4378
[iter 300] loss=-0.9277 val_loss=0.0000 scale=1.0000 norm=0.4105
[iter 400] loss=-1.2958 val_loss=0.0000 scale=1.0000 norm=0.3773
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3098 val_loss=0.0000 scale=1.0000 norm=0.5127
[iter 200] loss=-0.1987 val_loss=0.0000 scale=2.0000 norm=0.9187
[iter 300] loss=-0.5672 val_loss=0.0000 scale=1.0000 norm=0.4206
[iter 400] loss=-0.8944 val_loss=0.0000 scale=1.0000 norm=0.3982
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4550 val_loss=0.0000 scale=2.0000 norm=1.0741
[iter 200] loss=-0.0076 val_loss=0.0000 scale=1.0000 norm=0.4704
[iter 300] loss=-0.3681 val_loss=0.0000 scale=1.0000 norm=0.4282
[iter 400] loss=-0.6150 val_loss=0.0000 scale=1.0000 norm=0.4015
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2966 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 200] loss=-0.5855 val_loss=0.0000 scale=2.0000 norm=0.9056
[iter 300] loss=-1.3348 val_loss=0.0000 scale=1.0000 norm=0.4159
[iter 400] loss=-1.9084 val_loss=0.0000 scale=2.0000 norm=0.7509
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2519 val_loss=0.0000 scale=2.0000 norm=0.9944
[iter 200] loss=-0.4595 val_loss=0.0000 scale=2.0000 norm=0.8851
[iter 300] loss=-0.9447 val_loss=0.0000 scale=1.0000 norm=0.3997
[iter 400] loss=-1.2793 val_loss=0.0000 scale=2.0000 norm=0.7227
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3439 val_loss=0.0000 scale=2.0000 norm=1.0054
[iter 200] loss=-0.4622 val_loss=0.0000 scale=2.0000 norm=0.8736
[iter 300] loss=-1.0310 val_loss=0.0000 scale=1.0000 norm=0.3969
[iter 400] loss=-1.4301 val_loss=0.0000 scale=1.0000 norm=0.3554
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2997 val_loss=0.0000 scale=2.0000 norm=1.0267
[iter 200] loss=-0.2302 val_loss=0.0000 scale=2.0000 norm=0.9049
[iter 300] loss=-0.6869 val_loss=0.0000 scale=2.0000 norm=0.8632
[iter 400] loss=-1.0219 val_loss=0.0000 scale=2.0000 norm=0.8619
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0972 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.8449 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-1.8387 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9335 val_loss=0.0000 scale=2.0000 norm=0.9864
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4822 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.1726 val_loss=0.0000 scale=2.0000 norm=0.9073
[iter 300] loss=-0.6031 val_loss=0.0000 scale=1.0000 norm=0.4131
[iter 400] loss=-0.9893 val_loss=0.0000 scale=2.0000 norm=0.7622
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3702 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 200] loss=-0.5252 val_loss=0.0000 scale=2.0000 norm=0.9159
[iter 300] loss=-1.3659 val_loss=0.0000 scale=2.0000 norm=0.8483
[iter 400] loss=-2.0866 val_loss=0.0000 scale=2.0000 norm=0.7777
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5127 val_loss=0.0000 scale=2.0000 norm=1.1113
[iter 200] loss=-0.1156 val_loss=0.0000 scale=2.0000 norm=0.9408
[iter 300] loss=-0.5940 val_loss=0.0000 scale=1.0000 norm=0.4287
[iter 400] loss=-0.9417 val_loss=0.0000 scale=2.0000 norm=0.7877
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3029 val_loss=0.0000 scale=1.0000 norm=0.5127
[iter 200] loss=-0.3106 val_loss=0.0000 scale=2.0000 norm=0.8865
[iter 300] loss=-0.6775 val_loss=0.0000 scale=1.0000 norm=0.4139
[iter 400] loss=-1.0303 val_loss=0.0000 scale=1.0000 norm=0.3848
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3003 val_loss=0.0000 scale=2.0000 norm=1.0154
[iter 200] loss=-0.4131 val_loss=0.0000 scale=2.0000 norm=0.8663
[iter 300] loss=-0.8865 val_loss=0.0000 scale=1.0000 norm=0.3952
[iter 400] loss=-1.1886 val_loss=0.0000 scale=2.0000 norm=0.7487
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3113 val_loss=0.0000 scale=2.0000 norm=1.0133
[iter 200] loss=-0.2584 val_loss=0.0000 scale=2.0000 norm=0.8763
[iter 300] loss=-0.6669 val_loss=0.0000 scale=2.0000 norm=0.8043
[iter 400] loss=-0.9563 val_loss=0.0000 scale=1.0000 norm=0.3888
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2910 val_loss=0.0000 scale=2.0000 norm=1.0040
[iter 200] loss=-0.3693 val_loss=0.0000 scale=1.0000 norm=0.4284
[iter 300] loss=-0.7631 val_loss=0.0000 scale=1.0000 norm=0.3861
[iter 400] loss=-1.0203 val_loss=0.0000 scale=1.0000 norm=0.3693
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2884 val_loss=0.0000 scale=2.0000 norm=1.0269
[iter 200] loss=-0.2280 val_loss=0.0000 scale=1.0000 norm=0.4586
[iter 300] loss=-0.6564 val_loss=0.0000 scale=2.0000 norm=0.8373
[iter 400] loss=-1.0098 val_loss=0.0000 scale=1.0000 norm=0.3901
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3913 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.3247 val_loss=0.0000 scale=2.0000 norm=0.8552
[iter 300] loss=-0.8255 val_loss=0.0000 scale=2.0000 norm=0.7611
[iter 400] loss=-1.1409 val_loss=0.0000 scale=1.0000 norm=0.3566
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1477 val_loss=0.0000 scale=2.0000 norm=0.9742
[iter 200] loss=-0.7366 val_loss=0.0000 scale=2.0000 norm=0.8996
[iter 300] loss=-1.5583 val_loss=0.0000 scale=2.0000 norm=0.8286
[iter 400] loss=-2.2259 val_loss=0.0000 scale=2.0000 norm=0.7216
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4367 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 200] loss=-0.1274 val_loss=0.0000 scale=2.0000 norm=0.9259
[iter 300] loss=-0.5287 val_loss=0.0000 scale=1.0000 norm=0.4204
[iter 400] loss=-0.8690 val_loss=0.0000 scale=2.0000 norm=0.7872
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3572 val_loss=0.0000 scale=1.0000 norm=0.5183
[iter 200] loss=-0.1588 val_loss=0.0000 scale=2.0000 norm=0.8940
[iter 300] loss=-0.5645 val_loss=0.0000 scale=2.0000 norm=0.8022
[iter 400] loss=-0.8524 val_loss=0.0000 scale=1.0000 norm=0.3819
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3093 val_loss=0.0000 scale=1.0000 norm=0.5116
[iter 200] loss=-0.3239 val_loss=0.0000 scale=1.0000 norm=0.4547
[iter 300] loss=-0.6971 val_loss=0.0000 scale=1.0000 norm=0.4262
[iter 400] loss=-0.9660 val_loss=0.0000 scale=1.0000 norm=0.4207
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2907 val_loss=0.0000 scale=2.0000 norm=1.0219
[iter 200] loss=-0.3214 val_loss=0.0000 scale=1.0000 norm=0.4451
[iter 300] loss=-0.6968 val_loss=0.0000 scale=1.0000 norm=0.4068
[iter 400] loss=-0.9738 val_loss=0.0000 scale=2.0000 norm=0.7857
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1899 val_loss=0.0000 scale=2.0000 norm=0.9760
[iter 200] loss=-0.6503 val_loss=0.0000 scale=2.0000 norm=0.8784
[iter 300] loss=-1.4255 val_loss=0.0000 scale=2.0000 norm=0.8135
[iter 400] loss=-1.9594 val_loss=0.0000 scale=1.0000 norm=0.3919
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6116 val_loss=0.0000 scale=2.0000 norm=1.1231
[iter 200] loss=-0.0715 val_loss=0.0000 scale=2.0000 norm=0.9247
[iter 300] loss=-0.5409 val_loss=0.0000 scale=1.0000 norm=0.4108
[iter 400] loss=-0.8230 val_loss=0.0000 scale=1.0000 norm=0.3946
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4521 val_loss=0.0000 scale=2.0000 norm=1.0711
[iter 200] loss=-0.0741 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 300] loss=-0.5320 val_loss=0.0000 scale=2.0000 norm=0.8224
[iter 400] loss=-0.9064 val_loss=0.0000 scale=2.0000 norm=0.7653
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1047 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 200] loss=-0.8756 val_loss=0.0000 scale=2.0000 norm=0.9785
[iter 300] loss=-1.8577 val_loss=0.0000 scale=2.0000 norm=0.9818
[iter 400] loss=-2.8487 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2996 val_loss=0.0000 scale=2.0000 norm=1.0125
[iter 200] loss=-0.4647 val_loss=0.0000 scale=2.0000 norm=0.8820
[iter 300] loss=-1.0377 val_loss=0.0000 scale=2.0000 norm=0.7716
[iter 400] loss=-1.4312 val_loss=0.0000 scale=1.0000 norm=0.3585
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2119 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.5516 val_loss=0.0000 scale=2.0000 norm=0.8607
[iter 300] loss=-1.1479 val_loss=0.0000 scale=1.0000 norm=0.3822
[iter 400] loss=-1.5721 val_loss=0.0000 scale=1.0000 norm=0.3601
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2865 val_loss=0.0000 scale=2.0000 norm=0.9884
[iter 200] loss=-0.4101 val_loss=0.0000 scale=2.0000 norm=0.8609
[iter 300] loss=-0.8679 val_loss=0.0000 scale=1.0000 norm=0.4055
[iter 400] loss=-1.1522 val_loss=0.0000 scale=1.0000 norm=0.3919
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3074 val_loss=0.0000 scale=2.0000 norm=1.0215
[iter 200] loss=-0.2390 val_loss=0.0000 scale=2.0000 norm=0.8932
[iter 300] loss=-0.6498 val_loss=0.0000 scale=2.0000 norm=0.8308
[iter 400] loss=-0.9406 val_loss=0.0000 scale=1.0000 norm=0.4050
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2786 val_loss=0.0000 scale=2.0000 norm=1.0061
[iter 200] loss=-0.3131 val_loss=0.0000 scale=1.0000 norm=0.4453
[iter 300] loss=-0.7177 val_loss=0.0000 scale=1.0000 norm=0.3957
[iter 400] loss=-0.9580 val_loss=0.0000 scale=1.0000 norm=0.3753
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3322 val_loss=0.0000 scale=2.0000 norm=1.0388
[iter 200] loss=-0.1562 val_loss=0.0000 scale=2.0000 norm=0.9167
[iter 300] loss=-0.5170 val_loss=0.0000 scale=2.0000 norm=0.8319
[iter 400] loss=-0.7313 val_loss=0.0000 scale=1.0000 norm=0.3996
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2947 val_loss=0.0000 scale=2.0000 norm=1.0213
[iter 200] loss=-0.2900 val_loss=0.0000 scale=2.0000 norm=0.8883
[iter 300] loss=-0.7433 val_loss=0.0000 scale=2.0000 norm=0.8054
[iter 400] loss=-1.0254 val_loss=0.0000 scale=1.0000 norm=0.3976
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3751 val_loss=0.0000 scale=1.0000 norm=0.5309
[iter 200] loss=-0.1047 val_loss=0.0000 scale=2.0000 norm=0.9336
[iter 300] loss=-0.4980 val_loss=0.0000 scale=1.0000 norm=0.4286
[iter 400] loss=-0.7868 val_loss=0.0000 scale=1.0000 norm=0.4114
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3001 val_loss=0.0000 scale=2.0000 norm=1.0229
[iter 200] loss=-0.3607 val_loss=0.0000 scale=1.0000 norm=0.4341
[iter 300] loss=-0.7310 val_loss=0.0000 scale=1.0000 norm=0.3986
[iter 400] loss=-1.0320 val_loss=0.0000 scale=1.0000 norm=0.3601
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=0.9788
[iter 200] loss=-0.5862 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 300] loss=-1.5328 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 400] loss=-2.4926 val_loss=0.0000 scale=2.0000 norm=0.9606
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4083 val_loss=0.0000 scale=2.0000 norm=1.0478
[iter 200] loss=-0.1534 val_loss=0.0000 scale=1.0000 norm=0.4683
[iter 300] loss=-0.5016 val_loss=0.0000 scale=1.0000 norm=0.4373
[iter 400] loss=-0.8417 val_loss=0.0000 scale=1.0000 norm=0.4137
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2727 val_loss=0.0000 scale=2.0000 norm=1.0147
[iter 200] loss=-0.2878 val_loss=0.0000 scale=2.0000 norm=0.9010
[iter 300] loss=-0.6852 val_loss=0.0000 scale=1.0000 norm=0.4119
[iter 400] loss=-1.0229 val_loss=0.0000 scale=1.0000 norm=0.3782
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3690 val_loss=0.0000 scale=2.0000 norm=1.0217
[iter 200] loss=-0.2451 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 300] loss=-0.6200 val_loss=0.0000 scale=1.0000 norm=0.4108
[iter 400] loss=-0.8854 val_loss=0.0000 scale=1.0000 norm=0.3900
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2735 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.2000 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 300] loss=-0.5957 val_loss=0.0000 scale=1.0000 norm=0.4318
[iter 400] loss=-0.8879 val_loss=0.0000 scale=1.0000 norm=0.4122
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3957 val_loss=0.0000 scale=1.0000 norm=0.5171
[iter 200] loss=-0.1398 val_loss=0.0000 scale=1.0000 norm=0.4467
[iter 300] loss=-0.5917 val_loss=0.0000 scale=2.0000 norm=0.7962
[iter 400] loss=-0.9433 val_loss=0.0000 scale=2.0000 norm=0.7338
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2437 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 200] loss=-0.7503 val_loss=0.0000 scale=2.0000 norm=0.9853
[iter 300] loss=-2.1993 val_loss=0.0000 scale=4.0000 norm=1.9752
[iter 400] loss=-4.1752 val_loss=0.0000 scale=4.0000 norm=1.9722
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2108 val_loss=0.0000 scale=2.0000 norm=0.9938
[iter 200] loss=-0.5752 val_loss=0.0000 scale=2.0000 norm=0.8758
[iter 300] loss=-1.0446 val_loss=0.0000 scale=1.0000 norm=0.3973
[iter 400] loss=-1.3657 val_loss=0.0000 scale=2.0000 norm=0.7575
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2771 val_loss=0.0000 scale=2.0000 norm=1.0070
[iter 200] loss=-0.5153 val_loss=0.0000 scale=2.0000 norm=0.8655
[iter 300] loss=-1.0807 val_loss=0.0000 scale=1.0000 norm=0.3694
[iter 400] loss=-1.4217 val_loss=0.0000 scale=1.0000 norm=0.3332
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1028 val_loss=0.0000 scale=2.0000 norm=0.9843
[iter 200] loss=-0.8005 val_loss=0.0000 scale=2.0000 norm=0.9126
[iter 300] loss=-1.6647 val_loss=0.0000 scale=2.0000 norm=0.8682
[iter 400] loss=-2.4544 val_loss=0.0000 scale=2.0000 norm=0.8111
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3774 val_loss=0.0000 scale=1.0000 norm=0.5219
[iter 200] loss=-0.2008 val_loss=0.0000 scale=2.0000 norm=0.9142
[iter 300] loss=-0.6316 val_loss=0.0000 scale=1.0000 norm=0.4218
[iter 400] loss=-0.9819 val_loss=0.0000 scale=1.0000 norm=0.3999
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2437 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 200] loss=-0.6797 val_loss=0.0000 scale=2.0000 norm=0.9233
[iter 300] loss=-1.5440 val_loss=0.0000 scale=2.0000 norm=0.8653
[iter 400] loss=-2.2649 val_loss=0.0000 scale=2.0000 norm=0.7766
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3797 val_loss=0.0000 scale=1.0000 norm=0.5216
[iter 200] loss=-0.0827 val_loss=0.0000 scale=2.0000 norm=0.9238
[iter 300] loss=-0.3943 val_loss=0.0000 scale=1.0000 norm=0.4227
[iter 400] loss=-0.6120 val_loss=0.0000 scale=1.0000 norm=0.4024
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5699 val_loss=0.0000 scale=1.0000 norm=0.5806
[iter 200] loss=-0.0822 val_loss=0.0000 scale=2.0000 norm=0.9447
[iter 300] loss=-0.6609 val_loss=0.0000 scale=2.0000 norm=0.8345
[iter 400] loss=-1.0031 val_loss=0.0000 scale=1.0000 norm=0.4023
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3344 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.3390 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 300] loss=-0.8569 val_loss=0.0000 scale=2.0000 norm=0.7843
[iter 400] loss=-1.1526 val_loss=0.0000 scale=1.0000 norm=0.3740
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2976 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6129 val_loss=0.0000 scale=2.0000 norm=0.9203
[iter 300] loss=-1.5383 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 400] loss=-2.4571 val_loss=0.0000 scale=2.0000 norm=0.9170
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4362 val_loss=0.0000 scale=2.0000 norm=1.0102
[iter 200] loss=-0.4035 val_loss=0.0000 scale=2.0000 norm=0.8879
[iter 300] loss=-1.1354 val_loss=0.0000 scale=1.0000 norm=0.4069
[iter 400] loss=-1.7417 val_loss=0.0000 scale=1.0000 norm=0.3863
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5164 val_loss=0.0000 scale=2.0000 norm=1.0748
[iter 200] loss=-0.1709 val_loss=0.0000 scale=1.0000 norm=0.4621
[iter 300] loss=-0.6823 val_loss=0.0000 scale=1.0000 norm=0.4140
[iter 400] loss=-1.0427 val_loss=0.0000 scale=1.0000 norm=0.3746
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2774 val_loss=0.0000 scale=2.0000 norm=1.0105
[iter 200] loss=-0.2524 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 300] loss=-0.5593 val_loss=0.0000 scale=1.0000 norm=0.4066
[iter 400] loss=-0.8108 val_loss=0.0000 scale=1.0000 norm=0.3797
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3852 val_loss=0.0000 scale=1.0000 norm=0.5123
[iter 200] loss=-0.1498 val_loss=0.0000 scale=1.0000 norm=0.4406
[iter 300] loss=-0.4842 val_loss=0.0000 scale=1.0000 norm=0.3998
[iter 400] loss=-0.7792 val_loss=0.0000 scale=1.0000 norm=0.3739
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3529 val_loss=0.0000 scale=2.0000 norm=1.0269
[iter 200] loss=-0.1276 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 300] loss=-0.4752 val_loss=0.0000 scale=1.0000 norm=0.4256
[iter 400] loss=-0.7046 val_loss=0.0000 scale=1.0000 norm=0.4039
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5642 val_loss=0.0000 scale=2.0000 norm=1.0884
[iter 200] loss=-0.1371 val_loss=0.0000 scale=2.0000 norm=0.9215
[iter 300] loss=-0.6336 val_loss=0.0000 scale=2.0000 norm=0.8316
[iter 400] loss=-0.9789 val_loss=0.0000 scale=1.0000 norm=0.3751
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4447 val_loss=0.0000 scale=1.0000 norm=0.5383
[iter 200] loss=-0.0540 val_loss=0.0000 scale=2.0000 norm=0.9568
[iter 300] loss=-0.4782 val_loss=0.0000 scale=2.0000 norm=0.8946
[iter 400] loss=-0.7703 val_loss=0.0000 scale=1.0000 norm=0.4237
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2679 val_loss=0.0000 scale=2.0000 norm=1.0001
[iter 200] loss=-0.3272 val_loss=0.0000 scale=2.0000 norm=0.8864
[iter 300] loss=-0.7069 val_loss=0.0000 scale=1.0000 norm=0.4040
[iter 400] loss=-0.9880 val_loss=0.0000 scale=1.0000 norm=0.3741
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1009 val_loss=0.0000 scale=2.0000 norm=0.9932
[iter 200] loss=-0.8775 val_loss=0.0000 scale=2.0000 norm=0.9750
[iter 300] loss=-1.8561 val_loss=0.0000 scale=4.0000 norm=1.9622
[iter 400] loss=-2.9791 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4007 val_loss=0.0000 scale=2.0000 norm=1.0476
[iter 200] loss=-0.2576 val_loss=0.0000 scale=1.0000 norm=0.4477
[iter 300] loss=-0.7255 val_loss=0.0000 scale=1.0000 norm=0.3970
[iter 400] loss=-1.0081 val_loss=0.0000 scale=1.0000 norm=0.3702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2994 val_loss=0.0000 scale=2.0000 norm=1.0188
[iter 200] loss=-0.3720 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 300] loss=-0.8312 val_loss=0.0000 scale=1.0000 norm=0.4135
[iter 400] loss=-1.0969 val_loss=0.0000 scale=2.0000 norm=0.7758
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3007 val_loss=0.0000 scale=2.0000 norm=1.0255
[iter 200] loss=-0.3470 val_loss=0.0000 scale=2.0000 norm=0.8879
[iter 300] loss=-1.0082 val_loss=0.0000 scale=2.0000 norm=0.7551
[iter 400] loss=-1.4155 val_loss=0.0000 scale=2.0000 norm=0.6705
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3924 val_loss=0.0000 scale=1.0000 norm=0.5241
[iter 200] loss=-0.1519 val_loss=0.0000 scale=1.0000 norm=0.4519
[iter 300] loss=-0.5219 val_loss=0.0000 scale=1.0000 norm=0.4128
[iter 400] loss=-0.7861 val_loss=0.0000 scale=1.0000 norm=0.3889
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3979 val_loss=0.0000 scale=2.0000 norm=1.0221
[iter 200] loss=-0.4246 val_loss=0.0000 scale=2.0000 norm=0.8855
[iter 300] loss=-1.1104 val_loss=0.0000 scale=2.0000 norm=0.7916
[iter 400] loss=-1.5519 val_loss=0.0000 scale=2.0000 norm=0.7401
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1914 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 200] loss=-0.7889 val_loss=0.0000 scale=2.0000 norm=0.9744
[iter 300] loss=-1.7596 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 400] loss=-2.7381 val_loss=0.0000 scale=2.0000 norm=0.9777
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7440 val_loss=0.0000 scale=1.0000 norm=0.6225
[iter 200] loss=0.1973 val_loss=0.0000 scale=2.0000 norm=0.9923
[iter 300] loss=-0.3512 val_loss=0.0000 scale=1.0000 norm=0.4306
[iter 400] loss=-0.7744 val_loss=0.0000 scale=1.0000 norm=0.3940
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1205 val_loss=0.0000 scale=2.0000 norm=0.9886
[iter 200] loss=-0.7260 val_loss=0.0000 scale=2.0000 norm=0.8817
[iter 300] loss=-1.3479 val_loss=0.0000 scale=2.0000 norm=0.7926
[iter 400] loss=-1.7597 val_loss=0.0000 scale=2.0000 norm=0.6806
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3827 val_loss=0.0000 scale=2.0000 norm=1.0603
[iter 200] loss=-0.2470 val_loss=0.0000 scale=1.0000 norm=0.4554
[iter 300] loss=-0.6092 val_loss=0.0000 scale=2.0000 norm=0.8348
[iter 400] loss=-0.8873 val_loss=0.0000 scale=1.0000 norm=0.3955
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1598 val_loss=0.0000 scale=2.0000 norm=0.9790
[iter 200] loss=-0.7181 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 300] loss=-1.4833 val_loss=0.0000 scale=2.0000 norm=0.8061
[iter 400] loss=-2.1184 val_loss=0.0000 scale=2.0000 norm=0.7405
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2434 val_loss=0.0000 scale=2.0000 norm=1.0040
[iter 200] loss=-0.3789 val_loss=0.0000 scale=1.0000 norm=0.4378
[iter 300] loss=-0.7875 val_loss=0.0000 scale=1.0000 norm=0.4006
[iter 400] loss=-1.0323 val_loss=0.0000 scale=1.0000 norm=0.3898
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3428 val_loss=0.0000 scale=2.0000 norm=1.0163
[iter 200] loss=-0.4192 val_loss=0.0000 scale=2.0000 norm=0.8898
[iter 300] loss=-1.0139 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 400] loss=-1.4087 val_loss=0.0000 scale=1.0000 norm=0.3914
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3355 val_loss=0.0000 scale=1.0000 norm=0.5185
[iter 200] loss=-0.2450 val_loss=0.0000 scale=2.0000 norm=0.8967
[iter 300] loss=-0.5712 val_loss=0.0000 scale=1.0000 norm=0.4171
[iter 400] loss=-0.8393 val_loss=0.0000 scale=1.0000 norm=0.3960
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3019 val_loss=0.0000 scale=2.0000 norm=1.0106
[iter 200] loss=-0.3096 val_loss=0.0000 scale=2.0000 norm=0.8950
[iter 300] loss=-0.7728 val_loss=0.0000 scale=1.0000 norm=0.4138
[iter 400] loss=-1.1110 val_loss=0.0000 scale=1.0000 norm=0.4046
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2869 val_loss=0.0000 scale=2.0000 norm=1.0023
[iter 200] loss=-0.3178 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 300] loss=-0.6874 val_loss=0.0000 scale=1.0000 norm=0.4086
[iter 400] loss=-0.9798 val_loss=0.0000 scale=2.0000 norm=0.7574
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3152 val_loss=0.0000 scale=2.0000 norm=1.0227
[iter 200] loss=-0.2177 val_loss=0.0000 scale=1.0000 norm=0.4521
[iter 300] loss=-0.5942 val_loss=0.0000 scale=1.0000 norm=0.4168
[iter 400] loss=-0.8421 val_loss=0.0000 scale=0.5000 norm=0.2030
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2110 val_loss=0.0000 scale=2.0000 norm=0.9674
[iter 200] loss=-0.6982 val_loss=0.0000 scale=2.0000 norm=0.9097
[iter 300] loss=-1.5277 val_loss=0.0000 scale=2.0000 norm=0.8261
[iter 400] loss=-2.2520 val_loss=0.0000 scale=2.0000 norm=0.7434
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4721 val_loss=0.0000 scale=2.0000 norm=1.1081
[iter 200] loss=-0.1246 val_loss=0.0000 scale=2.0000 norm=0.9532
[iter 300] loss=-0.5449 val_loss=0.0000 scale=2.0000 norm=0.8889
[iter 400] loss=-0.8824 val_loss=0.0000 scale=1.0000 norm=0.4197
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1893 val_loss=0.0000 scale=2.0000 norm=0.9994
[iter 200] loss=-0.5690 val_loss=0.0000 scale=2.0000 norm=0.8651
[iter 300] loss=-1.0634 val_loss=0.0000 scale=2.0000 norm=0.7790
[iter 400] loss=-1.4438 val_loss=0.0000 scale=1.0000 norm=0.3612
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3238 val_loss=0.0000 scale=1.0000 norm=0.5136
[iter 200] loss=-0.1998 val_loss=0.0000 scale=1.0000 norm=0.4582
[iter 300] loss=-0.6787 val_loss=0.0000 scale=1.0000 norm=0.4226
[iter 400] loss=-1.0432 val_loss=0.0000 scale=1.0000 norm=0.4096
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2941 val_loss=0.0000 scale=2.0000 norm=1.0269
[iter 200] loss=-0.2587 val_loss=0.0000 scale=2.0000 norm=0.9019
[iter 300] loss=-0.6832 val_loss=0.0000 scale=1.0000 norm=0.4149
[iter 400] loss=-0.9809 val_loss=0.0000 scale=1.0000 norm=0.4062
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2964 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.2641 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 300] loss=-0.6582 val_loss=0.0000 scale=1.0000 norm=0.4019
[iter 400] loss=-0.9604 val_loss=0.0000 scale=1.0000 norm=0.3653
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2791 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2882 val_loss=0.0000 scale=1.0000 norm=0.4592
[iter 300] loss=-0.6578 val_loss=0.0000 scale=2.0000 norm=0.8541
[iter 400] loss=-0.8984 val_loss=0.0000 scale=1.0000 norm=0.4235
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2558 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.4052 val_loss=0.0000 scale=2.0000 norm=0.8690
[iter 300] loss=-0.8766 val_loss=0.0000 scale=1.0000 norm=0.3954
[iter 400] loss=-1.1978 val_loss=0.0000 scale=1.0000 norm=0.3749
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2763 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.4446 val_loss=0.0000 scale=1.0000 norm=0.4285
[iter 300] loss=-0.8657 val_loss=0.0000 scale=1.0000 norm=0.3836
[iter 400] loss=-1.1607 val_loss=0.0000 scale=1.0000 norm=0.3380
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2475 val_loss=0.0000 scale=2.0000 norm=0.9810
[iter 200] loss=-0.6666 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 300] loss=-1.4981 val_loss=0.0000 scale=2.0000 norm=0.8562
[iter 400] loss=-2.2013 val_loss=0.0000 scale=2.0000 norm=0.7701
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4674 val_loss=0.0000 scale=1.0000 norm=0.5386
[iter 200] loss=-0.0415 val_loss=0.0000 scale=2.0000 norm=0.9104
[iter 300] loss=-0.4015 val_loss=0.0000 scale=2.0000 norm=0.8232
[iter 400] loss=-0.6768 val_loss=0.0000 scale=1.0000 norm=0.3925
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2265 val_loss=0.0000 scale=2.0000 norm=0.9802
[iter 200] loss=-0.6268 val_loss=0.0000 scale=2.0000 norm=0.8860
[iter 300] loss=-1.4031 val_loss=0.0000 scale=2.0000 norm=0.8147
[iter 400] loss=-2.0042 val_loss=0.0000 scale=1.0000 norm=0.3668
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3119 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3238 val_loss=0.0000 scale=2.0000 norm=0.8773
[iter 300] loss=-0.7476 val_loss=0.0000 scale=1.0000 norm=0.3938
[iter 400] loss=-0.9810 val_loss=0.0000 scale=1.0000 norm=0.3733
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1293 val_loss=0.0000 scale=2.0000 norm=0.9914
[iter 200] loss=-0.8581 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 300] loss=-2.4725 val_loss=0.0000 scale=4.0000 norm=1.9772
[iter 400] loss=-4.1079 val_loss=0.0000 scale=4.0000 norm=1.9528
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3642 val_loss=0.0000 scale=2.0000 norm=1.0264
[iter 200] loss=-0.3914 val_loss=0.0000 scale=2.0000 norm=0.8854
[iter 300] loss=-0.9707 val_loss=0.0000 scale=2.0000 norm=0.7814
[iter 400] loss=-1.2776 val_loss=0.0000 scale=1.0000 norm=0.3702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2385 val_loss=0.0000 scale=2.0000 norm=0.9962
[iter 200] loss=-0.4732 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 300] loss=-0.8897 val_loss=0.0000 scale=2.0000 norm=0.7810
[iter 400] loss=-1.2165 val_loss=0.0000 scale=1.0000 norm=0.3741
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2765 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3369 val_loss=0.0000 scale=1.0000 norm=0.4422
[iter 300] loss=-0.7553 val_loss=0.0000 scale=1.0000 norm=0.4106
[iter 400] loss=-1.0192 val_loss=0.0000 scale=1.0000 norm=0.4047
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3987 val_loss=0.0000 scale=2.0000 norm=1.0157
[iter 200] loss=-0.5450 val_loss=0.0000 scale=2.0000 norm=0.9426
[iter 300] loss=-1.4887 val_loss=0.0000 scale=2.0000 norm=0.9444
[iter 400] loss=-2.4384 val_loss=0.0000 scale=2.0000 norm=0.9464
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5059 val_loss=0.0000 scale=2.0000 norm=1.0561
[iter 200] loss=-0.2869 val_loss=0.0000 scale=2.0000 norm=0.9059
[iter 300] loss=-0.8807 val_loss=0.0000 scale=1.0000 norm=0.3969
[iter 400] loss=-1.2656 val_loss=0.0000 scale=2.0000 norm=0.7294
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4134 val_loss=0.0000 scale=2.0000 norm=1.0492
[iter 200] loss=-0.1065 val_loss=0.0000 scale=1.0000 norm=0.4623
[iter 300] loss=-0.5244 val_loss=0.0000 scale=1.0000 norm=0.4169
[iter 400] loss=-0.8702 val_loss=0.0000 scale=1.0000 norm=0.3829
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2809 val_loss=0.0000 scale=2.0000 norm=1.0088
[iter 200] loss=-0.3302 val_loss=0.0000 scale=2.0000 norm=0.8778
[iter 300] loss=-0.7983 val_loss=0.0000 scale=2.0000 norm=0.7975
[iter 400] loss=-1.1732 val_loss=0.0000 scale=2.0000 norm=0.7522
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2109 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 200] loss=-0.5279 val_loss=0.0000 scale=2.0000 norm=0.8665
[iter 300] loss=-1.0818 val_loss=0.0000 scale=2.0000 norm=0.7704
[iter 400] loss=-1.4308 val_loss=0.0000 scale=1.0000 norm=0.3707
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2926 val_loss=0.0000 scale=2.0000 norm=1.0179
[iter 200] loss=-0.1959 val_loss=0.0000 scale=1.0000 norm=0.4549
[iter 300] loss=-0.6507 val_loss=0.0000 scale=1.0000 norm=0.4171
[iter 400] loss=-0.9999 val_loss=0.0000 scale=2.0000 norm=0.7868
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3162 val_loss=0.0000 scale=2.0000 norm=1.0280
[iter 200] loss=-0.2666 val_loss=0.0000 scale=2.0000 norm=0.9223
[iter 300] loss=-0.6118 val_loss=0.0000 scale=1.0000 norm=0.4277
[iter 400] loss=-0.8558 val_loss=0.0000 scale=1.0000 norm=0.4152
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0484
[iter 200] loss=-0.1391 val_loss=0.0000 scale=1.0000 norm=0.4762
[iter 300] loss=-0.5677 val_loss=0.0000 scale=1.0000 norm=0.4459
[iter 400] loss=-0.8802 val_loss=0.0000 scale=2.0000 norm=0.8666
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5470 val_loss=0.0000 scale=2.0000 norm=1.0684
[iter 200] loss=-0.3200 val_loss=0.0000 scale=2.0000 norm=0.9215
[iter 300] loss=-1.1119 val_loss=0.0000 scale=2.0000 norm=0.8300
[iter 400] loss=-1.7482 val_loss=0.0000 scale=2.0000 norm=0.7253
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6259 val_loss=0.0000 scale=1.0000 norm=0.5843
[iter 200] loss=0.1560 val_loss=0.0000 scale=1.0000 norm=0.5052
[iter 300] loss=-0.1700 val_loss=0.0000 scale=1.0000 norm=0.4646
[iter 400] loss=-0.4389 val_loss=0.0000 scale=1.0000 norm=0.4221
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4030 val_loss=0.0000 scale=1.0000 norm=0.5276
[iter 200] loss=-0.1858 val_loss=0.0000 scale=1.0000 norm=0.4538
[iter 300] loss=-0.6218 val_loss=0.0000 scale=2.0000 norm=0.8028
[iter 400] loss=-0.8932 val_loss=0.0000 scale=1.0000 norm=0.3712
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3434 val_loss=0.0000 scale=2.0000 norm=1.0125
[iter 200] loss=-0.2184 val_loss=0.0000 scale=2.0000 norm=0.8704
[iter 300] loss=-0.6474 val_loss=0.0000 scale=2.0000 norm=0.7890
[iter 400] loss=-0.9599 val_loss=0.0000 scale=1.0000 norm=0.3738
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3156 val_loss=0.0000 scale=2.0000 norm=1.0154
[iter 200] loss=-0.3511 val_loss=0.0000 scale=2.0000 norm=0.8639
[iter 300] loss=-0.7858 val_loss=0.0000 scale=1.0000 norm=0.4061
[iter 400] loss=-1.0642 val_loss=0.0000 scale=1.0000 norm=0.3936
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3041 val_loss=0.0000 scale=2.0000 norm=1.0172
[iter 200] loss=-0.2857 val_loss=0.0000 scale=1.0000 norm=0.4472
[iter 300] loss=-0.6852 val_loss=0.0000 scale=1.0000 norm=0.4200
[iter 400] loss=-0.9649 val_loss=0.0000 scale=1.0000 norm=0.4031
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2655 val_loss=0.0000 scale=2.0000 norm=1.0199
[iter 200] loss=-0.4015 val_loss=0.0000 scale=2.0000 norm=0.8816
[iter 300] loss=-0.9001 val_loss=0.0000 scale=2.0000 norm=0.7764
[iter 400] loss=-1.2301 val_loss=0.0000 scale=1.0000 norm=0.3527
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5756 val_loss=0.0000 scale=2.0000 norm=1.1175
[iter 200] loss=-0.0782 val_loss=0.0000 scale=1.0000 norm=0.4573
[iter 300] loss=-0.5460 val_loss=0.0000 scale=1.0000 norm=0.4122
[iter 400] loss=-1.0605 val_loss=0.0000 scale=2.0000 norm=0.7652
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3071 val_loss=0.0000 scale=2.0000 norm=1.0112
[iter 200] loss=-0.3255 val_loss=0.0000 scale=1.0000 norm=0.4429
[iter 300] loss=-0.7557 val_loss=0.0000 scale=1.0000 norm=0.4093
[iter 400] loss=-1.0609 val_loss=0.0000 scale=0.5000 norm=0.1975
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3296 val_loss=0.0000 scale=2.0000 norm=1.0220
[iter 200] loss=-0.2568 val_loss=0.0000 scale=1.0000 norm=0.4458
[iter 300] loss=-0.7172 val_loss=0.0000 scale=2.0000 norm=0.8410
[iter 400] loss=-1.0158 val_loss=0.0000 scale=2.0000 norm=0.7970
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1834 val_loss=0.0000 scale=2.0000 norm=0.9883
[iter 200] loss=-0.9052 val_loss=0.0000 scale=4.0000 norm=1.9871
[iter 300] loss=-2.8988 val_loss=0.0000 scale=4.0000 norm=1.9880
[iter 400] loss=-4.7617 val_loss=0.0000 scale=4.0000 norm=1.8447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1721 val_loss=0.0000 scale=2.0000 norm=0.9693
[iter 200] loss=-0.7164 val_loss=0.0000 scale=2.0000 norm=0.9019
[iter 300] loss=-1.5064 val_loss=0.0000 scale=2.0000 norm=0.7882
[iter 400] loss=-2.0715 val_loss=0.0000 scale=1.0000 norm=0.3635
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2748 val_loss=0.0000 scale=2.0000 norm=1.0117
[iter 200] loss=-0.3253 val_loss=0.0000 scale=2.0000 norm=0.8936
[iter 300] loss=-0.8140 val_loss=0.0000 scale=1.0000 norm=0.4096
[iter 400] loss=-1.1268 val_loss=0.0000 scale=1.0000 norm=0.3931
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1947 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 200] loss=-0.7912 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 300] loss=-1.9577 val_loss=0.0000 scale=4.0000 norm=1.9615
[iter 400] loss=-3.4034 val_loss=0.0000 scale=4.0000 norm=1.9802
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4664 val_loss=0.0000 scale=1.0000 norm=0.5445
[iter 200] loss=-0.1103 val_loss=0.0000 scale=2.0000 norm=0.9243
[iter 300] loss=-0.4828 val_loss=0.0000 scale=1.0000 norm=0.4211
[iter 400] loss=-0.7687 val_loss=0.0000 scale=1.0000 norm=0.3971
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2902 val_loss=0.0000 scale=2.0000 norm=1.0185
[iter 200] loss=-0.3017 val_loss=0.0000 scale=2.0000 norm=0.9125
[iter 300] loss=-0.7048 val_loss=0.0000 scale=2.0000 norm=0.8327
[iter 400] loss=-1.0079 val_loss=0.0000 scale=1.0000 norm=0.3977
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2508 val_loss=0.0000 scale=2.0000 norm=1.0008
[iter 200] loss=-0.3862 val_loss=0.0000 scale=1.0000 norm=0.4313
[iter 300] loss=-0.8641 val_loss=0.0000 scale=1.0000 norm=0.3871
[iter 400] loss=-1.2110 val_loss=0.0000 scale=1.0000 norm=0.3738
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2322 val_loss=0.0000 scale=2.0000 norm=1.0053
[iter 200] loss=-0.4703 val_loss=0.0000 scale=2.0000 norm=0.8618
[iter 300] loss=-0.9720 val_loss=0.0000 scale=2.0000 norm=0.7787
[iter 400] loss=-1.3119 val_loss=0.0000 scale=1.0000 norm=0.3648
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2493 val_loss=0.0000 scale=1.0000 norm=0.5117
[iter 200] loss=-0.3729 val_loss=0.0000 scale=2.0000 norm=0.9152
[iter 300] loss=-0.9047 val_loss=0.0000 scale=1.0000 norm=0.4218
[iter 400] loss=-1.2531 val_loss=0.0000 scale=1.0000 norm=0.3956
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3365 val_loss=0.0000 scale=2.0000 norm=1.0408
[iter 200] loss=-0.3748 val_loss=0.0000 scale=2.0000 norm=0.9028
[iter 300] loss=-0.8232 val_loss=0.0000 scale=1.0000 norm=0.4146
[iter 400] loss=-1.2019 val_loss=0.0000 scale=1.0000 norm=0.3805
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3003 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.3817 val_loss=0.0000 scale=2.0000 norm=0.8790
[iter 300] loss=-0.8108 val_loss=0.0000 scale=1.0000 norm=0.4134
[iter 400] loss=-1.1325 val_loss=0.0000 scale=1.0000 norm=0.3971
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3310 val_loss=0.0000 scale=2.0000 norm=0.9928
[iter 200] loss=-0.5725 val_loss=0.0000 scale=2.0000 norm=0.9229
[iter 300] loss=-1.3231 val_loss=0.0000 scale=2.0000 norm=0.8892
[iter 400] loss=-2.0117 val_loss=0.0000 scale=2.0000 norm=0.8357
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2821 val_loss=0.0000 scale=2.0000 norm=1.0218
[iter 200] loss=-0.3541 val_loss=0.0000 scale=2.0000 norm=0.8934
[iter 300] loss=-0.7783 val_loss=0.0000 scale=1.0000 norm=0.4163
[iter 400] loss=-1.0993 val_loss=0.0000 scale=1.0000 norm=0.3807
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1974 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 200] loss=-0.7009 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 300] loss=-1.5123 val_loss=0.0000 scale=2.0000 norm=0.8260
[iter 400] loss=-2.0987 val_loss=0.0000 scale=2.0000 norm=0.7343
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1970 val_loss=0.0000 scale=2.0000 norm=0.9850
[iter 200] loss=-0.6140 val_loss=0.0000 scale=2.0000 norm=0.8854
[iter 300] loss=-1.1815 val_loss=0.0000 scale=1.0000 norm=0.3982
[iter 400] loss=-1.5517 val_loss=0.0000 scale=1.0000 norm=0.3708
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1371 val_loss=0.0000 scale=2.0000 norm=0.9839
[iter 200] loss=-0.8534 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 300] loss=-2.3051 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 400] loss=-3.7711 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1666 val_loss=0.0000 scale=2.0000 norm=0.9766
[iter 200] loss=-0.6848 val_loss=0.0000 scale=2.0000 norm=0.8643
[iter 300] loss=-1.3638 val_loss=0.0000 scale=2.0000 norm=0.7395
[iter 400] loss=-1.7802 val_loss=0.0000 scale=1.0000 norm=0.3473
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3820 val_loss=0.0000 scale=2.0000 norm=1.0458
[iter 200] loss=-0.2230 val_loss=0.0000 scale=2.0000 norm=0.9301
[iter 300] loss=-0.6160 val_loss=0.0000 scale=1.0000 norm=0.4190
[iter 400] loss=-0.9073 val_loss=0.0000 scale=1.0000 norm=0.3983
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2145 val_loss=0.0000 scale=2.0000 norm=1.0097
[iter 200] loss=-0.5286 val_loss=0.0000 scale=2.0000 norm=0.8890
[iter 300] loss=-1.0991 val_loss=0.0000 scale=2.0000 norm=0.8124
[iter 400] loss=-1.4428 val_loss=0.0000 scale=1.0000 norm=0.3743
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4076 val_loss=0.0000 scale=2.0000 norm=1.0686
[iter 200] loss=-0.0643 val_loss=0.0000 scale=1.0000 norm=0.4767
[iter 300] loss=-0.4652 val_loss=0.0000 scale=1.0000 norm=0.4280
[iter 400] loss=-0.7805 val_loss=0.0000 scale=2.0000 norm=0.8005
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3418 val_loss=0.0000 scale=2.0000 norm=1.0286
[iter 200] loss=-0.2625 val_loss=0.0000 scale=1.0000 norm=0.4568
[iter 300] loss=-0.7982 val_loss=0.0000 scale=2.0000 norm=0.8258
[iter 400] loss=-1.1583 val_loss=0.0000 scale=1.0000 norm=0.3770
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3631 val_loss=0.0000 scale=1.0000 norm=0.5233
[iter 200] loss=-0.1676 val_loss=0.0000 scale=1.0000 norm=0.4589
[iter 300] loss=-0.5962 val_loss=0.0000 scale=1.0000 norm=0.4098
[iter 400] loss=-0.8564 val_loss=0.0000 scale=1.0000 norm=0.3834
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3248 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2219 val_loss=0.0000 scale=1.0000 norm=0.4523
[iter 300] loss=-0.6418 val_loss=0.0000 scale=2.0000 norm=0.8123
[iter 400] loss=-0.9272 val_loss=0.0000 scale=1.0000 norm=0.3818
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0984 val_loss=0.0000 scale=2.0000 norm=0.9993
[iter 200] loss=-0.8797 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 300] loss=-1.8909 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9990 val_loss=0.0000 scale=2.0000 norm=0.9817
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2238 val_loss=0.0000 scale=2.0000 norm=0.9787
[iter 200] loss=-0.7122 val_loss=0.0000 scale=2.0000 norm=0.9345
[iter 300] loss=-1.6022 val_loss=0.0000 scale=2.0000 norm=0.8851
[iter 400] loss=-2.3871 val_loss=0.0000 scale=2.0000 norm=0.7864
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3781 val_loss=0.0000 scale=2.0000 norm=1.0464
[iter 200] loss=-0.2716 val_loss=0.0000 scale=2.0000 norm=0.8833
[iter 300] loss=-0.6543 val_loss=0.0000 scale=1.0000 norm=0.4019
[iter 400] loss=-0.9157 val_loss=0.0000 scale=1.0000 norm=0.3931
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6786 val_loss=0.0000 scale=2.0000 norm=1.1494
[iter 200] loss=-0.0982 val_loss=0.0000 scale=2.0000 norm=0.9156
[iter 300] loss=-0.6744 val_loss=0.0000 scale=2.0000 norm=0.8424
[iter 400] loss=-1.1487 val_loss=0.0000 scale=1.0000 norm=0.3938
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2325 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.5702 val_loss=0.0000 scale=2.0000 norm=0.8748
[iter 300] loss=-1.1904 val_loss=0.0000 scale=1.0000 norm=0.3821
[iter 400] loss=-1.5899 val_loss=0.0000 scale=2.0000 norm=0.6949
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2241 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.5755 val_loss=0.0000 scale=2.0000 norm=0.8709
[iter 300] loss=-1.1865 val_loss=0.0000 scale=1.0000 norm=0.3848
[iter 400] loss=-1.6120 val_loss=0.0000 scale=2.0000 norm=0.7107
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5437 val_loss=0.0000 scale=2.0000 norm=1.1227
[iter 200] loss=-0.0101 val_loss=0.0000 scale=1.0000 norm=0.4764
[iter 300] loss=-0.4315 val_loss=0.0000 scale=1.0000 norm=0.4357
[iter 400] loss=-0.6781 val_loss=0.0000 scale=1.0000 norm=0.4223
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2524 val_loss=0.0000 scale=2.0000 norm=0.9974
[iter 200] loss=-0.4798 val_loss=0.0000 scale=2.0000 norm=0.8883
[iter 300] loss=-0.9683 val_loss=0.0000 scale=2.0000 norm=0.8100
[iter 400] loss=-1.2633 val_loss=0.0000 scale=1.0000 norm=0.3711
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3913 val_loss=0.0000 scale=2.0000 norm=1.0260
[iter 200] loss=-0.2028 val_loss=0.0000 scale=1.0000 norm=0.4460
[iter 300] loss=-0.5392 val_loss=0.0000 scale=2.0000 norm=0.8183
[iter 400] loss=-0.8020 val_loss=0.0000 scale=1.0000 norm=0.3804
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2396 val_loss=0.0000 scale=1.0000 norm=0.5090
[iter 200] loss=-0.4582 val_loss=0.0000 scale=2.0000 norm=0.9140
[iter 300] loss=-1.1379 val_loss=0.0000 scale=2.0000 norm=0.8194
[iter 400] loss=-1.5714 val_loss=0.0000 scale=1.0000 norm=0.3815
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1018 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.8851 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 300] loss=-2.2926 val_loss=0.0000 scale=4.0000 norm=1.9800
[iter 400] loss=-4.2046 val_loss=0.0000 scale=4.0000 norm=1.9677
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2395 val_loss=0.0000 scale=2.0000 norm=1.0088
[iter 200] loss=-0.3429 val_loss=0.0000 scale=2.0000 norm=0.8946
[iter 300] loss=-0.7313 val_loss=0.0000 scale=1.0000 norm=0.4052
[iter 400] loss=-1.0500 val_loss=0.0000 scale=1.0000 norm=0.3863
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3694 val_loss=0.0000 scale=2.0000 norm=0.9921
[iter 200] loss=-0.5909 val_loss=0.0000 scale=2.0000 norm=0.9542
[iter 300] loss=-1.5171 val_loss=0.0000 scale=2.0000 norm=0.9244
[iter 400] loss=-2.3525 val_loss=0.0000 scale=2.0000 norm=0.8314
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2856 val_loss=0.0000 scale=2.0000 norm=1.0037
[iter 200] loss=-0.3383 val_loss=0.0000 scale=1.0000 norm=0.4406
[iter 300] loss=-0.7550 val_loss=0.0000 scale=1.0000 norm=0.4073
[iter 400] loss=-1.0397 val_loss=0.0000 scale=1.0000 norm=0.3875
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3382 val_loss=0.0000 scale=2.0000 norm=1.0078
[iter 200] loss=-0.2394 val_loss=0.0000 scale=2.0000 norm=0.8681
[iter 300] loss=-0.6502 val_loss=0.0000 scale=1.0000 norm=0.4020
[iter 400] loss=-0.9537 val_loss=0.0000 scale=1.0000 norm=0.3909
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3091 val_loss=0.0000 scale=2.0000 norm=1.0181
[iter 200] loss=-0.3407 val_loss=0.0000 scale=2.0000 norm=0.8966
[iter 300] loss=-0.8234 val_loss=0.0000 scale=1.0000 norm=0.4084
[iter 400] loss=-1.2010 val_loss=0.0000 scale=1.0000 norm=0.3729
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5235 val_loss=0.0000 scale=2.0000 norm=1.1180
[iter 200] loss=-0.1355 val_loss=0.0000 scale=1.0000 norm=0.4748
[iter 300] loss=-0.5470 val_loss=0.0000 scale=1.0000 norm=0.4353
[iter 400] loss=-0.8934 val_loss=0.0000 scale=2.0000 norm=0.8100
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1408 val_loss=0.0000 scale=2.0000 norm=0.9845
[iter 200] loss=-0.7521 val_loss=0.0000 scale=2.0000 norm=0.9063
[iter 300] loss=-1.5751 val_loss=0.0000 scale=2.0000 norm=0.8480
[iter 400] loss=-2.1738 val_loss=0.0000 scale=1.0000 norm=0.3982
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3255 val_loss=0.0000 scale=2.0000 norm=1.0245
[iter 200] loss=-0.2272 val_loss=0.0000 scale=1.0000 norm=0.4523
[iter 300] loss=-0.5945 val_loss=0.0000 scale=1.0000 norm=0.4225
[iter 400] loss=-0.8891 val_loss=0.0000 scale=1.0000 norm=0.4094
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6166 val_loss=0.0000 scale=1.0000 norm=0.5757
[iter 200] loss=0.0093 val_loss=0.0000 scale=1.0000 norm=0.4748
[iter 300] loss=-0.6082 val_loss=0.0000 scale=1.0000 norm=0.4120
[iter 400] loss=-1.0935 val_loss=0.0000 scale=1.0000 norm=0.3750
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3104 val_loss=0.0000 scale=1.0000 norm=0.5106
[iter 200] loss=-0.2388 val_loss=0.0000 scale=2.0000 norm=0.8932
[iter 300] loss=-0.6406 val_loss=0.0000 scale=1.0000 norm=0.4106
[iter 400] loss=-0.9645 val_loss=0.0000 scale=2.0000 norm=0.7954
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4554 val_loss=0.0000 scale=2.0000 norm=1.0529
[iter 200] loss=-0.3379 val_loss=0.0000 scale=2.0000 norm=0.8953
[iter 300] loss=-1.0160 val_loss=0.0000 scale=1.0000 norm=0.4034
[iter 400] loss=-1.4689 val_loss=0.0000 scale=2.0000 norm=0.7261
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3332 val_loss=0.0000 scale=2.0000 norm=1.0279
[iter 200] loss=-0.2921 val_loss=0.0000 scale=2.0000 norm=0.9007
[iter 300] loss=-0.7458 val_loss=0.0000 scale=1.0000 norm=0.4108
[iter 400] loss=-1.0628 val_loss=0.0000 scale=1.0000 norm=0.3918
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3340 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 200] loss=-0.2739 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 300] loss=-0.6758 val_loss=0.0000 scale=1.0000 norm=0.4070
[iter 400] loss=-0.9621 val_loss=0.0000 scale=2.0000 norm=0.7739
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3043 val_loss=0.0000 scale=2.0000 norm=1.0267
[iter 200] loss=-0.2647 val_loss=0.0000 scale=1.0000 norm=0.4603
[iter 300] loss=-0.7134 val_loss=0.0000 scale=1.0000 norm=0.4246
[iter 400] loss=-1.0679 val_loss=0.0000 scale=1.0000 norm=0.4035
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3301 val_loss=0.0000 scale=2.0000 norm=1.0446
[iter 200] loss=-0.2463 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 300] loss=-0.6419 val_loss=0.0000 scale=1.0000 norm=0.4404
[iter 400] loss=-0.9356 val_loss=0.0000 scale=2.0000 norm=0.8293
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3060 val_loss=0.0000 scale=2.0000 norm=1.0078
[iter 200] loss=-0.2846 val_loss=0.0000 scale=1.0000 norm=0.4452
[iter 300] loss=-0.6659 val_loss=0.0000 scale=1.0000 norm=0.4153
[iter 400] loss=-0.9243 val_loss=0.0000 scale=1.0000 norm=0.4021
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1771 val_loss=0.0000 scale=2.0000 norm=1.0052
[iter 200] loss=-0.6853 val_loss=0.0000 scale=2.0000 norm=0.8985
[iter 300] loss=-1.4530 val_loss=0.0000 scale=1.0000 norm=0.4060
[iter 400] loss=-1.9907 val_loss=0.0000 scale=1.0000 norm=0.3800
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4012 val_loss=0.0000 scale=2.0000 norm=1.0494
[iter 200] loss=-0.1362 val_loss=0.0000 scale=1.0000 norm=0.4650
[iter 300] loss=-0.5136 val_loss=0.0000 scale=1.0000 norm=0.4369
[iter 400] loss=-0.8487 val_loss=0.0000 scale=1.0000 norm=0.4252
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2211 val_loss=0.0000 scale=2.0000 norm=1.0068
[iter 200] loss=-0.5193 val_loss=0.0000 scale=2.0000 norm=0.9075
[iter 300] loss=-0.9846 val_loss=0.0000 scale=1.0000 norm=0.4275
[iter 400] loss=-1.4934 val_loss=0.0000 scale=1.0000 norm=0.3762
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4925 val_loss=0.0000 scale=2.0000 norm=1.0279
[iter 200] loss=-0.3394 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 300] loss=-1.0481 val_loss=0.0000 scale=2.0000 norm=0.7872
[iter 400] loss=-1.5636 val_loss=0.0000 scale=2.0000 norm=0.7292
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2037 val_loss=0.0000 scale=2.0000 norm=0.9852
[iter 200] loss=-0.7361 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 300] loss=-1.6174 val_loss=0.0000 scale=2.0000 norm=0.8789
[iter 400] loss=-2.3914 val_loss=0.0000 scale=2.0000 norm=0.7828
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2754 val_loss=0.0000 scale=2.0000 norm=1.0101
[iter 200] loss=-0.3383 val_loss=0.0000 scale=1.0000 norm=0.4433
[iter 300] loss=-0.7742 val_loss=0.0000 scale=2.0000 norm=0.8184
[iter 400] loss=-1.0743 val_loss=0.0000 scale=1.0000 norm=0.3871
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3602 val_loss=0.0000 scale=2.0000 norm=1.0338
[iter 200] loss=-0.3792 val_loss=0.0000 scale=2.0000 norm=0.8865
[iter 300] loss=-0.9031 val_loss=0.0000 scale=2.0000 norm=0.7906
[iter 400] loss=-1.2632 val_loss=0.0000 scale=1.0000 norm=0.3637
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1082 val_loss=0.0000 scale=2.0000 norm=0.9844
[iter 200] loss=-0.7844 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 300] loss=-1.5860 val_loss=0.0000 scale=2.0000 norm=0.8406
[iter 400] loss=-2.1925 val_loss=0.0000 scale=1.0000 norm=0.3883
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5623 val_loss=0.0000 scale=1.0000 norm=0.5633
[iter 200] loss=0.1055 val_loss=0.0000 scale=1.0000 norm=0.5024
[iter 300] loss=-0.2740 val_loss=0.0000 scale=1.0000 norm=0.4617
[iter 400] loss=-0.6123 val_loss=0.0000 scale=1.0000 norm=0.4324
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3308 val_loss=0.0000 scale=2.0000 norm=1.0228
[iter 200] loss=-0.3035 val_loss=0.0000 scale=2.0000 norm=0.8858
[iter 300] loss=-0.6914 val_loss=0.0000 scale=1.0000 norm=0.4208
[iter 400] loss=-0.9698 val_loss=0.0000 scale=1.0000 norm=0.4091
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2641 val_loss=0.0000 scale=2.0000 norm=1.0036
[iter 200] loss=-0.4462 val_loss=0.0000 scale=1.0000 norm=0.4537
[iter 300] loss=-0.8569 val_loss=0.0000 scale=1.0000 norm=0.4147
[iter 400] loss=-1.1772 val_loss=0.0000 scale=1.0000 norm=0.3788
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4001 val_loss=0.0000 scale=2.0000 norm=1.0559
[iter 200] loss=-0.0718 val_loss=0.0000 scale=2.0000 norm=0.9468
[iter 300] loss=-0.3955 val_loss=0.0000 scale=1.0000 norm=0.4417
[iter 400] loss=-0.6242 val_loss=0.0000 scale=1.0000 norm=0.4247
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3111 val_loss=0.0000 scale=1.0000 norm=0.5112
[iter 200] loss=-0.1733 val_loss=0.0000 scale=1.0000 norm=0.4474
[iter 300] loss=-0.5967 val_loss=0.0000 scale=2.0000 norm=0.7965
[iter 400] loss=-0.8558 val_loss=0.0000 scale=1.0000 norm=0.3818
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2839 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.3680 val_loss=0.0000 scale=2.0000 norm=0.8978
[iter 300] loss=-0.8789 val_loss=0.0000 scale=1.0000 norm=0.4169
[iter 400] loss=-1.2951 val_loss=0.0000 scale=2.0000 norm=0.7728
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3264 val_loss=0.0000 scale=2.0000 norm=1.0364
[iter 200] loss=-0.2289 val_loss=0.0000 scale=2.0000 norm=0.9079
[iter 300] loss=-0.5673 val_loss=0.0000 scale=1.0000 norm=0.4119
[iter 400] loss=-0.8074 val_loss=0.0000 scale=0.5000 norm=0.1990
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1890 val_loss=0.0000 scale=2.0000 norm=0.9821
[iter 200] loss=-0.6096 val_loss=0.0000 scale=2.0000 norm=0.8467
[iter 300] loss=-1.2686 val_loss=0.0000 scale=2.0000 norm=0.7383
[iter 400] loss=-1.6875 val_loss=0.0000 scale=2.0000 norm=0.6742
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3918 val_loss=0.0000 scale=1.0000 norm=0.5257
[iter 200] loss=-0.1409 val_loss=0.0000 scale=2.0000 norm=0.9168
[iter 300] loss=-0.5613 val_loss=0.0000 scale=2.0000 norm=0.8452
[iter 400] loss=-0.8508 val_loss=0.0000 scale=1.0000 norm=0.4084
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3192 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.2876 val_loss=0.0000 scale=2.0000 norm=0.9017
[iter 300] loss=-0.7231 val_loss=0.0000 scale=1.0000 norm=0.4098
[iter 400] loss=-1.0680 val_loss=0.0000 scale=1.0000 norm=0.3909
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3334 val_loss=0.0000 scale=2.0000 norm=1.0407
[iter 200] loss=-0.2413 val_loss=0.0000 scale=1.0000 norm=0.4475
[iter 300] loss=-0.6131 val_loss=0.0000 scale=0.5000 norm=0.2049
[iter 400] loss=-0.8127 val_loss=0.0000 scale=1.0000 norm=0.3900
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2846 val_loss=0.0000 scale=2.0000 norm=1.0129
[iter 200] loss=-0.2600 val_loss=0.0000 scale=1.0000 norm=0.4439
[iter 300] loss=-0.7067 val_loss=0.0000 scale=1.0000 norm=0.4027
[iter 400] loss=-1.0014 val_loss=0.0000 scale=1.0000 norm=0.3767
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2915 val_loss=0.0000 scale=2.0000 norm=1.0333
[iter 200] loss=-0.2766 val_loss=0.0000 scale=1.0000 norm=0.4555
[iter 300] loss=-0.6781 val_loss=0.0000 scale=1.0000 norm=0.4177
[iter 400] loss=-0.9596 val_loss=0.0000 scale=0.5000 norm=0.1980
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2532 val_loss=0.0000 scale=2.0000 norm=1.0225
[iter 200] loss=-0.4889 val_loss=0.0000 scale=2.0000 norm=0.8818
[iter 300] loss=-1.0049 val_loss=0.0000 scale=1.0000 norm=0.3938
[iter 400] loss=-1.3359 val_loss=0.0000 scale=1.0000 norm=0.3779
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2201 val_loss=0.0000 scale=2.0000 norm=0.9793
[iter 200] loss=-0.5546 val_loss=0.0000 scale=2.0000 norm=0.8575
[iter 300] loss=-1.1486 val_loss=0.0000 scale=2.0000 norm=0.7545
[iter 400] loss=-1.5679 val_loss=0.0000 scale=1.0000 norm=0.3552
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2918 val_loss=0.0000 scale=2.0000 norm=1.0217
[iter 200] loss=-0.3450 val_loss=0.0000 scale=1.0000 norm=0.4479
[iter 300] loss=-0.7401 val_loss=0.0000 scale=1.0000 norm=0.4143
[iter 400] loss=-0.9677 val_loss=0.0000 scale=1.0000 norm=0.4027
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1085 val_loss=0.0000 scale=2.0000 norm=0.9823
[iter 200] loss=-0.8362 val_loss=0.0000 scale=2.0000 norm=0.9455
[iter 300] loss=-1.7360 val_loss=0.0000 scale=2.0000 norm=0.8966
[iter 400] loss=-2.5337 val_loss=0.0000 scale=2.0000 norm=0.8055
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2829 val_loss=0.0000 scale=2.0000 norm=1.0123
[iter 200] loss=-0.3435 val_loss=0.0000 scale=1.0000 norm=0.4463
[iter 300] loss=-0.7038 val_loss=0.0000 scale=1.0000 norm=0.4117
[iter 400] loss=-0.9620 val_loss=0.0000 scale=2.0000 norm=0.7971
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3621 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 200] loss=-0.1995 val_loss=0.0000 scale=1.0000 norm=0.4517
[iter 300] loss=-0.5943 val_loss=0.0000 scale=1.0000 norm=0.4205
[iter 400] loss=-0.8615 val_loss=0.0000 scale=2.0000 norm=0.8103
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3112 val_loss=0.0000 scale=1.0000 norm=0.5171
[iter 200] loss=-0.2001 val_loss=0.0000 scale=1.0000 norm=0.4514
[iter 300] loss=-0.5898 val_loss=0.0000 scale=1.0000 norm=0.4231
[iter 400] loss=-0.8735 val_loss=0.0000 scale=1.0000 norm=0.4094
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2866 val_loss=0.0000 scale=2.0000 norm=1.0090
[iter 200] loss=-0.5468 val_loss=0.0000 scale=2.0000 norm=0.8830
[iter 300] loss=-1.2176 val_loss=0.0000 scale=2.0000 norm=0.7876
[iter 400] loss=-1.5797 val_loss=0.0000 scale=2.0000 norm=0.7217
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3245 val_loss=0.0000 scale=2.0000 norm=0.9869
[iter 200] loss=-0.4998 val_loss=0.0000 scale=2.0000 norm=0.8703
[iter 300] loss=-1.2281 val_loss=0.0000 scale=2.0000 norm=0.7646
[iter 400] loss=-1.8041 val_loss=0.0000 scale=2.0000 norm=0.6620
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4011 val_loss=0.0000 scale=1.0000 norm=0.5114
[iter 200] loss=-0.1265 val_loss=0.0000 scale=2.0000 norm=0.8883
[iter 300] loss=-0.4762 val_loss=0.0000 scale=2.0000 norm=0.8016
[iter 400] loss=-0.7845 val_loss=0.0000 scale=2.0000 norm=0.7382
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2445 val_loss=0.0000 scale=2.0000 norm=1.0047
[iter 200] loss=-0.4445 val_loss=0.0000 scale=2.0000 norm=0.8808
[iter 300] loss=-0.8590 val_loss=0.0000 scale=1.0000 norm=0.3935
[iter 400] loss=-1.1942 val_loss=0.0000 scale=1.0000 norm=0.3658
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6488 val_loss=0.0000 scale=1.0000 norm=0.5700
[iter 200] loss=-0.0761 val_loss=0.0000 scale=2.0000 norm=0.9319
[iter 300] loss=-0.7046 val_loss=0.0000 scale=1.0000 norm=0.4198
[iter 400] loss=-1.1154 val_loss=0.0000 scale=1.0000 norm=0.3849
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1841 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 200] loss=-0.7878 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 300] loss=-1.7623 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 400] loss=-2.8661 val_loss=0.0000 scale=2.0000 norm=0.9847
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3187 val_loss=0.0000 scale=2.0000 norm=1.0033
[iter 200] loss=-0.3318 val_loss=0.0000 scale=2.0000 norm=0.8531
[iter 300] loss=-0.8520 val_loss=0.0000 scale=1.0000 norm=0.3782
[iter 400] loss=-1.2660 val_loss=0.0000 scale=1.0000 norm=0.3533
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1644 val_loss=0.0000 scale=2.0000 norm=0.9933
[iter 200] loss=-0.5491 val_loss=0.0000 scale=2.0000 norm=0.8906
[iter 300] loss=-1.2644 val_loss=0.0000 scale=2.0000 norm=0.7966
[iter 400] loss=-1.8002 val_loss=0.0000 scale=1.0000 norm=0.3735
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3192 val_loss=0.0000 scale=2.0000 norm=1.0323
[iter 200] loss=-0.2304 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 300] loss=-0.7069 val_loss=0.0000 scale=1.0000 norm=0.4299
[iter 400] loss=-1.0033 val_loss=0.0000 scale=1.0000 norm=0.4169
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3250 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.5670 val_loss=0.0000 scale=2.0000 norm=0.9203
[iter 300] loss=-1.4213 val_loss=0.0000 scale=2.0000 norm=0.8567
[iter 400] loss=-2.1376 val_loss=0.0000 scale=2.0000 norm=0.7156
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.3089 val_loss=0.0000 scale=1.0000 norm=0.4426
[iter 300] loss=-0.8049 val_loss=0.0000 scale=1.0000 norm=0.3995
[iter 400] loss=-1.1151 val_loss=0.0000 scale=1.0000 norm=0.3716
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1975 val_loss=0.0000 scale=2.0000 norm=0.9830
[iter 200] loss=-0.5805 val_loss=0.0000 scale=2.0000 norm=0.8554
[iter 300] loss=-1.1911 val_loss=0.0000 scale=2.0000 norm=0.7664
[iter 400] loss=-1.5443 val_loss=0.0000 scale=2.0000 norm=0.7011
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2239 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 200] loss=-0.6255 val_loss=0.0000 scale=2.0000 norm=0.8896
[iter 300] loss=-1.2982 val_loss=0.0000 scale=1.0000 norm=0.3951
[iter 400] loss=-1.7680 val_loss=0.0000 scale=1.0000 norm=0.3583
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4370 val_loss=0.0000 scale=1.0000 norm=0.5286
[iter 200] loss=-0.0470 val_loss=0.0000 scale=2.0000 norm=0.9297
[iter 300] loss=-0.4830 val_loss=0.0000 scale=2.0000 norm=0.8537
[iter 400] loss=-0.8441 val_loss=0.0000 scale=1.0000 norm=0.3877
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5504 val_loss=0.0000 scale=2.0000 norm=1.0938
[iter 200] loss=-0.2802 val_loss=0.0000 scale=2.0000 norm=0.9037
[iter 300] loss=-1.0121 val_loss=0.0000 scale=2.0000 norm=0.8201
[iter 400] loss=-1.5350 val_loss=0.0000 scale=2.0000 norm=0.7508
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3865 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.0638 val_loss=0.0000 scale=1.0000 norm=0.4594
[iter 300] loss=-0.4010 val_loss=0.0000 scale=1.0000 norm=0.4246
[iter 400] loss=-0.7105 val_loss=0.0000 scale=1.0000 norm=0.4009
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2549 val_loss=0.0000 scale=2.0000 norm=1.0014
[iter 200] loss=-0.3163 val_loss=0.0000 scale=1.0000 norm=0.4447
[iter 300] loss=-0.7055 val_loss=0.0000 scale=1.0000 norm=0.4138
[iter 400] loss=-1.0076 val_loss=0.0000 scale=0.5000 norm=0.2007
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2063 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 200] loss=-0.6180 val_loss=0.0000 scale=1.0000 norm=0.4464
[iter 300] loss=-1.1756 val_loss=0.0000 scale=2.0000 norm=0.8093
[iter 400] loss=-1.6793 val_loss=0.0000 scale=2.0000 norm=0.7114
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2479 val_loss=0.0000 scale=2.0000 norm=1.0012
[iter 200] loss=-0.4819 val_loss=0.0000 scale=2.0000 norm=0.8626
[iter 300] loss=-0.9191 val_loss=0.0000 scale=1.0000 norm=0.3960
[iter 400] loss=-1.2117 val_loss=0.0000 scale=0.5000 norm=0.1899
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2749 val_loss=0.0000 scale=2.0000 norm=1.0090
[iter 200] loss=-0.3762 val_loss=0.0000 scale=2.0000 norm=0.8934
[iter 300] loss=-0.8305 val_loss=0.0000 scale=1.0000 norm=0.4045
[iter 400] loss=-1.1188 val_loss=0.0000 scale=1.0000 norm=0.3770
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1429 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 200] loss=-0.7713 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-1.5918 val_loss=0.0000 scale=2.0000 norm=0.8228
[iter 400] loss=-2.1919 val_loss=0.0000 scale=1.0000 norm=0.3556
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3509 val_loss=0.0000 scale=2.0000 norm=1.0302
[iter 200] loss=-0.2307 val_loss=0.0000 scale=1.0000 norm=0.4524
[iter 300] loss=-0.6203 val_loss=0.0000 scale=1.0000 norm=0.4259
[iter 400] loss=-0.8652 val_loss=0.0000 scale=1.0000 norm=0.4128
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2556 val_loss=0.0000 scale=2.0000 norm=1.0055
[iter 200] loss=-0.6368 val_loss=0.0000 scale=2.0000 norm=0.9103
[iter 300] loss=-1.4482 val_loss=0.0000 scale=2.0000 norm=0.8449
[iter 400] loss=-2.0626 val_loss=0.0000 scale=1.0000 norm=0.3840
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4019 val_loss=0.0000 scale=1.0000 norm=0.5355
[iter 200] loss=-0.0913 val_loss=0.0000 scale=1.0000 norm=0.4617
[iter 300] loss=-0.4672 val_loss=0.0000 scale=1.0000 norm=0.4124
[iter 400] loss=-0.7751 val_loss=0.0000 scale=1.0000 norm=0.3762
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2929 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 200] loss=-0.2536 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 300] loss=-0.6863 val_loss=0.0000 scale=1.0000 norm=0.4125
[iter 400] loss=-0.9843 val_loss=0.0000 scale=1.0000 norm=0.3962
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3808 val_loss=0.0000 scale=2.0000 norm=1.0047
[iter 200] loss=-0.5375 val_loss=0.0000 scale=2.0000 norm=0.9287
[iter 300] loss=-1.4228 val_loss=0.0000 scale=2.0000 norm=0.8898
[iter 400] loss=-2.2465 val_loss=0.0000 scale=2.0000 norm=0.8240
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3062 val_loss=0.0000 scale=2.0000 norm=1.0150
[iter 200] loss=-0.2271 val_loss=0.0000 scale=1.0000 norm=0.4469
[iter 300] loss=-0.6346 val_loss=0.0000 scale=1.0000 norm=0.4294
[iter 400] loss=-0.9213 val_loss=0.0000 scale=1.0000 norm=0.4106
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4245 val_loss=0.0000 scale=2.0000 norm=1.0047
[iter 200] loss=-0.4442 val_loss=0.0000 scale=2.0000 norm=0.8820
[iter 300] loss=-1.1999 val_loss=0.0000 scale=2.0000 norm=0.7773
[iter 400] loss=-1.7870 val_loss=0.0000 scale=2.0000 norm=0.6612
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5842 val_loss=0.0000 scale=2.0000 norm=1.1318
[iter 200] loss=-0.0315 val_loss=0.0000 scale=2.0000 norm=0.9185
[iter 300] loss=-0.6021 val_loss=0.0000 scale=2.0000 norm=0.8379
[iter 400] loss=-0.9355 val_loss=0.0000 scale=1.0000 norm=0.3914
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2612 val_loss=0.0000 scale=1.0000 norm=0.5027
[iter 200] loss=-0.4110 val_loss=0.0000 scale=2.0000 norm=0.8866
[iter 300] loss=-0.9154 val_loss=0.0000 scale=1.0000 norm=0.4077
[iter 400] loss=-1.2284 val_loss=0.0000 scale=2.0000 norm=0.7646
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2060 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 200] loss=-0.7315 val_loss=0.0000 scale=2.0000 norm=0.9443
[iter 300] loss=-1.6778 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 400] loss=-2.6070 val_loss=0.0000 scale=2.0000 norm=0.9356
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3002 val_loss=0.0000 scale=2.0000 norm=0.9932
[iter 200] loss=-0.4750 val_loss=0.0000 scale=2.0000 norm=0.8746
[iter 300] loss=-1.0735 val_loss=0.0000 scale=1.0000 norm=0.3875
[iter 400] loss=-1.4172 val_loss=0.0000 scale=1.0000 norm=0.3604
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3466 val_loss=0.0000 scale=1.0000 norm=0.5112
[iter 200] loss=-0.2141 val_loss=0.0000 scale=1.0000 norm=0.4514
[iter 300] loss=-0.6167 val_loss=0.0000 scale=2.0000 norm=0.8129
[iter 400] loss=-0.9584 val_loss=0.0000 scale=2.0000 norm=0.7577
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3542 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 200] loss=-0.4978 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 300] loss=-1.2283 val_loss=0.0000 scale=2.0000 norm=0.9099
[iter 400] loss=-2.0764 val_loss=0.0000 scale=2.0000 norm=0.8862
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2815 val_loss=0.0000 scale=2.0000 norm=1.0014
[iter 200] loss=-0.3893 val_loss=0.0000 scale=1.0000 norm=0.4398
[iter 300] loss=-0.7942 val_loss=0.0000 scale=1.0000 norm=0.3995
[iter 400] loss=-1.1085 val_loss=0.0000 scale=1.0000 norm=0.3713
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3053 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 200] loss=-0.3393 val_loss=0.0000 scale=1.0000 norm=0.4387
[iter 300] loss=-0.7366 val_loss=0.0000 scale=1.0000 norm=0.4015
[iter 400] loss=-0.9920 val_loss=0.0000 scale=1.0000 norm=0.3807
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3982 val_loss=0.0000 scale=2.0000 norm=1.0403
[iter 200] loss=-0.1723 val_loss=0.0000 scale=1.0000 norm=0.4595
[iter 300] loss=-0.5687 val_loss=0.0000 scale=1.0000 norm=0.4273
[iter 400] loss=-0.8720 val_loss=0.0000 scale=0.5000 norm=0.1963
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3449 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 200] loss=-0.2995 val_loss=0.0000 scale=1.0000 norm=0.4380
[iter 300] loss=-0.6967 val_loss=0.0000 scale=1.0000 norm=0.3974
[iter 400] loss=-1.0032 val_loss=0.0000 scale=1.0000 norm=0.3709
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2674 val_loss=0.0000 scale=2.0000 norm=0.9680
[iter 200] loss=-0.6529 val_loss=0.0000 scale=2.0000 norm=0.9271
[iter 300] loss=-1.5475 val_loss=0.0000 scale=2.0000 norm=0.8970
[iter 400] loss=-2.3859 val_loss=0.0000 scale=2.0000 norm=0.8388
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2812 val_loss=0.0000 scale=1.0000 norm=0.5090
[iter 200] loss=-0.2512 val_loss=0.0000 scale=1.0000 norm=0.4510
[iter 300] loss=-0.6859 val_loss=0.0000 scale=2.0000 norm=0.8354
[iter 400] loss=-0.9553 val_loss=0.0000 scale=1.0000 norm=0.4038
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5387 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.4141 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 300] loss=-1.3784 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 400] loss=-2.3170 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2394 val_loss=0.0000 scale=2.0000 norm=0.9915
[iter 200] loss=-0.4883 val_loss=0.0000 scale=2.0000 norm=0.8659
[iter 300] loss=-0.9249 val_loss=0.0000 scale=1.0000 norm=0.4033
[iter 400] loss=-1.1955 val_loss=0.0000 scale=1.0000 norm=0.3796
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3456 val_loss=0.0000 scale=2.0000 norm=1.0364
[iter 200] loss=-0.1922 val_loss=0.0000 scale=2.0000 norm=0.9051
[iter 300] loss=-0.5885 val_loss=0.0000 scale=1.0000 norm=0.4181
[iter 400] loss=-0.8546 val_loss=0.0000 scale=1.0000 norm=0.4023
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5011 val_loss=0.0000 scale=2.0000 norm=1.0676
[iter 200] loss=-0.1938 val_loss=0.0000 scale=2.0000 norm=0.9133
[iter 300] loss=-0.7253 val_loss=0.0000 scale=2.0000 norm=0.8255
[iter 400] loss=-1.0949 val_loss=0.0000 scale=1.0000 norm=0.3925
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2444 val_loss=0.0000 scale=2.0000 norm=1.0090
[iter 200] loss=-0.4339 val_loss=0.0000 scale=1.0000 norm=0.4455
[iter 300] loss=-0.8433 val_loss=0.0000 scale=2.0000 norm=0.8210
[iter 400] loss=-1.1762 val_loss=0.0000 scale=1.0000 norm=0.3837
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.6721 val_loss=0.0000 scale=2.0000 norm=1.1671
[iter 200] loss=0.0677 val_loss=0.0000 scale=2.0000 norm=0.9698
[iter 300] loss=-0.3749 val_loss=0.0000 scale=1.0000 norm=0.4465
[iter 400] loss=-0.6897 val_loss=0.0000 scale=1.0000 norm=0.4011
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2405 val_loss=0.0000 scale=2.0000 norm=0.9784
[iter 200] loss=-0.7571 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 300] loss=-2.6001 val_loss=0.0000 scale=4.0000 norm=1.9918
[iter 400] loss=-4.5835 val_loss=0.0000 scale=4.0000 norm=1.9773
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4470 val_loss=0.0000 scale=1.0000 norm=0.5315
[iter 200] loss=-0.0526 val_loss=0.0000 scale=2.0000 norm=0.9425
[iter 300] loss=-0.5134 val_loss=0.0000 scale=1.0000 norm=0.4237
[iter 400] loss=-0.8692 val_loss=0.0000 scale=1.0000 norm=0.3921
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2483 val_loss=0.0000 scale=2.0000 norm=1.0051
[iter 200] loss=-0.3559 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 300] loss=-0.7400 val_loss=0.0000 scale=1.0000 norm=0.4152
[iter 400] loss=-0.9871 val_loss=0.0000 scale=0.5000 norm=0.1957
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3877 val_loss=0.0000 scale=2.0000 norm=1.0471
[iter 200] loss=-0.1203 val_loss=0.0000 scale=1.0000 norm=0.4645
[iter 300] loss=-0.5616 val_loss=0.0000 scale=2.0000 norm=0.8420
[iter 400] loss=-0.8491 val_loss=0.0000 scale=1.0000 norm=0.3985
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3346 val_loss=0.0000 scale=1.0000 norm=0.5121
[iter 200] loss=-0.1772 val_loss=0.0000 scale=2.0000 norm=0.8915
[iter 300] loss=-0.5743 val_loss=0.0000 scale=1.0000 norm=0.4098
[iter 400] loss=-0.8340 val_loss=0.0000 scale=1.0000 norm=0.3877
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2808 val_loss=0.0000 scale=1.0000 norm=0.5150
[iter 200] loss=-0.3578 val_loss=0.0000 scale=2.0000 norm=0.8774
[iter 300] loss=-0.8501 val_loss=0.0000 scale=1.0000 norm=0.3937
[iter 400] loss=-1.1596 val_loss=0.0000 scale=2.0000 norm=0.7409
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3661 val_loss=0.0000 scale=2.0000 norm=1.0220
[iter 200] loss=-0.1725 val_loss=0.0000 scale=2.0000 norm=0.8922
[iter 300] loss=-0.6763 val_loss=0.0000 scale=2.0000 norm=0.8081
[iter 400] loss=-0.9443 val_loss=0.0000 scale=1.0000 norm=0.3851
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5175 val_loss=0.0000 scale=2.0000 norm=1.0634
[iter 200] loss=-0.2884 val_loss=0.0000 scale=2.0000 norm=0.8929
[iter 300] loss=-0.8899 val_loss=0.0000 scale=1.0000 norm=0.3998
[iter 400] loss=-1.2542 val_loss=0.0000 scale=1.0000 norm=0.3707
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3277 val_loss=0.0000 scale=2.0000 norm=0.9712
[iter 200] loss=-0.6488 val_loss=0.0000 scale=2.0000 norm=0.9702
[iter 300] loss=-1.6821 val_loss=0.0000 scale=2.0000 norm=0.9817
[iter 400] loss=-2.9103 val_loss=0.0000 scale=4.0000 norm=1.9626
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2253 val_loss=0.0000 scale=2.0000 norm=0.9983
[iter 200] loss=-0.4352 val_loss=0.0000 scale=2.0000 norm=0.8673
[iter 300] loss=-0.8403 val_loss=0.0000 scale=2.0000 norm=0.8017
[iter 400] loss=-1.1309 val_loss=0.0000 scale=1.0000 norm=0.3778
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3113 val_loss=0.0000 scale=2.0000 norm=1.0262
[iter 200] loss=-0.1857 val_loss=0.0000 scale=1.0000 norm=0.4513
[iter 300] loss=-0.5311 val_loss=0.0000 scale=1.0000 norm=0.4204
[iter 400] loss=-0.8169 val_loss=0.0000 scale=1.0000 norm=0.4057
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4259 val_loss=0.0000 scale=2.0000 norm=1.0709
[iter 200] loss=-0.0955 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 300] loss=-0.5472 val_loss=0.0000 scale=1.0000 norm=0.4237
[iter 400] loss=-0.9361 val_loss=0.0000 scale=1.0000 norm=0.3829
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3865 val_loss=0.0000 scale=2.0000 norm=1.0584
[iter 200] loss=-0.2053 val_loss=0.0000 scale=2.0000 norm=0.9159
[iter 300] loss=-0.6402 val_loss=0.0000 scale=1.0000 norm=0.4194
[iter 400] loss=-0.9324 val_loss=0.0000 scale=1.0000 norm=0.3978
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2556 val_loss=0.0000 scale=2.0000 norm=1.0240
[iter 200] loss=-0.4189 val_loss=0.0000 scale=2.0000 norm=0.8949
[iter 300] loss=-0.7875 val_loss=0.0000 scale=2.0000 norm=0.8348
[iter 400] loss=-1.0342 val_loss=0.0000 scale=1.0000 norm=0.4101
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1303 val_loss=0.0000 scale=2.0000 norm=0.9725
[iter 200] loss=-0.7238 val_loss=0.0000 scale=2.0000 norm=0.8693
[iter 300] loss=-1.4459 val_loss=0.0000 scale=2.0000 norm=0.7561
[iter 400] loss=-1.9295 val_loss=0.0000 scale=1.0000 norm=0.3340
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1450 val_loss=0.0000 scale=2.0000 norm=0.9996
[iter 200] loss=-0.8429 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-2.3452 val_loss=0.0000 scale=4.0000 norm=1.9717
[iter 400] loss=-3.7202 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3626 val_loss=0.0000 scale=2.0000 norm=1.0373
[iter 200] loss=-0.2668 val_loss=0.0000 scale=2.0000 norm=0.9254
[iter 300] loss=-0.7406 val_loss=0.0000 scale=1.0000 norm=0.4335
[iter 400] loss=-1.0683 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2322 val_loss=0.0000 scale=2.0000 norm=1.0201
[iter 200] loss=-0.4407 val_loss=0.0000 scale=1.0000 norm=0.4639
[iter 300] loss=-1.0351 val_loss=0.0000 scale=1.0000 norm=0.4167
[iter 400] loss=-1.4213 val_loss=0.0000 scale=1.0000 norm=0.3698
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1427 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 200] loss=-0.7706 val_loss=0.0000 scale=2.0000 norm=0.9220
[iter 300] loss=-1.6406 val_loss=0.0000 scale=2.0000 norm=0.8668
[iter 400] loss=-2.4117 val_loss=0.0000 scale=2.0000 norm=0.7827
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2517 val_loss=0.0000 scale=2.0000 norm=0.9980
[iter 200] loss=-0.3482 val_loss=0.0000 scale=1.0000 norm=0.4390
[iter 300] loss=-0.7418 val_loss=0.0000 scale=1.0000 norm=0.4046
[iter 400] loss=-1.0291 val_loss=0.0000 scale=1.0000 norm=0.3882

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n09>
Subject: Job 856542: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:28 2024
Job was executed on host(s) <4*c207n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:30 2024
                            <4*c207n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:11:30 2024
Terminated at Wed Oct 23 12:37:19 2024
Results reported at Wed Oct 23 12:37:19 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "RRU Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4144.34 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.04 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1563 sec.
    Turnaround time :                            1551 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err> for stderr output of this job.

polymer representation: Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
RRU Trimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3432 val_loss=0.0000 scale=2.0000 norm=1.0305
[iter 200] loss=-0.2887 val_loss=0.0000 scale=2.0000 norm=0.9114
[iter 300] loss=-0.8651 val_loss=0.0000 scale=2.0000 norm=0.8061
[iter 400] loss=-1.1772 val_loss=0.0000 scale=1.0000 norm=0.3795
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3290 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 200] loss=-0.2149 val_loss=0.0000 scale=1.0000 norm=0.4526
[iter 300] loss=-0.5990 val_loss=0.0000 scale=2.0000 norm=0.8193
[iter 400] loss=-0.8380 val_loss=0.0000 scale=2.0000 norm=0.7950
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3376 val_loss=0.0000 scale=2.0000 norm=1.0162
[iter 200] loss=-0.3313 val_loss=0.0000 scale=2.0000 norm=0.8773
[iter 300] loss=-0.7124 val_loss=0.0000 scale=1.0000 norm=0.4141
[iter 400] loss=-1.0012 val_loss=0.0000 scale=2.0000 norm=0.7973
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3732 val_loss=0.0000 scale=2.0000 norm=1.0262
[iter 200] loss=-0.2597 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 300] loss=-0.7061 val_loss=0.0000 scale=1.0000 norm=0.4019
[iter 400] loss=-0.9763 val_loss=0.0000 scale=1.0000 norm=0.3863
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2870 val_loss=0.0000 scale=2.0000 norm=1.0121
[iter 200] loss=-0.6010 val_loss=0.0000 scale=2.0000 norm=0.9058
[iter 300] loss=-1.4210 val_loss=0.0000 scale=2.0000 norm=0.8423
[iter 400] loss=-2.0772 val_loss=0.0000 scale=2.0000 norm=0.7646
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4278 val_loss=0.0000 scale=1.0000 norm=0.5356
[iter 200] loss=-0.0134 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 300] loss=-0.3780 val_loss=0.0000 scale=1.0000 norm=0.4318
[iter 400] loss=-0.6747 val_loss=0.0000 scale=1.0000 norm=0.3978
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3986 val_loss=0.0000 scale=2.0000 norm=1.0157
[iter 200] loss=-0.5454 val_loss=0.0000 scale=2.0000 norm=0.9433
[iter 300] loss=-1.4919 val_loss=0.0000 scale=2.0000 norm=0.9470
[iter 400] loss=-2.4382 val_loss=0.0000 scale=2.0000 norm=0.9424
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5068 val_loss=0.0000 scale=2.0000 norm=1.0570
[iter 200] loss=-0.2834 val_loss=0.0000 scale=2.0000 norm=0.9082
[iter 300] loss=-0.8455 val_loss=0.0000 scale=1.0000 norm=0.4043
[iter 400] loss=-1.1909 val_loss=0.0000 scale=1.0000 norm=0.3594
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6166 val_loss=0.0000 scale=1.0000 norm=0.5757
[iter 200] loss=0.0042 val_loss=0.0000 scale=1.0000 norm=0.4740
[iter 300] loss=-0.6598 val_loss=0.0000 scale=1.0000 norm=0.4109
[iter 400] loss=-1.1402 val_loss=0.0000 scale=2.0000 norm=0.7396
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1221 val_loss=0.0000 scale=2.0000 norm=0.9884
[iter 200] loss=-0.7225 val_loss=0.0000 scale=2.0000 norm=0.8812
[iter 300] loss=-1.2986 val_loss=0.0000 scale=1.0000 norm=0.3989
[iter 400] loss=-1.7875 val_loss=0.0000 scale=1.0000 norm=0.3372
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3847 val_loss=0.0000 scale=1.0000 norm=0.5308
[iter 200] loss=-0.1993 val_loss=0.0000 scale=2.0000 norm=0.9161
[iter 300] loss=-0.5964 val_loss=0.0000 scale=1.0000 norm=0.4134
[iter 400] loss=-0.8722 val_loss=0.0000 scale=0.5000 norm=0.1992
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2682 val_loss=0.0000 scale=1.0000 norm=0.5036
[iter 200] loss=-0.3888 val_loss=0.0000 scale=2.0000 norm=0.8988
[iter 300] loss=-0.9262 val_loss=0.0000 scale=1.0000 norm=0.4049
[iter 400] loss=-1.2508 val_loss=0.0000 scale=1.0000 norm=0.3812
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3711 val_loss=0.0000 scale=2.0000 norm=1.0300
[iter 200] loss=-0.2072 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 300] loss=-0.6245 val_loss=0.0000 scale=1.0000 norm=0.4163
[iter 400] loss=-0.8824 val_loss=0.0000 scale=1.0000 norm=0.3920
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2231 val_loss=0.0000 scale=1.0000 norm=0.5058
[iter 200] loss=-0.4634 val_loss=0.0000 scale=2.0000 norm=0.8962
[iter 300] loss=-1.0574 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 400] loss=-1.4207 val_loss=0.0000 scale=2.0000 norm=0.7521
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3075 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 200] loss=-0.4392 val_loss=0.0000 scale=2.0000 norm=0.8885
[iter 300] loss=-0.9674 val_loss=0.0000 scale=1.0000 norm=0.4107
[iter 400] loss=-1.3110 val_loss=0.0000 scale=0.5000 norm=0.1878
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2839 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.3675 val_loss=0.0000 scale=1.0000 norm=0.4480
[iter 300] loss=-0.8973 val_loss=0.0000 scale=1.0000 norm=0.4136
[iter 400] loss=-1.3373 val_loss=0.0000 scale=2.0000 norm=0.7475
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4091 val_loss=0.0000 scale=1.0000 norm=0.5267
[iter 200] loss=-0.2641 val_loss=0.0000 scale=2.0000 norm=0.8980
[iter 300] loss=-0.8222 val_loss=0.0000 scale=1.0000 norm=0.3904
[iter 400] loss=-1.0986 val_loss=0.0000 scale=1.0000 norm=0.3573
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3313 val_loss=0.0000 scale=1.0000 norm=0.5035
[iter 200] loss=-0.2753 val_loss=0.0000 scale=2.0000 norm=0.8596
[iter 300] loss=-0.7282 val_loss=0.0000 scale=1.0000 norm=0.3919
[iter 400] loss=-1.0137 val_loss=0.0000 scale=1.0000 norm=0.3807
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3202 val_loss=0.0000 scale=1.0000 norm=0.5118
[iter 200] loss=-0.3180 val_loss=0.0000 scale=2.0000 norm=0.8996
[iter 300] loss=-0.8223 val_loss=0.0000 scale=1.0000 norm=0.4074
[iter 400] loss=-1.1798 val_loss=0.0000 scale=2.0000 norm=0.7473
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5401 val_loss=0.0000 scale=2.0000 norm=1.1270
[iter 200] loss=-0.0794 val_loss=0.0000 scale=1.0000 norm=0.4841
[iter 300] loss=-0.5169 val_loss=0.0000 scale=2.0000 norm=0.8823
[iter 400] loss=-0.8325 val_loss=0.0000 scale=1.0000 norm=0.4130
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1410 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.7518 val_loss=0.0000 scale=2.0000 norm=0.9075
[iter 300] loss=-1.5827 val_loss=0.0000 scale=2.0000 norm=0.8421
[iter 400] loss=-2.3400 val_loss=0.0000 scale=2.0000 norm=0.7981
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5730 val_loss=0.0000 scale=1.0000 norm=0.5690
[iter 200] loss=-0.0008 val_loss=0.0000 scale=2.0000 norm=0.9599
[iter 300] loss=-0.4261 val_loss=0.0000 scale=1.0000 norm=0.4496
[iter 400] loss=-0.7839 val_loss=0.0000 scale=1.0000 norm=0.4300
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3224 val_loss=0.0000 scale=1.0000 norm=0.5127
[iter 200] loss=-0.3109 val_loss=0.0000 scale=2.0000 norm=0.8912
[iter 300] loss=-0.8429 val_loss=0.0000 scale=2.0000 norm=0.7880
[iter 400] loss=-1.2030 val_loss=0.0000 scale=1.0000 norm=0.3612
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3129 val_loss=0.0000 scale=2.0000 norm=1.0245
[iter 200] loss=-0.2518 val_loss=0.0000 scale=1.0000 norm=0.4484
[iter 300] loss=-0.5725 val_loss=0.0000 scale=1.0000 norm=0.4103
[iter 400] loss=-0.8323 val_loss=0.0000 scale=2.0000 norm=0.7779
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2794 val_loss=0.0000 scale=2.0000 norm=0.9636
[iter 200] loss=-0.6018 val_loss=0.0000 scale=2.0000 norm=0.8940
[iter 300] loss=-1.4205 val_loss=0.0000 scale=2.0000 norm=0.8338
[iter 400] loss=-2.1650 val_loss=0.0000 scale=2.0000 norm=0.7804
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8130 val_loss=0.0000 scale=1.0000 norm=0.6281
[iter 200] loss=0.3312 val_loss=0.0000 scale=1.0000 norm=0.5100
[iter 300] loss=-0.1960 val_loss=0.0000 scale=2.0000 norm=0.8872
[iter 400] loss=-0.6306 val_loss=0.0000 scale=1.0000 norm=0.4176
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1068 val_loss=0.0000 scale=2.0000 norm=1.0019
[iter 200] loss=-0.9461 val_loss=0.0000 scale=4.0000 norm=1.9817
[iter 300] loss=-2.9412 val_loss=0.0000 scale=4.0000 norm=1.9970
[iter 400] loss=-4.9391 val_loss=0.0000 scale=4.0000 norm=1.9975
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1643 val_loss=0.0000 scale=2.0000 norm=0.9776
[iter 200] loss=-0.6838 val_loss=0.0000 scale=2.0000 norm=0.8728
[iter 300] loss=-1.3871 val_loss=0.0000 scale=2.0000 norm=0.7590
[iter 400] loss=-1.8116 val_loss=0.0000 scale=2.0000 norm=0.7051
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2060 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 200] loss=-0.7315 val_loss=0.0000 scale=2.0000 norm=0.9443
[iter 300] loss=-1.6778 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 400] loss=-2.6071 val_loss=0.0000 scale=2.0000 norm=0.9357
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3429 val_loss=0.0000 scale=2.0000 norm=1.0163
[iter 200] loss=-0.3793 val_loss=0.0000 scale=2.0000 norm=0.8960
[iter 300] loss=-0.9650 val_loss=0.0000 scale=1.0000 norm=0.4087
[iter 400] loss=-1.3789 val_loss=0.0000 scale=1.0000 norm=0.3903
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4495 val_loss=0.0000 scale=2.0000 norm=1.0899
[iter 200] loss=-0.1289 val_loss=0.0000 scale=1.0000 norm=0.4601
[iter 300] loss=-0.4345 val_loss=0.0000 scale=1.0000 norm=0.4222
[iter 400] loss=-0.6817 val_loss=0.0000 scale=1.0000 norm=0.4058
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3014 val_loss=0.0000 scale=2.0000 norm=1.0110
[iter 200] loss=-0.5495 val_loss=0.0000 scale=2.0000 norm=0.9018
[iter 300] loss=-1.2479 val_loss=0.0000 scale=2.0000 norm=0.8100
[iter 400] loss=-1.7436 val_loss=0.0000 scale=1.0000 norm=0.3571
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1727 val_loss=0.0000 scale=2.0000 norm=0.9677
[iter 200] loss=-0.7643 val_loss=0.0000 scale=2.0000 norm=0.9510
[iter 300] loss=-1.7335 val_loss=0.0000 scale=2.0000 norm=0.9625
[iter 400] loss=-2.6665 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2597 val_loss=0.0000 scale=2.0000 norm=1.0025
[iter 200] loss=-0.3942 val_loss=0.0000 scale=1.0000 norm=0.4329
[iter 300] loss=-0.8954 val_loss=0.0000 scale=1.0000 norm=0.3898
[iter 400] loss=-1.2110 val_loss=0.0000 scale=1.0000 norm=0.3779
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2729 val_loss=0.0000 scale=1.0000 norm=0.5135
[iter 200] loss=-0.2998 val_loss=0.0000 scale=2.0000 norm=0.8915
[iter 300] loss=-0.8080 val_loss=0.0000 scale=1.0000 norm=0.3958
[iter 400] loss=-1.1205 val_loss=0.0000 scale=1.0000 norm=0.3726
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3096 val_loss=0.0000 scale=2.0000 norm=1.0127
[iter 200] loss=-0.2612 val_loss=0.0000 scale=2.0000 norm=0.8782
[iter 300] loss=-0.6547 val_loss=0.0000 scale=2.0000 norm=0.8056
[iter 400] loss=-0.9391 val_loss=0.0000 scale=2.0000 norm=0.7750
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3064 val_loss=0.0000 scale=2.0000 norm=1.0153
[iter 200] loss=-0.2841 val_loss=0.0000 scale=1.0000 norm=0.4436
[iter 300] loss=-0.7356 val_loss=0.0000 scale=1.0000 norm=0.3974
[iter 400] loss=-1.0369 val_loss=0.0000 scale=1.0000 norm=0.3794
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3285 val_loss=0.0000 scale=2.0000 norm=1.0447
[iter 200] loss=-0.2069 val_loss=0.0000 scale=2.0000 norm=0.9052
[iter 300] loss=-0.6570 val_loss=0.0000 scale=2.0000 norm=0.8132
[iter 400] loss=-0.9246 val_loss=0.0000 scale=1.0000 norm=0.3889
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2880 val_loss=0.0000 scale=2.0000 norm=1.0112
[iter 200] loss=-0.2758 val_loss=0.0000 scale=1.0000 norm=0.4403
[iter 300] loss=-0.7330 val_loss=0.0000 scale=2.0000 norm=0.7954
[iter 400] loss=-1.0022 val_loss=0.0000 scale=1.0000 norm=0.3777
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6518 val_loss=0.0000 scale=1.0000 norm=0.5819
[iter 200] loss=0.1037 val_loss=0.0000 scale=2.0000 norm=0.9511
[iter 300] loss=-0.4970 val_loss=0.0000 scale=1.0000 norm=0.4107
[iter 400] loss=-0.8916 val_loss=0.0000 scale=1.0000 norm=0.3830
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2833 val_loss=0.0000 scale=2.0000 norm=1.0089
[iter 200] loss=-0.2907 val_loss=0.0000 scale=2.0000 norm=0.8818
[iter 300] loss=-0.7683 val_loss=0.0000 scale=1.0000 norm=0.4079
[iter 400] loss=-1.1078 val_loss=0.0000 scale=2.0000 norm=0.7768
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3001 val_loss=0.0000 scale=2.0000 norm=1.0195
[iter 200] loss=-0.3386 val_loss=0.0000 scale=1.0000 norm=0.4550
[iter 300] loss=-0.7472 val_loss=0.0000 scale=2.0000 norm=0.8524
[iter 400] loss=-1.0622 val_loss=0.0000 scale=0.5000 norm=0.2029
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2773 val_loss=0.0000 scale=2.0000 norm=1.0108
[iter 200] loss=-0.2345 val_loss=0.0000 scale=1.0000 norm=0.4435
[iter 300] loss=-0.5903 val_loss=0.0000 scale=1.0000 norm=0.4051
[iter 400] loss=-0.8076 val_loss=0.0000 scale=1.0000 norm=0.3855
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3373 val_loss=0.0000 scale=2.0000 norm=1.0243
[iter 200] loss=-0.2665 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 300] loss=-0.6148 val_loss=0.0000 scale=1.0000 norm=0.4227
[iter 400] loss=-0.8639 val_loss=0.0000 scale=1.0000 norm=0.4009
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2652 val_loss=0.0000 scale=2.0000 norm=1.0312
[iter 200] loss=-0.2305 val_loss=0.0000 scale=1.0000 norm=0.4601
[iter 300] loss=-0.6456 val_loss=0.0000 scale=1.0000 norm=0.4252
[iter 400] loss=-0.8964 val_loss=0.0000 scale=1.0000 norm=0.4026
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2598 val_loss=0.0000 scale=2.0000 norm=0.9799
[iter 200] loss=-0.7165 val_loss=0.0000 scale=2.0000 norm=0.9748
[iter 300] loss=-1.9868 val_loss=0.0000 scale=4.0000 norm=1.9636
[iter 400] loss=-3.2291 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2903 val_loss=0.0000 scale=2.0000 norm=1.0190
[iter 200] loss=-0.2938 val_loss=0.0000 scale=1.0000 norm=0.4551
[iter 300] loss=-0.6648 val_loss=0.0000 scale=1.0000 norm=0.4197
[iter 400] loss=-0.9411 val_loss=0.0000 scale=1.0000 norm=0.4037
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3872 val_loss=0.0000 scale=2.0000 norm=1.0501
[iter 200] loss=-0.2102 val_loss=0.0000 scale=1.0000 norm=0.4473
[iter 300] loss=-0.6021 val_loss=0.0000 scale=1.0000 norm=0.4062
[iter 400] loss=-0.8563 val_loss=0.0000 scale=2.0000 norm=0.7651
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3277 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.2905 val_loss=0.0000 scale=2.0000 norm=0.8876
[iter 300] loss=-0.6986 val_loss=0.0000 scale=1.0000 norm=0.4072
[iter 400] loss=-0.9547 val_loss=0.0000 scale=1.0000 norm=0.3883
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4074 val_loss=0.0000 scale=2.0000 norm=1.0463
[iter 200] loss=-0.2965 val_loss=0.0000 scale=2.0000 norm=0.8906
[iter 300] loss=-0.7996 val_loss=0.0000 scale=2.0000 norm=0.7466
[iter 400] loss=-1.0791 val_loss=0.0000 scale=1.0000 norm=0.3366
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4090 val_loss=0.0000 scale=2.0000 norm=1.0568
[iter 200] loss=-0.2224 val_loss=0.0000 scale=2.0000 norm=0.9240
[iter 300] loss=-0.6845 val_loss=0.0000 scale=1.0000 norm=0.4191
[iter 400] loss=-0.9671 val_loss=0.0000 scale=1.0000 norm=0.3936
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3314 val_loss=0.0000 scale=2.0000 norm=1.0580
[iter 200] loss=-0.1734 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 300] loss=-0.5891 val_loss=0.0000 scale=2.0000 norm=0.8721
[iter 400] loss=-0.8898 val_loss=0.0000 scale=1.0000 norm=0.4203
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3410 val_loss=0.0000 scale=2.0000 norm=1.0407
[iter 200] loss=-0.1580 val_loss=0.0000 scale=2.0000 norm=0.9158
[iter 300] loss=-0.5502 val_loss=0.0000 scale=1.0000 norm=0.4184
[iter 400] loss=-0.8310 val_loss=0.0000 scale=1.0000 norm=0.4001
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3250 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.5695 val_loss=0.0000 scale=2.0000 norm=0.9214
[iter 300] loss=-1.4235 val_loss=0.0000 scale=2.0000 norm=0.8549
[iter 400] loss=-2.1374 val_loss=0.0000 scale=2.0000 norm=0.7167
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3279 val_loss=0.0000 scale=2.0000 norm=1.0198
[iter 200] loss=-0.3438 val_loss=0.0000 scale=2.0000 norm=0.8619
[iter 300] loss=-0.8332 val_loss=0.0000 scale=1.0000 norm=0.3966
[iter 400] loss=-1.0945 val_loss=0.0000 scale=1.0000 norm=0.3766
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2954 val_loss=0.0000 scale=2.0000 norm=1.0315
[iter 200] loss=-0.3609 val_loss=0.0000 scale=2.0000 norm=0.8955
[iter 300] loss=-0.7836 val_loss=0.0000 scale=1.0000 norm=0.4122
[iter 400] loss=-1.1040 val_loss=0.0000 scale=1.0000 norm=0.3910
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1085 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.8367 val_loss=0.0000 scale=2.0000 norm=0.9462
[iter 300] loss=-1.7415 val_loss=0.0000 scale=2.0000 norm=0.9002
[iter 400] loss=-2.5461 val_loss=0.0000 scale=2.0000 norm=0.8369
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3439 val_loss=0.0000 scale=2.0000 norm=1.0054
[iter 200] loss=-0.4629 val_loss=0.0000 scale=2.0000 norm=0.8743
[iter 300] loss=-1.0310 val_loss=0.0000 scale=2.0000 norm=0.8034
[iter 400] loss=-1.4955 val_loss=0.0000 scale=1.0000 norm=0.3482
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2475 val_loss=0.0000 scale=2.0000 norm=0.9810
[iter 200] loss=-0.6666 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 300] loss=-1.4969 val_loss=0.0000 scale=2.0000 norm=0.8551
[iter 400] loss=-2.1653 val_loss=0.0000 scale=2.0000 norm=0.7761
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3930 val_loss=0.0000 scale=2.0000 norm=1.0564
[iter 200] loss=-0.0801 val_loss=0.0000 scale=1.0000 norm=0.4636
[iter 300] loss=-0.5366 val_loss=0.0000 scale=1.0000 norm=0.4186
[iter 400] loss=-0.8521 val_loss=0.0000 scale=2.0000 norm=0.7973
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4335 val_loss=0.0000 scale=2.0000 norm=1.0855
[iter 200] loss=-0.0390 val_loss=0.0000 scale=1.0000 norm=0.4786
[iter 300] loss=-0.4200 val_loss=0.0000 scale=1.0000 norm=0.4500
[iter 400] loss=-0.7196 val_loss=0.0000 scale=2.0000 norm=0.8366
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3708 val_loss=0.0000 scale=1.0000 norm=0.5252
[iter 200] loss=-0.1367 val_loss=0.0000 scale=1.0000 norm=0.4619
[iter 300] loss=-0.5128 val_loss=0.0000 scale=2.0000 norm=0.8343
[iter 400] loss=-0.7896 val_loss=0.0000 scale=1.0000 norm=0.3919
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2346 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 200] loss=-0.4646 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 300] loss=-0.9672 val_loss=0.0000 scale=2.0000 norm=0.7974
[iter 400] loss=-1.3454 val_loss=0.0000 scale=0.5000 norm=0.1877
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3147 val_loss=0.0000 scale=2.0000 norm=1.0145
[iter 200] loss=-0.3809 val_loss=0.0000 scale=2.0000 norm=0.8592
[iter 300] loss=-0.8427 val_loss=0.0000 scale=1.0000 norm=0.3963
[iter 400] loss=-1.1404 val_loss=0.0000 scale=1.0000 norm=0.3805
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4489 val_loss=0.0000 scale=2.0000 norm=1.0384
[iter 200] loss=-0.3152 val_loss=0.0000 scale=2.0000 norm=0.8869
[iter 300] loss=-0.8153 val_loss=0.0000 scale=1.0000 norm=0.3983
[iter 400] loss=-1.1996 val_loss=0.0000 scale=1.0000 norm=0.3700
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3884 val_loss=0.0000 scale=2.0000 norm=1.0444
[iter 200] loss=-0.0820 val_loss=0.0000 scale=2.0000 norm=0.9290
[iter 300] loss=-0.4753 val_loss=0.0000 scale=2.0000 norm=0.8357
[iter 400] loss=-0.7732 val_loss=0.0000 scale=2.0000 norm=0.7816
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5691 val_loss=0.0000 scale=1.0000 norm=0.5792
[iter 200] loss=-0.1498 val_loss=0.0000 scale=2.0000 norm=0.9325
[iter 300] loss=-0.6366 val_loss=0.0000 scale=1.0000 norm=0.4177
[iter 400] loss=-1.0168 val_loss=0.0000 scale=1.0000 norm=0.3912
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2518 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 200] loss=-0.5061 val_loss=0.0000 scale=2.0000 norm=0.8668
[iter 300] loss=-1.1252 val_loss=0.0000 scale=2.0000 norm=0.7662
[iter 400] loss=-1.5462 val_loss=0.0000 scale=1.0000 norm=0.3395
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2700 val_loss=0.0000 scale=1.0000 norm=0.5014
[iter 200] loss=-0.3216 val_loss=0.0000 scale=2.0000 norm=0.9014
[iter 300] loss=-0.7686 val_loss=0.0000 scale=2.0000 norm=0.8338
[iter 400] loss=-1.1042 val_loss=0.0000 scale=1.0000 norm=0.3941
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4637 val_loss=0.0000 scale=2.0000 norm=1.0784
[iter 200] loss=-0.0398 val_loss=0.0000 scale=1.0000 norm=0.4666
[iter 300] loss=-0.3930 val_loss=0.0000 scale=1.0000 norm=0.4251
[iter 400] loss=-0.6972 val_loss=0.0000 scale=1.0000 norm=0.3960
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2966 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 200] loss=-0.5849 val_loss=0.0000 scale=2.0000 norm=0.9056
[iter 300] loss=-1.2960 val_loss=0.0000 scale=1.0000 norm=0.4154
[iter 400] loss=-1.8825 val_loss=0.0000 scale=2.0000 norm=0.7495
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2515 val_loss=0.0000 scale=2.0000 norm=0.9937
[iter 200] loss=-0.4846 val_loss=0.0000 scale=2.0000 norm=0.8814
[iter 300] loss=-1.0127 val_loss=0.0000 scale=1.0000 norm=0.3947
[iter 400] loss=-1.3392 val_loss=0.0000 scale=1.0000 norm=0.3654
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2763 val_loss=0.0000 scale=2.0000 norm=0.9947
[iter 200] loss=-0.4286 val_loss=0.0000 scale=2.0000 norm=0.8545
[iter 300] loss=-0.8973 val_loss=0.0000 scale=1.0000 norm=0.3771
[iter 400] loss=-1.2056 val_loss=0.0000 scale=1.0000 norm=0.3366
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3413 val_loss=0.0000 scale=2.0000 norm=1.0485
[iter 200] loss=-0.1699 val_loss=0.0000 scale=2.0000 norm=0.9339
[iter 300] loss=-0.5536 val_loss=0.0000 scale=1.0000 norm=0.4289
[iter 400] loss=-0.8909 val_loss=0.0000 scale=2.0000 norm=0.8278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2346 val_loss=0.0000 scale=2.0000 norm=0.9781
[iter 200] loss=-0.6004 val_loss=0.0000 scale=2.0000 norm=0.8724
[iter 300] loss=-1.3414 val_loss=0.0000 scale=2.0000 norm=0.7993
[iter 400] loss=-1.9173 val_loss=0.0000 scale=1.0000 norm=0.3732
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3974 val_loss=0.0000 scale=2.0000 norm=1.0573
[iter 200] loss=-0.0301 val_loss=0.0000 scale=1.0000 norm=0.4608
[iter 300] loss=-0.3764 val_loss=0.0000 scale=1.0000 norm=0.4244
[iter 400] loss=-0.7208 val_loss=0.0000 scale=2.0000 norm=0.8185
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5436 val_loss=0.0000 scale=2.0000 norm=1.1294
[iter 200] loss=0.0852 val_loss=0.0000 scale=2.0000 norm=0.9881
[iter 300] loss=-0.2231 val_loss=0.0000 scale=1.0000 norm=0.4496
[iter 400] loss=-0.4629 val_loss=0.0000 scale=1.0000 norm=0.4212
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2697 val_loss=0.0000 scale=2.0000 norm=0.9969
[iter 200] loss=-0.6790 val_loss=0.0000 scale=2.0000 norm=0.9503
[iter 300] loss=-1.6257 val_loss=0.0000 scale=2.0000 norm=0.9456
[iter 400] loss=-2.5624 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2054 val_loss=0.0000 scale=2.0000 norm=0.9562
[iter 200] loss=-0.7477 val_loss=0.0000 scale=2.0000 norm=0.9487
[iter 300] loss=-1.6958 val_loss=0.0000 scale=2.0000 norm=0.9463
[iter 400] loss=-2.6250 val_loss=0.0000 scale=2.0000 norm=0.9290
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4063 val_loss=0.0000 scale=1.0000 norm=0.5216
[iter 200] loss=-0.3202 val_loss=0.0000 scale=1.0000 norm=0.4478
[iter 300] loss=-0.8606 val_loss=0.0000 scale=1.0000 norm=0.4015
[iter 400] loss=-1.2145 val_loss=0.0000 scale=1.0000 norm=0.3637
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2381 val_loss=0.0000 scale=2.0000 norm=0.9965
[iter 200] loss=-0.4542 val_loss=0.0000 scale=2.0000 norm=0.8668
[iter 300] loss=-0.9405 val_loss=0.0000 scale=1.0000 norm=0.3909
[iter 400] loss=-1.2403 val_loss=0.0000 scale=1.0000 norm=0.3729
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2920 val_loss=0.0000 scale=2.0000 norm=1.0095
[iter 200] loss=-0.3452 val_loss=0.0000 scale=2.0000 norm=0.8795
[iter 300] loss=-0.7894 val_loss=0.0000 scale=1.0000 norm=0.3920
[iter 400] loss=-1.0563 val_loss=0.0000 scale=1.0000 norm=0.3715
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2904 val_loss=0.0000 scale=1.0000 norm=0.5147
[iter 200] loss=-0.2647 val_loss=0.0000 scale=2.0000 norm=0.9064
[iter 300] loss=-0.6873 val_loss=0.0000 scale=2.0000 norm=0.8214
[iter 400] loss=-0.9661 val_loss=0.0000 scale=1.0000 norm=0.3882
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4892 val_loss=0.0000 scale=2.0000 norm=1.0552
[iter 200] loss=-0.2787 val_loss=0.0000 scale=2.0000 norm=0.8726
[iter 300] loss=-0.7894 val_loss=0.0000 scale=1.0000 norm=0.4000
[iter 400] loss=-1.1695 val_loss=0.0000 scale=1.0000 norm=0.3844
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1477 val_loss=0.0000 scale=2.0000 norm=0.9742
[iter 200] loss=-0.7364 val_loss=0.0000 scale=2.0000 norm=0.8985
[iter 300] loss=-1.5613 val_loss=0.0000 scale=2.0000 norm=0.8305
[iter 400] loss=-2.2474 val_loss=0.0000 scale=2.0000 norm=0.7664
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3839 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.1462 val_loss=0.0000 scale=1.0000 norm=0.4550
[iter 300] loss=-0.5703 val_loss=0.0000 scale=2.0000 norm=0.8380
[iter 400] loss=-0.8918 val_loss=0.0000 scale=1.0000 norm=0.3973
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2543 val_loss=0.0000 scale=2.0000 norm=1.0229
[iter 200] loss=-0.4054 val_loss=0.0000 scale=2.0000 norm=0.8991
[iter 300] loss=-0.8869 val_loss=0.0000 scale=1.0000 norm=0.4157
[iter 400] loss=-1.2348 val_loss=0.0000 scale=1.0000 norm=0.3921
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1970 val_loss=0.0000 scale=2.0000 norm=0.9850
[iter 200] loss=-0.6140 val_loss=0.0000 scale=2.0000 norm=0.8854
[iter 300] loss=-1.1837 val_loss=0.0000 scale=2.0000 norm=0.8038
[iter 400] loss=-1.5528 val_loss=0.0000 scale=1.0000 norm=0.3814
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2239 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 200] loss=-0.6150 val_loss=0.0000 scale=2.0000 norm=0.8783
[iter 300] loss=-1.2519 val_loss=0.0000 scale=1.0000 norm=0.3886
[iter 400] loss=-1.6165 val_loss=0.0000 scale=1.0000 norm=0.3452
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1450 val_loss=0.0000 scale=2.0000 norm=0.9996
[iter 200] loss=-0.8429 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-2.3452 val_loss=0.0000 scale=4.0000 norm=1.9717
[iter 400] loss=-3.7202 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3234 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.2442 val_loss=0.0000 scale=1.0000 norm=0.4633
[iter 300] loss=-0.6601 val_loss=0.0000 scale=1.0000 norm=0.4252
[iter 400] loss=-0.9213 val_loss=0.0000 scale=1.0000 norm=0.4097
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3335 val_loss=0.0000 scale=2.0000 norm=1.0487
[iter 200] loss=-0.1024 val_loss=0.0000 scale=2.0000 norm=0.9590
[iter 300] loss=-0.5121 val_loss=0.0000 scale=1.0000 norm=0.4506
[iter 400] loss=-0.8140 val_loss=0.0000 scale=1.0000 norm=0.4321
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2406 val_loss=0.0000 scale=2.0000 norm=1.0086
[iter 200] loss=-0.3476 val_loss=0.0000 scale=2.0000 norm=0.8929
[iter 300] loss=-0.7354 val_loss=0.0000 scale=2.0000 norm=0.8136
[iter 400] loss=-1.0158 val_loss=0.0000 scale=1.0000 norm=0.3926
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3164 val_loss=0.0000 scale=1.0000 norm=0.5101
[iter 200] loss=-0.2647 val_loss=0.0000 scale=1.0000 norm=0.4540
[iter 300] loss=-0.6701 val_loss=0.0000 scale=1.0000 norm=0.4241
[iter 400] loss=-1.0342 val_loss=0.0000 scale=1.0000 norm=0.4111
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2727 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.5311 val_loss=0.0000 scale=2.0000 norm=0.8787
[iter 300] loss=-1.0489 val_loss=0.0000 scale=1.0000 norm=0.3822
[iter 400] loss=-1.4210 val_loss=0.0000 scale=1.0000 norm=0.3416
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1293 val_loss=0.0000 scale=2.0000 norm=0.9914
[iter 200] loss=-0.8581 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 300] loss=-2.4725 val_loss=0.0000 scale=4.0000 norm=1.9772
[iter 400] loss=-4.1079 val_loss=0.0000 scale=4.0000 norm=1.9528
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1766 val_loss=0.0000 scale=2.0000 norm=0.9809
[iter 200] loss=-0.6340 val_loss=0.0000 scale=2.0000 norm=0.8719
[iter 300] loss=-1.2484 val_loss=0.0000 scale=2.0000 norm=0.7547
[iter 400] loss=-1.5698 val_loss=0.0000 scale=1.0000 norm=0.3334
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3038 val_loss=0.0000 scale=2.0000 norm=1.0165
[iter 200] loss=-0.4743 val_loss=0.0000 scale=1.0000 norm=0.4421
[iter 300] loss=-0.9310 val_loss=0.0000 scale=2.0000 norm=0.7664
[iter 400] loss=-1.2211 val_loss=0.0000 scale=1.0000 norm=0.3549
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1478 val_loss=0.0000 scale=2.0000 norm=0.9895
[iter 200] loss=-0.8299 val_loss=0.0000 scale=2.0000 norm=0.9787
[iter 300] loss=-2.2818 val_loss=0.0000 scale=4.0000 norm=1.9880
[iter 400] loss=-4.2794 val_loss=0.0000 scale=4.0000 norm=1.9967
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4048 val_loss=0.0000 scale=1.0000 norm=0.5360
[iter 200] loss=-0.0827 val_loss=0.0000 scale=1.0000 norm=0.4624
[iter 300] loss=-0.4731 val_loss=0.0000 scale=2.0000 norm=0.8319
[iter 400] loss=-0.7561 val_loss=0.0000 scale=1.0000 norm=0.3849
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6695 val_loss=0.0000 scale=2.0000 norm=1.1512
[iter 200] loss=-0.1126 val_loss=0.0000 scale=2.0000 norm=0.9108
[iter 300] loss=-0.7036 val_loss=0.0000 scale=2.0000 norm=0.8279
[iter 400] loss=-1.1415 val_loss=0.0000 scale=1.0000 norm=0.3835
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4383 val_loss=0.0000 scale=1.0000 norm=0.5377
[iter 200] loss=-0.0780 val_loss=0.0000 scale=1.0000 norm=0.4690
[iter 300] loss=-0.5018 val_loss=0.0000 scale=2.0000 norm=0.8326
[iter 400] loss=-0.8631 val_loss=0.0000 scale=1.0000 norm=0.3805
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4245 val_loss=0.0000 scale=2.0000 norm=1.0047
[iter 200] loss=-0.4442 val_loss=0.0000 scale=2.0000 norm=0.8820
[iter 300] loss=-1.1999 val_loss=0.0000 scale=2.0000 norm=0.7773
[iter 400] loss=-1.7867 val_loss=0.0000 scale=2.0000 norm=0.6583
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4900 val_loss=0.0000 scale=2.0000 norm=1.0968
[iter 200] loss=-0.0575 val_loss=0.0000 scale=2.0000 norm=0.9376
[iter 300] loss=-0.4867 val_loss=0.0000 scale=1.0000 norm=0.4302
[iter 400] loss=-0.7166 val_loss=0.0000 scale=1.0000 norm=0.4198
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2430 val_loss=0.0000 scale=2.0000 norm=1.0077
[iter 200] loss=-0.4220 val_loss=0.0000 scale=1.0000 norm=0.4461
[iter 300] loss=-0.8861 val_loss=0.0000 scale=1.0000 norm=0.4092
[iter 400] loss=-1.2057 val_loss=0.0000 scale=1.0000 norm=0.3812
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3571 val_loss=0.0000 scale=2.0000 norm=1.0235
[iter 200] loss=-0.0768 val_loss=0.0000 scale=1.0000 norm=0.4502
[iter 300] loss=-0.3862 val_loss=0.0000 scale=1.0000 norm=0.4126
[iter 400] loss=-0.6642 val_loss=0.0000 scale=0.5000 norm=0.1916
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2405 val_loss=0.0000 scale=2.0000 norm=0.9784
[iter 200] loss=-0.7571 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 300] loss=-2.6002 val_loss=0.0000 scale=4.0000 norm=1.9919
[iter 400] loss=-4.5856 val_loss=0.0000 scale=4.0000 norm=1.9809
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3901 val_loss=0.0000 scale=2.0000 norm=1.0520
[iter 200] loss=-0.1036 val_loss=0.0000 scale=1.0000 norm=0.4553
[iter 300] loss=-0.4246 val_loss=0.0000 scale=1.0000 norm=0.4223
[iter 400] loss=-0.7297 val_loss=0.0000 scale=1.0000 norm=0.3995
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2582 val_loss=0.0000 scale=1.0000 norm=0.4998
[iter 200] loss=-0.3390 val_loss=0.0000 scale=2.0000 norm=0.8758
[iter 300] loss=-0.7734 val_loss=0.0000 scale=2.0000 norm=0.8082
[iter 400] loss=-1.0555 val_loss=0.0000 scale=1.0000 norm=0.3922
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4817 val_loss=0.0000 scale=1.0000 norm=0.5394
[iter 200] loss=-0.1286 val_loss=0.0000 scale=2.0000 norm=0.9289
[iter 300] loss=-0.6268 val_loss=0.0000 scale=1.0000 norm=0.4226
[iter 400] loss=-0.9379 val_loss=0.0000 scale=1.0000 norm=0.3888
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3344 val_loss=0.0000 scale=1.0000 norm=0.5135
[iter 200] loss=-0.2321 val_loss=0.0000 scale=1.0000 norm=0.4504
[iter 300] loss=-0.6308 val_loss=0.0000 scale=1.0000 norm=0.4062
[iter 400] loss=-0.9003 val_loss=0.0000 scale=2.0000 norm=0.7755
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2433 val_loss=0.0000 scale=2.0000 norm=1.0046
[iter 200] loss=-0.4052 val_loss=0.0000 scale=2.0000 norm=0.8872
[iter 300] loss=-0.8195 val_loss=0.0000 scale=1.0000 norm=0.4026
[iter 400] loss=-1.1730 val_loss=0.0000 scale=1.0000 norm=0.3792
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3209 val_loss=0.0000 scale=2.0000 norm=1.0086
[iter 200] loss=-0.5751 val_loss=0.0000 scale=2.0000 norm=0.9098
[iter 300] loss=-1.4295 val_loss=0.0000 scale=2.0000 norm=0.8673
[iter 400] loss=-2.2279 val_loss=0.0000 scale=2.0000 norm=0.7942
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3191 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.2565 val_loss=0.0000 scale=1.0000 norm=0.4509
[iter 300] loss=-0.7447 val_loss=0.0000 scale=2.0000 norm=0.8252
[iter 400] loss=-1.0633 val_loss=0.0000 scale=1.0000 norm=0.3920
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3007 val_loss=0.0000 scale=2.0000 norm=1.0255
[iter 200] loss=-0.3447 val_loss=0.0000 scale=1.0000 norm=0.4410
[iter 300] loss=-0.9841 val_loss=0.0000 scale=2.0000 norm=0.7571
[iter 400] loss=-1.4320 val_loss=0.0000 scale=2.0000 norm=0.6648
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4651 val_loss=0.0000 scale=2.0000 norm=1.0729
[iter 200] loss=-0.0890 val_loss=0.0000 scale=2.0000 norm=0.9038
[iter 300] loss=-0.4545 val_loss=0.0000 scale=1.0000 norm=0.4075
[iter 400] loss=-0.6994 val_loss=0.0000 scale=1.0000 norm=0.3857
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2891 val_loss=0.0000 scale=1.0000 norm=0.5124
[iter 200] loss=-0.3203 val_loss=0.0000 scale=2.0000 norm=0.9045
[iter 300] loss=-0.7532 val_loss=0.0000 scale=1.0000 norm=0.4202
[iter 400] loss=-1.1123 val_loss=0.0000 scale=1.0000 norm=0.3918
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2937 val_loss=0.0000 scale=2.0000 norm=1.0214
[iter 200] loss=-0.3316 val_loss=0.0000 scale=1.0000 norm=0.4430
[iter 300] loss=-0.7199 val_loss=0.0000 scale=1.0000 norm=0.4081
[iter 400] loss=-0.9799 val_loss=0.0000 scale=1.0000 norm=0.3987
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2925 val_loss=0.0000 scale=2.0000 norm=1.0322
[iter 200] loss=-0.3225 val_loss=0.0000 scale=2.0000 norm=0.9013
[iter 300] loss=-0.7153 val_loss=0.0000 scale=1.0000 norm=0.4142
[iter 400] loss=-1.0477 val_loss=0.0000 scale=2.0000 norm=0.7733
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2934 val_loss=0.0000 scale=1.0000 norm=0.5105
[iter 200] loss=-0.3856 val_loss=0.0000 scale=1.0000 norm=0.4293
[iter 300] loss=-0.7696 val_loss=0.0000 scale=1.0000 norm=0.3894
[iter 400] loss=-1.0684 val_loss=0.0000 scale=0.5000 norm=0.1828
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1082 val_loss=0.0000 scale=2.0000 norm=0.9844
[iter 200] loss=-0.7844 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 300] loss=-1.5794 val_loss=0.0000 scale=2.0000 norm=0.8374
[iter 400] loss=-2.1951 val_loss=0.0000 scale=1.0000 norm=0.3882
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4923 val_loss=0.0000 scale=2.0000 norm=1.0703
[iter 200] loss=-0.2060 val_loss=0.0000 scale=2.0000 norm=0.9188
[iter 300] loss=-0.6943 val_loss=0.0000 scale=1.0000 norm=0.4171
[iter 400] loss=-1.0200 val_loss=0.0000 scale=1.0000 norm=0.3950
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1303 val_loss=0.0000 scale=2.0000 norm=0.9725
[iter 200] loss=-0.7262 val_loss=0.0000 scale=2.0000 norm=0.8717
[iter 300] loss=-1.4635 val_loss=0.0000 scale=2.0000 norm=0.7595
[iter 400] loss=-2.0148 val_loss=0.0000 scale=1.0000 norm=0.3434
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3069 val_loss=0.0000 scale=2.0000 norm=1.0168
[iter 200] loss=-0.2776 val_loss=0.0000 scale=1.0000 norm=0.4575
[iter 300] loss=-0.6510 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 400] loss=-0.9643 val_loss=0.0000 scale=2.0000 norm=0.8360
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2998 val_loss=0.0000 scale=1.0000 norm=0.5137
[iter 200] loss=-0.2511 val_loss=0.0000 scale=1.0000 norm=0.4504
[iter 300] loss=-0.6693 val_loss=0.0000 scale=2.0000 norm=0.8609
[iter 400] loss=-0.9924 val_loss=0.0000 scale=2.0000 norm=0.8496
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0972 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.8449 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-1.8387 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9335 val_loss=0.0000 scale=2.0000 norm=0.9864
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4822 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.1719 val_loss=0.0000 scale=2.0000 norm=0.9075
[iter 300] loss=-0.6078 val_loss=0.0000 scale=1.0000 norm=0.4131
[iter 400] loss=-0.9967 val_loss=0.0000 scale=2.0000 norm=0.7643
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=0.9864
[iter 200] loss=-0.5280 val_loss=0.0000 scale=2.0000 norm=0.9178
[iter 300] loss=-1.3876 val_loss=0.0000 scale=2.0000 norm=0.8655
[iter 400] loss=-2.1789 val_loss=0.0000 scale=2.0000 norm=0.7969
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3542 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 200] loss=-0.4978 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 300] loss=-1.2283 val_loss=0.0000 scale=2.0000 norm=0.9099
[iter 400] loss=-2.0764 val_loss=0.0000 scale=2.0000 norm=0.8862
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2530 val_loss=0.0000 scale=2.0000 norm=0.9978
[iter 200] loss=-0.4836 val_loss=0.0000 scale=2.0000 norm=0.8491
[iter 300] loss=-0.9475 val_loss=0.0000 scale=1.0000 norm=0.3822
[iter 400] loss=-1.2324 val_loss=0.0000 scale=1.0000 norm=0.3649
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1771 val_loss=0.0000 scale=2.0000 norm=1.0052
[iter 200] loss=-0.6849 val_loss=0.0000 scale=2.0000 norm=0.8989
[iter 300] loss=-1.4721 val_loss=0.0000 scale=2.0000 norm=0.8169
[iter 400] loss=-1.9383 val_loss=0.0000 scale=1.0000 norm=0.3900
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4256 val_loss=0.0000 scale=1.0000 norm=0.5305
[iter 200] loss=-0.1352 val_loss=0.0000 scale=2.0000 norm=0.9287
[iter 300] loss=-0.5507 val_loss=0.0000 scale=1.0000 norm=0.4306
[iter 400] loss=-0.8812 val_loss=0.0000 scale=2.0000 norm=0.8230
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2437 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 200] loss=-0.6813 val_loss=0.0000 scale=2.0000 norm=0.9252
[iter 300] loss=-1.5477 val_loss=0.0000 scale=2.0000 norm=0.8678
[iter 400] loss=-2.3101 val_loss=0.0000 scale=2.0000 norm=0.7810
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3278 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6486 val_loss=0.0000 scale=2.0000 norm=0.9702
[iter 300] loss=-1.6319 val_loss=0.0000 scale=2.0000 norm=0.9811
[iter 400] loss=-2.7331 val_loss=0.0000 scale=2.0000 norm=0.9718
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2651 val_loss=0.0000 scale=2.0000 norm=1.0195
[iter 200] loss=-0.3941 val_loss=0.0000 scale=1.0000 norm=0.4395
[iter 300] loss=-0.7730 val_loss=0.0000 scale=1.0000 norm=0.4068
[iter 400] loss=-1.1659 val_loss=0.0000 scale=1.0000 norm=0.3717
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5630 val_loss=0.0000 scale=2.0000 norm=1.0755
[iter 200] loss=-0.0919 val_loss=0.0000 scale=1.0000 norm=0.4580
[iter 300] loss=-0.6458 val_loss=0.0000 scale=2.0000 norm=0.7950
[iter 400] loss=-1.0340 val_loss=0.0000 scale=1.0000 norm=0.3917
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2775 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 200] loss=-0.3455 val_loss=0.0000 scale=2.0000 norm=0.8863
[iter 300] loss=-0.8254 val_loss=0.0000 scale=1.0000 norm=0.4063
[iter 400] loss=-1.1123 val_loss=0.0000 scale=1.0000 norm=0.3877
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3646 val_loss=0.0000 scale=2.0000 norm=1.0392
[iter 200] loss=-0.3263 val_loss=0.0000 scale=2.0000 norm=0.8927
[iter 300] loss=-0.8573 val_loss=0.0000 scale=1.0000 norm=0.3950
[iter 400] loss=-1.2138 val_loss=0.0000 scale=1.0000 norm=0.3618
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2351 val_loss=0.0000 scale=2.0000 norm=0.9830
[iter 200] loss=-0.5651 val_loss=0.0000 scale=2.0000 norm=0.8552
[iter 300] loss=-1.1885 val_loss=0.0000 scale=1.0000 norm=0.3751
[iter 400] loss=-1.6344 val_loss=0.0000 scale=2.0000 norm=0.7067
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1722 val_loss=0.0000 scale=2.0000 norm=0.9693
[iter 200] loss=-0.7163 val_loss=0.0000 scale=2.0000 norm=0.9018
[iter 300] loss=-1.5108 val_loss=0.0000 scale=2.0000 norm=0.7959
[iter 400] loss=-2.1087 val_loss=0.0000 scale=1.0000 norm=0.3611
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2555 val_loss=0.0000 scale=2.0000 norm=1.0095
[iter 200] loss=-0.4257 val_loss=0.0000 scale=1.0000 norm=0.4401
[iter 300] loss=-0.8534 val_loss=0.0000 scale=1.0000 norm=0.4030
[iter 400] loss=-1.1208 val_loss=0.0000 scale=1.0000 norm=0.3936
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3385 val_loss=0.0000 scale=2.0000 norm=1.0022
[iter 200] loss=-0.3803 val_loss=0.0000 scale=2.0000 norm=0.8598
[iter 300] loss=-0.8897 val_loss=0.0000 scale=2.0000 norm=0.7892
[iter 400] loss=-1.2303 val_loss=0.0000 scale=1.0000 norm=0.3635
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3988 val_loss=0.0000 scale=2.0000 norm=1.0374
[iter 200] loss=-0.1428 val_loss=0.0000 scale=1.0000 norm=0.4489
[iter 300] loss=-0.5263 val_loss=0.0000 scale=1.0000 norm=0.4060
[iter 400] loss=-0.8520 val_loss=0.0000 scale=1.0000 norm=0.3753
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4225 val_loss=0.0000 scale=2.0000 norm=1.0495
[iter 200] loss=-0.2821 val_loss=0.0000 scale=2.0000 norm=0.8830
[iter 300] loss=-0.7526 val_loss=0.0000 scale=1.0000 norm=0.3970
[iter 400] loss=-1.0938 val_loss=0.0000 scale=1.0000 norm=0.3760
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2942 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 200] loss=-0.3677 val_loss=0.0000 scale=2.0000 norm=0.8665
[iter 300] loss=-0.8418 val_loss=0.0000 scale=2.0000 norm=0.7670
[iter 400] loss=-1.1744 val_loss=0.0000 scale=1.0000 norm=0.3616
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3774 val_loss=0.0000 scale=2.0000 norm=1.0270
[iter 200] loss=-0.3188 val_loss=0.0000 scale=1.0000 norm=0.4487
[iter 300] loss=-0.9218 val_loss=0.0000 scale=1.0000 norm=0.4075
[iter 400] loss=-1.2805 val_loss=0.0000 scale=1.0000 norm=0.3881
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2464 val_loss=0.0000 scale=2.0000 norm=1.0217
[iter 200] loss=-0.3582 val_loss=0.0000 scale=1.0000 norm=0.4572
[iter 300] loss=-0.8989 val_loss=0.0000 scale=1.0000 norm=0.4187
[iter 400] loss=-1.2562 val_loss=0.0000 scale=0.5000 norm=0.1944
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2370 val_loss=0.0000 scale=2.0000 norm=1.0155
[iter 200] loss=-0.4497 val_loss=0.0000 scale=1.0000 norm=0.4538
[iter 300] loss=-0.9308 val_loss=0.0000 scale=1.0000 norm=0.4184
[iter 400] loss=-1.3267 val_loss=0.0000 scale=2.0000 norm=0.7562
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2676 val_loss=0.0000 scale=2.0000 norm=0.9680
[iter 200] loss=-0.6511 val_loss=0.0000 scale=2.0000 norm=0.9266
[iter 300] loss=-1.5443 val_loss=0.0000 scale=2.0000 norm=0.8975
[iter 400] loss=-2.3518 val_loss=0.0000 scale=2.0000 norm=0.8399
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2256 val_loss=0.0000 scale=2.0000 norm=0.9983
[iter 200] loss=-0.4457 val_loss=0.0000 scale=1.0000 norm=0.4338
[iter 300] loss=-0.8518 val_loss=0.0000 scale=1.0000 norm=0.4030
[iter 400] loss=-1.1651 val_loss=0.0000 scale=0.5000 norm=0.1930
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4918 val_loss=0.0000 scale=2.0000 norm=1.0675
[iter 200] loss=-0.1217 val_loss=0.0000 scale=2.0000 norm=0.8940
[iter 300] loss=-0.7180 val_loss=0.0000 scale=2.0000 norm=0.7831
[iter 400] loss=-1.1216 val_loss=0.0000 scale=2.0000 norm=0.7394
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4144 val_loss=0.0000 scale=2.0000 norm=1.0661
[iter 200] loss=-0.1494 val_loss=0.0000 scale=1.0000 norm=0.4602
[iter 300] loss=-0.5218 val_loss=0.0000 scale=1.0000 norm=0.4172
[iter 400] loss=-0.8132 val_loss=0.0000 scale=2.0000 norm=0.7742
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3232 val_loss=0.0000 scale=2.0000 norm=1.0256
[iter 200] loss=-0.2902 val_loss=0.0000 scale=1.0000 norm=0.4466
[iter 300] loss=-0.6982 val_loss=0.0000 scale=2.0000 norm=0.8190
[iter 400] loss=-1.0285 val_loss=0.0000 scale=1.0000 norm=0.3909
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4511 val_loss=0.0000 scale=2.0000 norm=1.0482
[iter 200] loss=-0.2897 val_loss=0.0000 scale=2.0000 norm=0.9047
[iter 300] loss=-0.9914 val_loss=0.0000 scale=2.0000 norm=0.8135
[iter 400] loss=-1.4735 val_loss=0.0000 scale=1.0000 norm=0.3614
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3296 val_loss=0.0000 scale=1.0000 norm=0.5140
[iter 200] loss=-0.2735 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 300] loss=-0.7230 val_loss=0.0000 scale=1.0000 norm=0.4126
[iter 400] loss=-1.0389 val_loss=0.0000 scale=2.0000 norm=0.7731
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3614 val_loss=0.0000 scale=2.0000 norm=1.0211
[iter 200] loss=-0.1721 val_loss=0.0000 scale=1.0000 norm=0.4491
[iter 300] loss=-0.4955 val_loss=0.0000 scale=1.0000 norm=0.4244
[iter 400] loss=-0.7812 val_loss=0.0000 scale=1.0000 norm=0.4050
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2322 val_loss=0.0000 scale=2.0000 norm=1.0201
[iter 200] loss=-0.5096 val_loss=0.0000 scale=2.0000 norm=0.9195
[iter 300] loss=-1.1341 val_loss=0.0000 scale=1.0000 norm=0.4088
[iter 400] loss=-1.4946 val_loss=0.0000 scale=1.0000 norm=0.3603
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3430 val_loss=0.0000 scale=2.0000 norm=1.0403
[iter 200] loss=-0.2995 val_loss=0.0000 scale=2.0000 norm=0.8729
[iter 300] loss=-0.7419 val_loss=0.0000 scale=2.0000 norm=0.7858
[iter 400] loss=-1.0222 val_loss=0.0000 scale=1.0000 norm=0.3876
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3696 val_loss=0.0000 scale=2.0000 norm=0.9918
[iter 200] loss=-0.5894 val_loss=0.0000 scale=2.0000 norm=0.9523
[iter 300] loss=-1.5110 val_loss=0.0000 scale=2.0000 norm=0.9175
[iter 400] loss=-2.3460 val_loss=0.0000 scale=2.0000 norm=0.8308
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2980 val_loss=0.0000 scale=2.0000 norm=1.0035
[iter 200] loss=-0.3252 val_loss=0.0000 scale=2.0000 norm=0.8827
[iter 300] loss=-0.7737 val_loss=0.0000 scale=2.0000 norm=0.8050
[iter 400] loss=-1.0943 val_loss=0.0000 scale=2.0000 norm=0.7577
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2009 val_loss=0.0000 scale=2.0000 norm=0.9915
[iter 200] loss=-0.6173 val_loss=0.0000 scale=2.0000 norm=0.8711
[iter 300] loss=-1.3121 val_loss=0.0000 scale=2.0000 norm=0.7711
[iter 400] loss=-1.8207 val_loss=0.0000 scale=1.0000 norm=0.3538
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1459 val_loss=0.0000 scale=2.0000 norm=0.9922
[iter 200] loss=-0.8550 val_loss=0.0000 scale=4.0000 norm=1.9724
[iter 300] loss=-2.3651 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 400] loss=-3.9644 val_loss=0.0000 scale=4.0000 norm=1.9730
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2905 val_loss=0.0000 scale=2.0000 norm=1.0099
[iter 200] loss=-0.3684 val_loss=0.0000 scale=1.0000 norm=0.4339
[iter 300] loss=-0.7502 val_loss=0.0000 scale=1.0000 norm=0.3983
[iter 400] loss=-1.0162 val_loss=0.0000 scale=1.0000 norm=0.3679
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3136 val_loss=0.0000 scale=2.0000 norm=1.0106
[iter 200] loss=-0.2887 val_loss=0.0000 scale=1.0000 norm=0.4406
[iter 300] loss=-0.6694 val_loss=0.0000 scale=1.0000 norm=0.3987
[iter 400] loss=-0.9574 val_loss=0.0000 scale=1.0000 norm=0.3707
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3460 val_loss=0.0000 scale=2.0000 norm=1.0448
[iter 200] loss=-0.1696 val_loss=0.0000 scale=2.0000 norm=0.9116
[iter 300] loss=-0.5340 val_loss=0.0000 scale=1.0000 norm=0.4129
[iter 400] loss=-0.7634 val_loss=0.0000 scale=1.0000 norm=0.3925
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3166 val_loss=0.0000 scale=1.0000 norm=0.5141
[iter 200] loss=-0.3517 val_loss=0.0000 scale=1.0000 norm=0.4405
[iter 300] loss=-0.6828 val_loss=0.0000 scale=1.0000 norm=0.4119
[iter 400] loss=-0.9716 val_loss=0.0000 scale=1.0000 norm=0.4017
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4597 val_loss=0.0000 scale=1.0000 norm=0.5334
[iter 200] loss=-0.1217 val_loss=0.0000 scale=1.0000 norm=0.4651
[iter 300] loss=-0.5962 val_loss=0.0000 scale=2.0000 norm=0.8354
[iter 400] loss=-0.9606 val_loss=0.0000 scale=1.0000 norm=0.3938
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3448 val_loss=0.0000 scale=2.0000 norm=1.0340
[iter 200] loss=-0.0912 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-0.4760 val_loss=0.0000 scale=1.0000 norm=0.4073
[iter 400] loss=-0.7488 val_loss=0.0000 scale=1.0000 norm=0.3901
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4998 val_loss=0.0000 scale=2.0000 norm=1.0807
[iter 200] loss=-0.1709 val_loss=0.0000 scale=2.0000 norm=0.9250
[iter 300] loss=-0.6990 val_loss=0.0000 scale=2.0000 norm=0.8528
[iter 400] loss=-1.0586 val_loss=0.0000 scale=1.0000 norm=0.3993
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2928 val_loss=0.0000 scale=2.0000 norm=1.0216
[iter 200] loss=-0.3171 val_loss=0.0000 scale=1.0000 norm=0.4451
[iter 300] loss=-0.6962 val_loss=0.0000 scale=2.0000 norm=0.8119
[iter 400] loss=-0.9614 val_loss=0.0000 scale=1.0000 norm=0.3845
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3699 val_loss=0.0000 scale=2.0000 norm=1.0393
[iter 200] loss=-0.2709 val_loss=0.0000 scale=1.0000 norm=0.4618
[iter 300] loss=-0.7722 val_loss=0.0000 scale=1.0000 norm=0.4306
[iter 400] loss=-1.0955 val_loss=0.0000 scale=1.0000 norm=0.4024
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2396 val_loss=0.0000 scale=1.0000 norm=0.5090
[iter 200] loss=-0.3980 val_loss=0.0000 scale=1.0000 norm=0.4557
[iter 300] loss=-1.0385 val_loss=0.0000 scale=1.0000 norm=0.4113
[iter 400] loss=-1.4768 val_loss=0.0000 scale=0.5000 norm=0.1914
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4546 val_loss=0.0000 scale=1.0000 norm=0.5365
[iter 200] loss=-0.0447 val_loss=0.0000 scale=2.0000 norm=0.9415
[iter 300] loss=-0.4862 val_loss=0.0000 scale=1.0000 norm=0.4153
[iter 400] loss=-0.8008 val_loss=0.0000 scale=1.0000 norm=0.3873
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2437 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 200] loss=-0.7503 val_loss=0.0000 scale=2.0000 norm=0.9853
[iter 300] loss=-2.1993 val_loss=0.0000 scale=4.0000 norm=1.9752
[iter 400] loss=-4.0432 val_loss=0.0000 scale=2.0000 norm=0.9833
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2160 val_loss=0.0000 scale=2.0000 norm=0.9940
[iter 200] loss=-0.5772 val_loss=0.0000 scale=2.0000 norm=0.8717
[iter 300] loss=-1.0868 val_loss=0.0000 scale=1.0000 norm=0.3902
[iter 400] loss=-1.3707 val_loss=0.0000 scale=1.0000 norm=0.3761
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2993 val_loss=0.0000 scale=2.0000 norm=1.0102
[iter 200] loss=-0.2096 val_loss=0.0000 scale=1.0000 norm=0.4493
[iter 300] loss=-0.5451 val_loss=0.0000 scale=1.0000 norm=0.4127
[iter 400] loss=-0.8117 val_loss=0.0000 scale=1.0000 norm=0.3912
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3283 val_loss=0.0000 scale=1.0000 norm=0.5128
[iter 200] loss=-0.1723 val_loss=0.0000 scale=1.0000 norm=0.4515
[iter 300] loss=-0.5783 val_loss=0.0000 scale=1.0000 norm=0.4149
[iter 400] loss=-0.8213 val_loss=0.0000 scale=1.0000 norm=0.3985
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2110 val_loss=0.0000 scale=2.0000 norm=0.9674
[iter 200] loss=-0.6982 val_loss=0.0000 scale=2.0000 norm=0.9097
[iter 300] loss=-1.5277 val_loss=0.0000 scale=2.0000 norm=0.8261
[iter 400] loss=-2.2520 val_loss=0.0000 scale=2.0000 norm=0.7434
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3368 val_loss=0.0000 scale=2.0000 norm=1.0384
[iter 200] loss=-0.3819 val_loss=0.0000 scale=2.0000 norm=0.8970
[iter 300] loss=-0.8575 val_loss=0.0000 scale=2.0000 norm=0.8157
[iter 400] loss=-1.2073 val_loss=0.0000 scale=1.0000 norm=0.3746
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2773 val_loss=0.0000 scale=2.0000 norm=1.0159
[iter 200] loss=-0.3037 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 300] loss=-0.7391 val_loss=0.0000 scale=1.0000 norm=0.4061
[iter 400] loss=-0.9936 val_loss=0.0000 scale=1.0000 norm=0.3904
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3317 val_loss=0.0000 scale=1.0000 norm=0.5199
[iter 200] loss=-0.2169 val_loss=0.0000 scale=2.0000 norm=0.9234
[iter 300] loss=-0.6947 val_loss=0.0000 scale=1.0000 norm=0.4284
[iter 400] loss=-1.0131 val_loss=0.0000 scale=1.0000 norm=0.4197
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2612 val_loss=0.0000 scale=2.0000 norm=0.9531
[iter 200] loss=-0.6809 val_loss=0.0000 scale=2.0000 norm=0.9436
[iter 300] loss=-1.6199 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-2.5472 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2976 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6129 val_loss=0.0000 scale=2.0000 norm=0.9203
[iter 300] loss=-1.5383 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 400] loss=-2.4571 val_loss=0.0000 scale=2.0000 norm=0.9170
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7810 val_loss=0.0000 scale=2.0000 norm=1.2097
[iter 200] loss=0.1551 val_loss=0.0000 scale=1.0000 norm=0.4775
[iter 300] loss=-0.3689 val_loss=0.0000 scale=2.0000 norm=0.8671
[iter 400] loss=-0.8404 val_loss=0.0000 scale=1.0000 norm=0.4071
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5196 val_loss=0.0000 scale=1.0000 norm=0.5500
[iter 200] loss=0.0307 val_loss=0.0000 scale=1.0000 norm=0.4928
[iter 300] loss=-0.2176 val_loss=0.0000 scale=2.0000 norm=0.9360
[iter 400] loss=-0.4879 val_loss=0.0000 scale=1.0000 norm=0.4455
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2524 val_loss=0.0000 scale=2.0000 norm=0.9937
[iter 200] loss=-0.4471 val_loss=0.0000 scale=2.0000 norm=0.8677
[iter 300] loss=-0.8948 val_loss=0.0000 scale=2.0000 norm=0.7754
[iter 400] loss=-1.1948 val_loss=0.0000 scale=1.0000 norm=0.3705
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.6722 val_loss=0.0000 scale=2.0000 norm=1.1672
[iter 200] loss=0.0864 val_loss=0.0000 scale=2.0000 norm=0.9663
[iter 300] loss=-0.3440 val_loss=0.0000 scale=2.0000 norm=0.8925
[iter 400] loss=-0.6037 val_loss=0.0000 scale=1.0000 norm=0.4167
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5484 val_loss=0.0000 scale=1.0000 norm=0.5558
[iter 200] loss=-0.0386 val_loss=0.0000 scale=2.0000 norm=0.9394
[iter 300] loss=-0.5076 val_loss=0.0000 scale=1.0000 norm=0.4229
[iter 400] loss=-0.8151 val_loss=0.0000 scale=1.0000 norm=0.4012
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4003 val_loss=0.0000 scale=1.0000 norm=0.5328
[iter 200] loss=-0.0138 val_loss=0.0000 scale=1.0000 norm=0.4791
[iter 300] loss=-0.3805 val_loss=0.0000 scale=1.0000 norm=0.4315
[iter 400] loss=-0.6996 val_loss=0.0000 scale=1.0000 norm=0.4124
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2731 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 200] loss=-0.5026 val_loss=0.0000 scale=2.0000 norm=0.8350
[iter 300] loss=-1.1602 val_loss=0.0000 scale=1.0000 norm=0.3824
[iter 400] loss=-1.6674 val_loss=0.0000 scale=1.0000 norm=0.3325
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2917 val_loss=0.0000 scale=2.0000 norm=1.0077
[iter 200] loss=-0.3012 val_loss=0.0000 scale=1.0000 norm=0.4386
[iter 300] loss=-0.6862 val_loss=0.0000 scale=1.0000 norm=0.3975
[iter 400] loss=-0.9049 val_loss=0.0000 scale=1.0000 norm=0.3745
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2682 val_loss=0.0000 scale=2.0000 norm=1.0009
[iter 200] loss=-0.3443 val_loss=0.0000 scale=2.0000 norm=0.8851
[iter 300] loss=-0.7233 val_loss=0.0000 scale=1.0000 norm=0.4119
[iter 400] loss=-1.0085 val_loss=0.0000 scale=1.0000 norm=0.3942
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1009 val_loss=0.0000 scale=2.0000 norm=0.9932
[iter 200] loss=-0.8775 val_loss=0.0000 scale=2.0000 norm=0.9750
[iter 300] loss=-1.8561 val_loss=0.0000 scale=4.0000 norm=1.9622
[iter 400] loss=-2.9791 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4405 val_loss=0.0000 scale=1.0000 norm=0.5331
[iter 200] loss=-0.1938 val_loss=0.0000 scale=2.0000 norm=0.9210
[iter 300] loss=-0.6233 val_loss=0.0000 scale=2.0000 norm=0.8298
[iter 400] loss=-0.9633 val_loss=0.0000 scale=1.0000 norm=0.3877
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3057 val_loss=0.0000 scale=1.0000 norm=0.5103
[iter 200] loss=-0.2507 val_loss=0.0000 scale=1.0000 norm=0.4551
[iter 300] loss=-0.6844 val_loss=0.0000 scale=2.0000 norm=0.8372
[iter 400] loss=-1.0134 val_loss=0.0000 scale=1.0000 norm=0.3848
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1989 val_loss=0.0000 scale=2.0000 norm=0.9811
[iter 200] loss=-0.7871 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 300] loss=-1.7701 val_loss=0.0000 scale=2.0000 norm=0.9822
[iter 400] loss=-2.9153 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3069 val_loss=0.0000 scale=2.0000 norm=1.0048
[iter 200] loss=-0.3525 val_loss=0.0000 scale=1.0000 norm=0.4254
[iter 300] loss=-0.8952 val_loss=0.0000 scale=2.0000 norm=0.7630
[iter 400] loss=-1.3132 val_loss=0.0000 scale=1.0000 norm=0.3579
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1306 val_loss=0.0000 scale=2.0000 norm=0.9911
[iter 200] loss=-0.8482 val_loss=0.0000 scale=2.0000 norm=0.9765
[iter 300] loss=-1.8416 val_loss=0.0000 scale=2.0000 norm=0.9837
[iter 400] loss=-3.0814 val_loss=0.0000 scale=4.0000 norm=1.9672
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4228 val_loss=0.0000 scale=2.0000 norm=1.0315
[iter 200] loss=-0.3905 val_loss=0.0000 scale=2.0000 norm=0.8786
[iter 300] loss=-1.0654 val_loss=0.0000 scale=2.0000 norm=0.7584
[iter 400] loss=-1.4868 val_loss=0.0000 scale=1.0000 norm=0.3451
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3074 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.2337 val_loss=0.0000 scale=1.0000 norm=0.4456
[iter 300] loss=-0.6352 val_loss=0.0000 scale=1.0000 norm=0.4269
[iter 400] loss=-0.9012 val_loss=0.0000 scale=1.0000 norm=0.4138
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2241 val_loss=0.0000 scale=2.0000 norm=0.9728
[iter 200] loss=-0.7407 val_loss=0.0000 scale=2.0000 norm=0.9573
[iter 300] loss=-1.6618 val_loss=0.0000 scale=2.0000 norm=0.9200
[iter 400] loss=-2.6667 val_loss=0.0000 scale=2.0000 norm=0.8714
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4398 val_loss=0.0000 scale=2.0000 norm=1.0109
[iter 200] loss=-0.4003 val_loss=0.0000 scale=2.0000 norm=0.8856
[iter 300] loss=-1.1373 val_loss=0.0000 scale=2.0000 norm=0.8211
[iter 400] loss=-1.6953 val_loss=0.0000 scale=1.0000 norm=0.3905
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2497 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 200] loss=-0.4185 val_loss=0.0000 scale=2.0000 norm=0.8999
[iter 300] loss=-0.8224 val_loss=0.0000 scale=1.0000 norm=0.4217
[iter 400] loss=-1.0743 val_loss=0.0000 scale=2.0000 norm=0.8028
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1598 val_loss=0.0000 scale=2.0000 norm=0.9790
[iter 200] loss=-0.7180 val_loss=0.0000 scale=2.0000 norm=0.8880
[iter 300] loss=-1.4830 val_loss=0.0000 scale=2.0000 norm=0.8059
[iter 400] loss=-2.1115 val_loss=0.0000 scale=1.0000 norm=0.3714
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2731 val_loss=0.0000 scale=2.0000 norm=0.9958
[iter 200] loss=-0.3086 val_loss=0.0000 scale=2.0000 norm=0.8954
[iter 300] loss=-0.7793 val_loss=0.0000 scale=1.0000 norm=0.4205
[iter 400] loss=-1.1293 val_loss=0.0000 scale=1.0000 norm=0.4004
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3171 val_loss=0.0000 scale=2.0000 norm=1.0380
[iter 200] loss=-0.2723 val_loss=0.0000 scale=1.0000 norm=0.4573
[iter 300] loss=-0.6359 val_loss=0.0000 scale=1.0000 norm=0.4158
[iter 400] loss=-0.9059 val_loss=0.0000 scale=1.0000 norm=0.3881
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3406 val_loss=0.0000 scale=1.0000 norm=0.5209
[iter 200] loss=-0.1327 val_loss=0.0000 scale=2.0000 norm=0.9387
[iter 300] loss=-0.5281 val_loss=0.0000 scale=1.0000 norm=0.4433
[iter 400] loss=-0.8316 val_loss=0.0000 scale=1.0000 norm=0.4277
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3493 val_loss=0.0000 scale=1.0000 norm=0.5188
[iter 200] loss=-0.1201 val_loss=0.0000 scale=2.0000 norm=0.9305
[iter 300] loss=-0.5619 val_loss=0.0000 scale=2.0000 norm=0.8406
[iter 400] loss=-0.8534 val_loss=0.0000 scale=1.0000 norm=0.4047
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2972 val_loss=0.0000 scale=2.0000 norm=1.0042
[iter 200] loss=-0.3641 val_loss=0.0000 scale=2.0000 norm=0.8728
[iter 300] loss=-0.8294 val_loss=0.0000 scale=2.0000 norm=0.8037
[iter 400] loss=-1.1607 val_loss=0.0000 scale=1.0000 norm=0.3891
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3069 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2635 val_loss=0.0000 scale=2.0000 norm=0.8941
[iter 300] loss=-0.6791 val_loss=0.0000 scale=1.0000 norm=0.4069
[iter 400] loss=-0.9849 val_loss=0.0000 scale=1.0000 norm=0.3853
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1022 val_loss=0.0000 scale=2.0000 norm=0.9845
[iter 200] loss=-0.8016 val_loss=0.0000 scale=2.0000 norm=0.9129
[iter 300] loss=-1.6672 val_loss=0.0000 scale=2.0000 norm=0.8689
[iter 400] loss=-2.4456 val_loss=0.0000 scale=2.0000 norm=0.8322
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4021 val_loss=0.0000 scale=1.0000 norm=0.5272
[iter 200] loss=-0.1123 val_loss=0.0000 scale=2.0000 norm=0.9361
[iter 300] loss=-0.4359 val_loss=0.0000 scale=1.0000 norm=0.4425
[iter 400] loss=-0.7537 val_loss=0.0000 scale=2.0000 norm=0.8330
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3138 val_loss=0.0000 scale=2.0000 norm=1.0260
[iter 200] loss=-0.2365 val_loss=0.0000 scale=1.0000 norm=0.4532
[iter 300] loss=-0.6858 val_loss=0.0000 scale=2.0000 norm=0.8426
[iter 400] loss=-0.9929 val_loss=0.0000 scale=1.0000 norm=0.4058
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3066 val_loss=0.0000 scale=1.0000 norm=0.5091
[iter 200] loss=-0.2178 val_loss=0.0000 scale=2.0000 norm=0.8961
[iter 300] loss=-0.6271 val_loss=0.0000 scale=1.0000 norm=0.4161
[iter 400] loss=-0.9121 val_loss=0.0000 scale=1.0000 norm=0.4025
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5387 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.4141 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 300] loss=-1.3784 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 400] loss=-2.3170 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2992 val_loss=0.0000 scale=2.0000 norm=1.0258
[iter 200] loss=-0.3742 val_loss=0.0000 scale=2.0000 norm=0.8919
[iter 300] loss=-0.7885 val_loss=0.0000 scale=1.0000 norm=0.4169
[iter 400] loss=-1.1204 val_loss=0.0000 scale=1.0000 norm=0.3790
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3863 val_loss=0.0000 scale=2.0000 norm=1.0514
[iter 200] loss=-0.2401 val_loss=0.0000 scale=2.0000 norm=0.8999
[iter 300] loss=-0.6881 val_loss=0.0000 scale=1.0000 norm=0.4091
[iter 400] loss=-1.0318 val_loss=0.0000 scale=2.0000 norm=0.7591
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2778 val_loss=0.0000 scale=2.0000 norm=1.0245
[iter 200] loss=-0.3123 val_loss=0.0000 scale=1.0000 norm=0.4514
[iter 300] loss=-0.7114 val_loss=0.0000 scale=1.0000 norm=0.4215
[iter 400] loss=-0.9748 val_loss=0.0000 scale=1.0000 norm=0.4126
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3427 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.2836 val_loss=0.0000 scale=2.0000 norm=0.8899
[iter 300] loss=-0.6603 val_loss=0.0000 scale=1.0000 norm=0.4191
[iter 400] loss=-0.9199 val_loss=0.0000 scale=1.0000 norm=0.4059
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1947 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 200] loss=-0.7912 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 300] loss=-1.9577 val_loss=0.0000 scale=4.0000 norm=1.9615
[iter 400] loss=-3.4034 val_loss=0.0000 scale=4.0000 norm=1.9802
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4470 val_loss=0.0000 scale=2.0000 norm=1.0630
[iter 200] loss=-0.0470 val_loss=0.0000 scale=1.0000 norm=0.4722
[iter 300] loss=-0.4781 val_loss=0.0000 scale=2.0000 norm=0.8536
[iter 400] loss=-0.8399 val_loss=0.0000 scale=2.0000 norm=0.7848
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5584 val_loss=0.0000 scale=2.0000 norm=1.0872
[iter 200] loss=-0.1063 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 300] loss=-0.6423 val_loss=0.0000 scale=1.0000 norm=0.4169
[iter 400] loss=-0.9987 val_loss=0.0000 scale=1.0000 norm=0.3867
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1047 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 200] loss=-0.8756 val_loss=0.0000 scale=2.0000 norm=0.9785
[iter 300] loss=-1.8577 val_loss=0.0000 scale=2.0000 norm=0.9818
[iter 400] loss=-2.8487 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2987 val_loss=0.0000 scale=2.0000 norm=1.0085
[iter 200] loss=-0.4713 val_loss=0.0000 scale=2.0000 norm=0.8685
[iter 300] loss=-1.0503 val_loss=0.0000 scale=1.0000 norm=0.3863
[iter 400] loss=-1.3906 val_loss=0.0000 scale=1.0000 norm=0.3541
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3798 val_loss=0.0000 scale=1.0000 norm=0.5103
[iter 200] loss=-0.1593 val_loss=0.0000 scale=1.0000 norm=0.4447
[iter 300] loss=-0.5225 val_loss=0.0000 scale=2.0000 norm=0.8014
[iter 400] loss=-0.7945 val_loss=0.0000 scale=1.0000 norm=0.3683
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1888 val_loss=0.0000 scale=2.0000 norm=0.9818
[iter 200] loss=-0.6111 val_loss=0.0000 scale=2.0000 norm=0.8508
[iter 300] loss=-1.2400 val_loss=0.0000 scale=2.0000 norm=0.7476
[iter 400] loss=-1.6418 val_loss=0.0000 scale=1.0000 norm=0.3514
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3978 val_loss=0.0000 scale=1.0000 norm=0.5265
[iter 200] loss=-0.1468 val_loss=0.0000 scale=1.0000 norm=0.4597
[iter 300] loss=-0.5327 val_loss=0.0000 scale=1.0000 norm=0.4281
[iter 400] loss=-0.8249 val_loss=0.0000 scale=2.0000 norm=0.8225
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4653 val_loss=0.0000 scale=2.0000 norm=1.1058
[iter 200] loss=-0.1698 val_loss=0.0000 scale=2.0000 norm=0.9460
[iter 300] loss=-0.5393 val_loss=0.0000 scale=1.0000 norm=0.4419
[iter 400] loss=-0.8844 val_loss=0.0000 scale=2.0000 norm=0.8184
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4917 val_loss=0.0000 scale=2.0000 norm=1.0291
[iter 200] loss=-0.3414 val_loss=0.0000 scale=2.0000 norm=0.8906
[iter 300] loss=-1.0571 val_loss=0.0000 scale=2.0000 norm=0.7873
[iter 400] loss=-1.6020 val_loss=0.0000 scale=2.0000 norm=0.7156
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2037 val_loss=0.0000 scale=2.0000 norm=0.9852
[iter 200] loss=-0.7356 val_loss=0.0000 scale=2.0000 norm=0.9372
[iter 300] loss=-1.6084 val_loss=0.0000 scale=2.0000 norm=0.8736
[iter 400] loss=-2.3620 val_loss=0.0000 scale=2.0000 norm=0.7671
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2390 val_loss=0.0000 scale=2.0000 norm=0.9928
[iter 200] loss=-0.4510 val_loss=0.0000 scale=2.0000 norm=0.8745
[iter 300] loss=-0.8701 val_loss=0.0000 scale=2.0000 norm=0.8176
[iter 400] loss=-1.1359 val_loss=0.0000 scale=1.0000 norm=0.3738
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2230 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 200] loss=-0.5968 val_loss=0.0000 scale=2.0000 norm=0.8606
[iter 300] loss=-1.2171 val_loss=0.0000 scale=2.0000 norm=0.7325
[iter 400] loss=-1.6535 val_loss=0.0000 scale=2.0000 norm=0.6712
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6359 val_loss=0.0000 scale=2.0000 norm=1.1609
[iter 200] loss=0.0785 val_loss=0.0000 scale=2.0000 norm=0.9452
[iter 300] loss=-0.3431 val_loss=0.0000 scale=1.0000 norm=0.4278
[iter 400] loss=-0.6631 val_loss=0.0000 scale=1.0000 norm=0.4078
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2940 val_loss=0.0000 scale=2.0000 norm=1.0214
[iter 200] loss=-0.3297 val_loss=0.0000 scale=1.0000 norm=0.4487
[iter 300] loss=-0.7619 val_loss=0.0000 scale=1.0000 norm=0.4175
[iter 400] loss=-1.0603 val_loss=0.0000 scale=1.0000 norm=0.4018
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0427 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-1.0293 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 300] loss=-2.3712 val_loss=0.0000 scale=2.0000 norm=0.9762
[iter 400] loss=-3.4236 val_loss=0.0000 scale=2.0000 norm=0.9644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2432 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 200] loss=-0.3767 val_loss=0.0000 scale=1.0000 norm=0.4379
[iter 300] loss=-0.8572 val_loss=0.0000 scale=1.0000 norm=0.3936
[iter 400] loss=-1.1974 val_loss=0.0000 scale=1.0000 norm=0.3720
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3865 val_loss=0.0000 scale=2.0000 norm=1.0452
[iter 200] loss=-0.1902 val_loss=0.0000 scale=2.0000 norm=0.9341
[iter 300] loss=-0.5771 val_loss=0.0000 scale=1.0000 norm=0.4248
[iter 400] loss=-0.8681 val_loss=0.0000 scale=1.0000 norm=0.4015
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2988 val_loss=0.0000 scale=2.0000 norm=1.0343
[iter 200] loss=-0.1853 val_loss=0.0000 scale=2.0000 norm=0.9321
[iter 300] loss=-0.5911 val_loss=0.0000 scale=1.0000 norm=0.4424
[iter 400] loss=-0.8737 val_loss=0.0000 scale=1.0000 norm=0.4243
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3168 val_loss=0.0000 scale=2.0000 norm=1.0224
[iter 200] loss=-0.1372 val_loss=0.0000 scale=1.0000 norm=0.4540
[iter 300] loss=-0.5639 val_loss=0.0000 scale=1.0000 norm=0.4153
[iter 400] loss=-0.9028 val_loss=0.0000 scale=1.0000 norm=0.3914
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2681 val_loss=0.0000 scale=2.0000 norm=0.9997
[iter 200] loss=-0.5509 val_loss=0.0000 scale=2.0000 norm=0.8843
[iter 300] loss=-1.1810 val_loss=0.0000 scale=1.0000 norm=0.4059
[iter 400] loss=-1.6427 val_loss=0.0000 scale=1.0000 norm=0.3874
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3108 val_loss=0.0000 scale=2.0000 norm=1.0088
[iter 200] loss=-0.3261 val_loss=0.0000 scale=1.0000 norm=0.4413
[iter 300] loss=-0.7185 val_loss=0.0000 scale=1.0000 norm=0.3989
[iter 400] loss=-0.9371 val_loss=0.0000 scale=0.5000 norm=0.1849
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3019 val_loss=0.0000 scale=2.0000 norm=1.0151
[iter 200] loss=-0.4148 val_loss=0.0000 scale=2.0000 norm=0.8710
[iter 300] loss=-0.8793 val_loss=0.0000 scale=2.0000 norm=0.8024
[iter 400] loss=-1.2361 val_loss=0.0000 scale=0.5000 norm=0.1929
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6571 val_loss=0.0000 scale=2.0000 norm=1.1427
[iter 200] loss=-0.0676 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 300] loss=-0.7175 val_loss=0.0000 scale=1.0000 norm=0.4211
[iter 400] loss=-1.1678 val_loss=0.0000 scale=2.0000 norm=0.7643
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1841 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 200] loss=-0.7878 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 300] loss=-1.7623 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 400] loss=-2.8661 val_loss=0.0000 scale=2.0000 norm=0.9847
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5076 val_loss=0.0000 scale=1.0000 norm=0.5436
[iter 200] loss=-0.1166 val_loss=0.0000 scale=2.0000 norm=0.9099
[iter 300] loss=-0.7022 val_loss=0.0000 scale=1.0000 norm=0.3885
[iter 400] loss=-1.0523 val_loss=0.0000 scale=2.0000 norm=0.7415
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2786 val_loss=0.0000 scale=1.0000 norm=0.5092
[iter 200] loss=-0.1957 val_loss=0.0000 scale=1.0000 norm=0.4578
[iter 300] loss=-0.6446 val_loss=0.0000 scale=1.0000 norm=0.4188
[iter 400] loss=-0.9464 val_loss=0.0000 scale=1.0000 norm=0.4000
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3793 val_loss=0.0000 scale=2.0000 norm=1.0052
[iter 200] loss=-0.5365 val_loss=0.0000 scale=2.0000 norm=0.9271
[iter 300] loss=-1.4254 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 400] loss=-2.2381 val_loss=0.0000 scale=2.0000 norm=0.8173
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3147 val_loss=0.0000 scale=2.0000 norm=1.0129
[iter 200] loss=-0.3085 val_loss=0.0000 scale=1.0000 norm=0.4439
[iter 300] loss=-0.7369 val_loss=0.0000 scale=1.0000 norm=0.4101
[iter 400] loss=-1.0282 val_loss=0.0000 scale=1.0000 norm=0.3905
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3669 val_loss=0.0000 scale=2.0000 norm=1.0396
[iter 200] loss=-0.2271 val_loss=0.0000 scale=2.0000 norm=0.8965
[iter 300] loss=-0.6287 val_loss=0.0000 scale=1.0000 norm=0.4184
[iter 400] loss=-0.8764 val_loss=0.0000 scale=1.0000 norm=0.4073
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1834 val_loss=0.0000 scale=2.0000 norm=0.9883
[iter 200] loss=-0.9052 val_loss=0.0000 scale=4.0000 norm=1.9871
[iter 300] loss=-2.8988 val_loss=0.0000 scale=4.0000 norm=1.9880
[iter 400] loss=-4.7617 val_loss=0.0000 scale=4.0000 norm=1.8447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1877 val_loss=0.0000 scale=2.0000 norm=0.9862
[iter 200] loss=-0.6943 val_loss=0.0000 scale=2.0000 norm=0.8975
[iter 300] loss=-1.4860 val_loss=0.0000 scale=2.0000 norm=0.7940
[iter 400] loss=-2.0342 val_loss=0.0000 scale=2.0000 norm=0.6976
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2901 val_loss=0.0000 scale=2.0000 norm=1.0169
[iter 200] loss=-0.1871 val_loss=0.0000 scale=2.0000 norm=0.9112
[iter 300] loss=-0.6245 val_loss=0.0000 scale=1.0000 norm=0.4196
[iter 400] loss=-0.9068 val_loss=0.0000 scale=1.0000 norm=0.4113
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4151 val_loss=0.0000 scale=1.0000 norm=0.5220
[iter 200] loss=-0.0508 val_loss=0.0000 scale=1.0000 norm=0.4678
[iter 300] loss=-0.3626 val_loss=0.0000 scale=1.0000 norm=0.4429
[iter 400] loss=-0.6472 val_loss=0.0000 scale=2.0000 norm=0.8443
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3371 val_loss=0.0000 scale=1.0000 norm=0.5225
[iter 200] loss=-0.1184 val_loss=0.0000 scale=2.0000 norm=0.9295
[iter 300] loss=-0.5696 val_loss=0.0000 scale=2.0000 norm=0.8492
[iter 400] loss=-0.8746 val_loss=0.0000 scale=1.0000 norm=0.4095
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5685 val_loss=0.0000 scale=2.0000 norm=1.1533
[iter 200] loss=0.1268 val_loss=0.0000 scale=1.0000 norm=0.5103
[iter 300] loss=-0.2874 val_loss=0.0000 scale=2.0000 norm=0.9319
[iter 400] loss=-0.5649 val_loss=0.0000 scale=1.0000 norm=0.4480
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2120 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.5520 val_loss=0.0000 scale=2.0000 norm=0.8603
[iter 300] loss=-1.1685 val_loss=0.0000 scale=2.0000 norm=0.7787
[iter 400] loss=-1.6330 val_loss=0.0000 scale=1.0000 norm=0.3552
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3471 val_loss=0.0000 scale=2.0000 norm=1.0173
[iter 200] loss=-0.2039 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 300] loss=-0.5817 val_loss=0.0000 scale=2.0000 norm=0.8188
[iter 400] loss=-0.8589 val_loss=0.0000 scale=1.0000 norm=0.3933
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3064 val_loss=0.0000 scale=2.0000 norm=1.0220
[iter 200] loss=-0.2738 val_loss=0.0000 scale=1.0000 norm=0.4473
[iter 300] loss=-0.6767 val_loss=0.0000 scale=2.0000 norm=0.8297
[iter 400] loss=-0.9792 val_loss=0.0000 scale=1.0000 norm=0.3987
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2801 val_loss=0.0000 scale=2.0000 norm=1.0064
[iter 200] loss=-0.3355 val_loss=0.0000 scale=1.0000 norm=0.4419
[iter 300] loss=-0.7290 val_loss=0.0000 scale=1.0000 norm=0.4070
[iter 400] loss=-0.9647 val_loss=0.0000 scale=1.0000 norm=0.3976
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1644 val_loss=0.0000 scale=2.0000 norm=0.9933
[iter 200] loss=-0.5520 val_loss=0.0000 scale=2.0000 norm=0.8970
[iter 300] loss=-1.3016 val_loss=0.0000 scale=2.0000 norm=0.7909
[iter 400] loss=-1.8465 val_loss=0.0000 scale=1.0000 norm=0.3632
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3443 val_loss=0.0000 scale=1.0000 norm=0.5195
[iter 200] loss=-0.1731 val_loss=0.0000 scale=1.0000 norm=0.4588
[iter 300] loss=-0.6612 val_loss=0.0000 scale=1.0000 norm=0.4264
[iter 400] loss=-0.9947 val_loss=0.0000 scale=1.0000 norm=0.4100
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2966 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 200] loss=-0.2705 val_loss=0.0000 scale=2.0000 norm=0.8969
[iter 300] loss=-0.6823 val_loss=0.0000 scale=1.0000 norm=0.4193
[iter 400] loss=-1.0015 val_loss=0.0000 scale=1.0000 norm=0.4086
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3041 val_loss=0.0000 scale=2.0000 norm=1.0130
[iter 200] loss=-0.2598 val_loss=0.0000 scale=1.0000 norm=0.4423
[iter 300] loss=-0.6004 val_loss=0.0000 scale=2.0000 norm=0.8106
[iter 400] loss=-0.9028 val_loss=0.0000 scale=1.0000 norm=0.3814
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2187 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.5095 val_loss=0.0000 scale=2.0000 norm=0.8704
[iter 300] loss=-1.0586 val_loss=0.0000 scale=2.0000 norm=0.7827
[iter 400] loss=-1.4248 val_loss=0.0000 scale=1.0000 norm=0.3760
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2972 val_loss=0.0000 scale=2.0000 norm=1.0208
[iter 200] loss=-0.2671 val_loss=0.0000 scale=2.0000 norm=0.8977
[iter 300] loss=-0.6800 val_loss=0.0000 scale=2.0000 norm=0.8249
[iter 400] loss=-1.0247 val_loss=0.0000 scale=2.0000 norm=0.7882
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1899 val_loss=0.0000 scale=2.0000 norm=0.9760
[iter 200] loss=-0.6503 val_loss=0.0000 scale=2.0000 norm=0.8777
[iter 300] loss=-1.3983 val_loss=0.0000 scale=2.0000 norm=0.8096
[iter 400] loss=-1.9113 val_loss=0.0000 scale=1.0000 norm=0.3938
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6757 val_loss=0.0000 scale=2.0000 norm=1.1976
[iter 200] loss=0.0780 val_loss=0.0000 scale=1.0000 norm=0.4896
[iter 300] loss=-0.2389 val_loss=0.0000 scale=1.0000 norm=0.4553
[iter 400] loss=-0.5302 val_loss=0.0000 scale=1.0000 norm=0.4334
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5470 val_loss=0.0000 scale=2.0000 norm=1.0684
[iter 200] loss=-0.3197 val_loss=0.0000 scale=2.0000 norm=0.9208
[iter 300] loss=-1.1012 val_loss=0.0000 scale=2.0000 norm=0.8252
[iter 400] loss=-1.7424 val_loss=0.0000 scale=2.0000 norm=0.7300
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2058 val_loss=0.0000 scale=2.0000 norm=1.0029
[iter 200] loss=-0.6775 val_loss=0.0000 scale=2.0000 norm=0.9119
[iter 300] loss=-1.3715 val_loss=0.0000 scale=2.0000 norm=0.8073
[iter 400] loss=-1.8287 val_loss=0.0000 scale=1.0000 norm=0.3539
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3215 val_loss=0.0000 scale=2.0000 norm=1.0129
[iter 200] loss=-0.2661 val_loss=0.0000 scale=2.0000 norm=0.8990
[iter 300] loss=-0.6656 val_loss=0.0000 scale=2.0000 norm=0.8315
[iter 400] loss=-0.9480 val_loss=0.0000 scale=2.0000 norm=0.7961
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3113 val_loss=0.0000 scale=2.0000 norm=1.0227
[iter 200] loss=-0.2685 val_loss=0.0000 scale=2.0000 norm=0.8911
[iter 300] loss=-0.6402 val_loss=0.0000 scale=1.0000 norm=0.3999
[iter 400] loss=-0.9532 val_loss=0.0000 scale=1.0000 norm=0.3777
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0984 val_loss=0.0000 scale=2.0000 norm=0.9993
[iter 200] loss=-0.8797 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 300] loss=-1.8909 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9990 val_loss=0.0000 scale=2.0000 norm=0.9817
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2238 val_loss=0.0000 scale=2.0000 norm=0.9787
[iter 200] loss=-0.7122 val_loss=0.0000 scale=2.0000 norm=0.9345
[iter 300] loss=-1.6005 val_loss=0.0000 scale=2.0000 norm=0.8828
[iter 400] loss=-2.3854 val_loss=0.0000 scale=2.0000 norm=0.7839
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4052 val_loss=0.0000 scale=1.0000 norm=0.5288
[iter 200] loss=-0.1810 val_loss=0.0000 scale=2.0000 norm=0.9045
[iter 300] loss=-0.5022 val_loss=0.0000 scale=1.0000 norm=0.4187
[iter 400] loss=-0.7425 val_loss=0.0000 scale=1.0000 norm=0.4070
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3310 val_loss=0.0000 scale=2.0000 norm=0.9928
[iter 200] loss=-0.5771 val_loss=0.0000 scale=2.0000 norm=0.9307
[iter 300] loss=-1.4825 val_loss=0.0000 scale=2.0000 norm=0.9051
[iter 400] loss=-2.3409 val_loss=0.0000 scale=2.0000 norm=0.8554
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1914 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 200] loss=-0.7889 val_loss=0.0000 scale=2.0000 norm=0.9744
[iter 300] loss=-1.7596 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 400] loss=-2.7381 val_loss=0.0000 scale=2.0000 norm=0.9777
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3343 val_loss=0.0000 scale=1.0000 norm=0.5163
[iter 200] loss=-0.1942 val_loss=0.0000 scale=1.0000 norm=0.4540
[iter 300] loss=-0.7114 val_loss=0.0000 scale=1.0000 norm=0.4123
[iter 400] loss=-1.0402 val_loss=0.0000 scale=1.0000 norm=0.3903
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2479 val_loss=0.0000 scale=2.0000 norm=0.9716
[iter 200] loss=-0.7137 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 300] loss=-1.7190 val_loss=0.0000 scale=2.0000 norm=0.9839
[iter 400] loss=-3.1734 val_loss=0.0000 scale=2.0000 norm=0.9786
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5940 val_loss=0.0000 scale=2.0000 norm=1.1560
[iter 200] loss=0.0487 val_loss=0.0000 scale=1.0000 norm=0.4894
[iter 300] loss=-0.2759 val_loss=0.0000 scale=1.0000 norm=0.4541
[iter 400] loss=-0.5316 val_loss=0.0000 scale=1.0000 norm=0.4368
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1371 val_loss=0.0000 scale=2.0000 norm=0.9839
[iter 200] loss=-0.8534 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 300] loss=-2.3051 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 400] loss=-3.7711 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2908 val_loss=0.0000 scale=1.0000 norm=0.5074
[iter 200] loss=-0.3669 val_loss=0.0000 scale=1.0000 norm=0.4438
[iter 300] loss=-0.8514 val_loss=0.0000 scale=2.0000 norm=0.8156
[iter 400] loss=-1.1661 val_loss=0.0000 scale=1.0000 norm=0.3905
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2910 val_loss=0.0000 scale=2.0000 norm=0.9887
[iter 200] loss=-0.4779 val_loss=0.0000 scale=2.0000 norm=0.8679
[iter 300] loss=-1.0553 val_loss=0.0000 scale=1.0000 norm=0.3907
[iter 400] loss=-1.4171 val_loss=0.0000 scale=1.0000 norm=0.3557
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1426 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 200] loss=-0.7707 val_loss=0.0000 scale=2.0000 norm=0.9220
[iter 300] loss=-1.6447 val_loss=0.0000 scale=2.0000 norm=0.8740
[iter 400] loss=-2.4207 val_loss=0.0000 scale=2.0000 norm=0.7845
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2488 val_loss=0.0000 scale=2.0000 norm=1.0050
[iter 200] loss=-0.3695 val_loss=0.0000 scale=2.0000 norm=0.9041
[iter 300] loss=-0.8166 val_loss=0.0000 scale=2.0000 norm=0.8217
[iter 400] loss=-1.0917 val_loss=0.0000 scale=1.0000 norm=0.3882
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3738 val_loss=0.0000 scale=2.0000 norm=1.0262
[iter 200] loss=-0.3961 val_loss=0.0000 scale=2.0000 norm=0.8662
[iter 300] loss=-0.9484 val_loss=0.0000 scale=2.0000 norm=0.7819
[iter 400] loss=-1.3344 val_loss=0.0000 scale=1.0000 norm=0.3590
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3244 val_loss=0.0000 scale=2.0000 norm=0.9869
[iter 200] loss=-0.5024 val_loss=0.0000 scale=2.0000 norm=0.8717
[iter 300] loss=-1.2127 val_loss=0.0000 scale=2.0000 norm=0.7662
[iter 400] loss=-1.7932 val_loss=0.0000 scale=2.0000 norm=0.6471
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2760 val_loss=0.0000 scale=2.0000 norm=1.0098
[iter 200] loss=-0.3589 val_loss=0.0000 scale=1.0000 norm=0.4484
[iter 300] loss=-0.8016 val_loss=0.0000 scale=1.0000 norm=0.4111
[iter 400] loss=-1.1094 val_loss=0.0000 scale=1.0000 norm=0.3857
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1426 val_loss=0.0000 scale=2.0000 norm=0.9859
[iter 200] loss=-0.7591 val_loss=0.0000 scale=2.0000 norm=0.9113
[iter 300] loss=-1.5502 val_loss=0.0000 scale=2.0000 norm=0.7958
[iter 400] loss=-2.2169 val_loss=0.0000 scale=2.0000 norm=0.7207
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3610 val_loss=0.0000 scale=2.0000 norm=1.0414
[iter 200] loss=-0.1410 val_loss=0.0000 scale=1.0000 norm=0.4583
[iter 300] loss=-0.4800 val_loss=0.0000 scale=1.0000 norm=0.4318
[iter 400] loss=-0.7596 val_loss=0.0000 scale=1.0000 norm=0.4136
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3479 val_loss=0.0000 scale=2.0000 norm=1.0349
[iter 200] loss=-0.2894 val_loss=0.0000 scale=2.0000 norm=0.8807
[iter 300] loss=-0.7035 val_loss=0.0000 scale=1.0000 norm=0.4003
[iter 400] loss=-0.9951 val_loss=0.0000 scale=1.0000 norm=0.3754
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2153 val_loss=0.0000 scale=1.0000 norm=0.5022
[iter 200] loss=-0.4986 val_loss=0.0000 scale=2.0000 norm=0.8674
[iter 300] loss=-0.9736 val_loss=0.0000 scale=2.0000 norm=0.7738
[iter 400] loss=-1.3014 val_loss=0.0000 scale=1.0000 norm=0.3639
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1752 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.8281 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-2.7237 val_loss=0.0000 scale=4.0000 norm=1.9876
[iter 400] loss=-4.5911 val_loss=0.0000 scale=2.0000 norm=0.9841
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2659 val_loss=0.0000 scale=2.0000 norm=1.0071
[iter 200] loss=-0.4587 val_loss=0.0000 scale=1.0000 norm=0.4442
[iter 300] loss=-0.8613 val_loss=0.0000 scale=1.0000 norm=0.4106
[iter 400] loss=-1.2001 val_loss=0.0000 scale=1.0000 norm=0.3879
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1990 val_loss=0.0000 scale=2.0000 norm=1.0032
[iter 200] loss=-0.6986 val_loss=0.0000 scale=2.0000 norm=0.9110
[iter 300] loss=-1.4917 val_loss=0.0000 scale=2.0000 norm=0.8296
[iter 400] loss=-2.0962 val_loss=0.0000 scale=1.0000 norm=0.3516
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=0.9788
[iter 200] loss=-0.5862 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 300] loss=-1.5311 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 400] loss=-2.4801 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5383 val_loss=0.0000 scale=2.0000 norm=1.1052
[iter 200] loss=-0.0926 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 300] loss=-0.5350 val_loss=0.0000 scale=1.0000 norm=0.4359
[iter 400] loss=-0.9380 val_loss=0.0000 scale=1.0000 norm=0.4078
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2741 val_loss=0.0000 scale=2.0000 norm=1.0158
[iter 200] loss=-0.2941 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 300] loss=-0.6589 val_loss=0.0000 scale=1.0000 norm=0.4145
[iter 400] loss=-0.9753 val_loss=0.0000 scale=1.0000 norm=0.3843
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2641 val_loss=0.0000 scale=2.0000 norm=1.0036
[iter 200] loss=-0.4170 val_loss=0.0000 scale=2.0000 norm=0.9118
[iter 300] loss=-0.8617 val_loss=0.0000 scale=1.0000 norm=0.4141
[iter 400] loss=-1.1678 val_loss=0.0000 scale=1.0000 norm=0.3803
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5504 val_loss=0.0000 scale=2.0000 norm=1.0938
[iter 200] loss=-0.2799 val_loss=0.0000 scale=2.0000 norm=0.9037
[iter 300] loss=-1.0443 val_loss=0.0000 scale=1.0000 norm=0.4057
[iter 400] loss=-1.5727 val_loss=0.0000 scale=1.0000 norm=0.3787
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1018 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.8851 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 300] loss=-2.2926 val_loss=0.0000 scale=4.0000 norm=1.9800
[iter 400] loss=-4.2046 val_loss=0.0000 scale=4.0000 norm=1.9678
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3337 val_loss=0.0000 scale=2.0000 norm=1.0439
[iter 200] loss=-0.1972 val_loss=0.0000 scale=2.0000 norm=0.9376
[iter 300] loss=-0.6424 val_loss=0.0000 scale=2.0000 norm=0.8754
[iter 400] loss=-0.9574 val_loss=0.0000 scale=1.0000 norm=0.4233
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3315 val_loss=0.0000 scale=2.0000 norm=1.0275
[iter 200] loss=-0.2313 val_loss=0.0000 scale=2.0000 norm=0.9095
[iter 300] loss=-0.5734 val_loss=0.0000 scale=1.0000 norm=0.4251
[iter 400] loss=-0.8119 val_loss=0.0000 scale=1.0000 norm=0.4155
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2861 val_loss=0.0000 scale=2.0000 norm=1.0065
[iter 200] loss=-0.2752 val_loss=0.0000 scale=1.0000 norm=0.4497
[iter 300] loss=-0.6882 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 400] loss=-0.9616 val_loss=0.0000 scale=1.0000 norm=0.3791
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3513 val_loss=0.0000 scale=2.0000 norm=1.0344
[iter 200] loss=-0.2676 val_loss=0.0000 scale=1.0000 norm=0.4507
[iter 300] loss=-0.6409 val_loss=0.0000 scale=2.0000 norm=0.8228
[iter 400] loss=-0.9117 val_loss=0.0000 scale=1.0000 norm=0.4038
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3986 val_loss=0.0000 scale=2.0000 norm=1.0400
[iter 200] loss=-0.1422 val_loss=0.0000 scale=1.0000 norm=0.4658
[iter 300] loss=-0.5832 val_loss=0.0000 scale=1.0000 norm=0.4268
[iter 400] loss=-0.8644 val_loss=0.0000 scale=1.0000 norm=0.3956
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2965 val_loss=0.0000 scale=1.0000 norm=0.5040
[iter 200] loss=-0.2859 val_loss=0.0000 scale=2.0000 norm=0.8809
[iter 300] loss=-0.7581 val_loss=0.0000 scale=1.0000 norm=0.3883
[iter 400] loss=-1.0486 val_loss=0.0000 scale=1.0000 norm=0.3671
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3135 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.2096 val_loss=0.0000 scale=1.0000 norm=0.4634
[iter 300] loss=-0.6033 val_loss=0.0000 scale=2.0000 norm=0.8519
[iter 400] loss=-0.8773 val_loss=0.0000 scale=1.0000 norm=0.4029
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3944 val_loss=0.0000 scale=2.0000 norm=1.0671
[iter 200] loss=-0.1741 val_loss=0.0000 scale=2.0000 norm=0.9120
[iter 300] loss=-0.6053 val_loss=0.0000 scale=1.0000 norm=0.4057
[iter 400] loss=-0.8501 val_loss=0.0000 scale=2.0000 norm=0.7578
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3876 val_loss=0.0000 scale=1.0000 norm=0.5324
[iter 200] loss=-0.1329 val_loss=0.0000 scale=2.0000 norm=0.9164
[iter 300] loss=-0.5298 val_loss=0.0000 scale=1.0000 norm=0.4206
[iter 400] loss=-0.8018 val_loss=0.0000 scale=1.0000 norm=0.3965
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4058 val_loss=0.0000 scale=1.0000 norm=0.5311
[iter 200] loss=-0.1600 val_loss=0.0000 scale=2.0000 norm=0.9227
[iter 300] loss=-0.6035 val_loss=0.0000 scale=2.0000 norm=0.8374
[iter 400] loss=-0.8935 val_loss=0.0000 scale=1.0000 norm=0.3993
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1976 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 200] loss=-0.5796 val_loss=0.0000 scale=2.0000 norm=0.8586
[iter 300] loss=-1.1668 val_loss=0.0000 scale=1.0000 norm=0.3854
[iter 400] loss=-1.5333 val_loss=0.0000 scale=1.0000 norm=0.3515
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2519 val_loss=0.0000 scale=2.0000 norm=0.9980
[iter 200] loss=-0.4624 val_loss=0.0000 scale=2.0000 norm=0.8902
[iter 300] loss=-0.9858 val_loss=0.0000 scale=2.0000 norm=0.8055
[iter 400] loss=-1.2799 val_loss=0.0000 scale=1.0000 norm=0.3753
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4462 val_loss=0.0000 scale=1.0000 norm=0.5298
[iter 200] loss=-0.0607 val_loss=0.0000 scale=2.0000 norm=0.9217
[iter 300] loss=-0.5132 val_loss=0.0000 scale=1.0000 norm=0.4241
[iter 400] loss=-0.7708 val_loss=0.0000 scale=1.0000 norm=0.4026
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3496 val_loss=0.0000 scale=2.0000 norm=1.0296
[iter 200] loss=-0.1928 val_loss=0.0000 scale=1.0000 norm=0.4470
[iter 300] loss=-0.5592 val_loss=0.0000 scale=1.0000 norm=0.4188
[iter 400] loss=-0.8291 val_loss=0.0000 scale=1.0000 norm=0.4045
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2661 val_loss=0.0000 scale=2.0000 norm=1.0065
[iter 200] loss=-0.3108 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 300] loss=-0.7175 val_loss=0.0000 scale=1.0000 norm=0.4180
[iter 400] loss=-1.0146 val_loss=0.0000 scale=2.0000 norm=0.8209

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n04>
Subject: Job 856544: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:39 2024
Job was executed on host(s) <4*c207n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:40 2024
                            <4*c207n07>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:11:40 2024
Terminated at Wed Oct 23 12:53:10 2024
Results reported at Wed Oct 23 12:53:10 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "RRU Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4529.37 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.28 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   2516 sec.
    Turnaround time :                            2491 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err> for stderr output of this job.

polymer representation: Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
RRU Dimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3107 val_loss=0.0000 scale=1.0000 norm=0.5093
[iter 200] loss=-0.2356 val_loss=0.0000 scale=1.0000 norm=0.4544
[iter 300] loss=-0.6055 val_loss=0.0000 scale=1.0000 norm=0.4291
[iter 400] loss=-0.9261 val_loss=0.0000 scale=2.0000 norm=0.8154
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2726 val_loss=0.0000 scale=2.0000 norm=1.0066
[iter 200] loss=-0.5344 val_loss=0.0000 scale=2.0000 norm=0.8736
[iter 300] loss=-1.1136 val_loss=0.0000 scale=1.0000 norm=0.3824
[iter 400] loss=-1.4627 val_loss=0.0000 scale=1.0000 norm=0.3473
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1885 val_loss=0.0000 scale=2.0000 norm=0.9818
[iter 200] loss=-0.6104 val_loss=0.0000 scale=2.0000 norm=0.8466
[iter 300] loss=-1.2455 val_loss=0.0000 scale=2.0000 norm=0.7356
[iter 400] loss=-1.6517 val_loss=0.0000 scale=1.0000 norm=0.3404
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3206 val_loss=0.0000 scale=2.0000 norm=1.0095
[iter 200] loss=-0.5725 val_loss=0.0000 scale=2.0000 norm=0.9081
[iter 300] loss=-1.4170 val_loss=0.0000 scale=2.0000 norm=0.8560
[iter 400] loss=-2.1972 val_loss=0.0000 scale=2.0000 norm=0.8080
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1841 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 200] loss=-0.7878 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 300] loss=-1.7623 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 400] loss=-2.8661 val_loss=0.0000 scale=2.0000 norm=0.9847
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4506 val_loss=0.0000 scale=2.0000 norm=1.0660
[iter 200] loss=-0.0923 val_loss=0.0000 scale=1.0000 norm=0.4488
[iter 300] loss=-0.4981 val_loss=0.0000 scale=2.0000 norm=0.7999
[iter 400] loss=-0.8114 val_loss=0.0000 scale=2.0000 norm=0.7537
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3986 val_loss=0.0000 scale=2.0000 norm=1.0157
[iter 200] loss=-0.5454 val_loss=0.0000 scale=2.0000 norm=0.9433
[iter 300] loss=-1.4904 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 400] loss=-2.4364 val_loss=0.0000 scale=2.0000 norm=0.9414
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2680 val_loss=0.0000 scale=2.0000 norm=1.0098
[iter 200] loss=-0.4650 val_loss=0.0000 scale=2.0000 norm=0.8852
[iter 300] loss=-0.8964 val_loss=0.0000 scale=1.0000 norm=0.4119
[iter 400] loss=-1.2201 val_loss=0.0000 scale=1.0000 norm=0.3868
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2976 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6129 val_loss=0.0000 scale=2.0000 norm=0.9203
[iter 300] loss=-1.5383 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 400] loss=-2.4572 val_loss=0.0000 scale=2.0000 norm=0.9171
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5833 val_loss=0.0000 scale=2.0000 norm=1.1330
[iter 200] loss=0.0417 val_loss=0.0000 scale=1.0000 norm=0.4637
[iter 300] loss=-0.3117 val_loss=0.0000 scale=2.0000 norm=0.8573
[iter 400] loss=-0.6610 val_loss=0.0000 scale=1.0000 norm=0.4070
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2239 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 200] loss=-0.6150 val_loss=0.0000 scale=2.0000 norm=0.8779
[iter 300] loss=-1.2433 val_loss=0.0000 scale=1.0000 norm=0.3848
[iter 400] loss=-1.6114 val_loss=0.0000 scale=1.0000 norm=0.3457
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3439 val_loss=0.0000 scale=2.0000 norm=1.0054
[iter 200] loss=-0.4614 val_loss=0.0000 scale=2.0000 norm=0.8743
[iter 300] loss=-1.0476 val_loss=0.0000 scale=1.0000 norm=0.3968
[iter 400] loss=-1.4386 val_loss=0.0000 scale=1.0000 norm=0.3468
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2475 val_loss=0.0000 scale=2.0000 norm=0.9810
[iter 200] loss=-0.6666 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 300] loss=-1.4969 val_loss=0.0000 scale=2.0000 norm=0.8551
[iter 400] loss=-2.1964 val_loss=0.0000 scale=1.0000 norm=0.3843
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4310 val_loss=0.0000 scale=1.0000 norm=0.5312
[iter 200] loss=-0.0470 val_loss=0.0000 scale=1.0000 norm=0.4606
[iter 300] loss=-0.4408 val_loss=0.0000 scale=1.0000 norm=0.4215
[iter 400] loss=-0.7437 val_loss=0.0000 scale=2.0000 norm=0.8184
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2839 val_loss=0.0000 scale=2.0000 norm=1.0153
[iter 200] loss=-0.3695 val_loss=0.0000 scale=2.0000 norm=0.9002
[iter 300] loss=-0.9084 val_loss=0.0000 scale=1.0000 norm=0.4154
[iter 400] loss=-1.2925 val_loss=0.0000 scale=1.0000 norm=0.3901
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3425 val_loss=0.0000 scale=2.0000 norm=1.0302
[iter 200] loss=-0.2487 val_loss=0.0000 scale=1.0000 norm=0.4479
[iter 300] loss=-0.6421 val_loss=0.0000 scale=1.0000 norm=0.4135
[iter 400] loss=-0.8923 val_loss=0.0000 scale=1.0000 norm=0.3873
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3116 val_loss=0.0000 scale=2.0000 norm=1.0232
[iter 200] loss=-0.2761 val_loss=0.0000 scale=2.0000 norm=0.8910
[iter 300] loss=-0.6427 val_loss=0.0000 scale=1.0000 norm=0.4017
[iter 400] loss=-0.9511 val_loss=0.0000 scale=1.0000 norm=0.3771
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2110 val_loss=0.0000 scale=2.0000 norm=0.9674
[iter 200] loss=-0.6982 val_loss=0.0000 scale=2.0000 norm=0.9097
[iter 300] loss=-1.5275 val_loss=0.0000 scale=2.0000 norm=0.8258
[iter 400] loss=-2.2515 val_loss=0.0000 scale=2.0000 norm=0.7427
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5392 val_loss=0.0000 scale=2.0000 norm=1.1265
[iter 200] loss=-0.1103 val_loss=0.0000 scale=2.0000 norm=0.9603
[iter 300] loss=-0.5356 val_loss=0.0000 scale=1.0000 norm=0.4365
[iter 400] loss=-0.8371 val_loss=0.0000 scale=0.5000 norm=0.2066
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2257 val_loss=0.0000 scale=2.0000 norm=0.9984
[iter 200] loss=-0.4350 val_loss=0.0000 scale=1.0000 norm=0.4350
[iter 300] loss=-0.8206 val_loss=0.0000 scale=1.0000 norm=0.4050
[iter 400] loss=-1.1321 val_loss=0.0000 scale=1.0000 norm=0.3820
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2862 val_loss=0.0000 scale=2.0000 norm=1.0135
[iter 200] loss=-0.2486 val_loss=0.0000 scale=1.0000 norm=0.4455
[iter 300] loss=-0.6910 val_loss=0.0000 scale=2.0000 norm=0.8119
[iter 400] loss=-0.9841 val_loss=0.0000 scale=1.0000 norm=0.3769
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6166 val_loss=0.0000 scale=1.0000 norm=0.5757
[iter 200] loss=-0.0055 val_loss=0.0000 scale=2.0000 norm=0.9466
[iter 300] loss=-0.5553 val_loss=0.0000 scale=1.0000 norm=0.4211
[iter 400] loss=-1.1106 val_loss=0.0000 scale=2.0000 norm=0.7694
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4245 val_loss=0.0000 scale=2.0000 norm=1.0047
[iter 200] loss=-0.4442 val_loss=0.0000 scale=2.0000 norm=0.8820
[iter 300] loss=-1.1999 val_loss=0.0000 scale=2.0000 norm=0.7773
[iter 400] loss=-1.7870 val_loss=0.0000 scale=2.0000 norm=0.6612
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5571 val_loss=0.0000 scale=2.0000 norm=1.1315
[iter 200] loss=0.0267 val_loss=0.0000 scale=1.0000 norm=0.4862
[iter 300] loss=-0.3200 val_loss=0.0000 scale=1.0000 norm=0.4535
[iter 400] loss=-0.5498 val_loss=0.0000 scale=1.0000 norm=0.4346
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3296 val_loss=0.0000 scale=1.0000 norm=0.5140
[iter 200] loss=-0.2768 val_loss=0.0000 scale=2.0000 norm=0.9048
[iter 300] loss=-0.6933 val_loss=0.0000 scale=1.0000 norm=0.4135
[iter 400] loss=-1.0505 val_loss=0.0000 scale=1.0000 norm=0.3894
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3628 val_loss=0.0000 scale=2.0000 norm=1.0372
[iter 200] loss=-0.2344 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 300] loss=-0.7293 val_loss=0.0000 scale=1.0000 norm=0.4338
[iter 400] loss=-1.0388 val_loss=0.0000 scale=1.0000 norm=0.4098
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2342 val_loss=0.0000 scale=2.0000 norm=1.0194
[iter 200] loss=-0.6104 val_loss=0.0000 scale=2.0000 norm=0.9057
[iter 300] loss=-1.3316 val_loss=0.0000 scale=1.0000 norm=0.3999
[iter 400] loss=-1.6990 val_loss=0.0000 scale=1.0000 norm=0.3526
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1425 val_loss=0.0000 scale=2.0000 norm=0.9733
[iter 200] loss=-0.7699 val_loss=0.0000 scale=2.0000 norm=0.9212
[iter 300] loss=-1.6492 val_loss=0.0000 scale=2.0000 norm=0.8758
[iter 400] loss=-2.4210 val_loss=0.0000 scale=2.0000 norm=0.7897
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3542 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 200] loss=-0.4978 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 300] loss=-1.2283 val_loss=0.0000 scale=2.0000 norm=0.9099
[iter 400] loss=-2.0764 val_loss=0.0000 scale=2.0000 norm=0.8862
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2986 val_loss=0.0000 scale=2.0000 norm=1.0087
[iter 200] loss=-0.4608 val_loss=0.0000 scale=2.0000 norm=0.8678
[iter 300] loss=-1.0198 val_loss=0.0000 scale=2.0000 norm=0.7710
[iter 400] loss=-1.3664 val_loss=0.0000 scale=2.0000 norm=0.7132
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2805 val_loss=0.0000 scale=2.0000 norm=1.0068
[iter 200] loss=-0.3801 val_loss=0.0000 scale=1.0000 norm=0.4331
[iter 300] loss=-0.8734 val_loss=0.0000 scale=1.0000 norm=0.3898
[iter 400] loss=-1.1612 val_loss=0.0000 scale=2.0000 norm=0.7542
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2346 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 200] loss=-0.4620 val_loss=0.0000 scale=2.0000 norm=0.8636
[iter 300] loss=-0.9778 val_loss=0.0000 scale=2.0000 norm=0.7903
[iter 400] loss=-1.3666 val_loss=0.0000 scale=1.0000 norm=0.3662
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3163 val_loss=0.0000 scale=1.0000 norm=0.5106
[iter 200] loss=-0.3141 val_loss=0.0000 scale=2.0000 norm=0.9008
[iter 300] loss=-0.8392 val_loss=0.0000 scale=1.0000 norm=0.4044
[iter 400] loss=-1.1720 val_loss=0.0000 scale=2.0000 norm=0.7555
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2358 val_loss=0.0000 scale=2.0000 norm=1.0163
[iter 200] loss=-0.4787 val_loss=0.0000 scale=1.0000 norm=0.4483
[iter 300] loss=-1.0177 val_loss=0.0000 scale=2.0000 norm=0.8215
[iter 400] loss=-1.4664 val_loss=0.0000 scale=2.0000 norm=0.7528
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3280 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 200] loss=-0.6482 val_loss=0.0000 scale=2.0000 norm=0.9700
[iter 300] loss=-1.6638 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 400] loss=-2.9150 val_loss=0.0000 scale=2.0000 norm=0.9741
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1644 val_loss=0.0000 scale=2.0000 norm=0.9933
[iter 200] loss=-0.5491 val_loss=0.0000 scale=2.0000 norm=0.8906
[iter 300] loss=-1.2642 val_loss=0.0000 scale=2.0000 norm=0.7916
[iter 400] loss=-1.8265 val_loss=0.0000 scale=1.0000 norm=0.3674
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3436 val_loss=0.0000 scale=2.0000 norm=1.0335
[iter 200] loss=-0.1352 val_loss=0.0000 scale=2.0000 norm=0.9121
[iter 300] loss=-0.4824 val_loss=0.0000 scale=1.0000 norm=0.4234
[iter 400] loss=-0.7330 val_loss=0.0000 scale=1.0000 norm=0.4038
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3302 val_loss=0.0000 scale=1.0000 norm=0.5160
[iter 200] loss=-0.1307 val_loss=0.0000 scale=2.0000 norm=0.9201
[iter 300] loss=-0.6503 val_loss=0.0000 scale=2.0000 norm=0.8409
[iter 400] loss=-0.9366 val_loss=0.0000 scale=1.0000 norm=0.3947
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4637 val_loss=0.0000 scale=2.0000 norm=1.0784
[iter 200] loss=-0.0681 val_loss=0.0000 scale=1.0000 norm=0.4617
[iter 300] loss=-0.4024 val_loss=0.0000 scale=1.0000 norm=0.4247
[iter 400] loss=-0.6435 val_loss=0.0000 scale=1.0000 norm=0.4033
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4886 val_loss=0.0000 scale=1.0000 norm=0.5312
[iter 200] loss=-0.2216 val_loss=0.0000 scale=2.0000 norm=0.9061
[iter 300] loss=-0.7648 val_loss=0.0000 scale=2.0000 norm=0.8258
[iter 400] loss=-1.0773 val_loss=0.0000 scale=1.0000 norm=0.3944
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2535 val_loss=0.0000 scale=2.0000 norm=0.9939
[iter 200] loss=-0.4422 val_loss=0.0000 scale=1.0000 norm=0.4317
[iter 300] loss=-0.8855 val_loss=0.0000 scale=1.0000 norm=0.3912
[iter 400] loss=-1.2194 val_loss=0.0000 scale=2.0000 norm=0.7449
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3946 val_loss=0.0000 scale=2.0000 norm=1.0318
[iter 200] loss=-0.1806 val_loss=0.0000 scale=2.0000 norm=0.8977
[iter 300] loss=-0.4773 val_loss=0.0000 scale=1.0000 norm=0.4140
[iter 400] loss=-0.7481 val_loss=0.0000 scale=2.0000 norm=0.7825
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2396 val_loss=0.0000 scale=1.0000 norm=0.5090
[iter 200] loss=-0.3942 val_loss=0.0000 scale=2.0000 norm=0.9118
[iter 300] loss=-1.0419 val_loss=0.0000 scale=2.0000 norm=0.8222
[iter 400] loss=-1.4897 val_loss=0.0000 scale=1.0000 norm=0.3784
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3075 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 200] loss=-0.4392 val_loss=0.0000 scale=2.0000 norm=0.8885
[iter 300] loss=-0.9857 val_loss=0.0000 scale=1.0000 norm=0.4092
[iter 400] loss=-1.3246 val_loss=0.0000 scale=1.0000 norm=0.3763
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3738 val_loss=0.0000 scale=2.0000 norm=1.0262
[iter 200] loss=-0.3961 val_loss=0.0000 scale=2.0000 norm=0.8662
[iter 300] loss=-0.9484 val_loss=0.0000 scale=2.0000 norm=0.7819
[iter 400] loss=-1.3344 val_loss=0.0000 scale=1.0000 norm=0.3590
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1728 val_loss=0.0000 scale=2.0000 norm=0.9676
[iter 200] loss=-0.7643 val_loss=0.0000 scale=2.0000 norm=0.9511
[iter 300] loss=-1.7335 val_loss=0.0000 scale=2.0000 norm=0.9625
[iter 400] loss=-2.6665 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2855 val_loss=0.0000 scale=2.0000 norm=1.0033
[iter 200] loss=-0.3388 val_loss=0.0000 scale=1.0000 norm=0.4405
[iter 300] loss=-0.7136 val_loss=0.0000 scale=1.0000 norm=0.4053
[iter 400] loss=-0.9572 val_loss=0.0000 scale=1.0000 norm=0.3818
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3205 val_loss=0.0000 scale=2.0000 norm=1.0256
[iter 200] loss=-0.1874 val_loss=0.0000 scale=2.0000 norm=0.9000
[iter 300] loss=-0.5887 val_loss=0.0000 scale=1.0000 norm=0.4120
[iter 400] loss=-0.9017 val_loss=0.0000 scale=1.0000 norm=0.3913
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3037 val_loss=0.0000 scale=2.0000 norm=1.0164
[iter 200] loss=-0.4744 val_loss=0.0000 scale=1.0000 norm=0.4421
[iter 300] loss=-0.9311 val_loss=0.0000 scale=2.0000 norm=0.7665
[iter 400] loss=-1.2210 val_loss=0.0000 scale=1.0000 norm=0.3551
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3164 val_loss=0.0000 scale=2.0000 norm=1.0253
[iter 200] loss=-0.2493 val_loss=0.0000 scale=2.0000 norm=0.8965
[iter 300] loss=-0.6678 val_loss=0.0000 scale=1.0000 norm=0.4045
[iter 400] loss=-0.9410 val_loss=0.0000 scale=1.0000 norm=0.3875
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3285 val_loss=0.0000 scale=2.0000 norm=1.0447
[iter 200] loss=-0.1479 val_loss=0.0000 scale=2.0000 norm=0.9205
[iter 300] loss=-0.6154 val_loss=0.0000 scale=1.0000 norm=0.4079
[iter 400] loss=-0.8914 val_loss=0.0000 scale=2.0000 norm=0.7723
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4892 val_loss=0.0000 scale=2.0000 norm=1.0552
[iter 200] loss=-0.2793 val_loss=0.0000 scale=2.0000 norm=0.8740
[iter 300] loss=-0.8097 val_loss=0.0000 scale=2.0000 norm=0.7886
[iter 400] loss=-1.1262 val_loss=0.0000 scale=1.0000 norm=0.3789
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1914 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 200] loss=-0.7889 val_loss=0.0000 scale=2.0000 norm=0.9744
[iter 300] loss=-1.7596 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 400] loss=-2.7381 val_loss=0.0000 scale=2.0000 norm=0.9777
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3842 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 200] loss=-0.1266 val_loss=0.0000 scale=1.0000 norm=0.4625
[iter 300] loss=-0.4976 val_loss=0.0000 scale=1.0000 norm=0.4246
[iter 400] loss=-0.7795 val_loss=0.0000 scale=0.5000 norm=0.2006
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3664 val_loss=0.0000 scale=2.0000 norm=1.0395
[iter 200] loss=-0.2383 val_loss=0.0000 scale=2.0000 norm=0.8947
[iter 300] loss=-0.6642 val_loss=0.0000 scale=1.0000 norm=0.4174
[iter 400] loss=-0.9122 val_loss=0.0000 scale=1.0000 norm=0.4088
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5384 val_loss=0.0000 scale=2.0000 norm=1.1052
[iter 200] loss=-0.1101 val_loss=0.0000 scale=2.0000 norm=0.9500
[iter 300] loss=-0.5569 val_loss=0.0000 scale=1.0000 norm=0.4332
[iter 400] loss=-0.9569 val_loss=0.0000 scale=1.0000 norm=0.4081
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2778 val_loss=0.0000 scale=2.0000 norm=1.0113
[iter 200] loss=-0.2354 val_loss=0.0000 scale=1.0000 norm=0.4432
[iter 300] loss=-0.5982 val_loss=0.0000 scale=1.0000 norm=0.4058
[iter 400] loss=-0.8073 val_loss=0.0000 scale=0.5000 norm=0.1915
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3399 val_loss=0.0000 scale=2.0000 norm=1.0350
[iter 200] loss=-0.2182 val_loss=0.0000 scale=2.0000 norm=0.8988
[iter 300] loss=-0.5796 val_loss=0.0000 scale=1.0000 norm=0.4121
[iter 400] loss=-0.8242 val_loss=0.0000 scale=1.0000 norm=0.3935
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2986 val_loss=0.0000 scale=2.0000 norm=1.0344
[iter 200] loss=-0.1899 val_loss=0.0000 scale=1.0000 norm=0.4660
[iter 300] loss=-0.6002 val_loss=0.0000 scale=1.0000 norm=0.4420
[iter 400] loss=-0.8465 val_loss=0.0000 scale=2.0000 norm=0.8587
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2598 val_loss=0.0000 scale=2.0000 norm=0.9799
[iter 200] loss=-0.7165 val_loss=0.0000 scale=2.0000 norm=0.9748
[iter 300] loss=-1.9868 val_loss=0.0000 scale=4.0000 norm=1.9636
[iter 400] loss=-3.2291 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4106 val_loss=0.0000 scale=2.0000 norm=1.0640
[iter 200] loss=-0.1012 val_loss=0.0000 scale=1.0000 norm=0.4621
[iter 300] loss=-0.4941 val_loss=0.0000 scale=2.0000 norm=0.8576
[iter 400] loss=-0.7396 val_loss=0.0000 scale=1.0000 norm=0.4066
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=1.0142
[iter 200] loss=-0.1950 val_loss=0.0000 scale=2.0000 norm=0.8765
[iter 300] loss=-0.5913 val_loss=0.0000 scale=2.0000 norm=0.7956
[iter 400] loss=-0.9158 val_loss=0.0000 scale=1.0000 norm=0.3702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2769 val_loss=0.0000 scale=2.0000 norm=1.0286
[iter 200] loss=-0.3420 val_loss=0.0000 scale=2.0000 norm=0.8805
[iter 300] loss=-0.8633 val_loss=0.0000 scale=2.0000 norm=0.7813
[iter 400] loss=-1.1879 val_loss=0.0000 scale=1.0000 norm=0.3579
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3653 val_loss=0.0000 scale=2.0000 norm=1.0220
[iter 200] loss=-0.2695 val_loss=0.0000 scale=2.0000 norm=0.8730
[iter 300] loss=-0.6800 val_loss=0.0000 scale=2.0000 norm=0.8154
[iter 400] loss=-0.9323 val_loss=0.0000 scale=1.0000 norm=0.3932
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4086 val_loss=0.0000 scale=2.0000 norm=1.0576
[iter 200] loss=-0.2341 val_loss=0.0000 scale=2.0000 norm=0.9188
[iter 300] loss=-0.6436 val_loss=0.0000 scale=1.0000 norm=0.4257
[iter 400] loss=-0.9840 val_loss=0.0000 scale=0.5000 norm=0.1976
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2738 val_loss=0.0000 scale=2.0000 norm=1.0159
[iter 200] loss=-0.3260 val_loss=0.0000 scale=1.0000 norm=0.4446
[iter 300] loss=-0.7693 val_loss=0.0000 scale=2.0000 norm=0.7931
[iter 400] loss=-1.0591 val_loss=0.0000 scale=1.0000 norm=0.3787
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5730 val_loss=0.0000 scale=1.0000 norm=0.5689
[iter 200] loss=-0.0045 val_loss=0.0000 scale=2.0000 norm=0.9603
[iter 300] loss=-0.3879 val_loss=0.0000 scale=1.0000 norm=0.4541
[iter 400] loss=-0.7361 val_loss=0.0000 scale=1.0000 norm=0.4327
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2962 val_loss=0.0000 scale=2.0000 norm=1.0281
[iter 200] loss=-0.2673 val_loss=0.0000 scale=1.0000 norm=0.4490
[iter 300] loss=-0.6857 val_loss=0.0000 scale=2.0000 norm=0.8328
[iter 400] loss=-0.9817 val_loss=0.0000 scale=1.0000 norm=0.4076
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3447 val_loss=0.0000 scale=2.0000 norm=1.0346
[iter 200] loss=-0.1123 val_loss=0.0000 scale=2.0000 norm=0.9122
[iter 300] loss=-0.4582 val_loss=0.0000 scale=2.0000 norm=0.8201
[iter 400] loss=-0.7345 val_loss=0.0000 scale=1.0000 norm=0.3877
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4538 val_loss=0.0000 scale=2.0000 norm=1.0474
[iter 200] loss=-0.2938 val_loss=0.0000 scale=2.0000 norm=0.9055
[iter 300] loss=-1.0068 val_loss=0.0000 scale=2.0000 norm=0.8147
[iter 400] loss=-1.4815 val_loss=0.0000 scale=1.0000 norm=0.3728
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2971 val_loss=0.0000 scale=2.0000 norm=1.0205
[iter 200] loss=-0.2603 val_loss=0.0000 scale=1.0000 norm=0.4491
[iter 300] loss=-0.7219 val_loss=0.0000 scale=1.0000 norm=0.4100
[iter 400] loss=-1.0226 val_loss=0.0000 scale=1.0000 norm=0.4018
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3289 val_loss=0.0000 scale=2.0000 norm=1.0391
[iter 200] loss=-0.2252 val_loss=0.0000 scale=1.0000 norm=0.4623
[iter 300] loss=-0.6011 val_loss=0.0000 scale=1.0000 norm=0.4244
[iter 400] loss=-0.8971 val_loss=0.0000 scale=1.0000 norm=0.4072
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3417 val_loss=0.0000 scale=1.0000 norm=0.5245
[iter 200] loss=-0.0981 val_loss=0.0000 scale=2.0000 norm=0.9535
[iter 300] loss=-0.4947 val_loss=0.0000 scale=1.0000 norm=0.4513
[iter 400] loss=-0.7890 val_loss=0.0000 scale=1.0000 norm=0.4352
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3352 val_loss=0.0000 scale=2.0000 norm=1.0460
[iter 200] loss=-0.1769 val_loss=0.0000 scale=1.0000 norm=0.4708
[iter 300] loss=-0.6358 val_loss=0.0000 scale=1.0000 norm=0.4339
[iter 400] loss=-0.9555 val_loss=0.0000 scale=1.0000 norm=0.4154
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3234 val_loss=0.0000 scale=1.0000 norm=0.5089
[iter 200] loss=-0.2434 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 300] loss=-0.6032 val_loss=0.0000 scale=1.0000 norm=0.4217
[iter 400] loss=-0.8923 val_loss=0.0000 scale=2.0000 norm=0.8289
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2120 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.5520 val_loss=0.0000 scale=2.0000 norm=0.8603
[iter 300] loss=-1.1922 val_loss=0.0000 scale=2.0000 norm=0.7763
[iter 400] loss=-1.6181 val_loss=0.0000 scale=1.0000 norm=0.3651
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1293 val_loss=0.0000 scale=2.0000 norm=0.9914
[iter 200] loss=-0.8581 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 300] loss=-2.4725 val_loss=0.0000 scale=4.0000 norm=1.9772
[iter 400] loss=-4.1079 val_loss=0.0000 scale=4.0000 norm=1.9528
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4488 val_loss=0.0000 scale=1.0000 norm=0.5354
[iter 200] loss=-0.2066 val_loss=0.0000 scale=1.0000 norm=0.4527
[iter 300] loss=-0.6872 val_loss=0.0000 scale=1.0000 norm=0.4087
[iter 400] loss=-1.0590 val_loss=0.0000 scale=1.0000 norm=0.3826
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3256 val_loss=0.0000 scale=1.0000 norm=0.5132
[iter 200] loss=-0.2525 val_loss=0.0000 scale=1.0000 norm=0.4493
[iter 300] loss=-0.7286 val_loss=0.0000 scale=2.0000 norm=0.8277
[iter 400] loss=-1.0673 val_loss=0.0000 scale=2.0000 norm=0.7795
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3007 val_loss=0.0000 scale=2.0000 norm=1.0255
[iter 200] loss=-0.3571 val_loss=0.0000 scale=2.0000 norm=0.8823
[iter 300] loss=-1.0047 val_loss=0.0000 scale=2.0000 norm=0.7581
[iter 400] loss=-1.4285 val_loss=0.0000 scale=2.0000 norm=0.6676
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3834 val_loss=0.0000 scale=2.0000 norm=1.0406
[iter 200] loss=-0.0728 val_loss=0.0000 scale=2.0000 norm=0.9247
[iter 300] loss=-0.4172 val_loss=0.0000 scale=1.0000 norm=0.4212
[iter 400] loss=-0.6413 val_loss=0.0000 scale=1.0000 norm=0.4030
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3309 val_loss=0.0000 scale=2.0000 norm=0.9929
[iter 200] loss=-0.5798 val_loss=0.0000 scale=2.0000 norm=0.9289
[iter 300] loss=-1.4846 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 400] loss=-2.2380 val_loss=0.0000 scale=1.0000 norm=0.4340
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2389 val_loss=0.0000 scale=2.0000 norm=0.9928
[iter 200] loss=-0.4619 val_loss=0.0000 scale=2.0000 norm=0.8761
[iter 300] loss=-0.8560 val_loss=0.0000 scale=1.0000 norm=0.4087
[iter 400] loss=-1.1206 val_loss=0.0000 scale=1.0000 norm=0.3771
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3635 val_loss=0.0000 scale=2.0000 norm=1.0403
[iter 200] loss=-0.2717 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 300] loss=-0.7494 val_loss=0.0000 scale=2.0000 norm=0.8013
[iter 400] loss=-1.0678 val_loss=0.0000 scale=1.0000 norm=0.3850
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2190 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.5197 val_loss=0.0000 scale=2.0000 norm=0.8681
[iter 300] loss=-1.0643 val_loss=0.0000 scale=2.0000 norm=0.7756
[iter 400] loss=-1.3937 val_loss=0.0000 scale=1.0000 norm=0.3756
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2443 val_loss=0.0000 scale=2.0000 norm=1.0082
[iter 200] loss=-0.4111 val_loss=0.0000 scale=2.0000 norm=0.8963
[iter 300] loss=-0.8843 val_loss=0.0000 scale=1.0000 norm=0.4065
[iter 400] loss=-1.1946 val_loss=0.0000 scale=1.0000 norm=0.3791
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.6554 val_loss=0.0000 scale=1.0000 norm=0.5786
[iter 200] loss=0.0952 val_loss=0.0000 scale=1.0000 norm=0.4897
[iter 300] loss=-0.3698 val_loss=0.0000 scale=1.0000 norm=0.4387
[iter 400] loss=-0.6959 val_loss=0.0000 scale=1.0000 norm=0.3967
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4033 val_loss=0.0000 scale=1.0000 norm=0.5177
[iter 200] loss=-0.0794 val_loss=0.0000 scale=1.0000 norm=0.4629
[iter 300] loss=-0.4076 val_loss=0.0000 scale=1.0000 norm=0.4387
[iter 400] loss=-0.7025 val_loss=0.0000 scale=1.0000 norm=0.4141
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=0.9863
[iter 200] loss=-0.5288 val_loss=0.0000 scale=2.0000 norm=0.9187
[iter 300] loss=-1.3831 val_loss=0.0000 scale=2.0000 norm=0.8589
[iter 400] loss=-2.1240 val_loss=0.0000 scale=1.0000 norm=0.3908
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3694 val_loss=0.0000 scale=2.0000 norm=0.9921
[iter 200] loss=-0.5896 val_loss=0.0000 scale=2.0000 norm=0.9522
[iter 300] loss=-1.5083 val_loss=0.0000 scale=2.0000 norm=0.9154
[iter 400] loss=-2.3398 val_loss=0.0000 scale=2.0000 norm=0.8282
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2924 val_loss=0.0000 scale=2.0000 norm=1.0074
[iter 200] loss=-0.3021 val_loss=0.0000 scale=1.0000 norm=0.4386
[iter 300] loss=-0.6856 val_loss=0.0000 scale=2.0000 norm=0.8015
[iter 400] loss=-0.9259 val_loss=0.0000 scale=1.0000 norm=0.3797
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2983 val_loss=0.0000 scale=2.0000 norm=0.9987
[iter 200] loss=-0.3899 val_loss=0.0000 scale=2.0000 norm=0.8698
[iter 300] loss=-0.7802 val_loss=0.0000 scale=1.0000 norm=0.4089
[iter 400] loss=-1.0833 val_loss=0.0000 scale=1.0000 norm=0.3980
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3066 val_loss=0.0000 scale=2.0000 norm=1.0230
[iter 200] loss=-0.2751 val_loss=0.0000 scale=1.0000 norm=0.4462
[iter 300] loss=-0.6388 val_loss=0.0000 scale=1.0000 norm=0.4157
[iter 400] loss=-0.9501 val_loss=0.0000 scale=2.0000 norm=0.7776
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1477 val_loss=0.0000 scale=2.0000 norm=0.9896
[iter 200] loss=-0.8300 val_loss=0.0000 scale=2.0000 norm=0.9788
[iter 300] loss=-2.2820 val_loss=0.0000 scale=4.0000 norm=1.9881
[iter 400] loss=-4.2798 val_loss=0.0000 scale=4.0000 norm=1.9970
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3069 val_loss=0.0000 scale=2.0000 norm=1.0048
[iter 200] loss=-0.3800 val_loss=0.0000 scale=2.0000 norm=0.8506
[iter 300] loss=-0.9779 val_loss=0.0000 scale=1.0000 norm=0.3746
[iter 400] loss=-1.3591 val_loss=0.0000 scale=1.0000 norm=0.3511
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3504 val_loss=0.0000 scale=1.0000 norm=0.5222
[iter 200] loss=-0.1378 val_loss=0.0000 scale=2.0000 norm=0.9178
[iter 300] loss=-0.5238 val_loss=0.0000 scale=2.0000 norm=0.8255
[iter 400] loss=-0.7609 val_loss=0.0000 scale=0.5000 norm=0.1987
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2958 val_loss=0.0000 scale=2.0000 norm=1.0148
[iter 200] loss=-0.3703 val_loss=0.0000 scale=1.0000 norm=0.4393
[iter 300] loss=-0.7759 val_loss=0.0000 scale=1.0000 norm=0.4112
[iter 400] loss=-1.0162 val_loss=0.0000 scale=1.0000 norm=0.4056
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3250 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.5683 val_loss=0.0000 scale=2.0000 norm=0.9206
[iter 300] loss=-1.4234 val_loss=0.0000 scale=2.0000 norm=0.8537
[iter 400] loss=-2.1456 val_loss=0.0000 scale=2.0000 norm=0.7330
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3207 val_loss=0.0000 scale=1.0000 norm=0.5120
[iter 200] loss=-0.2386 val_loss=0.0000 scale=2.0000 norm=0.8894
[iter 300] loss=-0.6758 val_loss=0.0000 scale=1.0000 norm=0.4036
[iter 400] loss=-1.0103 val_loss=0.0000 scale=2.0000 norm=0.7804
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2946 val_loss=0.0000 scale=2.0000 norm=1.0314
[iter 200] loss=-0.3452 val_loss=0.0000 scale=1.0000 norm=0.4498
[iter 300] loss=-0.8338 val_loss=0.0000 scale=1.0000 norm=0.4129
[iter 400] loss=-1.1570 val_loss=0.0000 scale=1.0000 norm=0.3933
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0427 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-1.0293 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 300] loss=-2.3712 val_loss=0.0000 scale=2.0000 norm=0.9762
[iter 400] loss=-3.4236 val_loss=0.0000 scale=2.0000 norm=0.9644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3069 val_loss=0.0000 scale=2.0000 norm=1.0168
[iter 200] loss=-0.2800 val_loss=0.0000 scale=1.0000 norm=0.4564
[iter 300] loss=-0.6809 val_loss=0.0000 scale=1.0000 norm=0.4280
[iter 400] loss=-0.9762 val_loss=0.0000 scale=1.0000 norm=0.4219
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3287 val_loss=0.0000 scale=2.0000 norm=1.0055
[iter 200] loss=-0.4038 val_loss=0.0000 scale=2.0000 norm=0.8593
[iter 300] loss=-0.8799 val_loss=0.0000 scale=2.0000 norm=0.7960
[iter 400] loss=-1.2480 val_loss=0.0000 scale=1.0000 norm=0.3686
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3990 val_loss=0.0000 scale=2.0000 norm=1.0377
[iter 200] loss=-0.1607 val_loss=0.0000 scale=1.0000 norm=0.4473
[iter 300] loss=-0.5827 val_loss=0.0000 scale=1.0000 norm=0.4066
[iter 400] loss=-0.9171 val_loss=0.0000 scale=2.0000 norm=0.7425
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4360 val_loss=0.0000 scale=2.0000 norm=1.0768
[iter 200] loss=-0.1627 val_loss=0.0000 scale=2.0000 norm=0.9346
[iter 300] loss=-0.6761 val_loss=0.0000 scale=1.0000 norm=0.4254
[iter 400] loss=-0.9734 val_loss=0.0000 scale=1.0000 norm=0.3972
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3871 val_loss=0.0000 scale=2.0000 norm=1.0501
[iter 200] loss=-0.2587 val_loss=0.0000 scale=2.0000 norm=0.8809
[iter 300] loss=-0.6723 val_loss=0.0000 scale=1.0000 norm=0.3952
[iter 400] loss=-0.9433 val_loss=0.0000 scale=1.0000 norm=0.3697
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3424 val_loss=0.0000 scale=2.0000 norm=1.0030
[iter 200] loss=-0.1593 val_loss=0.0000 scale=2.0000 norm=0.8862
[iter 300] loss=-0.5715 val_loss=0.0000 scale=1.0000 norm=0.4079
[iter 400] loss=-0.8628 val_loss=0.0000 scale=1.0000 norm=0.3947
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3092 val_loss=0.0000 scale=2.0000 norm=1.0127
[iter 200] loss=-0.2351 val_loss=0.0000 scale=1.0000 norm=0.4401
[iter 300] loss=-0.6605 val_loss=0.0000 scale=1.0000 norm=0.3997
[iter 400] loss=-0.9437 val_loss=0.0000 scale=1.0000 norm=0.3824
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5174 val_loss=0.0000 scale=2.0000 norm=1.0634
[iter 200] loss=-0.2896 val_loss=0.0000 scale=2.0000 norm=0.8934
[iter 300] loss=-0.8896 val_loss=0.0000 scale=1.0000 norm=0.4009
[iter 400] loss=-1.2705 val_loss=0.0000 scale=2.0000 norm=0.7390
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4118 val_loss=0.0000 scale=1.0000 norm=0.5302
[iter 200] loss=-0.0173 val_loss=0.0000 scale=1.0000 norm=0.4724
[iter 300] loss=-0.4007 val_loss=0.0000 scale=1.0000 norm=0.4347
[iter 400] loss=-0.6693 val_loss=0.0000 scale=1.0000 norm=0.4079
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2037 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 200] loss=-0.7352 val_loss=0.0000 scale=2.0000 norm=0.9367
[iter 300] loss=-1.6056 val_loss=0.0000 scale=2.0000 norm=0.8696
[iter 400] loss=-2.3605 val_loss=0.0000 scale=2.0000 norm=0.7699
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2951 val_loss=0.0000 scale=2.0000 norm=1.0254
[iter 200] loss=-0.3941 val_loss=0.0000 scale=2.0000 norm=0.8886
[iter 300] loss=-0.7957 val_loss=0.0000 scale=1.0000 norm=0.4164
[iter 400] loss=-1.1232 val_loss=0.0000 scale=2.0000 norm=0.7610
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4318 val_loss=0.0000 scale=2.0000 norm=1.0557
[iter 200] loss=-0.1108 val_loss=0.0000 scale=1.0000 norm=0.4644
[iter 300] loss=-0.5690 val_loss=0.0000 scale=1.0000 norm=0.4249
[iter 400] loss=-0.9191 val_loss=0.0000 scale=1.0000 norm=0.4011
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2827 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-0.2830 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 300] loss=-0.7342 val_loss=0.0000 scale=2.0000 norm=0.8184
[iter 400] loss=-1.0891 val_loss=0.0000 scale=1.0000 norm=0.3889
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1082 val_loss=0.0000 scale=2.0000 norm=0.9844
[iter 200] loss=-0.7844 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 300] loss=-1.5794 val_loss=0.0000 scale=2.0000 norm=0.8370
[iter 400] loss=-2.2314 val_loss=0.0000 scale=1.0000 norm=0.3884
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5578 val_loss=0.0000 scale=1.0000 norm=0.5611
[iter 200] loss=0.0433 val_loss=0.0000 scale=1.0000 norm=0.4949
[iter 300] loss=-0.2636 val_loss=0.0000 scale=1.0000 norm=0.4595
[iter 400] loss=-0.5128 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1371 val_loss=0.0000 scale=2.0000 norm=0.9839
[iter 200] loss=-0.8534 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 300] loss=-2.3051 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 400] loss=-3.7711 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2538 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.3212 val_loss=0.0000 scale=2.0000 norm=0.8801
[iter 300] loss=-0.9057 val_loss=0.0000 scale=2.0000 norm=0.7547
[iter 400] loss=-1.2625 val_loss=0.0000 scale=1.0000 norm=0.3412
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3666 val_loss=0.0000 scale=1.0000 norm=0.5092
[iter 200] loss=-0.0870 val_loss=0.0000 scale=1.0000 norm=0.4463
[iter 300] loss=-0.4256 val_loss=0.0000 scale=1.0000 norm=0.4092
[iter 400] loss=-0.7362 val_loss=0.0000 scale=1.0000 norm=0.3757
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5504 val_loss=0.0000 scale=2.0000 norm=1.0938
[iter 200] loss=-0.2799 val_loss=0.0000 scale=2.0000 norm=0.9037
[iter 300] loss=-1.0443 val_loss=0.0000 scale=2.0000 norm=0.8117
[iter 400] loss=-1.5552 val_loss=0.0000 scale=2.0000 norm=0.7626
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4532 val_loss=0.0000 scale=2.0000 norm=1.0909
[iter 200] loss=-0.1278 val_loss=0.0000 scale=1.0000 norm=0.4594
[iter 300] loss=-0.4261 val_loss=0.0000 scale=1.0000 norm=0.4244
[iter 400] loss=-0.6388 val_loss=0.0000 scale=1.0000 norm=0.4088
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5644 val_loss=0.0000 scale=2.0000 norm=1.1510
[iter 200] loss=0.1168 val_loss=0.0000 scale=1.0000 norm=0.5014
[iter 300] loss=-0.2631 val_loss=0.0000 scale=1.0000 norm=0.4642
[iter 400] loss=-0.6089 val_loss=0.0000 scale=1.0000 norm=0.4269
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2697 val_loss=0.0000 scale=2.0000 norm=0.9969
[iter 200] loss=-0.6790 val_loss=0.0000 scale=2.0000 norm=0.9503
[iter 300] loss=-1.6257 val_loss=0.0000 scale=2.0000 norm=0.9456
[iter 400] loss=-2.5624 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2765 val_loss=0.0000 scale=2.0000 norm=1.0102
[iter 200] loss=-0.3497 val_loss=0.0000 scale=2.0000 norm=0.8975
[iter 300] loss=-0.8001 val_loss=0.0000 scale=2.0000 norm=0.8188
[iter 400] loss=-1.0924 val_loss=0.0000 scale=1.0000 norm=0.3866
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1009 val_loss=0.0000 scale=2.0000 norm=0.9932
[iter 200] loss=-0.8775 val_loss=0.0000 scale=2.0000 norm=0.9750
[iter 300] loss=-1.8561 val_loss=0.0000 scale=4.0000 norm=1.9622
[iter 400] loss=-2.9791 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4016 val_loss=0.0000 scale=1.0000 norm=0.5204
[iter 200] loss=-0.3072 val_loss=0.0000 scale=2.0000 norm=0.8975
[iter 300] loss=-0.8675 val_loss=0.0000 scale=1.0000 norm=0.4020
[iter 400] loss=-1.2111 val_loss=0.0000 scale=1.0000 norm=0.3750
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3986 val_loss=0.0000 scale=2.0000 norm=1.0400
[iter 200] loss=-0.1442 val_loss=0.0000 scale=1.0000 norm=0.4651
[iter 300] loss=-0.5571 val_loss=0.0000 scale=1.0000 norm=0.4316
[iter 400] loss=-0.8212 val_loss=0.0000 scale=1.0000 norm=0.4077
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3088 val_loss=0.0000 scale=2.0000 norm=1.0201
[iter 200] loss=-0.2714 val_loss=0.0000 scale=1.0000 norm=0.4470
[iter 300] loss=-0.6794 val_loss=0.0000 scale=1.0000 norm=0.4185
[iter 400] loss=-0.9844 val_loss=0.0000 scale=1.0000 norm=0.4031
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2854 val_loss=0.0000 scale=1.0000 norm=0.5124
[iter 200] loss=-0.2962 val_loss=0.0000 scale=2.0000 norm=0.9085
[iter 300] loss=-0.7101 val_loss=0.0000 scale=2.0000 norm=0.8465
[iter 400] loss=-1.0578 val_loss=0.0000 scale=2.0000 norm=0.7890
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3126 val_loss=0.0000 scale=1.0000 norm=0.5144
[iter 200] loss=-0.3221 val_loss=0.0000 scale=1.0000 norm=0.4510
[iter 300] loss=-0.7621 val_loss=0.0000 scale=1.0000 norm=0.4130
[iter 400] loss=-1.0981 val_loss=0.0000 scale=1.0000 norm=0.3917
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4160 val_loss=0.0000 scale=1.0000 norm=0.5250
[iter 200] loss=-0.1226 val_loss=0.0000 scale=2.0000 norm=0.9134
[iter 300] loss=-0.5859 val_loss=0.0000 scale=1.0000 norm=0.4154
[iter 400] loss=-0.9189 val_loss=0.0000 scale=1.0000 norm=0.3855
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3041 val_loss=0.0000 scale=2.0000 norm=1.0130
[iter 200] loss=-0.2356 val_loss=0.0000 scale=1.0000 norm=0.4523
[iter 300] loss=-0.6181 val_loss=0.0000 scale=1.0000 norm=0.4062
[iter 400] loss=-0.8998 val_loss=0.0000 scale=2.0000 norm=0.7431
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2788 val_loss=0.0000 scale=2.0000 norm=1.0251
[iter 200] loss=-0.2909 val_loss=0.0000 scale=2.0000 norm=0.9059
[iter 300] loss=-0.7295 val_loss=0.0000 scale=1.0000 norm=0.4238
[iter 400] loss=-0.9910 val_loss=0.0000 scale=2.0000 norm=0.8258
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2935 val_loss=0.0000 scale=2.0000 norm=1.0223
[iter 200] loss=-0.3021 val_loss=0.0000 scale=1.0000 norm=0.4460
[iter 300] loss=-0.6724 val_loss=0.0000 scale=1.0000 norm=0.4077
[iter 400] loss=-0.9476 val_loss=0.0000 scale=1.0000 norm=0.3860
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3838 val_loss=0.0000 scale=2.0000 norm=1.0464
[iter 200] loss=-0.1687 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 300] loss=-0.5936 val_loss=0.0000 scale=1.0000 norm=0.4227
[iter 400] loss=-0.9201 val_loss=0.0000 scale=1.0000 norm=0.3959
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2285 val_loss=0.0000 scale=1.0000 norm=0.5064
[iter 200] loss=-0.4821 val_loss=0.0000 scale=2.0000 norm=0.8972
[iter 300] loss=-1.0513 val_loss=0.0000 scale=2.0000 norm=0.8198
[iter 400] loss=-1.3872 val_loss=0.0000 scale=1.0000 norm=0.3813
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4537 val_loss=0.0000 scale=1.0000 norm=0.5365
[iter 200] loss=-0.0850 val_loss=0.0000 scale=2.0000 norm=0.9309
[iter 300] loss=-0.4970 val_loss=0.0000 scale=1.0000 norm=0.4140
[iter 400] loss=-0.8424 val_loss=0.0000 scale=1.0000 norm=0.3897
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4097 val_loss=0.0000 scale=2.0000 norm=1.0468
[iter 200] loss=-0.2349 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 300] loss=-0.6673 val_loss=0.0000 scale=1.0000 norm=0.4121
[iter 400] loss=-1.0215 val_loss=0.0000 scale=1.0000 norm=0.3836
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4091 val_loss=0.0000 scale=1.0000 norm=0.5267
[iter 200] loss=-0.2588 val_loss=0.0000 scale=1.0000 norm=0.4494
[iter 300] loss=-0.8362 val_loss=0.0000 scale=1.0000 norm=0.3912
[iter 400] loss=-1.1609 val_loss=0.0000 scale=1.0000 norm=0.3583
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2064 val_loss=0.0000 scale=2.0000 norm=0.9553
[iter 200] loss=-0.7450 val_loss=0.0000 scale=2.0000 norm=0.9478
[iter 300] loss=-1.6913 val_loss=0.0000 scale=2.0000 norm=0.9442
[iter 400] loss=-2.6188 val_loss=0.0000 scale=2.0000 norm=0.9281
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1766 val_loss=0.0000 scale=2.0000 norm=0.9809
[iter 200] loss=-0.6477 val_loss=0.0000 scale=2.0000 norm=0.8787
[iter 300] loss=-1.2714 val_loss=0.0000 scale=2.0000 norm=0.7701
[iter 400] loss=-1.6547 val_loss=0.0000 scale=1.0000 norm=0.3349
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0984 val_loss=0.0000 scale=2.0000 norm=0.9993
[iter 200] loss=-0.8797 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 300] loss=-1.8909 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9990 val_loss=0.0000 scale=2.0000 norm=0.9817
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2437 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 200] loss=-0.6813 val_loss=0.0000 scale=2.0000 norm=0.9247
[iter 300] loss=-1.5474 val_loss=0.0000 scale=2.0000 norm=0.8673
[iter 400] loss=-2.3108 val_loss=0.0000 scale=2.0000 norm=0.7907
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4159 val_loss=0.0000 scale=2.0000 norm=1.0679
[iter 200] loss=-0.0023 val_loss=0.0000 scale=2.0000 norm=0.9452
[iter 300] loss=-0.3495 val_loss=0.0000 scale=1.0000 norm=0.4328
[iter 400] loss=-0.6427 val_loss=0.0000 scale=1.0000 norm=0.4005
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3065 val_loss=0.0000 scale=1.0000 norm=0.5092
[iter 200] loss=-0.2457 val_loss=0.0000 scale=1.0000 norm=0.4467
[iter 300] loss=-0.6508 val_loss=0.0000 scale=1.0000 norm=0.4160
[iter 400] loss=-0.9526 val_loss=0.0000 scale=1.0000 norm=0.4005
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3793 val_loss=0.0000 scale=2.0000 norm=1.0052
[iter 200] loss=-0.5334 val_loss=0.0000 scale=2.0000 norm=0.9225
[iter 300] loss=-1.3992 val_loss=0.0000 scale=2.0000 norm=0.8698
[iter 400] loss=-2.2267 val_loss=0.0000 scale=2.0000 norm=0.8338
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3093 val_loss=0.0000 scale=2.0000 norm=1.0166
[iter 200] loss=-0.2228 val_loss=0.0000 scale=2.0000 norm=0.8896
[iter 300] loss=-0.6633 val_loss=0.0000 scale=2.0000 norm=0.8448
[iter 400] loss=-0.9498 val_loss=0.0000 scale=1.0000 norm=0.4086
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2252 val_loss=0.0000 scale=2.0000 norm=0.9891
[iter 200] loss=-0.5513 val_loss=0.0000 scale=2.0000 norm=0.8734
[iter 300] loss=-1.1951 val_loss=0.0000 scale=1.0000 norm=0.3809
[iter 400] loss=-1.6210 val_loss=0.0000 scale=2.0000 norm=0.7046
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4897 val_loss=0.0000 scale=2.0000 norm=1.1051
[iter 200] loss=-0.0143 val_loss=0.0000 scale=2.0000 norm=0.9551
[iter 300] loss=-0.4437 val_loss=0.0000 scale=1.0000 norm=0.4350
[iter 400] loss=-0.6915 val_loss=0.0000 scale=0.5000 norm=0.2137
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1068 val_loss=0.0000 scale=2.0000 norm=1.0019
[iter 200] loss=-0.9461 val_loss=0.0000 scale=4.0000 norm=1.9817
[iter 300] loss=-2.9414 val_loss=0.0000 scale=4.0000 norm=1.9969
[iter 400] loss=-4.9380 val_loss=0.0000 scale=4.0000 norm=1.9951
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1643 val_loss=0.0000 scale=2.0000 norm=0.9776
[iter 200] loss=-0.6898 val_loss=0.0000 scale=2.0000 norm=0.8758
[iter 300] loss=-1.3901 val_loss=0.0000 scale=2.0000 norm=0.7555
[iter 400] loss=-1.8362 val_loss=0.0000 scale=1.0000 norm=0.3589
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2763 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.4431 val_loss=0.0000 scale=2.0000 norm=0.8555
[iter 300] loss=-0.9056 val_loss=0.0000 scale=1.0000 norm=0.3778
[iter 400] loss=-1.2138 val_loss=0.0000 scale=1.0000 norm=0.3378
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2903 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 200] loss=-0.4868 val_loss=0.0000 scale=2.0000 norm=0.8717
[iter 300] loss=-1.0900 val_loss=0.0000 scale=1.0000 norm=0.3853
[iter 400] loss=-1.4123 val_loss=0.0000 scale=1.0000 norm=0.3625
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1018 val_loss=0.0000 scale=2.0000 norm=0.9946
[iter 200] loss=-0.8851 val_loss=0.0000 scale=2.0000 norm=0.9835
[iter 300] loss=-2.2926 val_loss=0.0000 scale=4.0000 norm=1.9800
[iter 400] loss=-4.2046 val_loss=0.0000 scale=4.0000 norm=1.9677
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5581 val_loss=0.0000 scale=2.0000 norm=1.0871
[iter 200] loss=-0.1124 val_loss=0.0000 scale=2.0000 norm=0.9281
[iter 300] loss=-0.6926 val_loss=0.0000 scale=1.0000 norm=0.4114
[iter 400] loss=-1.0422 val_loss=0.0000 scale=1.0000 norm=0.3825
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2731 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 200] loss=-0.4992 val_loss=0.0000 scale=2.0000 norm=0.8310
[iter 300] loss=-1.1697 val_loss=0.0000 scale=1.0000 norm=0.3855
[iter 400] loss=-1.6818 val_loss=0.0000 scale=2.0000 norm=0.6684
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3253 val_loss=0.0000 scale=2.0000 norm=1.0145
[iter 200] loss=-0.2606 val_loss=0.0000 scale=2.0000 norm=0.8995
[iter 300] loss=-0.6541 val_loss=0.0000 scale=2.0000 norm=0.8394
[iter 400] loss=-0.9566 val_loss=0.0000 scale=1.0000 norm=0.4016
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1021 val_loss=0.0000 scale=2.0000 norm=0.9846
[iter 200] loss=-0.8027 val_loss=0.0000 scale=2.0000 norm=0.9140
[iter 300] loss=-1.6625 val_loss=0.0000 scale=2.0000 norm=0.8684
[iter 400] loss=-2.4720 val_loss=0.0000 scale=2.0000 norm=0.8174
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3825 val_loss=0.0000 scale=1.0000 norm=0.5219
[iter 200] loss=-0.1562 val_loss=0.0000 scale=2.0000 norm=0.9236
[iter 300] loss=-0.5469 val_loss=0.0000 scale=1.0000 norm=0.4377
[iter 400] loss=-0.8895 val_loss=0.0000 scale=2.0000 norm=0.8183
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2833 val_loss=0.0000 scale=2.0000 norm=1.0114
[iter 200] loss=-0.6034 val_loss=0.0000 scale=2.0000 norm=0.9059
[iter 300] loss=-1.4401 val_loss=0.0000 scale=2.0000 norm=0.8528
[iter 400] loss=-2.0942 val_loss=0.0000 scale=1.0000 norm=0.3893
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2666 val_loss=0.0000 scale=2.0000 norm=0.9678
[iter 200] loss=-0.6586 val_loss=0.0000 scale=2.0000 norm=0.9284
[iter 300] loss=-1.5340 val_loss=0.0000 scale=2.0000 norm=0.8787
[iter 400] loss=-2.2922 val_loss=0.0000 scale=1.0000 norm=0.4031
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3949 val_loss=0.0000 scale=2.0000 norm=1.0212
[iter 200] loss=-0.4065 val_loss=0.0000 scale=2.0000 norm=0.8774
[iter 300] loss=-1.0552 val_loss=0.0000 scale=2.0000 norm=0.7827
[iter 400] loss=-1.5042 val_loss=0.0000 scale=2.0000 norm=0.7137
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2518 val_loss=0.0000 scale=2.0000 norm=0.9959
[iter 200] loss=-0.4969 val_loss=0.0000 scale=2.0000 norm=0.8764
[iter 300] loss=-1.1074 val_loss=0.0000 scale=2.0000 norm=0.7806
[iter 400] loss=-1.4916 val_loss=0.0000 scale=1.0000 norm=0.3610
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3759 val_loss=0.0000 scale=2.0000 norm=1.0435
[iter 200] loss=-0.3452 val_loss=0.0000 scale=2.0000 norm=0.8903
[iter 300] loss=-0.8658 val_loss=0.0000 scale=2.0000 norm=0.7975
[iter 400] loss=-1.2076 val_loss=0.0000 scale=1.0000 norm=0.3664
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1970 val_loss=0.0000 scale=2.0000 norm=0.9850
[iter 200] loss=-0.6140 val_loss=0.0000 scale=2.0000 norm=0.8854
[iter 300] loss=-1.2000 val_loss=0.0000 scale=2.0000 norm=0.7921
[iter 400] loss=-1.5811 val_loss=0.0000 scale=1.0000 norm=0.3738
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2519 val_loss=0.0000 scale=2.0000 norm=0.9980
[iter 200] loss=-0.4792 val_loss=0.0000 scale=2.0000 norm=0.8857
[iter 300] loss=-0.9887 val_loss=0.0000 scale=1.0000 norm=0.4073
[iter 400] loss=-1.2584 val_loss=0.0000 scale=0.5000 norm=0.1895
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2060 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 200] loss=-0.7315 val_loss=0.0000 scale=2.0000 norm=0.9443
[iter 300] loss=-1.6778 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 400] loss=-2.6071 val_loss=0.0000 scale=2.0000 norm=0.9357
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3429 val_loss=0.0000 scale=2.0000 norm=1.0162
[iter 200] loss=-0.4282 val_loss=0.0000 scale=2.0000 norm=0.8858
[iter 300] loss=-0.9984 val_loss=0.0000 scale=2.0000 norm=0.8088
[iter 400] loss=-1.3994 val_loss=0.0000 scale=1.0000 norm=0.3892
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3432 val_loss=0.0000 scale=2.0000 norm=1.0411
[iter 200] loss=-0.3149 val_loss=0.0000 scale=1.0000 norm=0.4370
[iter 300] loss=-0.7108 val_loss=0.0000 scale=1.0000 norm=0.3992
[iter 400] loss=-0.9877 val_loss=0.0000 scale=2.0000 norm=0.7840
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1047 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 200] loss=-0.8756 val_loss=0.0000 scale=2.0000 norm=0.9785
[iter 300] loss=-1.8577 val_loss=0.0000 scale=2.0000 norm=0.9818
[iter 400] loss=-2.8487 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2508 val_loss=0.0000 scale=2.0000 norm=0.9955
[iter 200] loss=-0.5011 val_loss=0.0000 scale=2.0000 norm=0.8455
[iter 300] loss=-0.9702 val_loss=0.0000 scale=1.0000 norm=0.3751
[iter 400] loss=-1.2712 val_loss=0.0000 scale=1.0000 norm=0.3539
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3001 val_loss=0.0000 scale=2.0000 norm=1.0148
[iter 200] loss=-0.4059 val_loss=0.0000 scale=2.0000 norm=0.8715
[iter 300] loss=-0.9013 val_loss=0.0000 scale=2.0000 norm=0.7955
[iter 400] loss=-1.1838 val_loss=0.0000 scale=0.5000 norm=0.1923
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3147 val_loss=0.0000 scale=2.0000 norm=1.0141
[iter 200] loss=-0.3767 val_loss=0.0000 scale=2.0000 norm=0.8601
[iter 300] loss=-0.8031 val_loss=0.0000 scale=2.0000 norm=0.8071
[iter 400] loss=-1.0728 val_loss=0.0000 scale=1.0000 norm=0.3847
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3253 val_loss=0.0000 scale=2.0000 norm=1.0196
[iter 200] loss=-0.2682 val_loss=0.0000 scale=2.0000 norm=0.8874
[iter 300] loss=-0.6786 val_loss=0.0000 scale=2.0000 norm=0.7957
[iter 400] loss=-0.9773 val_loss=0.0000 scale=1.0000 norm=0.3760
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1304 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.8485 val_loss=0.0000 scale=2.0000 norm=0.9768
[iter 300] loss=-1.8302 val_loss=0.0000 scale=2.0000 norm=0.9819
[iter 400] loss=-3.1986 val_loss=0.0000 scale=4.0000 norm=1.9670
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3442 val_loss=0.0000 scale=1.0000 norm=0.5194
[iter 200] loss=-0.1958 val_loss=0.0000 scale=2.0000 norm=0.9098
[iter 300] loss=-0.6485 val_loss=0.0000 scale=1.0000 norm=0.4201
[iter 400] loss=-0.9635 val_loss=0.0000 scale=1.0000 norm=0.4022
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6556 val_loss=0.0000 scale=1.0000 norm=0.5826
[iter 200] loss=0.1167 val_loss=0.0000 scale=2.0000 norm=0.9559
[iter 300] loss=-0.5256 val_loss=0.0000 scale=2.0000 norm=0.8186
[iter 400] loss=-0.9383 val_loss=0.0000 scale=1.0000 norm=0.3755
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2533 val_loss=0.0000 scale=2.0000 norm=1.0218
[iter 200] loss=-0.4217 val_loss=0.0000 scale=2.0000 norm=0.8895
[iter 300] loss=-0.9395 val_loss=0.0000 scale=2.0000 norm=0.8109
[iter 400] loss=-1.2981 val_loss=0.0000 scale=1.0000 norm=0.3747
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2521 val_loss=0.0000 scale=2.0000 norm=1.0187
[iter 200] loss=-0.4311 val_loss=0.0000 scale=2.0000 norm=0.8879
[iter 300] loss=-0.8220 val_loss=0.0000 scale=2.0000 norm=0.8329
[iter 400] loss=-1.0755 val_loss=0.0000 scale=2.0000 norm=0.8072
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2732 val_loss=0.0000 scale=2.0000 norm=1.0155
[iter 200] loss=-0.2948 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 300] loss=-0.6517 val_loss=0.0000 scale=1.0000 norm=0.4145
[iter 400] loss=-0.9641 val_loss=0.0000 scale=1.0000 norm=0.3855
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1899 val_loss=0.0000 scale=2.0000 norm=0.9760
[iter 200] loss=-0.6503 val_loss=0.0000 scale=2.0000 norm=0.8777
[iter 300] loss=-1.3615 val_loss=0.0000 scale=2.0000 norm=0.8100
[iter 400] loss=-1.9191 val_loss=0.0000 scale=2.0000 norm=0.7891
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5320 val_loss=0.0000 scale=2.0000 norm=1.0975
[iter 200] loss=-0.0728 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 300] loss=-0.5274 val_loss=0.0000 scale=1.0000 norm=0.4203
[iter 400] loss=-0.8437 val_loss=0.0000 scale=2.0000 norm=0.8082
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4002 val_loss=0.0000 scale=1.0000 norm=0.5326
[iter 200] loss=0.0044 val_loss=0.0000 scale=1.0000 norm=0.4815
[iter 300] loss=-0.3474 val_loss=0.0000 scale=1.0000 norm=0.4359
[iter 400] loss=-0.6175 val_loss=0.0000 scale=1.0000 norm=0.4157
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3060 val_loss=0.0000 scale=2.0000 norm=1.0121
[iter 200] loss=-0.5453 val_loss=0.0000 scale=2.0000 norm=0.9033
[iter 300] loss=-1.2647 val_loss=0.0000 scale=2.0000 norm=0.8277
[iter 400] loss=-1.7332 val_loss=0.0000 scale=2.0000 norm=0.7281
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3244 val_loss=0.0000 scale=2.0000 norm=0.9869
[iter 200] loss=-0.5009 val_loss=0.0000 scale=2.0000 norm=0.8695
[iter 300] loss=-1.2293 val_loss=0.0000 scale=2.0000 norm=0.7626
[iter 400] loss=-1.8061 val_loss=0.0000 scale=2.0000 norm=0.6529
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2995 val_loss=0.0000 scale=1.0000 norm=0.5052
[iter 200] loss=-0.1723 val_loss=0.0000 scale=1.0000 norm=0.4522
[iter 300] loss=-0.5344 val_loss=0.0000 scale=1.0000 norm=0.4107
[iter 400] loss=-0.7880 val_loss=0.0000 scale=1.0000 norm=0.3825
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2435 val_loss=0.0000 scale=2.0000 norm=1.0040
[iter 200] loss=-0.4018 val_loss=0.0000 scale=1.0000 norm=0.4428
[iter 300] loss=-0.8118 val_loss=0.0000 scale=2.0000 norm=0.8053
[iter 400] loss=-1.1719 val_loss=0.0000 scale=1.0000 norm=0.3818
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2464 val_loss=0.0000 scale=2.0000 norm=1.0217
[iter 200] loss=-0.3979 val_loss=0.0000 scale=2.0000 norm=0.9114
[iter 300] loss=-0.9315 val_loss=0.0000 scale=2.0000 norm=0.8414
[iter 400] loss=-1.2663 val_loss=0.0000 scale=1.0000 norm=0.3916
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4775 val_loss=0.0000 scale=2.0000 norm=1.1098
[iter 200] loss=-0.1421 val_loss=0.0000 scale=1.0000 norm=0.4732
[iter 300] loss=-0.5660 val_loss=0.0000 scale=1.0000 norm=0.4424
[iter 400] loss=-0.8887 val_loss=0.0000 scale=1.0000 norm=0.4188
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3014 val_loss=0.0000 scale=2.0000 norm=1.0292
[iter 200] loss=-0.2271 val_loss=0.0000 scale=2.0000 norm=0.9120
[iter 300] loss=-0.6574 val_loss=0.0000 scale=2.0000 norm=0.8196
[iter 400] loss=-0.9313 val_loss=0.0000 scale=1.0000 norm=0.3907
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5630 val_loss=0.0000 scale=2.0000 norm=1.0755
[iter 200] loss=-0.0920 val_loss=0.0000 scale=1.0000 norm=0.4580
[iter 300] loss=-0.6324 val_loss=0.0000 scale=1.0000 norm=0.4008
[iter 400] loss=-1.0298 val_loss=0.0000 scale=1.0000 norm=0.3911
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1477 val_loss=0.0000 scale=2.0000 norm=0.9742
[iter 200] loss=-0.7386 val_loss=0.0000 scale=2.0000 norm=0.9006
[iter 300] loss=-1.5736 val_loss=0.0000 scale=2.0000 norm=0.8461
[iter 400] loss=-2.3024 val_loss=0.0000 scale=1.0000 norm=0.3775
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3125 val_loss=0.0000 scale=2.0000 norm=1.0245
[iter 200] loss=-0.2519 val_loss=0.0000 scale=2.0000 norm=0.8986
[iter 300] loss=-0.5980 val_loss=0.0000 scale=1.0000 norm=0.4100
[iter 400] loss=-0.8619 val_loss=0.0000 scale=1.0000 norm=0.3902
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2786 val_loss=0.0000 scale=2.0000 norm=0.9643
[iter 200] loss=-0.6074 val_loss=0.0000 scale=2.0000 norm=0.8976
[iter 300] loss=-1.4330 val_loss=0.0000 scale=2.0000 norm=0.8420
[iter 400] loss=-2.1656 val_loss=0.0000 scale=1.0000 norm=0.3900
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3881 val_loss=0.0000 scale=2.0000 norm=1.0632
[iter 200] loss=-0.2295 val_loss=0.0000 scale=2.0000 norm=0.9129
[iter 300] loss=-0.6007 val_loss=0.0000 scale=1.0000 norm=0.4136
[iter 400] loss=-0.8538 val_loss=0.0000 scale=1.0000 norm=0.3913
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1598 val_loss=0.0000 scale=2.0000 norm=0.9790
[iter 200] loss=-0.7181 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 300] loss=-1.5040 val_loss=0.0000 scale=2.0000 norm=0.8018
[iter 400] loss=-2.1230 val_loss=0.0000 scale=1.0000 norm=0.3784
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2905 val_loss=0.0000 scale=2.0000 norm=1.0169
[iter 200] loss=-0.1872 val_loss=0.0000 scale=1.0000 norm=0.4561
[iter 300] loss=-0.6344 val_loss=0.0000 scale=2.0000 norm=0.8350
[iter 400] loss=-0.9193 val_loss=0.0000 scale=1.0000 norm=0.4031
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6760 val_loss=0.0000 scale=1.0000 norm=0.5986
[iter 200] loss=0.0597 val_loss=0.0000 scale=2.0000 norm=0.9717
[iter 300] loss=-0.3268 val_loss=0.0000 scale=1.0000 norm=0.4461
[iter 400] loss=-0.6226 val_loss=0.0000 scale=2.0000 norm=0.8514
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5470 val_loss=0.0000 scale=2.0000 norm=1.0684
[iter 200] loss=-0.3171 val_loss=0.0000 scale=2.0000 norm=0.9188
[iter 300] loss=-1.0945 val_loss=0.0000 scale=2.0000 norm=0.8205
[iter 400] loss=-1.7280 val_loss=0.0000 scale=2.0000 norm=0.7211
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2685 val_loss=0.0000 scale=2.0000 norm=1.0012
[iter 200] loss=-0.4952 val_loss=0.0000 scale=2.0000 norm=0.8906
[iter 300] loss=-1.1838 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 400] loss=-1.6670 val_loss=0.0000 scale=1.0000 norm=0.3662
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3108 val_loss=0.0000 scale=2.0000 norm=1.0088
[iter 200] loss=-0.3188 val_loss=0.0000 scale=2.0000 norm=0.8828
[iter 300] loss=-0.7291 val_loss=0.0000 scale=1.0000 norm=0.3983
[iter 400] loss=-0.9663 val_loss=0.0000 scale=1.0000 norm=0.3727
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3521 val_loss=0.0000 scale=1.0000 norm=0.5074
[iter 200] loss=-0.2152 val_loss=0.0000 scale=2.0000 norm=0.8666
[iter 300] loss=-0.6706 val_loss=0.0000 scale=1.0000 norm=0.3957
[iter 400] loss=-0.9379 val_loss=0.0000 scale=1.0000 norm=0.3818
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6615 val_loss=0.0000 scale=2.0000 norm=1.1443
[iter 200] loss=-0.0710 val_loss=0.0000 scale=2.0000 norm=0.9360
[iter 300] loss=-0.7172 val_loss=0.0000 scale=1.0000 norm=0.4211
[iter 400] loss=-1.1632 val_loss=0.0000 scale=1.0000 norm=0.3900
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3056 val_loss=0.0000 scale=1.0000 norm=0.5103
[iter 200] loss=-0.2510 val_loss=0.0000 scale=1.0000 norm=0.4543
[iter 300] loss=-0.7247 val_loss=0.0000 scale=2.0000 norm=0.8180
[iter 400] loss=-0.9777 val_loss=0.0000 scale=1.0000 norm=0.3834
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2901 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 200] loss=-0.3340 val_loss=0.0000 scale=2.0000 norm=0.8655
[iter 300] loss=-0.7293 val_loss=0.0000 scale=1.0000 norm=0.3854
[iter 400] loss=-0.9763 val_loss=0.0000 scale=1.0000 norm=0.3723
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2118 val_loss=0.0000 scale=2.0000 norm=1.0042
[iter 200] loss=-0.4578 val_loss=0.0000 scale=1.0000 norm=0.4372
[iter 300] loss=-0.8802 val_loss=0.0000 scale=1.0000 norm=0.3980
[iter 400] loss=-1.2288 val_loss=0.0000 scale=1.0000 norm=0.3794
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6673 val_loss=0.0000 scale=2.0000 norm=1.1477
[iter 200] loss=-0.1137 val_loss=0.0000 scale=2.0000 norm=0.9139
[iter 300] loss=-0.7023 val_loss=0.0000 scale=1.0000 norm=0.4200
[iter 400] loss=-1.1198 val_loss=0.0000 scale=1.0000 norm=0.3900
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3101 val_loss=0.0000 scale=2.0000 norm=1.0107
[iter 200] loss=-0.3213 val_loss=0.0000 scale=2.0000 norm=0.8868
[iter 300] loss=-0.7356 val_loss=0.0000 scale=1.0000 norm=0.4095
[iter 400] loss=-1.0343 val_loss=0.0000 scale=1.0000 norm=0.3898
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1982 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 200] loss=-0.7043 val_loss=0.0000 scale=2.0000 norm=0.9119
[iter 300] loss=-1.5040 val_loss=0.0000 scale=2.0000 norm=0.8278
[iter 400] loss=-2.0581 val_loss=0.0000 scale=1.0000 norm=0.3663
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5864 val_loss=0.0000 scale=1.0000 norm=0.5689
[iter 200] loss=0.0256 val_loss=0.0000 scale=2.0000 norm=0.9349
[iter 300] loss=-0.5566 val_loss=0.0000 scale=1.0000 norm=0.4258
[iter 400] loss=-0.9421 val_loss=0.0000 scale=1.0000 norm=0.4021
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1834 val_loss=0.0000 scale=2.0000 norm=0.9883
[iter 200] loss=-0.9052 val_loss=0.0000 scale=4.0000 norm=1.9871
[iter 300] loss=-2.8988 val_loss=0.0000 scale=4.0000 norm=1.9880
[iter 400] loss=-4.7617 val_loss=0.0000 scale=4.0000 norm=1.8447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1722 val_loss=0.0000 scale=2.0000 norm=0.9693
[iter 200] loss=-0.7163 val_loss=0.0000 scale=2.0000 norm=0.9018
[iter 300] loss=-1.5106 val_loss=0.0000 scale=2.0000 norm=0.7957
[iter 400] loss=-2.0558 val_loss=0.0000 scale=1.0000 norm=0.3632
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2730 val_loss=0.0000 scale=1.0000 norm=0.4985
[iter 200] loss=-0.2785 val_loss=0.0000 scale=1.0000 norm=0.4475
[iter 300] loss=-0.7523 val_loss=0.0000 scale=1.0000 norm=0.4186
[iter 400] loss=-1.1227 val_loss=0.0000 scale=2.0000 norm=0.7987
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3661 val_loss=0.0000 scale=2.0000 norm=1.0251
[iter 200] loss=-0.2170 val_loss=0.0000 scale=2.0000 norm=0.8981
[iter 300] loss=-0.6301 val_loss=0.0000 scale=1.0000 norm=0.4181
[iter 400] loss=-0.9103 val_loss=0.0000 scale=1.0000 norm=0.3925
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3238 val_loss=0.0000 scale=2.0000 norm=1.0401
[iter 200] loss=-0.1768 val_loss=0.0000 scale=1.0000 norm=0.4661
[iter 300] loss=-0.5756 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 400] loss=-0.8884 val_loss=0.0000 scale=1.0000 norm=0.4268
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3110 val_loss=0.0000 scale=1.0000 norm=0.5162
[iter 200] loss=-0.2076 val_loss=0.0000 scale=1.0000 norm=0.4508
[iter 300] loss=-0.6500 val_loss=0.0000 scale=2.0000 norm=0.8352
[iter 400] loss=-0.9458 val_loss=0.0000 scale=1.0000 norm=0.4009
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2918 val_loss=0.0000 scale=2.0000 norm=1.0009
[iter 200] loss=-0.3410 val_loss=0.0000 scale=1.0000 norm=0.4397
[iter 300] loss=-0.8617 val_loss=0.0000 scale=1.0000 norm=0.4005
[iter 400] loss=-1.2029 val_loss=0.0000 scale=1.0000 norm=0.3823
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2947 val_loss=0.0000 scale=2.0000 norm=1.0202
[iter 200] loss=-0.3775 val_loss=0.0000 scale=1.0000 norm=0.4324
[iter 300] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.7496
[iter 400] loss=-1.2584 val_loss=0.0000 scale=2.0000 norm=0.6841
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1849 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 200] loss=-0.6423 val_loss=0.0000 scale=2.0000 norm=0.8765
[iter 300] loss=-1.3517 val_loss=0.0000 scale=2.0000 norm=0.7709
[iter 400] loss=-1.8834 val_loss=0.0000 scale=2.0000 norm=0.7129
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1459 val_loss=0.0000 scale=2.0000 norm=0.9922
[iter 200] loss=-0.8550 val_loss=0.0000 scale=4.0000 norm=1.9724
[iter 300] loss=-2.3651 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 400] loss=-4.0255 val_loss=0.0000 scale=4.0000 norm=1.9777
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2377 val_loss=0.0000 scale=2.0000 norm=0.9962
[iter 200] loss=-0.4670 val_loss=0.0000 scale=1.0000 norm=0.4321
[iter 300] loss=-0.9094 val_loss=0.0000 scale=1.0000 norm=0.3972
[iter 400] loss=-1.1922 val_loss=0.0000 scale=2.0000 norm=0.7537
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1989 val_loss=0.0000 scale=2.0000 norm=0.9811
[iter 200] loss=-0.7871 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 300] loss=-1.7701 val_loss=0.0000 scale=2.0000 norm=0.9822
[iter 400] loss=-2.9153 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4048 val_loss=0.0000 scale=1.0000 norm=0.5360
[iter 200] loss=-0.0922 val_loss=0.0000 scale=1.0000 norm=0.4609
[iter 300] loss=-0.4720 val_loss=0.0000 scale=1.0000 norm=0.4129
[iter 400] loss=-0.7719 val_loss=0.0000 scale=1.0000 norm=0.3810
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5691 val_loss=0.0000 scale=1.0000 norm=0.5792
[iter 200] loss=-0.0434 val_loss=0.0000 scale=2.0000 norm=0.9524
[iter 300] loss=-0.6598 val_loss=0.0000 scale=2.0000 norm=0.8359
[iter 400] loss=-1.0168 val_loss=0.0000 scale=1.0000 norm=0.3941
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4279 val_loss=0.0000 scale=2.0000 norm=1.0708
[iter 200] loss=-0.1047 val_loss=0.0000 scale=1.0000 norm=0.4673
[iter 300] loss=-0.5244 val_loss=0.0000 scale=2.0000 norm=0.8429
[iter 400] loss=-0.8841 val_loss=0.0000 scale=1.0000 norm=0.3914
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2241 val_loss=0.0000 scale=2.0000 norm=0.9728
[iter 200] loss=-0.7407 val_loss=0.0000 scale=2.0000 norm=0.9573
[iter 300] loss=-1.6618 val_loss=0.0000 scale=2.0000 norm=0.9200
[iter 400] loss=-2.6667 val_loss=0.0000 scale=2.0000 norm=0.8714
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7899 val_loss=0.0000 scale=1.0000 norm=0.6087
[iter 200] loss=0.1970 val_loss=0.0000 scale=2.0000 norm=0.9511
[iter 300] loss=-0.2890 val_loss=0.0000 scale=2.0000 norm=0.8511
[iter 400] loss=-0.7656 val_loss=0.0000 scale=1.0000 norm=0.4037
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2921 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.3001 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 300] loss=-0.7052 val_loss=0.0000 scale=1.0000 norm=0.4191
[iter 400] loss=-1.0554 val_loss=0.0000 scale=1.0000 norm=0.4041
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1085 val_loss=0.0000 scale=2.0000 norm=0.9823
[iter 200] loss=-0.8370 val_loss=0.0000 scale=2.0000 norm=0.9461
[iter 300] loss=-1.7299 val_loss=0.0000 scale=2.0000 norm=0.8885
[iter 400] loss=-2.5246 val_loss=0.0000 scale=1.0000 norm=0.4060
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1450 val_loss=0.0000 scale=2.0000 norm=0.9996
[iter 200] loss=-0.8429 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-2.3452 val_loss=0.0000 scale=4.0000 norm=1.9717
[iter 400] loss=-3.7202 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3172 val_loss=0.0000 scale=2.0000 norm=1.0380
[iter 200] loss=-0.2532 val_loss=0.0000 scale=2.0000 norm=0.9172
[iter 300] loss=-0.6163 val_loss=0.0000 scale=1.0000 norm=0.4208
[iter 400] loss=-0.9140 val_loss=0.0000 scale=1.0000 norm=0.3903
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2654 val_loss=0.0000 scale=2.0000 norm=1.0313
[iter 200] loss=-0.2291 val_loss=0.0000 scale=2.0000 norm=0.9215
[iter 300] loss=-0.6617 val_loss=0.0000 scale=1.0000 norm=0.4252
[iter 400] loss=-0.9381 val_loss=0.0000 scale=2.0000 norm=0.8029
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3972 val_loss=0.0000 scale=1.0000 norm=0.5283
[iter 200] loss=-0.0214 val_loss=0.0000 scale=1.0000 norm=0.4818
[iter 300] loss=-0.3743 val_loss=0.0000 scale=2.0000 norm=0.8810
[iter 400] loss=-0.6729 val_loss=0.0000 scale=1.0000 norm=0.4128
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2058 val_loss=0.0000 scale=2.0000 norm=1.0029
[iter 200] loss=-0.6460 val_loss=0.0000 scale=2.0000 norm=0.8941
[iter 300] loss=-1.2181 val_loss=0.0000 scale=1.0000 norm=0.4076
[iter 400] loss=-1.6592 val_loss=0.0000 scale=2.0000 norm=0.7039
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3060 val_loss=0.0000 scale=2.0000 norm=1.0052
[iter 200] loss=-0.3452 val_loss=0.0000 scale=1.0000 norm=0.4410
[iter 300] loss=-0.7980 val_loss=0.0000 scale=1.0000 norm=0.3966
[iter 400] loss=-1.0992 val_loss=0.0000 scale=1.0000 norm=0.3756
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1771 val_loss=0.0000 scale=2.0000 norm=1.0052
[iter 200] loss=-0.6849 val_loss=0.0000 scale=2.0000 norm=0.8989
[iter 300] loss=-1.4679 val_loss=0.0000 scale=1.0000 norm=0.4062
[iter 400] loss=-1.9525 val_loss=0.0000 scale=1.0000 norm=0.3906
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4134 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 200] loss=-0.1442 val_loss=0.0000 scale=2.0000 norm=0.9240
[iter 300] loss=-0.5732 val_loss=0.0000 scale=1.0000 norm=0.4268
[iter 400] loss=-0.9175 val_loss=0.0000 scale=1.0000 norm=0.4190
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2138 val_loss=0.0000 scale=2.0000 norm=0.9753
[iter 200] loss=-0.7268 val_loss=0.0000 scale=2.0000 norm=0.9374
[iter 300] loss=-1.6204 val_loss=0.0000 scale=2.0000 norm=0.8893
[iter 400] loss=-2.4068 val_loss=0.0000 scale=2.0000 norm=0.7840
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5076 val_loss=0.0000 scale=1.0000 norm=0.5436
[iter 200] loss=-0.1224 val_loss=0.0000 scale=2.0000 norm=0.9085
[iter 300] loss=-0.6969 val_loss=0.0000 scale=1.0000 norm=0.3920
[iter 400] loss=-1.0427 val_loss=0.0000 scale=1.0000 norm=0.3745
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1410 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.7524 val_loss=0.0000 scale=2.0000 norm=0.9081
[iter 300] loss=-1.5817 val_loss=0.0000 scale=2.0000 norm=0.8406
[iter 400] loss=-2.2914 val_loss=0.0000 scale=2.0000 norm=0.7992
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3229 val_loss=0.0000 scale=1.0000 norm=0.5180
[iter 200] loss=-0.2293 val_loss=0.0000 scale=1.0000 norm=0.4581
[iter 300] loss=-0.6578 val_loss=0.0000 scale=2.0000 norm=0.8576
[iter 400] loss=-0.9756 val_loss=0.0000 scale=1.0000 norm=0.4207
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3385 val_loss=0.0000 scale=2.0000 norm=1.0289
[iter 200] loss=-0.3037 val_loss=0.0000 scale=2.0000 norm=0.8953
[iter 300] loss=-0.8145 val_loss=0.0000 scale=2.0000 norm=0.7971
[iter 400] loss=-1.1819 val_loss=0.0000 scale=1.0000 norm=0.3687
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2634 val_loss=0.0000 scale=1.0000 norm=0.5018
[iter 200] loss=-0.3636 val_loss=0.0000 scale=1.0000 norm=0.4481
[iter 300] loss=-0.7709 val_loss=0.0000 scale=1.0000 norm=0.4130
[iter 400] loss=-1.0920 val_loss=0.0000 scale=1.0000 norm=0.3969
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2479 val_loss=0.0000 scale=2.0000 norm=0.9716
[iter 200] loss=-0.7137 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 300] loss=-1.6875 val_loss=0.0000 scale=2.0000 norm=0.9752
[iter 400] loss=-2.8891 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4318 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 200] loss=-0.4095 val_loss=0.0000 scale=2.0000 norm=0.8874
[iter 300] loss=-1.1569 val_loss=0.0000 scale=2.0000 norm=0.8162
[iter 400] loss=-1.6806 val_loss=0.0000 scale=1.0000 norm=0.3956
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1976 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 200] loss=-0.5788 val_loss=0.0000 scale=2.0000 norm=0.8561
[iter 300] loss=-1.1529 val_loss=0.0000 scale=1.0000 norm=0.3836
[iter 400] loss=-1.5389 val_loss=0.0000 scale=1.0000 norm=0.3430
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1877 val_loss=0.0000 scale=2.0000 norm=0.9862
[iter 200] loss=-0.6992 val_loss=0.0000 scale=2.0000 norm=0.9033
[iter 300] loss=-1.5052 val_loss=0.0000 scale=2.0000 norm=0.8095
[iter 400] loss=-2.1104 val_loss=0.0000 scale=2.0000 norm=0.6794
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2574 val_loss=0.0000 scale=2.0000 norm=1.0111
[iter 200] loss=-0.3490 val_loss=0.0000 scale=2.0000 norm=0.8959
[iter 300] loss=-0.8529 val_loss=0.0000 scale=2.0000 norm=0.8139
[iter 400] loss=-1.1565 val_loss=0.0000 scale=1.0000 norm=0.3942
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1947 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 200] loss=-0.7912 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 300] loss=-1.9577 val_loss=0.0000 scale=4.0000 norm=1.9615
[iter 400] loss=-3.4034 val_loss=0.0000 scale=4.0000 norm=1.9802
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4822 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.1719 val_loss=0.0000 scale=2.0000 norm=0.9075
[iter 300] loss=-0.6114 val_loss=0.0000 scale=1.0000 norm=0.4130
[iter 400] loss=-0.9930 val_loss=0.0000 scale=1.0000 norm=0.3829
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3243 val_loss=0.0000 scale=1.0000 norm=0.5129
[iter 200] loss=-0.1134 val_loss=0.0000 scale=1.0000 norm=0.4561
[iter 300] loss=-0.5390 val_loss=0.0000 scale=2.0000 norm=0.8325
[iter 400] loss=-0.8544 val_loss=0.0000 scale=1.0000 norm=0.3924
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2902 val_loss=0.0000 scale=2.0000 norm=1.0192
[iter 200] loss=-0.3192 val_loss=0.0000 scale=1.0000 norm=0.4542
[iter 300] loss=-0.7095 val_loss=0.0000 scale=2.0000 norm=0.8233
[iter 400] loss=-1.0052 val_loss=0.0000 scale=1.0000 norm=0.4003
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3364 val_loss=0.0000 scale=2.0000 norm=1.0387
[iter 200] loss=-0.2252 val_loss=0.0000 scale=1.0000 norm=0.4517
[iter 300] loss=-0.6112 val_loss=0.0000 scale=2.0000 norm=0.8226
[iter 400] loss=-0.8399 val_loss=0.0000 scale=1.0000 norm=0.3986
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3245 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2933 val_loss=0.0000 scale=2.0000 norm=0.8857
[iter 300] loss=-0.6855 val_loss=0.0000 scale=1.0000 norm=0.4070
[iter 400] loss=-0.9472 val_loss=0.0000 scale=1.0000 norm=0.3895
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4074 val_loss=0.0000 scale=2.0000 norm=1.0463
[iter 200] loss=-0.2968 val_loss=0.0000 scale=2.0000 norm=0.8909
[iter 300] loss=-0.8110 val_loss=0.0000 scale=2.0000 norm=0.7443
[iter 400] loss=-1.0726 val_loss=0.0000 scale=1.0000 norm=0.3344
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2905 val_loss=0.0000 scale=2.0000 norm=1.0094
[iter 200] loss=-0.3738 val_loss=0.0000 scale=2.0000 norm=0.8755
[iter 300] loss=-0.8126 val_loss=0.0000 scale=2.0000 norm=0.7872
[iter 400] loss=-1.0747 val_loss=0.0000 scale=1.0000 norm=0.3701
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2684 val_loss=0.0000 scale=2.0000 norm=1.0172
[iter 200] loss=-0.3500 val_loss=0.0000 scale=2.0000 norm=0.8882
[iter 300] loss=-0.7688 val_loss=0.0000 scale=1.0000 norm=0.4063
[iter 400] loss=-1.1596 val_loss=0.0000 scale=1.0000 norm=0.3679
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4918 val_loss=0.0000 scale=2.0000 norm=1.0675
[iter 200] loss=-0.1053 val_loss=0.0000 scale=2.0000 norm=0.8974
[iter 300] loss=-0.6979 val_loss=0.0000 scale=2.0000 norm=0.7900
[iter 400] loss=-1.0977 val_loss=0.0000 scale=1.0000 norm=0.3666
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3949 val_loss=0.0000 scale=2.0000 norm=1.0621
[iter 200] loss=-0.1665 val_loss=0.0000 scale=2.0000 norm=0.9158
[iter 300] loss=-0.6137 val_loss=0.0000 scale=1.0000 norm=0.4054
[iter 400] loss=-0.9264 val_loss=0.0000 scale=1.0000 norm=0.3801
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2938 val_loss=0.0000 scale=2.0000 norm=1.0183
[iter 200] loss=-0.3802 val_loss=0.0000 scale=2.0000 norm=0.8556
[iter 300] loss=-0.7689 val_loss=0.0000 scale=1.0000 norm=0.3844
[iter 400] loss=-1.0603 val_loss=0.0000 scale=1.0000 norm=0.3567
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2351 val_loss=0.0000 scale=2.0000 norm=0.9830
[iter 200] loss=-0.5640 val_loss=0.0000 scale=2.0000 norm=0.8539
[iter 300] loss=-1.1740 val_loss=0.0000 scale=1.0000 norm=0.3726
[iter 400] loss=-1.5920 val_loss=0.0000 scale=2.0000 norm=0.6992
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2515 val_loss=0.0000 scale=2.0000 norm=0.9937
[iter 200] loss=-0.4359 val_loss=0.0000 scale=2.0000 norm=0.8923
[iter 300] loss=-0.9804 val_loss=0.0000 scale=2.0000 norm=0.7871
[iter 400] loss=-1.3027 val_loss=0.0000 scale=1.0000 norm=0.3637
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4509 val_loss=0.0000 scale=2.0000 norm=1.0616
[iter 200] loss=-0.0950 val_loss=0.0000 scale=1.0000 norm=0.4573
[iter 300] loss=-0.4798 val_loss=0.0000 scale=1.0000 norm=0.4259
[iter 400] loss=-0.7403 val_loss=0.0000 scale=2.0000 norm=0.8109
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3509 val_loss=0.0000 scale=2.0000 norm=1.0273
[iter 200] loss=-0.1784 val_loss=0.0000 scale=2.0000 norm=0.8990
[iter 300] loss=-0.5335 val_loss=0.0000 scale=1.0000 norm=0.4210
[iter 400] loss=-0.7926 val_loss=0.0000 scale=1.0000 norm=0.4043
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2403 val_loss=0.0000 scale=2.0000 norm=1.0087
[iter 200] loss=-0.3399 val_loss=0.0000 scale=1.0000 norm=0.4477
[iter 300] loss=-0.7234 val_loss=0.0000 scale=1.0000 norm=0.4118
[iter 400] loss=-1.0257 val_loss=0.0000 scale=1.0000 norm=0.3965
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3423 val_loss=0.0000 scale=2.0000 norm=1.0302
[iter 200] loss=-0.3239 val_loss=0.0000 scale=2.0000 norm=0.9045
[iter 300] loss=-0.8796 val_loss=0.0000 scale=1.0000 norm=0.3985
[iter 400] loss=-1.1637 val_loss=0.0000 scale=1.0000 norm=0.3774
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3069 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2773 val_loss=0.0000 scale=2.0000 norm=0.8891
[iter 300] loss=-0.6955 val_loss=0.0000 scale=1.0000 norm=0.4051
[iter 400] loss=-0.9951 val_loss=0.0000 scale=1.0000 norm=0.3833
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3775 val_loss=0.0000 scale=2.0000 norm=1.0288
[iter 200] loss=-0.3815 val_loss=0.0000 scale=2.0000 norm=0.8919
[iter 300] loss=-0.9953 val_loss=0.0000 scale=2.0000 norm=0.8122
[iter 400] loss=-1.3993 val_loss=0.0000 scale=1.0000 norm=0.3879
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3525 val_loss=0.0000 scale=2.0000 norm=1.0351
[iter 200] loss=-0.1101 val_loss=0.0000 scale=1.0000 norm=0.4633
[iter 300] loss=-0.4988 val_loss=0.0000 scale=1.0000 norm=0.4360
[iter 400] loss=-0.7653 val_loss=0.0000 scale=1.0000 norm=0.4202
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3302 val_loss=0.0000 scale=2.0000 norm=1.0375
[iter 200] loss=-0.3824 val_loss=0.0000 scale=2.0000 norm=0.9043
[iter 300] loss=-0.9318 val_loss=0.0000 scale=1.0000 norm=0.4028
[iter 400] loss=-1.2992 val_loss=0.0000 scale=1.0000 norm=0.3741
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4921 val_loss=0.0000 scale=2.0000 norm=1.0280
[iter 200] loss=-0.3413 val_loss=0.0000 scale=2.0000 norm=0.8915
[iter 300] loss=-1.0525 val_loss=0.0000 scale=2.0000 norm=0.7847
[iter 400] loss=-1.6279 val_loss=0.0000 scale=2.0000 norm=0.7178
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2786 val_loss=0.0000 scale=1.0000 norm=0.5093
[iter 200] loss=-0.1886 val_loss=0.0000 scale=1.0000 norm=0.4583
[iter 300] loss=-0.6289 val_loss=0.0000 scale=2.0000 norm=0.8426
[iter 400] loss=-0.9236 val_loss=0.0000 scale=1.0000 norm=0.4020
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5387 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.4141 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 300] loss=-1.3784 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 400] loss=-2.3170 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5057 val_loss=0.0000 scale=2.0000 norm=1.0561
[iter 200] loss=-0.2851 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 300] loss=-0.8569 val_loss=0.0000 scale=2.0000 norm=0.8028
[iter 400] loss=-1.2541 val_loss=0.0000 scale=1.0000 norm=0.3582
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2919 val_loss=0.0000 scale=2.0000 norm=1.0319
[iter 200] loss=-0.3282 val_loss=0.0000 scale=2.0000 norm=0.9001
[iter 300] loss=-0.7311 val_loss=0.0000 scale=1.0000 norm=0.4128
[iter 400] loss=-1.0300 val_loss=0.0000 scale=1.0000 norm=0.3919
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1221 val_loss=0.0000 scale=2.0000 norm=0.9884
[iter 200] loss=-0.7219 val_loss=0.0000 scale=2.0000 norm=0.8791
[iter 300] loss=-1.2916 val_loss=0.0000 scale=1.0000 norm=0.4004
[iter 400] loss=-1.7721 val_loss=0.0000 scale=1.0000 norm=0.3363
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3693 val_loss=0.0000 scale=2.0000 norm=0.9788
[iter 200] loss=-0.5862 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 300] loss=-1.5311 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 400] loss=-2.4801 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5001 val_loss=0.0000 scale=2.0000 norm=1.0805
[iter 200] loss=-0.1703 val_loss=0.0000 scale=2.0000 norm=0.9250
[iter 300] loss=-0.6986 val_loss=0.0000 scale=2.0000 norm=0.8530
[iter 400] loss=-1.0535 val_loss=0.0000 scale=2.0000 norm=0.8009
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3440 val_loss=0.0000 scale=2.0000 norm=1.0359
[iter 200] loss=-0.2749 val_loss=0.0000 scale=2.0000 norm=0.8916
[iter 300] loss=-0.6462 val_loss=0.0000 scale=1.0000 norm=0.4204
[iter 400] loss=-0.9029 val_loss=0.0000 scale=0.5000 norm=0.2048
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3274 val_loss=0.0000 scale=2.0000 norm=1.0452
[iter 200] loss=-0.1509 val_loss=0.0000 scale=1.0000 norm=0.4673
[iter 300] loss=-0.5470 val_loss=0.0000 scale=2.0000 norm=0.8670
[iter 400] loss=-0.8991 val_loss=0.0000 scale=2.0000 norm=0.8409
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0972 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.8449 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-1.8387 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 400] loss=-2.9335 val_loss=0.0000 scale=2.0000 norm=0.9864
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4470 val_loss=0.0000 scale=1.0000 norm=0.5315
[iter 200] loss=-0.0546 val_loss=0.0000 scale=2.0000 norm=0.9414
[iter 300] loss=-0.5564 val_loss=0.0000 scale=2.0000 norm=0.8354
[iter 400] loss=-0.9278 val_loss=0.0000 scale=1.0000 norm=0.3949
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2488 val_loss=0.0000 scale=2.0000 norm=1.0050
[iter 200] loss=-0.3674 val_loss=0.0000 scale=2.0000 norm=0.9034
[iter 300] loss=-0.8469 val_loss=0.0000 scale=1.0000 norm=0.4085
[iter 400] loss=-1.1135 val_loss=0.0000 scale=1.0000 norm=0.3856
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5674 val_loss=0.0000 scale=1.0000 norm=0.5720
[iter 200] loss=0.0995 val_loss=0.0000 scale=1.0000 norm=0.4960
[iter 300] loss=-0.1917 val_loss=0.0000 scale=1.0000 norm=0.4559
[iter 400] loss=-0.4524 val_loss=0.0000 scale=1.0000 norm=0.4232
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3710 val_loss=0.0000 scale=1.0000 norm=0.5251
[iter 200] loss=-0.1487 val_loss=0.0000 scale=2.0000 norm=0.9147
[iter 300] loss=-0.5048 val_loss=0.0000 scale=1.0000 norm=0.4186
[iter 400] loss=-0.7770 val_loss=0.0000 scale=1.0000 norm=0.3967
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3116 val_loss=0.0000 scale=2.0000 norm=1.0257
[iter 200] loss=-0.2730 val_loss=0.0000 scale=2.0000 norm=0.8903
[iter 300] loss=-0.6048 val_loss=0.0000 scale=1.0000 norm=0.4115
[iter 400] loss=-0.8559 val_loss=0.0000 scale=0.5000 norm=0.2000
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2907 val_loss=0.0000 scale=2.0000 norm=1.0101
[iter 200] loss=-0.3801 val_loss=0.0000 scale=2.0000 norm=0.8691
[iter 300] loss=-0.8370 val_loss=0.0000 scale=0.5000 norm=0.1970
[iter 400] loss=-1.0961 val_loss=0.0000 scale=2.0000 norm=0.7403
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2798 val_loss=0.0000 scale=2.0000 norm=1.0066
[iter 200] loss=-0.3402 val_loss=0.0000 scale=1.0000 norm=0.4408
[iter 300] loss=-0.7379 val_loss=0.0000 scale=2.0000 norm=0.8098
[iter 400] loss=-1.0264 val_loss=0.0000 scale=1.0000 norm=0.3980
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3135 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.1839 val_loss=0.0000 scale=1.0000 norm=0.4659
[iter 300] loss=-0.6081 val_loss=0.0000 scale=2.0000 norm=0.8544
[iter 400] loss=-0.9099 val_loss=0.0000 scale=1.0000 norm=0.3994
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3945 val_loss=0.0000 scale=2.0000 norm=1.0671
[iter 200] loss=-0.1816 val_loss=0.0000 scale=1.0000 norm=0.4552
[iter 300] loss=-0.5035 val_loss=0.0000 scale=2.0000 norm=0.8367
[iter 400] loss=-0.7662 val_loss=0.0000 scale=1.0000 norm=0.3963
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2612 val_loss=0.0000 scale=2.0000 norm=0.9531
[iter 200] loss=-0.6809 val_loss=0.0000 scale=2.0000 norm=0.9436
[iter 300] loss=-1.6199 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-2.5472 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3841 val_loss=0.0000 scale=2.0000 norm=1.0619
[iter 200] loss=-0.2261 val_loss=0.0000 scale=2.0000 norm=0.9057
[iter 300] loss=-0.5794 val_loss=0.0000 scale=1.0000 norm=0.4202
[iter 400] loss=-0.8910 val_loss=0.0000 scale=1.0000 norm=0.3985
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3107 val_loss=0.0000 scale=2.0000 norm=1.0231
[iter 200] loss=-0.3273 val_loss=0.0000 scale=1.0000 norm=0.4539
[iter 300] loss=-0.7077 val_loss=0.0000 scale=1.0000 norm=0.4261
[iter 400] loss=-0.9964 val_loss=0.0000 scale=0.5000 norm=0.2061
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1303 val_loss=0.0000 scale=2.0000 norm=0.9725
[iter 200] loss=-0.7262 val_loss=0.0000 scale=2.0000 norm=0.8716
[iter 300] loss=-1.4653 val_loss=0.0000 scale=2.0000 norm=0.7604
[iter 400] loss=-1.9838 val_loss=0.0000 scale=1.0000 norm=0.3376
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2905 val_loss=0.0000 scale=1.0000 norm=0.5073
[iter 200] loss=-0.3056 val_loss=0.0000 scale=2.0000 norm=0.8955
[iter 300] loss=-0.7226 val_loss=0.0000 scale=2.0000 norm=0.8230
[iter 400] loss=-1.0411 val_loss=0.0000 scale=1.0000 norm=0.4038
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2859 val_loss=0.0000 scale=2.0000 norm=1.0218
[iter 200] loss=-0.2507 val_loss=0.0000 scale=2.0000 norm=0.9023
[iter 300] loss=-0.6598 val_loss=0.0000 scale=1.0000 norm=0.4321
[iter 400] loss=-0.9906 val_loss=0.0000 scale=1.0000 norm=0.4228
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2346 val_loss=0.0000 scale=2.0000 norm=0.9781
[iter 200] loss=-0.6004 val_loss=0.0000 scale=2.0000 norm=0.8724
[iter 300] loss=-1.3296 val_loss=0.0000 scale=1.0000 norm=0.4001
[iter 400] loss=-1.9309 val_loss=0.0000 scale=1.0000 norm=0.3740
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3863 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 200] loss=-0.1264 val_loss=0.0000 scale=1.0000 norm=0.4597
[iter 300] loss=-0.5451 val_loss=0.0000 scale=1.0000 norm=0.4147
[iter 400] loss=-0.8770 val_loss=0.0000 scale=1.0000 norm=0.3968
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2661 val_loss=0.0000 scale=2.0000 norm=1.0065
[iter 200] loss=-0.3053 val_loss=0.0000 scale=1.0000 norm=0.4497
[iter 300] loss=-0.6973 val_loss=0.0000 scale=2.0000 norm=0.8380
[iter 400] loss=-0.9904 val_loss=0.0000 scale=1.0000 norm=0.4075
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2437 val_loss=0.0000 scale=2.0000 norm=0.9792
[iter 200] loss=-0.7503 val_loss=0.0000 scale=2.0000 norm=0.9853
[iter 300] loss=-2.1993 val_loss=0.0000 scale=4.0000 norm=1.9752
[iter 400] loss=-4.1738 val_loss=0.0000 scale=4.0000 norm=1.9680
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2159 val_loss=0.0000 scale=2.0000 norm=0.9941
[iter 200] loss=-0.5773 val_loss=0.0000 scale=1.0000 norm=0.4365
[iter 300] loss=-1.0653 val_loss=0.0000 scale=2.0000 norm=0.7898
[iter 400] loss=-1.4076 val_loss=0.0000 scale=1.0000 norm=0.3810
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2682 val_loss=0.0000 scale=2.0000 norm=1.0009
[iter 200] loss=-0.3230 val_loss=0.0000 scale=2.0000 norm=0.8895
[iter 300] loss=-0.6849 val_loss=0.0000 scale=1.0000 norm=0.4117
[iter 400] loss=-0.9781 val_loss=0.0000 scale=1.0000 norm=0.3869
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1426 val_loss=0.0000 scale=2.0000 norm=0.9859
[iter 200] loss=-0.7708 val_loss=0.0000 scale=2.0000 norm=0.9168
[iter 300] loss=-1.5753 val_loss=0.0000 scale=2.0000 norm=0.8083
[iter 400] loss=-2.2093 val_loss=0.0000 scale=1.0000 norm=0.3684
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4172 val_loss=0.0000 scale=2.0000 norm=1.0625
[iter 200] loss=-0.1314 val_loss=0.0000 scale=2.0000 norm=0.9178
[iter 300] loss=-0.5293 val_loss=0.0000 scale=1.0000 norm=0.4295
[iter 400] loss=-0.7980 val_loss=0.0000 scale=1.0000 norm=0.4158
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3449 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 200] loss=-0.3033 val_loss=0.0000 scale=1.0000 norm=0.4385
[iter 300] loss=-0.6977 val_loss=0.0000 scale=1.0000 norm=0.4029
[iter 400] loss=-1.0207 val_loss=0.0000 scale=1.0000 norm=0.3733
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3275 val_loss=0.0000 scale=2.0000 norm=1.0590
[iter 200] loss=-0.1893 val_loss=0.0000 scale=2.0000 norm=0.9330
[iter 300] loss=-0.5907 val_loss=0.0000 scale=1.0000 norm=0.4303
[iter 400] loss=-0.8894 val_loss=0.0000 scale=1.0000 norm=0.4169
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1752 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.8281 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-2.7237 val_loss=0.0000 scale=4.0000 norm=1.9876
[iter 400] loss=-4.5911 val_loss=0.0000 scale=2.0000 norm=0.9841
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2776 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 200] loss=-0.3785 val_loss=0.0000 scale=2.0000 norm=0.8826
[iter 300] loss=-0.8225 val_loss=0.0000 scale=1.0000 norm=0.4078
[iter 400] loss=-1.1034 val_loss=0.0000 scale=1.0000 norm=0.3820
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3161 val_loss=0.0000 scale=2.0000 norm=1.0174
[iter 200] loss=-0.3630 val_loss=0.0000 scale=1.0000 norm=0.4295
[iter 300] loss=-0.8337 val_loss=0.0000 scale=1.0000 norm=0.3995
[iter 400] loss=-1.1003 val_loss=0.0000 scale=1.0000 norm=0.3682
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2966 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 200] loss=-0.5849 val_loss=0.0000 scale=2.0000 norm=0.9056
[iter 300] loss=-1.3332 val_loss=0.0000 scale=2.0000 norm=0.8304
[iter 400] loss=-1.9301 val_loss=0.0000 scale=1.0000 norm=0.3792
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2682 val_loss=0.0000 scale=1.0000 norm=0.5036
[iter 200] loss=-0.3660 val_loss=0.0000 scale=2.0000 norm=0.9052
[iter 300] loss=-0.9086 val_loss=0.0000 scale=2.0000 norm=0.8078
[iter 400] loss=-1.2596 val_loss=0.0000 scale=1.0000 norm=0.3760
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2641 val_loss=0.0000 scale=2.0000 norm=1.0036
[iter 200] loss=-0.4461 val_loss=0.0000 scale=1.0000 norm=0.4560
[iter 300] loss=-0.8669 val_loss=0.0000 scale=1.0000 norm=0.4165
[iter 400] loss=-1.1590 val_loss=0.0000 scale=1.0000 norm=0.3770
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2405 val_loss=0.0000 scale=2.0000 norm=0.9784
[iter 200] loss=-0.7571 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 300] loss=-2.6002 val_loss=0.0000 scale=4.0000 norm=1.9919
[iter 400] loss=-4.5856 val_loss=0.0000 scale=4.0000 norm=1.9809
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3863 val_loss=0.0000 scale=2.0000 norm=1.0515
[iter 200] loss=-0.0879 val_loss=0.0000 scale=1.0000 norm=0.4565
[iter 300] loss=-0.4165 val_loss=0.0000 scale=1.0000 norm=0.4246
[iter 400] loss=-0.7694 val_loss=0.0000 scale=2.0000 norm=0.8014
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2549 val_loss=0.0000 scale=1.0000 norm=0.4998
[iter 200] loss=-0.3470 val_loss=0.0000 scale=1.0000 norm=0.4391
[iter 300] loss=-0.7719 val_loss=0.0000 scale=1.0000 norm=0.4040
[iter 400] loss=-1.0302 val_loss=0.0000 scale=1.0000 norm=0.3909

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n03>
Subject: Job 856543: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:36 2024
Job was executed on host(s) <4*c207n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:38 2024
                            <4*c207n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:11:38 2024
Terminated at Wed Oct 23 12:54:29 2024
Results reported at Wed Oct 23 12:54:29 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "RRU Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4660.33 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.39 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   2591 sec.
    Turnaround time :                            2573 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009926630968289543), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1949), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009984937680321783), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1996), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009730469951536886), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1987), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006991692945397764), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000981064472965474), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1945), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009211849839728791), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1989), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009819552909709406), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1931), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009942366255666852), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1966), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000982099586876546), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1995), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009984804295696643), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1995), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000987817189277156), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1998), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000848351705080768), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009920009697771928), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1985), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009009709136377458), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1976), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000996865050113866), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1971), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009929490136240285), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1944), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000977361368058278), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1987), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009875538871215834), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1998), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Monomer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c009n01>
Subject: Job 856539: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:11 2024
Job was executed on host(s) <4*c009n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:12 2024
                            <4*c010n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:11:12 2024
Terminated at Wed Oct 23 21:25:15 2024
Results reported at Wed Oct 23 21:25:15 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   139025.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.48 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               60.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   33256 sec.
    Turnaround time :                            33244 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009984937680321783), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1996), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009663307726610637), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1968), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 423), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009995295625309598), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1977), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009984804295696643), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1995), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009816387557166119), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1986), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000987817189277156), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1998), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008957197954137927), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1831), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009711780287675553), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1966), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1837), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009657444026693352), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1993), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009657444026693352), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1993), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000897908160058731), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009892670376043151), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1987), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009875538871215834), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1998), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Dimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizability_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c005n01>
Subject: Job 856540: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:19 2024
Job was executed on host(s) <4*c005n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 23 12:11:21 2024
                            <4*c003n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Wed Oct 23 12:11:21 2024
Terminated at Wed Oct 23 21:27:12 2024
Results reported at Wed Oct 23 21:27:12 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 5:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   141119.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.53 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               60.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   33355 sec.
    Turnaround time :                            33353 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizability_NGB_wo_hypo.err> for stderr output of this job.

