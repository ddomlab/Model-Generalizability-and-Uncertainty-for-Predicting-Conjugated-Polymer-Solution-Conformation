polymer representation: Monomer
polymer representation: Dimer
polymer representation: Trimer
polymer representation: RRU Monomer
Monomer_scaler
Filename: (ECFP3.binary.512-Mw-PDI)_NGB_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer_scaler/(ECFP3.binary.512-Mw-PDI)_NGB_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3261 val_loss=0.0000 scale=2.0000 norm=1.0322
[iter 200] loss=-0.3063 val_loss=0.0000 scale=2.0000 norm=0.9681
[iter 300] loss=-0.7784 val_loss=0.0000 scale=2.0000 norm=0.9258
[iter 400] loss=-1.0922 val_loss=0.0000 scale=1.0000 norm=0.4456
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2592 val_loss=0.0000 scale=2.0000 norm=1.0134
[iter 200] loss=-0.4462 val_loss=0.0000 scale=2.0000 norm=0.9475
[iter 300] loss=-1.0599 val_loss=0.0000 scale=2.0000 norm=0.8888
[iter 400] loss=-1.5712 val_loss=0.0000 scale=2.0000 norm=0.8338
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3971 val_loss=0.0000 scale=2.0000 norm=1.0674
[iter 200] loss=-0.1758 val_loss=0.0000 scale=2.0000 norm=0.9553
[iter 300] loss=-0.5239 val_loss=0.0000 scale=2.0000 norm=0.8961
[iter 400] loss=-0.7616 val_loss=0.0000 scale=1.0000 norm=0.4402
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3711 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.2680 val_loss=0.0000 scale=2.0000 norm=0.9681
[iter 300] loss=-0.7729 val_loss=0.0000 scale=2.0000 norm=0.9229
[iter 400] loss=-1.1471 val_loss=0.0000 scale=2.0000 norm=0.8869
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3898 val_loss=0.0000 scale=2.0000 norm=1.0962
[iter 200] loss=-0.3554 val_loss=0.0000 scale=2.0000 norm=0.9940
[iter 300] loss=-0.9944 val_loss=0.0000 scale=2.0000 norm=0.9475
[iter 400] loss=-1.5590 val_loss=0.0000 scale=2.0000 norm=0.8985
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4540 val_loss=0.0000 scale=2.0000 norm=1.1081
[iter 200] loss=-0.0693 val_loss=0.0000 scale=2.0000 norm=1.0296
[iter 300] loss=-0.4051 val_loss=0.0000 scale=1.0000 norm=0.4947
[iter 400] loss=-0.6317 val_loss=0.0000 scale=1.0000 norm=0.4834
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3583 val_loss=0.0000 scale=2.0000 norm=1.0431
[iter 200] loss=-0.1917 val_loss=0.0000 scale=2.0000 norm=0.9521
[iter 300] loss=-0.5183 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 400] loss=-0.7796 val_loss=0.0000 scale=1.0000 norm=0.4567
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5992 val_loss=0.0000 scale=2.0000 norm=1.0908
[iter 200] loss=-0.0541 val_loss=0.0000 scale=2.0000 norm=1.0207
[iter 300] loss=-0.6050 val_loss=0.0000 scale=2.0000 norm=0.9841
[iter 400] loss=-1.0349 val_loss=0.0000 scale=1.0000 norm=0.4737
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2685 val_loss=0.0000 scale=2.0000 norm=0.9881
[iter 200] loss=-0.3712 val_loss=0.0000 scale=2.0000 norm=0.9216
[iter 300] loss=-0.8208 val_loss=0.0000 scale=2.0000 norm=0.9333
[iter 400] loss=-1.1128 val_loss=0.0000 scale=2.0000 norm=0.8921
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3992 val_loss=0.0000 scale=2.0000 norm=1.0685
[iter 200] loss=-0.2082 val_loss=0.0000 scale=2.0000 norm=0.9386
[iter 300] loss=-0.6521 val_loss=0.0000 scale=1.0000 norm=0.4460
[iter 400] loss=-0.9376 val_loss=0.0000 scale=1.0000 norm=0.4192
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3117 val_loss=0.0000 scale=2.0000 norm=0.9621
[iter 200] loss=-0.5509 val_loss=0.0000 scale=2.0000 norm=0.8814
[iter 300] loss=-1.3612 val_loss=0.0000 scale=2.0000 norm=0.8337
[iter 400] loss=-2.0911 val_loss=0.0000 scale=2.0000 norm=0.8087
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4862 val_loss=0.0000 scale=2.0000 norm=1.1523
[iter 200] loss=-0.0418 val_loss=0.0000 scale=2.0000 norm=1.0500
[iter 300] loss=-0.4496 val_loss=0.0000 scale=2.0000 norm=0.9978
[iter 400] loss=-0.7287 val_loss=0.0000 scale=0.5000 norm=0.2417
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3646 val_loss=0.0000 scale=2.0000 norm=1.0517
[iter 200] loss=-0.2372 val_loss=0.0000 scale=2.0000 norm=0.9296
[iter 300] loss=-0.6311 val_loss=0.0000 scale=2.0000 norm=0.8986
[iter 400] loss=-0.8655 val_loss=0.0000 scale=2.0000 norm=0.8931
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3142 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 200] loss=-0.4301 val_loss=0.0000 scale=2.0000 norm=0.9064
[iter 300] loss=-1.0883 val_loss=0.0000 scale=2.0000 norm=0.8706
[iter 400] loss=-1.6647 val_loss=0.0000 scale=2.0000 norm=0.8834
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4304 val_loss=0.0000 scale=2.0000 norm=1.0852
[iter 200] loss=-0.0695 val_loss=0.0000 scale=2.0000 norm=0.9607
[iter 300] loss=-0.4111 val_loss=0.0000 scale=2.0000 norm=0.9210
[iter 400] loss=-0.6783 val_loss=0.0000 scale=2.0000 norm=0.8871
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6876 val_loss=0.0000 scale=2.0000 norm=1.1424
[iter 200] loss=-0.0225 val_loss=0.0000 scale=2.0000 norm=0.8900
[iter 300] loss=-0.6337 val_loss=0.0000 scale=2.0000 norm=0.7876
[iter 400] loss=-1.0837 val_loss=0.0000 scale=2.0000 norm=0.7951
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1058 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.8629 val_loss=0.0000 scale=2.0000 norm=0.9692
[iter 300] loss=-1.8256 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 400] loss=-2.7387 val_loss=0.0000 scale=2.0000 norm=0.9102
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3509 val_loss=0.0000 scale=2.0000 norm=1.0494
[iter 200] loss=-0.2952 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 300] loss=-0.7287 val_loss=0.0000 scale=2.0000 norm=0.8752
[iter 400] loss=-1.0485 val_loss=0.0000 scale=1.0000 norm=0.4157
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1916 val_loss=0.0000 scale=2.0000 norm=1.0227
[iter 200] loss=-0.6303 val_loss=0.0000 scale=2.0000 norm=0.9590
[iter 300] loss=-1.3581 val_loss=0.0000 scale=2.0000 norm=0.9082
[iter 400] loss=-1.9980 val_loss=0.0000 scale=2.0000 norm=0.8825
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2230 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 200] loss=-0.6284 val_loss=0.0000 scale=4.0000 norm=2.0476
[iter 300] loss=-1.6524 val_loss=0.0000 scale=4.0000 norm=1.9398
[iter 400] loss=-2.5362 val_loss=0.0000 scale=2.0000 norm=0.9120
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4203 val_loss=0.0000 scale=2.0000 norm=1.0308
[iter 200] loss=-0.3770 val_loss=0.0000 scale=2.0000 norm=0.9220
[iter 300] loss=-1.0783 val_loss=0.0000 scale=2.0000 norm=0.8990
[iter 400] loss=-1.7090 val_loss=0.0000 scale=2.0000 norm=0.8666
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4626 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.1399 val_loss=0.0000 scale=2.0000 norm=0.9959
[iter 300] loss=-0.5462 val_loss=0.0000 scale=2.0000 norm=0.9401
[iter 400] loss=-0.7956 val_loss=0.0000 scale=1.0000 norm=0.4664
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6167 val_loss=0.0000 scale=2.0000 norm=1.1465
[iter 200] loss=-0.0058 val_loss=0.0000 scale=2.0000 norm=1.0298
[iter 300] loss=-0.5064 val_loss=0.0000 scale=2.0000 norm=1.0040
[iter 400] loss=-0.8854 val_loss=0.0000 scale=1.0000 norm=0.4966
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3104 val_loss=0.0000 scale=2.0000 norm=1.0132
[iter 200] loss=-0.3337 val_loss=0.0000 scale=2.0000 norm=0.9404
[iter 300] loss=-0.7826 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 400] loss=-1.0596 val_loss=0.0000 scale=2.0000 norm=0.9058
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3640 val_loss=0.0000 scale=2.0000 norm=1.0391
[iter 200] loss=-0.2204 val_loss=0.0000 scale=2.0000 norm=0.9275
[iter 300] loss=-0.5895 val_loss=0.0000 scale=2.0000 norm=0.8948
[iter 400] loss=-0.8372 val_loss=0.0000 scale=2.0000 norm=0.8814
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.1565
[iter 200] loss=-0.4137 val_loss=0.0000 scale=2.0000 norm=1.1430
[iter 300] loss=-1.2506 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 400] loss=-2.3595 val_loss=0.0000 scale=4.0000 norm=2.3123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2715 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.4553 val_loss=0.0000 scale=2.0000 norm=0.9226
[iter 300] loss=-1.0203 val_loss=0.0000 scale=2.0000 norm=0.8527
[iter 400] loss=-1.3746 val_loss=0.0000 scale=2.0000 norm=0.8310
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3828 val_loss=0.0000 scale=2.0000 norm=1.0546
[iter 200] loss=-0.1640 val_loss=0.0000 scale=2.0000 norm=0.9699
[iter 300] loss=-0.6062 val_loss=0.0000 scale=2.0000 norm=0.9359
[iter 400] loss=-0.9257 val_loss=0.0000 scale=2.0000 norm=0.9495
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5758 val_loss=0.0000 scale=2.0000 norm=1.1638
[iter 200] loss=0.0602 val_loss=0.0000 scale=2.0000 norm=0.9936
[iter 300] loss=-0.2284 val_loss=0.0000 scale=1.0000 norm=0.4756
[iter 400] loss=-0.4515 val_loss=0.0000 scale=1.0000 norm=0.4644
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4067 val_loss=0.0000 scale=2.0000 norm=1.0747
[iter 200] loss=-0.1435 val_loss=0.0000 scale=2.0000 norm=1.0057
[iter 300] loss=-0.5918 val_loss=0.0000 scale=2.0000 norm=0.9660
[iter 400] loss=-0.8990 val_loss=0.0000 scale=1.0000 norm=0.4685
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2890 val_loss=0.0000 scale=2.0000 norm=1.0202
[iter 200] loss=-0.4544 val_loss=0.0000 scale=2.0000 norm=0.9442
[iter 300] loss=-1.0786 val_loss=0.0000 scale=2.0000 norm=0.8940
[iter 400] loss=-1.5396 val_loss=0.0000 scale=2.0000 norm=0.8752
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3755 val_loss=0.0000 scale=2.0000 norm=1.0455
[iter 200] loss=-0.2024 val_loss=0.0000 scale=2.0000 norm=0.9553
[iter 300] loss=-0.6070 val_loss=0.0000 scale=2.0000 norm=0.9289
[iter 400] loss=-0.8425 val_loss=0.0000 scale=2.0000 norm=0.9055
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4393 val_loss=0.0000 scale=2.0000 norm=1.0923
[iter 200] loss=-0.0775 val_loss=0.0000 scale=2.0000 norm=0.9739
[iter 300] loss=-0.4517 val_loss=0.0000 scale=2.0000 norm=0.9279
[iter 400] loss=-0.7250 val_loss=0.0000 scale=2.0000 norm=0.9015
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5616 val_loss=0.0000 scale=2.0000 norm=1.1687
[iter 200] loss=-0.0767 val_loss=0.0000 scale=2.0000 norm=1.0979
[iter 300] loss=-0.5348 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 400] loss=-0.8779 val_loss=0.0000 scale=0.5000 norm=0.2593
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3373 val_loss=0.0000 scale=2.0000 norm=1.0422
[iter 200] loss=-0.2651 val_loss=0.0000 scale=2.0000 norm=0.9548
[iter 300] loss=-0.6780 val_loss=0.0000 scale=1.0000 norm=0.4737
[iter 400] loss=-0.9648 val_loss=0.0000 scale=2.0000 norm=0.9050
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3382 val_loss=0.0000 scale=2.0000 norm=1.0258
[iter 200] loss=-0.2709 val_loss=0.0000 scale=2.0000 norm=0.9389
[iter 300] loss=-0.6929 val_loss=0.0000 scale=2.0000 norm=0.9180
[iter 400] loss=-0.9310 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1312 val_loss=0.0000 scale=2.0000 norm=0.9935
[iter 200] loss=-0.7310 val_loss=0.0000 scale=2.0000 norm=0.9255
[iter 300] loss=-1.4748 val_loss=0.0000 scale=2.0000 norm=0.8557
[iter 400] loss=-2.0904 val_loss=0.0000 scale=2.0000 norm=0.8654
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4272 val_loss=0.0000 scale=2.0000 norm=1.0705
[iter 200] loss=-0.3924 val_loss=0.0000 scale=2.0000 norm=1.0142
[iter 300] loss=-1.0855 val_loss=0.0000 scale=2.0000 norm=0.8949
[iter 400] loss=-1.5803 val_loss=0.0000 scale=2.0000 norm=0.8458
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3792 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.2184 val_loss=0.0000 scale=2.0000 norm=0.9722
[iter 300] loss=-0.6642 val_loss=0.0000 scale=2.0000 norm=0.9496
[iter 400] loss=-0.9414 val_loss=0.0000 scale=1.0000 norm=0.4714
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3324 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.2804 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 300] loss=-0.6907 val_loss=0.0000 scale=1.0000 norm=0.4684
[iter 400] loss=-1.0081 val_loss=0.0000 scale=1.0000 norm=0.4639
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3059 val_loss=0.0000 scale=2.0000 norm=0.9509
[iter 200] loss=-0.6227 val_loss=0.0000 scale=2.0000 norm=0.9326
[iter 300] loss=-1.5116 val_loss=0.0000 scale=2.0000 norm=0.8837
[iter 400] loss=-2.2820 val_loss=0.0000 scale=2.0000 norm=0.7799
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1368 val_loss=0.0000 scale=2.0000 norm=0.9794
[iter 200] loss=-0.6878 val_loss=0.0000 scale=2.0000 norm=0.9246
[iter 300] loss=-1.3618 val_loss=0.0000 scale=2.0000 norm=0.9021
[iter 400] loss=-1.9137 val_loss=0.0000 scale=2.0000 norm=0.8797
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5294 val_loss=0.0000 scale=2.0000 norm=1.1633
[iter 200] loss=0.0125 val_loss=0.0000 scale=2.0000 norm=1.0739
[iter 300] loss=-0.3608 val_loss=0.0000 scale=1.0000 norm=0.5133
[iter 400] loss=-0.6168 val_loss=0.0000 scale=1.0000 norm=0.4965
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3737 val_loss=0.0000 scale=2.0000 norm=1.0579
[iter 200] loss=-0.2020 val_loss=0.0000 scale=2.0000 norm=0.9398
[iter 300] loss=-0.5684 val_loss=0.0000 scale=1.0000 norm=0.4499
[iter 400] loss=-0.7758 val_loss=0.0000 scale=0.5000 norm=0.2262
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2934 val_loss=0.0000 scale=2.0000 norm=1.0182
[iter 200] loss=-0.3671 val_loss=0.0000 scale=2.0000 norm=0.9577
[iter 300] loss=-0.9349 val_loss=0.0000 scale=2.0000 norm=0.9627
[iter 400] loss=-1.4091 val_loss=0.0000 scale=1.0000 norm=0.4651
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3429 val_loss=0.0000 scale=2.0000 norm=1.0640
[iter 200] loss=-0.3222 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 300] loss=-0.8598 val_loss=0.0000 scale=2.0000 norm=0.9383
[iter 400] loss=-1.1973 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5246 val_loss=0.0000 scale=2.0000 norm=1.1677
[iter 200] loss=0.0541 val_loss=0.0000 scale=1.0000 norm=0.5242
[iter 300] loss=-0.2543 val_loss=0.0000 scale=2.0000 norm=0.9688
[iter 400] loss=-0.4637 val_loss=0.0000 scale=2.0000 norm=0.9432
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3707 val_loss=0.0000 scale=2.0000 norm=1.0412
[iter 200] loss=-0.3250 val_loss=0.0000 scale=2.0000 norm=0.9681
[iter 300] loss=-0.9045 val_loss=0.0000 scale=2.0000 norm=0.9260
[iter 400] loss=-1.4096 val_loss=0.0000 scale=2.0000 norm=0.8963
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3075 val_loss=0.0000 scale=2.0000 norm=1.0408
[iter 200] loss=-0.3136 val_loss=0.0000 scale=2.0000 norm=0.9536
[iter 300] loss=-0.8219 val_loss=0.0000 scale=2.0000 norm=0.8850
[iter 400] loss=-1.1399 val_loss=0.0000 scale=2.0000 norm=0.8526
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3140 val_loss=0.0000 scale=2.0000 norm=1.0336
[iter 200] loss=-0.4246 val_loss=0.0000 scale=2.0000 norm=0.9364
[iter 300] loss=-1.0001 val_loss=0.0000 scale=2.0000 norm=0.9000
[iter 400] loss=-1.5354 val_loss=0.0000 scale=2.0000 norm=0.8653
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3901 val_loss=0.0000 scale=2.0000 norm=1.0533
[iter 200] loss=-0.1657 val_loss=0.0000 scale=2.0000 norm=0.9586
[iter 300] loss=-0.5123 val_loss=0.0000 scale=1.0000 norm=0.4863
[iter 400] loss=-0.7450 val_loss=0.0000 scale=1.0000 norm=0.4784
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3009 val_loss=0.0000 scale=2.0000 norm=1.0279
[iter 200] loss=-0.3276 val_loss=0.0000 scale=2.0000 norm=0.9622
[iter 300] loss=-0.7780 val_loss=0.0000 scale=2.0000 norm=0.9289
[iter 400] loss=-1.0583 val_loss=0.0000 scale=1.0000 norm=0.4413
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3222 val_loss=0.0000 scale=2.0000 norm=1.0213
[iter 200] loss=-0.2980 val_loss=0.0000 scale=2.0000 norm=0.9436
[iter 300] loss=-0.7365 val_loss=0.0000 scale=2.0000 norm=0.9058
[iter 400] loss=-0.9948 val_loss=0.0000 scale=2.0000 norm=0.8619
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4959 val_loss=0.0000 scale=2.0000 norm=1.1035
[iter 200] loss=-0.0833 val_loss=0.0000 scale=2.0000 norm=1.0218
[iter 300] loss=-0.4922 val_loss=0.0000 scale=1.0000 norm=0.4947
[iter 400] loss=-0.7557 val_loss=0.0000 scale=2.0000 norm=0.9705
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0333
[iter 200] loss=-0.2586 val_loss=0.0000 scale=1.0000 norm=0.4736
[iter 300] loss=-0.7011 val_loss=0.0000 scale=2.0000 norm=0.9290
[iter 400] loss=-1.0124 val_loss=0.0000 scale=2.0000 norm=0.8926
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5592 val_loss=0.0000 scale=2.0000 norm=1.1064
[iter 200] loss=-0.1664 val_loss=0.0000 scale=2.0000 norm=1.0819
[iter 300] loss=-0.8649 val_loss=0.0000 scale=2.0000 norm=1.0763
[iter 400] loss=-1.5251 val_loss=0.0000 scale=2.0000 norm=1.0380
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3846 val_loss=0.0000 scale=2.0000 norm=1.1312
[iter 200] loss=-0.3661 val_loss=0.0000 scale=2.0000 norm=1.0940
[iter 300] loss=-1.0212 val_loss=0.0000 scale=2.0000 norm=1.0469
[iter 400] loss=-1.6547 val_loss=0.0000 scale=2.0000 norm=1.0705
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4479 val_loss=0.0000 scale=2.0000 norm=1.0803
[iter 200] loss=-0.1777 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 300] loss=-0.6350 val_loss=0.0000 scale=1.0000 norm=0.4502
[iter 400] loss=-0.9317 val_loss=0.0000 scale=1.0000 norm=0.4330
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5448 val_loss=0.0000 scale=2.0000 norm=1.1313
[iter 200] loss=-0.0357 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 300] loss=-0.4333 val_loss=0.0000 scale=1.0000 norm=0.4739
[iter 400] loss=-0.6450 val_loss=0.0000 scale=1.0000 norm=0.4650
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7035 val_loss=0.0000 scale=2.0000 norm=1.2368
[iter 200] loss=0.1910 val_loss=0.0000 scale=1.0000 norm=0.5301
[iter 300] loss=-0.1851 val_loss=0.0000 scale=1.0000 norm=0.4861
[iter 400] loss=-0.4508 val_loss=0.0000 scale=1.0000 norm=0.4387
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3544 val_loss=0.0000 scale=2.0000 norm=1.0487
[iter 200] loss=-0.2808 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-0.7873 val_loss=0.0000 scale=2.0000 norm=0.9187
[iter 400] loss=-1.1444 val_loss=0.0000 scale=2.0000 norm=0.9132
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3094 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.2934 val_loss=0.0000 scale=2.0000 norm=0.9507
[iter 300] loss=-0.6608 val_loss=0.0000 scale=1.0000 norm=0.4725
[iter 400] loss=-0.9506 val_loss=0.0000 scale=2.0000 norm=0.9281
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4761 val_loss=0.0000 scale=2.0000 norm=1.0976
[iter 200] loss=-0.1664 val_loss=0.0000 scale=2.0000 norm=0.9726
[iter 300] loss=-0.6256 val_loss=0.0000 scale=2.0000 norm=0.9490
[iter 400] loss=-1.0179 val_loss=0.0000 scale=1.0000 norm=0.4768
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5373 val_loss=0.0000 scale=2.0000 norm=1.1685
[iter 200] loss=0.0252 val_loss=0.0000 scale=1.0000 norm=0.5168
[iter 300] loss=-0.2375 val_loss=0.0000 scale=0.5000 norm=0.2423
[iter 400] loss=-0.3997 val_loss=0.0000 scale=1.0000 norm=0.4594
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4387 val_loss=0.0000 scale=2.0000 norm=1.1209
[iter 200] loss=-0.1266 val_loss=0.0000 scale=2.0000 norm=0.9935
[iter 300] loss=-0.4827 val_loss=0.0000 scale=2.0000 norm=0.9240
[iter 400] loss=-0.6782 val_loss=0.0000 scale=1.0000 norm=0.4427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2417 val_loss=0.0000 scale=2.0000 norm=1.0041
[iter 200] loss=-0.4438 val_loss=0.0000 scale=2.0000 norm=0.9111
[iter 300] loss=-0.9328 val_loss=0.0000 scale=2.0000 norm=0.8650
[iter 400] loss=-1.2853 val_loss=0.0000 scale=1.0000 norm=0.3990
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3425 val_loss=0.0000 scale=2.0000 norm=1.0337
[iter 200] loss=-0.2136 val_loss=0.0000 scale=1.0000 norm=0.4718
[iter 300] loss=-0.5951 val_loss=0.0000 scale=1.0000 norm=0.4523
[iter 400] loss=-0.8530 val_loss=0.0000 scale=1.0000 norm=0.4352
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0947 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 200] loss=-0.8696 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 300] loss=-1.8198 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 400] loss=-2.7043 val_loss=0.0000 scale=2.0000 norm=0.8837
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3609 val_loss=0.0000 scale=2.0000 norm=1.0527
[iter 200] loss=-0.2153 val_loss=0.0000 scale=1.0000 norm=0.4858
[iter 300] loss=-0.5803 val_loss=0.0000 scale=2.0000 norm=0.9757
[iter 400] loss=-0.8140 val_loss=0.0000 scale=0.5000 norm=0.2379
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2732 val_loss=0.0000 scale=2.0000 norm=1.0084
[iter 200] loss=-0.4577 val_loss=0.0000 scale=2.0000 norm=0.8914
[iter 300] loss=-1.0079 val_loss=0.0000 scale=1.0000 norm=0.4065
[iter 400] loss=-1.3871 val_loss=0.0000 scale=2.0000 norm=0.7469
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4102 val_loss=0.0000 scale=2.0000 norm=1.0864
[iter 200] loss=-0.1760 val_loss=0.0000 scale=2.0000 norm=1.0144
[iter 300] loss=-0.5860 val_loss=0.0000 scale=2.0000 norm=0.9966
[iter 400] loss=-0.8492 val_loss=0.0000 scale=1.0000 norm=0.4841
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2895 val_loss=0.0000 scale=2.0000 norm=1.0227
[iter 200] loss=-0.3647 val_loss=0.0000 scale=2.0000 norm=0.9164
[iter 300] loss=-0.8634 val_loss=0.0000 scale=1.0000 norm=0.4272
[iter 400] loss=-1.1702 val_loss=0.0000 scale=1.0000 norm=0.4183
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3887 val_loss=0.0000 scale=2.0000 norm=1.0786
[iter 200] loss=-0.1943 val_loss=0.0000 scale=2.0000 norm=0.9604
[iter 300] loss=-0.6208 val_loss=0.0000 scale=2.0000 norm=0.8995
[iter 400] loss=-0.8677 val_loss=0.0000 scale=2.0000 norm=0.8819
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4532 val_loss=0.0000 scale=2.0000 norm=1.0706
[iter 200] loss=-0.2499 val_loss=0.0000 scale=2.0000 norm=0.8843
[iter 300] loss=-0.6934 val_loss=0.0000 scale=1.0000 norm=0.3989
[iter 400] loss=-0.9959 val_loss=0.0000 scale=2.0000 norm=0.7944
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4131 val_loss=0.0000 scale=2.0000 norm=1.0915
[iter 200] loss=-0.1402 val_loss=0.0000 scale=2.0000 norm=0.9854
[iter 300] loss=-0.6073 val_loss=0.0000 scale=2.0000 norm=0.9276
[iter 400] loss=-0.8889 val_loss=0.0000 scale=1.0000 norm=0.4542
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3146 val_loss=0.0000 scale=2.0000 norm=1.0458
[iter 200] loss=-0.2633 val_loss=0.0000 scale=2.0000 norm=0.9685
[iter 300] loss=-0.6815 val_loss=0.0000 scale=2.0000 norm=0.9363
[iter 400] loss=-0.9061 val_loss=0.0000 scale=2.0000 norm=0.9143
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1854 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 200] loss=-0.6132 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 300] loss=-1.3228 val_loss=0.0000 scale=2.0000 norm=0.9064
[iter 400] loss=-1.9400 val_loss=0.0000 scale=2.0000 norm=0.8787
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3072 val_loss=0.0000 scale=2.0000 norm=1.0309
[iter 200] loss=-0.2986 val_loss=0.0000 scale=1.0000 norm=0.4692
[iter 300] loss=-0.6478 val_loss=0.0000 scale=2.0000 norm=0.9403
[iter 400] loss=-0.8956 val_loss=0.0000 scale=2.0000 norm=0.9288
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3853 val_loss=0.0000 scale=2.0000 norm=1.0705
[iter 200] loss=-0.2275 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 300] loss=-0.7094 val_loss=0.0000 scale=1.0000 norm=0.4773
[iter 400] loss=-0.9744 val_loss=0.0000 scale=0.5000 norm=0.2275
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3918 val_loss=0.0000 scale=2.0000 norm=1.0303
[iter 200] loss=-0.2104 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 300] loss=-0.6040 val_loss=0.0000 scale=2.0000 norm=0.9024
[iter 400] loss=-0.9477 val_loss=0.0000 scale=2.0000 norm=0.8801
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3723 val_loss=0.0000 scale=2.0000 norm=1.0500
[iter 200] loss=-0.2305 val_loss=0.0000 scale=2.0000 norm=0.9680
[iter 300] loss=-0.6857 val_loss=0.0000 scale=1.0000 norm=0.4867
[iter 400] loss=-1.0442 val_loss=0.0000 scale=1.0000 norm=0.4470
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3410 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 200] loss=-0.2842 val_loss=0.0000 scale=2.0000 norm=0.9581
[iter 300] loss=-0.7199 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 400] loss=-1.0585 val_loss=0.0000 scale=2.0000 norm=0.8964
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4012 val_loss=0.0000 scale=2.0000 norm=1.0759
[iter 200] loss=-0.1972 val_loss=0.0000 scale=2.0000 norm=0.9532
[iter 300] loss=-0.5702 val_loss=0.0000 scale=2.0000 norm=0.9221
[iter 400] loss=-0.8681 val_loss=0.0000 scale=1.0000 norm=0.4388
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3434 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.2612 val_loss=0.0000 scale=2.0000 norm=0.9356
[iter 300] loss=-0.6629 val_loss=0.0000 scale=1.0000 norm=0.4442
[iter 400] loss=-0.8846 val_loss=0.0000 scale=0.5000 norm=0.2178
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4158 val_loss=0.0000 scale=2.0000 norm=1.0692
[iter 200] loss=-0.3899 val_loss=0.0000 scale=2.0000 norm=0.9723
[iter 300] loss=-1.1223 val_loss=0.0000 scale=2.0000 norm=0.9371
[iter 400] loss=-1.7428 val_loss=0.0000 scale=2.0000 norm=0.8968
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2260 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 200] loss=-0.6403 val_loss=0.0000 scale=2.0000 norm=0.9146
[iter 300] loss=-1.4259 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 400] loss=-2.1793 val_loss=0.0000 scale=2.0000 norm=0.8447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4442 val_loss=0.0000 scale=2.0000 norm=1.1031
[iter 200] loss=-0.1091 val_loss=0.0000 scale=2.0000 norm=1.0080
[iter 300] loss=-0.4952 val_loss=0.0000 scale=2.0000 norm=0.9697
[iter 400] loss=-0.6978 val_loss=0.0000 scale=0.5000 norm=0.2399
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4572 val_loss=0.0000 scale=2.0000 norm=1.1200
[iter 200] loss=-0.1788 val_loss=0.0000 scale=2.0000 norm=0.9971
[iter 300] loss=-0.6593 val_loss=0.0000 scale=1.0000 norm=0.4807
[iter 400] loss=-0.9879 val_loss=0.0000 scale=1.0000 norm=0.4891
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2852 val_loss=0.0000 scale=2.0000 norm=1.0033
[iter 200] loss=-0.3600 val_loss=0.0000 scale=2.0000 norm=0.9402
[iter 300] loss=-0.8041 val_loss=0.0000 scale=2.0000 norm=0.9390
[iter 400] loss=-1.0845 val_loss=0.0000 scale=2.0000 norm=0.9113
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4112 val_loss=0.0000 scale=2.0000 norm=1.0733
[iter 200] loss=-0.1390 val_loss=0.0000 scale=2.0000 norm=0.9545
[iter 300] loss=-0.4994 val_loss=0.0000 scale=1.0000 norm=0.4710
[iter 400] loss=-0.7431 val_loss=0.0000 scale=1.0000 norm=0.4590
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7490 val_loss=0.0000 scale=2.0000 norm=1.2549
[iter 200] loss=0.1550 val_loss=0.0000 scale=2.0000 norm=1.0610
[iter 300] loss=-0.3727 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 400] loss=-0.7833 val_loss=0.0000 scale=2.0000 norm=0.9540
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2979 val_loss=0.0000 scale=2.0000 norm=1.0223
[iter 200] loss=-0.3695 val_loss=0.0000 scale=2.0000 norm=0.9351
[iter 300] loss=-0.9040 val_loss=0.0000 scale=2.0000 norm=0.9099
[iter 400] loss=-1.2652 val_loss=0.0000 scale=2.0000 norm=0.8597
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2588 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.4651 val_loss=0.0000 scale=2.0000 norm=0.9341
[iter 300] loss=-1.1399 val_loss=0.0000 scale=4.0000 norm=1.8934
[iter 400] loss=-2.0796 val_loss=0.0000 scale=4.0000 norm=1.8913
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3647 val_loss=0.0000 scale=2.0000 norm=1.0774
[iter 200] loss=-0.2681 val_loss=0.0000 scale=2.0000 norm=1.0016
[iter 300] loss=-0.7739 val_loss=0.0000 scale=2.0000 norm=0.9436
[iter 400] loss=-1.1094 val_loss=0.0000 scale=2.0000 norm=0.9047
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3822 val_loss=0.0000 scale=2.0000 norm=1.0693
[iter 200] loss=-0.1979 val_loss=0.0000 scale=2.0000 norm=0.9797
[iter 300] loss=-0.6035 val_loss=0.0000 scale=1.0000 norm=0.4726
[iter 400] loss=-0.8340 val_loss=0.0000 scale=2.0000 norm=0.9437
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5832 val_loss=0.0000 scale=2.0000 norm=1.1194
[iter 200] loss=-0.0441 val_loss=0.0000 scale=2.0000 norm=1.0230
[iter 300] loss=-0.5418 val_loss=0.0000 scale=2.0000 norm=1.0209
[iter 400] loss=-0.9648 val_loss=0.0000 scale=1.0000 norm=0.4803
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5719 val_loss=0.0000 scale=2.0000 norm=1.1861
[iter 200] loss=0.0333 val_loss=0.0000 scale=2.0000 norm=1.0499
[iter 300] loss=-0.3831 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 400] loss=-0.6275 val_loss=0.0000 scale=2.0000 norm=0.9415
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3986 val_loss=0.0000 scale=2.0000 norm=1.0711
[iter 200] loss=-0.1434 val_loss=0.0000 scale=2.0000 norm=0.9618
[iter 300] loss=-0.5452 val_loss=0.0000 scale=2.0000 norm=0.9140
[iter 400] loss=-0.7878 val_loss=0.0000 scale=2.0000 norm=0.9184
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3277 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 200] loss=-0.2578 val_loss=0.0000 scale=1.0000 norm=0.4664
[iter 300] loss=-0.6075 val_loss=0.0000 scale=2.0000 norm=0.8802
[iter 400] loss=-0.8374 val_loss=0.0000 scale=1.0000 norm=0.4199
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1275 val_loss=0.0000 scale=2.0000 norm=0.9768
[iter 200] loss=-0.7820 val_loss=0.0000 scale=2.0000 norm=0.9145
[iter 300] loss=-1.6261 val_loss=0.0000 scale=2.0000 norm=0.8452
[iter 400] loss=-2.3854 val_loss=0.0000 scale=2.0000 norm=0.7665
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3692 val_loss=0.0000 scale=2.0000 norm=1.0328
[iter 200] loss=-0.1807 val_loss=0.0000 scale=2.0000 norm=0.9355
[iter 300] loss=-0.5364 val_loss=0.0000 scale=2.0000 norm=0.9002
[iter 400] loss=-0.7604 val_loss=0.0000 scale=1.0000 norm=0.4600
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4041 val_loss=0.0000 scale=2.0000 norm=1.0688
[iter 200] loss=-0.2283 val_loss=0.0000 scale=2.0000 norm=0.9776
[iter 300] loss=-0.7314 val_loss=0.0000 scale=2.0000 norm=0.9309
[iter 400] loss=-1.0480 val_loss=0.0000 scale=2.0000 norm=0.9068
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3675 val_loss=0.0000 scale=2.0000 norm=1.0400
[iter 200] loss=-0.2214 val_loss=0.0000 scale=2.0000 norm=0.9533
[iter 300] loss=-0.6278 val_loss=0.0000 scale=2.0000 norm=0.9161
[iter 400] loss=-0.8628 val_loss=0.0000 scale=1.0000 norm=0.4353
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2026 val_loss=0.0000 scale=2.0000 norm=1.0331
[iter 200] loss=-0.5320 val_loss=0.0000 scale=2.0000 norm=0.9140
[iter 300] loss=-1.1088 val_loss=0.0000 scale=2.0000 norm=0.8176
[iter 400] loss=-1.5180 val_loss=0.0000 scale=1.0000 norm=0.3788
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7192 val_loss=0.0000 scale=2.0000 norm=1.2370
[iter 200] loss=0.1560 val_loss=0.0000 scale=1.0000 norm=0.5427
[iter 300] loss=-0.2229 val_loss=0.0000 scale=2.0000 norm=1.0328
[iter 400] loss=-0.5111 val_loss=0.0000 scale=1.0000 norm=0.4886
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3433 val_loss=0.0000 scale=2.0000 norm=1.0223
[iter 200] loss=-0.2566 val_loss=0.0000 scale=2.0000 norm=0.9404
[iter 300] loss=-0.6878 val_loss=0.0000 scale=2.0000 norm=0.9501
[iter 400] loss=-0.9801 val_loss=0.0000 scale=1.0000 norm=0.4618
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3704 val_loss=0.0000 scale=2.0000 norm=1.0478
[iter 200] loss=-0.1886 val_loss=0.0000 scale=2.0000 norm=0.9483
[iter 300] loss=-0.6099 val_loss=0.0000 scale=2.0000 norm=0.9416
[iter 400] loss=-0.8598 val_loss=0.0000 scale=1.0000 norm=0.4615
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7062 val_loss=0.0000 scale=2.0000 norm=1.2220
[iter 200] loss=-0.0596 val_loss=0.0000 scale=2.0000 norm=1.0589
[iter 300] loss=-0.7614 val_loss=0.0000 scale=2.0000 norm=0.9815
[iter 400] loss=-1.2508 val_loss=0.0000 scale=2.0000 norm=0.8808
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3310 val_loss=0.0000 scale=2.0000 norm=1.0340
[iter 200] loss=-0.2728 val_loss=0.0000 scale=2.0000 norm=0.9412
[iter 300] loss=-0.7139 val_loss=0.0000 scale=2.0000 norm=0.9130
[iter 400] loss=-0.9744 val_loss=0.0000 scale=1.0000 norm=0.4397
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4084 val_loss=0.0000 scale=2.0000 norm=1.0606
[iter 200] loss=-0.1209 val_loss=0.0000 scale=2.0000 norm=0.9333
[iter 300] loss=-0.4298 val_loss=0.0000 scale=2.0000 norm=0.8989
[iter 400] loss=-0.6571 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6146 val_loss=0.0000 scale=2.0000 norm=1.1552
[iter 200] loss=0.0495 val_loss=0.0000 scale=2.0000 norm=0.9908
[iter 300] loss=-0.3241 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 400] loss=-0.5452 val_loss=0.0000 scale=2.0000 norm=0.9488
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3310 val_loss=0.0000 scale=2.0000 norm=1.0328
[iter 200] loss=-0.2559 val_loss=0.0000 scale=2.0000 norm=0.9612
[iter 300] loss=-0.6917 val_loss=0.0000 scale=2.0000 norm=0.9367
[iter 400] loss=-0.9475 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4047 val_loss=0.0000 scale=2.0000 norm=1.1309
[iter 200] loss=-0.1924 val_loss=0.0000 scale=2.0000 norm=1.0827
[iter 300] loss=-0.6792 val_loss=0.0000 scale=2.0000 norm=1.0681
[iter 400] loss=-1.0463 val_loss=0.0000 scale=2.0000 norm=1.0217
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3926 val_loss=0.0000 scale=2.0000 norm=1.0775
[iter 200] loss=-0.1683 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 300] loss=-0.5018 val_loss=0.0000 scale=1.0000 norm=0.4757
[iter 400] loss=-0.6730 val_loss=0.0000 scale=0.5000 norm=0.2355
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3085 val_loss=0.0000 scale=2.0000 norm=1.0338
[iter 200] loss=-0.2918 val_loss=0.0000 scale=2.0000 norm=0.9595
[iter 300] loss=-0.7952 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 400] loss=-1.1671 val_loss=0.0000 scale=1.0000 norm=0.4381
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3993 val_loss=0.0000 scale=2.0000 norm=1.0775
[iter 200] loss=-0.1629 val_loss=0.0000 scale=2.0000 norm=0.9694
[iter 300] loss=-0.5774 val_loss=0.0000 scale=2.0000 norm=0.9248
[iter 400] loss=-0.8205 val_loss=0.0000 scale=1.0000 norm=0.4475
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1898 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 200] loss=-0.7107 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 300] loss=-1.5277 val_loss=0.0000 scale=2.0000 norm=0.8873
[iter 400] loss=-2.3863 val_loss=0.0000 scale=2.0000 norm=0.8724
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4744 val_loss=0.0000 scale=2.0000 norm=1.1073
[iter 200] loss=-0.0461 val_loss=0.0000 scale=2.0000 norm=1.0208
[iter 300] loss=-0.3928 val_loss=0.0000 scale=2.0000 norm=0.9665
[iter 400] loss=-0.5542 val_loss=0.0000 scale=0.5000 norm=0.2324
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3309 val_loss=0.0000 scale=2.0000 norm=0.9422
[iter 200] loss=-0.5584 val_loss=0.0000 scale=2.0000 norm=0.9269
[iter 300] loss=-1.3906 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 400] loss=-2.1634 val_loss=0.0000 scale=2.0000 norm=0.8505
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3314 val_loss=0.0000 scale=2.0000 norm=1.0374
[iter 200] loss=-0.2845 val_loss=0.0000 scale=2.0000 norm=0.9394
[iter 300] loss=-0.7090 val_loss=0.0000 scale=1.0000 norm=0.4407
[iter 400] loss=-1.0111 val_loss=0.0000 scale=0.5000 norm=0.2208
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8521 val_loss=0.0000 scale=1.0000 norm=0.6515
[iter 200] loss=0.3206 val_loss=0.0000 scale=1.0000 norm=0.5218
[iter 300] loss=-0.2900 val_loss=0.0000 scale=2.0000 norm=0.9698
[iter 400] loss=-0.8002 val_loss=0.0000 scale=2.0000 norm=0.9702
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6012 val_loss=0.0000 scale=2.0000 norm=1.1302
[iter 200] loss=0.1922 val_loss=0.0000 scale=1.0000 norm=0.5073
[iter 300] loss=-0.1440 val_loss=0.0000 scale=1.0000 norm=0.4875
[iter 400] loss=-0.3662 val_loss=0.0000 scale=1.0000 norm=0.4758
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4917 val_loss=0.0000 scale=2.0000 norm=1.1250
[iter 200] loss=-0.0959 val_loss=0.0000 scale=2.0000 norm=1.0118
[iter 300] loss=-0.4976 val_loss=0.0000 scale=1.0000 norm=0.4706
[iter 400] loss=-0.7716 val_loss=0.0000 scale=2.0000 norm=0.8935
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3431 val_loss=0.0000 scale=2.0000 norm=1.0408
[iter 200] loss=-0.2621 val_loss=0.0000 scale=2.0000 norm=0.9252
[iter 300] loss=-0.6789 val_loss=0.0000 scale=2.0000 norm=0.8789
[iter 400] loss=-0.9309 val_loss=0.0000 scale=1.0000 norm=0.4321
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3700 val_loss=0.0000 scale=2.0000 norm=1.0453
[iter 200] loss=-0.2059 val_loss=0.0000 scale=2.0000 norm=0.9262
[iter 300] loss=-0.5774 val_loss=0.0000 scale=1.0000 norm=0.4470
[iter 400] loss=-0.7990 val_loss=0.0000 scale=1.0000 norm=0.4342
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2671 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.3935 val_loss=0.0000 scale=2.0000 norm=0.9834
[iter 300] loss=-0.9223 val_loss=0.0000 scale=2.0000 norm=0.9475
[iter 400] loss=-1.2101 val_loss=0.0000 scale=1.0000 norm=0.4453
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2115 val_loss=0.0000 scale=2.0000 norm=0.9894
[iter 200] loss=-0.5655 val_loss=0.0000 scale=2.0000 norm=0.9521
[iter 300] loss=-1.2188 val_loss=0.0000 scale=2.0000 norm=0.9234
[iter 400] loss=-1.6839 val_loss=0.0000 scale=2.0000 norm=0.9059
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5292 val_loss=0.0000 scale=2.0000 norm=1.1809
[iter 200] loss=-0.0584 val_loss=0.0000 scale=2.0000 norm=1.0713
[iter 300] loss=-0.3868 val_loss=0.0000 scale=1.0000 norm=0.5055
[iter 400] loss=-0.6093 val_loss=0.0000 scale=1.0000 norm=0.4959
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3845 val_loss=0.0000 scale=2.0000 norm=1.1072
[iter 200] loss=-0.2531 val_loss=0.0000 scale=2.0000 norm=0.9728
[iter 300] loss=-0.7290 val_loss=0.0000 scale=2.0000 norm=0.8808
[iter 400] loss=-1.0164 val_loss=0.0000 scale=1.0000 norm=0.4257
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2089 val_loss=0.0000 scale=2.0000 norm=0.9631
[iter 200] loss=-0.6580 val_loss=0.0000 scale=2.0000 norm=0.8927
[iter 300] loss=-1.5063 val_loss=0.0000 scale=2.0000 norm=0.8781
[iter 400] loss=-2.3402 val_loss=0.0000 scale=2.0000 norm=0.8648
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4057 val_loss=0.0000 scale=2.0000 norm=1.0663
[iter 200] loss=-0.1526 val_loss=0.0000 scale=2.0000 norm=0.9730
[iter 300] loss=-0.5343 val_loss=0.0000 scale=2.0000 norm=0.9604
[iter 400] loss=-0.7133 val_loss=0.0000 scale=0.5000 norm=0.2398
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4158 val_loss=0.0000 scale=2.0000 norm=1.0806
[iter 200] loss=-0.1736 val_loss=0.0000 scale=2.0000 norm=0.9700
[iter 300] loss=-0.6240 val_loss=0.0000 scale=2.0000 norm=0.8869
[iter 400] loss=-0.8476 val_loss=0.0000 scale=2.0000 norm=0.8407
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3641 val_loss=0.0000 scale=2.0000 norm=1.0711
[iter 200] loss=-0.1928 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 300] loss=-0.5831 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 400] loss=-0.7971 val_loss=0.0000 scale=0.5000 norm=0.2236
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3595 val_loss=0.0000 scale=2.0000 norm=1.0585
[iter 200] loss=-0.2404 val_loss=0.0000 scale=2.0000 norm=0.9750
[iter 300] loss=-0.7079 val_loss=0.0000 scale=2.0000 norm=0.9536
[iter 400] loss=-0.9354 val_loss=0.0000 scale=1.0000 norm=0.4636
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3961 val_loss=0.0000 scale=2.0000 norm=1.0770
[iter 200] loss=-0.1815 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 300] loss=-0.6440 val_loss=0.0000 scale=2.0000 norm=0.9129
[iter 400] loss=-0.8821 val_loss=0.0000 scale=0.5000 norm=0.2270
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2859 val_loss=0.0000 scale=2.0000 norm=1.0231
[iter 200] loss=-0.3405 val_loss=0.0000 scale=2.0000 norm=0.9295
[iter 300] loss=-0.8445 val_loss=0.0000 scale=2.0000 norm=0.8786
[iter 400] loss=-1.1943 val_loss=0.0000 scale=2.0000 norm=0.8427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1982 val_loss=0.0000 scale=2.0000 norm=1.0089
[iter 200] loss=-0.4951 val_loss=0.0000 scale=2.0000 norm=0.9981
[iter 300] loss=-1.0500 val_loss=0.0000 scale=2.0000 norm=0.9396
[iter 400] loss=-1.4362 val_loss=0.0000 scale=2.0000 norm=0.8875
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3394 val_loss=0.0000 scale=2.0000 norm=1.0385
[iter 200] loss=-0.2591 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 300] loss=-0.6457 val_loss=0.0000 scale=1.0000 norm=0.4531
[iter 400] loss=-0.8830 val_loss=0.0000 scale=1.0000 norm=0.4562
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4137 val_loss=0.0000 scale=2.0000 norm=1.0711
[iter 200] loss=-0.1189 val_loss=0.0000 scale=1.0000 norm=0.4805
[iter 300] loss=-0.4475 val_loss=0.0000 scale=1.0000 norm=0.4579
[iter 400] loss=-0.6544 val_loss=0.0000 scale=1.0000 norm=0.4586
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3038 val_loss=0.0000 scale=2.0000 norm=1.0397
[iter 200] loss=-0.3307 val_loss=0.0000 scale=2.0000 norm=0.9795
[iter 300] loss=-0.8030 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 400] loss=-1.0474 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3931 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 200] loss=-0.2021 val_loss=0.0000 scale=2.0000 norm=0.9979
[iter 300] loss=-0.5839 val_loss=0.0000 scale=1.0000 norm=0.4877
[iter 400] loss=-0.8385 val_loss=0.0000 scale=1.0000 norm=0.4655
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4113 val_loss=0.0000 scale=2.0000 norm=1.1146
[iter 200] loss=-0.1468 val_loss=0.0000 scale=2.0000 norm=1.0424
[iter 300] loss=-0.5839 val_loss=0.0000 scale=1.0000 norm=0.4872
[iter 400] loss=-0.8507 val_loss=0.0000 scale=1.0000 norm=0.4674
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.1221
[iter 200] loss=-0.4232 val_loss=0.0000 scale=2.0000 norm=1.0781
[iter 300] loss=-1.1821 val_loss=0.0000 scale=2.0000 norm=1.0521
[iter 400] loss=-1.9048 val_loss=0.0000 scale=2.0000 norm=1.0077
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1637 val_loss=0.0000 scale=2.0000 norm=0.9906
[iter 200] loss=-0.6830 val_loss=0.0000 scale=2.0000 norm=0.9687
[iter 300] loss=-1.4334 val_loss=0.0000 scale=2.0000 norm=0.9571
[iter 400] loss=-2.0755 val_loss=0.0000 scale=2.0000 norm=0.9162
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4832 val_loss=0.0000 scale=2.0000 norm=1.1209
[iter 200] loss=-0.0780 val_loss=0.0000 scale=2.0000 norm=0.9931
[iter 300] loss=-0.4216 val_loss=0.0000 scale=2.0000 norm=0.9772
[iter 400] loss=-0.6843 val_loss=0.0000 scale=0.5000 norm=0.2383
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3832 val_loss=0.0000 scale=2.0000 norm=1.0462
[iter 200] loss=-0.2188 val_loss=0.0000 scale=2.0000 norm=0.9368
[iter 300] loss=-0.6097 val_loss=0.0000 scale=2.0000 norm=0.8999
[iter 400] loss=-0.8487 val_loss=0.0000 scale=1.0000 norm=0.4453
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3951 val_loss=0.0000 scale=2.0000 norm=1.0882
[iter 200] loss=-0.1338 val_loss=0.0000 scale=2.0000 norm=0.9833
[iter 300] loss=-0.4749 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 400] loss=-0.6865 val_loss=0.0000 scale=1.0000 norm=0.4726
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6352 val_loss=0.0000 scale=2.0000 norm=1.2181
[iter 200] loss=0.1203 val_loss=0.0000 scale=2.0000 norm=1.1052
[iter 300] loss=-0.2615 val_loss=0.0000 scale=2.0000 norm=1.0379
[iter 400] loss=-0.5125 val_loss=0.0000 scale=1.0000 norm=0.4932
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4278 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.3749 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 300] loss=-1.0725 val_loss=0.0000 scale=2.0000 norm=0.8359
[iter 400] loss=-1.7115 val_loss=0.0000 scale=2.0000 norm=0.8145
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1696 val_loss=0.0000 scale=2.0000 norm=1.0071
[iter 200] loss=-0.5582 val_loss=0.0000 scale=2.0000 norm=0.9757
[iter 300] loss=-1.1314 val_loss=0.0000 scale=2.0000 norm=0.9412
[iter 400] loss=-1.6097 val_loss=0.0000 scale=2.0000 norm=0.8943
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1734 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.5698 val_loss=0.0000 scale=2.0000 norm=0.9204
[iter 300] loss=-1.1619 val_loss=0.0000 scale=2.0000 norm=0.8709
[iter 400] loss=-1.6010 val_loss=0.0000 scale=2.0000 norm=0.8254
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1287 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 200] loss=-0.7764 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-1.6605 val_loss=0.0000 scale=2.0000 norm=0.8487
[iter 400] loss=-2.9076 val_loss=0.0000 scale=4.0000 norm=1.5995
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3567 val_loss=0.0000 scale=2.0000 norm=1.0317
[iter 200] loss=-0.3366 val_loss=0.0000 scale=2.0000 norm=0.9478
[iter 300] loss=-0.8196 val_loss=0.0000 scale=2.0000 norm=0.9464
[iter 400] loss=-1.0924 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3447 val_loss=0.0000 scale=2.0000 norm=1.0545
[iter 200] loss=-0.2896 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 300] loss=-0.7585 val_loss=0.0000 scale=1.0000 norm=0.4705
[iter 400] loss=-1.0309 val_loss=0.0000 scale=0.5000 norm=0.2284
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3753 val_loss=0.0000 scale=2.0000 norm=1.0687
[iter 200] loss=-0.2008 val_loss=0.0000 scale=1.0000 norm=0.4949
[iter 300] loss=-0.6181 val_loss=0.0000 scale=2.0000 norm=0.9722
[iter 400] loss=-0.8423 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6825 val_loss=0.0000 scale=2.0000 norm=1.1578
[iter 200] loss=-0.0419 val_loss=0.0000 scale=2.0000 norm=0.9917
[iter 300] loss=-0.6916 val_loss=0.0000 scale=2.0000 norm=0.9550
[iter 400] loss=-1.3106 val_loss=0.0000 scale=2.0000 norm=0.9432
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4143 val_loss=0.0000 scale=2.0000 norm=1.1163
[iter 200] loss=-0.3906 val_loss=0.0000 scale=4.0000 norm=2.2490
[iter 300] loss=-1.8072 val_loss=0.0000 scale=4.0000 norm=2.1115
[iter 400] loss=-2.8041 val_loss=0.0000 scale=4.0000 norm=2.0427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3389 val_loss=0.0000 scale=2.0000 norm=1.0269
[iter 200] loss=-0.2392 val_loss=0.0000 scale=2.0000 norm=0.9361
[iter 300] loss=-0.6554 val_loss=0.0000 scale=2.0000 norm=0.8973
[iter 400] loss=-0.9292 val_loss=0.0000 scale=2.0000 norm=0.8783
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1632 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 200] loss=-0.7202 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 300] loss=-1.6585 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 400] loss=-2.4145 val_loss=0.0000 scale=2.0000 norm=0.8686
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2789 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 200] loss=-0.2770 val_loss=0.0000 scale=1.0000 norm=0.4574
[iter 300] loss=-0.6737 val_loss=0.0000 scale=2.0000 norm=0.8674
[iter 400] loss=-1.0000 val_loss=0.0000 scale=1.0000 norm=0.4108
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3396 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 200] loss=-0.3118 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 300] loss=-0.7889 val_loss=0.0000 scale=2.0000 norm=0.9498
[iter 400] loss=-1.1186 val_loss=0.0000 scale=1.0000 norm=0.4488
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2774 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 200] loss=-0.5477 val_loss=0.0000 scale=2.0000 norm=0.8781
[iter 300] loss=-1.1976 val_loss=0.0000 scale=2.0000 norm=0.7569
[iter 400] loss=-2.0821 val_loss=0.0000 scale=4.0000 norm=1.3047
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3380 val_loss=0.0000 scale=2.0000 norm=0.9858
[iter 200] loss=-0.6226 val_loss=0.0000 scale=2.0000 norm=0.9567
[iter 300] loss=-1.8217 val_loss=0.0000 scale=4.0000 norm=1.7219
[iter 400] loss=-3.2033 val_loss=0.0000 scale=4.0000 norm=1.7304
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4191 val_loss=0.0000 scale=2.0000 norm=1.0843
[iter 200] loss=-0.3105 val_loss=0.0000 scale=2.0000 norm=1.0487
[iter 300] loss=-0.9533 val_loss=0.0000 scale=2.0000 norm=1.0508
[iter 400] loss=-1.4836 val_loss=0.0000 scale=2.0000 norm=1.0565
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5885 val_loss=0.0000 scale=2.0000 norm=1.1155
[iter 200] loss=-0.0282 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 300] loss=-0.4973 val_loss=0.0000 scale=2.0000 norm=0.9404
[iter 400] loss=-0.7786 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3899 val_loss=0.0000 scale=2.0000 norm=1.0531
[iter 200] loss=-0.2008 val_loss=0.0000 scale=1.0000 norm=0.4696
[iter 300] loss=-0.5618 val_loss=0.0000 scale=1.0000 norm=0.4522
[iter 400] loss=-0.8318 val_loss=0.0000 scale=1.0000 norm=0.4474
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3838 val_loss=0.0000 scale=2.0000 norm=1.0673
[iter 200] loss=-0.1554 val_loss=0.0000 scale=1.0000 norm=0.4844
[iter 300] loss=-0.5758 val_loss=0.0000 scale=2.0000 norm=0.9214
[iter 400] loss=-0.8162 val_loss=0.0000 scale=1.0000 norm=0.4462
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3393 val_loss=0.0000 scale=2.0000 norm=1.0478
[iter 200] loss=-0.2387 val_loss=0.0000 scale=2.0000 norm=0.9675
[iter 300] loss=-0.6385 val_loss=0.0000 scale=1.0000 norm=0.4670
[iter 400] loss=-0.8554 val_loss=0.0000 scale=1.0000 norm=0.4624
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1929 val_loss=0.0000 scale=2.0000 norm=0.9923
[iter 200] loss=-0.5687 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 300] loss=-1.1656 val_loss=0.0000 scale=2.0000 norm=0.8919
[iter 400] loss=-1.6031 val_loss=0.0000 scale=2.0000 norm=0.8763
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2979 val_loss=0.0000 scale=2.0000 norm=1.0243
[iter 200] loss=-0.3213 val_loss=0.0000 scale=2.0000 norm=0.9184
[iter 300] loss=-0.7228 val_loss=0.0000 scale=2.0000 norm=0.8995
[iter 400] loss=-1.0141 val_loss=0.0000 scale=2.0000 norm=0.8911
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3900 val_loss=0.0000 scale=2.0000 norm=1.0648
[iter 200] loss=-0.2432 val_loss=0.0000 scale=2.0000 norm=0.9637
[iter 300] loss=-0.6455 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 400] loss=-0.9108 val_loss=0.0000 scale=1.0000 norm=0.4547
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6084 val_loss=0.0000 scale=2.0000 norm=1.1521
[iter 200] loss=0.0047 val_loss=0.0000 scale=2.0000 norm=1.0497
[iter 300] loss=-0.5068 val_loss=0.0000 scale=2.0000 norm=1.0140
[iter 400] loss=-0.8366 val_loss=0.0000 scale=1.0000 norm=0.4922
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3074 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.4241 val_loss=0.0000 scale=2.0000 norm=0.9599
[iter 300] loss=-1.0000 val_loss=0.0000 scale=2.0000 norm=0.9359
[iter 400] loss=-1.3888 val_loss=0.0000 scale=2.0000 norm=0.8901
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3627 val_loss=0.0000 scale=2.0000 norm=1.0317
[iter 200] loss=-0.1998 val_loss=0.0000 scale=2.0000 norm=0.9429
[iter 300] loss=-0.5957 val_loss=0.0000 scale=2.0000 norm=0.9272
[iter 400] loss=-0.8548 val_loss=0.0000 scale=1.0000 norm=0.4379
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3779 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3414 val_loss=0.0000 scale=2.0000 norm=0.9134
[iter 300] loss=-0.9256 val_loss=0.0000 scale=2.0000 norm=0.8522
[iter 400] loss=-1.3813 val_loss=0.0000 scale=2.0000 norm=0.8025
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4582 val_loss=0.0000 scale=2.0000 norm=1.1023
[iter 200] loss=-0.0472 val_loss=0.0000 scale=2.0000 norm=1.0254
[iter 300] loss=-0.3997 val_loss=0.0000 scale=2.0000 norm=0.9915
[iter 400] loss=-0.5921 val_loss=0.0000 scale=0.5000 norm=0.2427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3521 val_loss=0.0000 scale=2.0000 norm=1.0619
[iter 200] loss=-0.2715 val_loss=0.0000 scale=2.0000 norm=0.9534
[iter 300] loss=-0.6970 val_loss=0.0000 scale=2.0000 norm=0.8932
[iter 400] loss=-0.9293 val_loss=0.0000 scale=0.5000 norm=0.2206
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1612 val_loss=0.0000 scale=2.0000 norm=0.9793
[iter 200] loss=-0.7637 val_loss=0.0000 scale=2.0000 norm=0.9277
[iter 300] loss=-1.6151 val_loss=0.0000 scale=2.0000 norm=0.8850
[iter 400] loss=-2.4313 val_loss=0.0000 scale=2.0000 norm=0.9014
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6661 val_loss=0.0000 scale=2.0000 norm=1.2275
[iter 200] loss=0.0954 val_loss=0.0000 scale=2.0000 norm=1.0733
[iter 300] loss=-0.2844 val_loss=0.0000 scale=2.0000 norm=0.9871
[iter 400] loss=-0.5428 val_loss=0.0000 scale=0.5000 norm=0.2357
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3252 val_loss=0.0000 scale=2.0000 norm=1.0229
[iter 200] loss=-0.2502 val_loss=0.0000 scale=2.0000 norm=0.9475
[iter 300] loss=-0.6448 val_loss=0.0000 scale=2.0000 norm=0.9516
[iter 400] loss=-0.9550 val_loss=0.0000 scale=1.0000 norm=0.4717
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3362 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 200] loss=-0.4873 val_loss=0.0000 scale=2.0000 norm=0.9142
[iter 300] loss=-1.3087 val_loss=0.0000 scale=2.0000 norm=0.9296
[iter 400] loss=-2.1360 val_loss=0.0000 scale=2.0000 norm=0.9310
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6892 val_loss=0.0000 scale=2.0000 norm=1.2006
[iter 200] loss=0.2017 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 300] loss=-0.1737 val_loss=0.0000 scale=1.0000 norm=0.5012
[iter 400] loss=-0.4275 val_loss=0.0000 scale=1.0000 norm=0.4919
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3578 val_loss=0.0000 scale=2.0000 norm=1.0503
[iter 200] loss=-0.2220 val_loss=0.0000 scale=2.0000 norm=0.9782
[iter 300] loss=-0.6118 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 400] loss=-0.8767 val_loss=0.0000 scale=1.0000 norm=0.4495
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0525 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 200] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-1.8273 val_loss=0.0000 scale=2.0000 norm=0.9106
[iter 400] loss=-2.8309 val_loss=0.0000 scale=2.0000 norm=0.8464
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3596 val_loss=0.0000 scale=2.0000 norm=1.0297
[iter 200] loss=-0.2344 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 300] loss=-0.6536 val_loss=0.0000 scale=2.0000 norm=0.9160
[iter 400] loss=-0.9546 val_loss=0.0000 scale=2.0000 norm=0.9212
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4272 val_loss=0.0000 scale=2.0000 norm=1.0443
[iter 200] loss=-0.2681 val_loss=0.0000 scale=2.0000 norm=0.9484
[iter 300] loss=-0.8205 val_loss=0.0000 scale=2.0000 norm=0.8896
[iter 400] loss=-1.1734 val_loss=0.0000 scale=2.0000 norm=0.9051
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4460 val_loss=0.0000 scale=2.0000 norm=1.1109
[iter 200] loss=-0.0697 val_loss=0.0000 scale=1.0000 norm=0.4940
[iter 300] loss=-0.3749 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 400] loss=-0.6137 val_loss=0.0000 scale=1.0000 norm=0.4610
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3335 val_loss=0.0000 scale=2.0000 norm=1.0529
[iter 200] loss=-0.3700 val_loss=0.0000 scale=2.0000 norm=0.9602
[iter 300] loss=-0.9469 val_loss=0.0000 scale=2.0000 norm=0.9249
[iter 400] loss=-1.3077 val_loss=0.0000 scale=2.0000 norm=0.8914
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3923 val_loss=0.0000 scale=2.0000 norm=1.0814
[iter 200] loss=-0.2450 val_loss=0.0000 scale=2.0000 norm=0.9552
[iter 300] loss=-0.7429 val_loss=0.0000 scale=2.0000 norm=0.9089
[iter 400] loss=-1.0403 val_loss=0.0000 scale=1.0000 norm=0.4263
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3370 val_loss=0.0000 scale=2.0000 norm=1.0327
[iter 200] loss=-0.2668 val_loss=0.0000 scale=2.0000 norm=0.9448
[iter 300] loss=-0.6441 val_loss=0.0000 scale=1.0000 norm=0.4424
[iter 400] loss=-0.8664 val_loss=0.0000 scale=2.0000 norm=0.8583
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2225 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.5153 val_loss=0.0000 scale=2.0000 norm=0.8610
[iter 300] loss=-0.9644 val_loss=0.0000 scale=2.0000 norm=0.7729
[iter 400] loss=-1.3407 val_loss=0.0000 scale=2.0000 norm=0.7260
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2986 val_loss=0.0000 scale=2.0000 norm=1.0473
[iter 200] loss=-0.3364 val_loss=0.0000 scale=2.0000 norm=0.9738
[iter 300] loss=-0.8109 val_loss=0.0000 scale=2.0000 norm=0.9237
[iter 400] loss=-1.1126 val_loss=0.0000 scale=1.0000 norm=0.4348
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3379 val_loss=0.0000 scale=2.0000 norm=1.0699
[iter 200] loss=-0.3340 val_loss=0.0000 scale=2.0000 norm=0.9558
[iter 300] loss=-0.8685 val_loss=0.0000 scale=2.0000 norm=0.8987
[iter 400] loss=-1.2249 val_loss=0.0000 scale=1.0000 norm=0.4323
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5115 val_loss=0.0000 scale=2.0000 norm=1.1284
[iter 200] loss=0.0101 val_loss=0.0000 scale=2.0000 norm=1.0154
[iter 300] loss=-0.3552 val_loss=0.0000 scale=1.0000 norm=0.4800
[iter 400] loss=-0.5942 val_loss=0.0000 scale=2.0000 norm=0.9395
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3634 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 200] loss=-0.2411 val_loss=0.0000 scale=2.0000 norm=0.9766
[iter 300] loss=-0.7004 val_loss=0.0000 scale=2.0000 norm=0.9543
[iter 400] loss=-0.9895 val_loss=0.0000 scale=2.0000 norm=0.9464
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4020 val_loss=0.0000 scale=2.0000 norm=1.0744
[iter 200] loss=-0.1818 val_loss=0.0000 scale=1.0000 norm=0.4825
[iter 300] loss=-0.5656 val_loss=0.0000 scale=1.0000 norm=0.4563
[iter 400] loss=-0.7624 val_loss=0.0000 scale=0.5000 norm=0.2246
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4141 val_loss=0.0000 scale=2.0000 norm=1.0927
[iter 200] loss=-0.1543 val_loss=0.0000 scale=2.0000 norm=0.9669
[iter 300] loss=-0.5862 val_loss=0.0000 scale=1.0000 norm=0.4691
[iter 400] loss=-0.8373 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2153 val_loss=0.0000 scale=2.0000 norm=1.0183
[iter 200] loss=-0.4745 val_loss=0.0000 scale=2.0000 norm=0.9906
[iter 300] loss=-1.0077 val_loss=0.0000 scale=2.0000 norm=0.9520
[iter 400] loss=-1.3807 val_loss=0.0000 scale=1.0000 norm=0.4410
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3026 val_loss=0.0000 scale=2.0000 norm=1.0004
[iter 200] loss=-0.3322 val_loss=0.0000 scale=2.0000 norm=0.9217
[iter 300] loss=-0.7985 val_loss=0.0000 scale=2.0000 norm=0.8722
[iter 400] loss=-1.0725 val_loss=0.0000 scale=2.0000 norm=0.8609
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2099 val_loss=0.0000 scale=2.0000 norm=0.9708
[iter 200] loss=-0.6149 val_loss=0.0000 scale=2.0000 norm=0.8964
[iter 300] loss=-1.3679 val_loss=0.0000 scale=2.0000 norm=0.8492
[iter 400] loss=-2.3781 val_loss=0.0000 scale=4.0000 norm=1.6926
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6582 val_loss=0.0000 scale=2.0000 norm=1.1657
[iter 200] loss=0.0855 val_loss=0.0000 scale=1.0000 norm=0.4895
[iter 300] loss=-0.2947 val_loss=0.0000 scale=1.0000 norm=0.4668
[iter 400] loss=-0.5390 val_loss=0.0000 scale=1.0000 norm=0.4761
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3688 val_loss=0.0000 scale=2.0000 norm=1.0484
[iter 200] loss=-0.2838 val_loss=0.0000 scale=2.0000 norm=0.9758
[iter 300] loss=-0.7996 val_loss=0.0000 scale=2.0000 norm=0.9774
[iter 400] loss=-1.1147 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2722 val_loss=0.0000 scale=2.0000 norm=1.0720
[iter 200] loss=-0.4555 val_loss=0.0000 scale=2.0000 norm=0.9825
[iter 300] loss=-1.0551 val_loss=0.0000 scale=2.0000 norm=0.8788
[iter 400] loss=-1.5183 val_loss=0.0000 scale=2.0000 norm=0.8370
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4766 val_loss=0.0000 scale=2.0000 norm=1.0922
[iter 200] loss=-0.2396 val_loss=0.0000 scale=2.0000 norm=0.9698
[iter 300] loss=-0.8788 val_loss=0.0000 scale=2.0000 norm=0.9608
[iter 400] loss=-1.4439 val_loss=0.0000 scale=2.0000 norm=0.9070
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3403 val_loss=0.0000 scale=2.0000 norm=1.0227
[iter 200] loss=-0.2327 val_loss=0.0000 scale=1.0000 norm=0.4690
[iter 300] loss=-0.6182 val_loss=0.0000 scale=2.0000 norm=0.8941
[iter 400] loss=-0.8837 val_loss=0.0000 scale=2.0000 norm=0.8575
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3476 val_loss=0.0000 scale=2.0000 norm=1.0418
[iter 200] loss=-0.2493 val_loss=0.0000 scale=2.0000 norm=0.9444
[iter 300] loss=-0.6501 val_loss=0.0000 scale=1.0000 norm=0.4571
[iter 400] loss=-0.8887 val_loss=0.0000 scale=1.0000 norm=0.4524
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3897 val_loss=0.0000 scale=2.0000 norm=1.0795
[iter 200] loss=-0.1880 val_loss=0.0000 scale=2.0000 norm=0.9589
[iter 300] loss=-0.5489 val_loss=0.0000 scale=2.0000 norm=0.9238
[iter 400] loss=-0.7540 val_loss=0.0000 scale=0.5000 norm=0.2262
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4086 val_loss=0.0000 scale=2.0000 norm=1.0539
[iter 200] loss=-0.1601 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 300] loss=-0.5190 val_loss=0.0000 scale=1.0000 norm=0.4740
[iter 400] loss=-0.7523 val_loss=0.0000 scale=1.0000 norm=0.4575
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3687 val_loss=0.0000 scale=2.0000 norm=1.0085
[iter 200] loss=-0.3719 val_loss=0.0000 scale=2.0000 norm=0.9221
[iter 300] loss=-1.0084 val_loss=0.0000 scale=2.0000 norm=0.8869
[iter 400] loss=-1.4882 val_loss=0.0000 scale=2.0000 norm=0.8636
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4981 val_loss=0.0000 scale=2.0000 norm=1.1303
[iter 200] loss=-0.1582 val_loss=0.0000 scale=2.0000 norm=1.0030
[iter 300] loss=-0.6534 val_loss=0.0000 scale=2.0000 norm=0.9686
[iter 400] loss=-1.0200 val_loss=0.0000 scale=2.0000 norm=0.9532
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2981 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.3175 val_loss=0.0000 scale=2.0000 norm=0.9873
[iter 300] loss=-0.7569 val_loss=0.0000 scale=2.0000 norm=0.9997
[iter 400] loss=-1.0647 val_loss=0.0000 scale=2.0000 norm=0.9381
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2890 val_loss=0.0000 scale=2.0000 norm=1.0432
[iter 200] loss=-0.3661 val_loss=0.0000 scale=2.0000 norm=0.9249
[iter 300] loss=-0.8714 val_loss=0.0000 scale=2.0000 norm=0.8408
[iter 400] loss=-1.2724 val_loss=0.0000 scale=1.0000 norm=0.4111
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7316 val_loss=0.0000 scale=2.0000 norm=1.2335
[iter 200] loss=0.2240 val_loss=0.0000 scale=2.0000 norm=1.0850
[iter 300] loss=-0.1189 val_loss=0.0000 scale=2.0000 norm=1.0294
[iter 400] loss=-0.3396 val_loss=0.0000 scale=1.0000 norm=0.5004
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3710 val_loss=0.0000 scale=2.0000 norm=1.0581
[iter 200] loss=-0.2124 val_loss=0.0000 scale=2.0000 norm=0.9776
[iter 300] loss=-0.6400 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 400] loss=-0.8735 val_loss=0.0000 scale=1.0000 norm=0.4536
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1440 val_loss=0.0000 scale=2.0000 norm=0.9758
[iter 200] loss=-0.7022 val_loss=0.0000 scale=2.0000 norm=0.8801
[iter 300] loss=-1.4316 val_loss=0.0000 scale=2.0000 norm=0.8396
[iter 400] loss=-1.9582 val_loss=0.0000 scale=2.0000 norm=0.7817
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4201 val_loss=0.0000 scale=2.0000 norm=1.0620
[iter 200] loss=-0.1487 val_loss=0.0000 scale=1.0000 norm=0.4785
[iter 300] loss=-0.5999 val_loss=0.0000 scale=2.0000 norm=0.8963
[iter 400] loss=-0.9062 val_loss=0.0000 scale=2.0000 norm=0.8624
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2361 val_loss=0.0000 scale=2.0000 norm=1.0184
[iter 200] loss=-0.4598 val_loss=0.0000 scale=2.0000 norm=0.9802
[iter 300] loss=-1.0377 val_loss=0.0000 scale=2.0000 norm=0.9609
[iter 400] loss=-1.3941 val_loss=0.0000 scale=1.0000 norm=0.4518
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4235 val_loss=0.0000 scale=2.0000 norm=1.1114
[iter 200] loss=-0.1450 val_loss=0.0000 scale=1.0000 norm=0.5070
[iter 300] loss=-0.5311 val_loss=0.0000 scale=1.0000 norm=0.4847
[iter 400] loss=-0.7786 val_loss=0.0000 scale=1.0000 norm=0.4754
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3496 val_loss=0.0000 scale=2.0000 norm=1.0472
[iter 200] loss=-0.3452 val_loss=0.0000 scale=2.0000 norm=0.9410
[iter 300] loss=-0.8783 val_loss=0.0000 scale=2.0000 norm=0.9188
[iter 400] loss=-1.2406 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2109 val_loss=0.0000 scale=2.0000 norm=1.0516
[iter 200] loss=-0.6729 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 300] loss=-1.5425 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 400] loss=-2.3952 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2906 val_loss=0.0000 scale=2.0000 norm=1.0020
[iter 200] loss=-0.3389 val_loss=0.0000 scale=2.0000 norm=0.9036
[iter 300] loss=-0.7256 val_loss=0.0000 scale=2.0000 norm=0.8472
[iter 400] loss=-1.0098 val_loss=0.0000 scale=2.0000 norm=0.8195
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3395 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.2523 val_loss=0.0000 scale=2.0000 norm=0.9418
[iter 300] loss=-0.6859 val_loss=0.0000 scale=2.0000 norm=0.9092
[iter 400] loss=-0.9386 val_loss=0.0000 scale=1.0000 norm=0.4443
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3391 val_loss=0.0000 scale=2.0000 norm=1.0505
[iter 200] loss=-0.3030 val_loss=0.0000 scale=2.0000 norm=0.9705
[iter 300] loss=-0.7746 val_loss=0.0000 scale=2.0000 norm=0.9438
[iter 400] loss=-1.0765 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5301 val_loss=0.0000 scale=2.0000 norm=1.1925
[iter 200] loss=0.0505 val_loss=0.0000 scale=1.0000 norm=0.5455
[iter 300] loss=-0.3410 val_loss=0.0000 scale=2.0000 norm=1.0014
[iter 400] loss=-0.6280 val_loss=0.0000 scale=1.0000 norm=0.4726
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5395 val_loss=0.0000 scale=2.0000 norm=1.1698
[iter 200] loss=0.0767 val_loss=0.0000 scale=2.0000 norm=1.0566
[iter 300] loss=-0.2465 val_loss=0.0000 scale=1.0000 norm=0.5033
[iter 400] loss=-0.4397 val_loss=0.0000 scale=1.0000 norm=0.4983
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3303 val_loss=0.0000 scale=2.0000 norm=1.0485
[iter 200] loss=-0.2917 val_loss=0.0000 scale=2.0000 norm=0.9532
[iter 300] loss=-0.6655 val_loss=0.0000 scale=1.0000 norm=0.4636
[iter 400] loss=-0.9615 val_loss=0.0000 scale=1.0000 norm=0.4482
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4352 val_loss=0.0000 scale=2.0000 norm=1.1086
[iter 200] loss=-0.1173 val_loss=0.0000 scale=2.0000 norm=1.0027
[iter 300] loss=-0.5222 val_loss=0.0000 scale=2.0000 norm=0.9561
[iter 400] loss=-0.7243 val_loss=0.0000 scale=2.0000 norm=0.8932
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5740 val_loss=0.0000 scale=2.0000 norm=1.1389
[iter 200] loss=0.0224 val_loss=0.0000 scale=1.0000 norm=0.4764
[iter 300] loss=-0.3177 val_loss=0.0000 scale=2.0000 norm=0.8836
[iter 400] loss=-0.6626 val_loss=0.0000 scale=2.0000 norm=0.8422
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3654 val_loss=0.0000 scale=2.0000 norm=1.0664
[iter 200] loss=-0.2381 val_loss=0.0000 scale=2.0000 norm=0.9817
[iter 300] loss=-0.6234 val_loss=0.0000 scale=2.0000 norm=0.9076
[iter 400] loss=-0.8746 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2371 val_loss=0.0000 scale=2.0000 norm=1.0193
[iter 200] loss=-0.3918 val_loss=0.0000 scale=2.0000 norm=0.9682
[iter 300] loss=-0.8857 val_loss=0.0000 scale=2.0000 norm=0.9237
[iter 400] loss=-1.1836 val_loss=0.0000 scale=2.0000 norm=0.8624
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2983 val_loss=0.0000 scale=2.0000 norm=0.9993
[iter 200] loss=-0.3692 val_loss=0.0000 scale=2.0000 norm=0.9204
[iter 300] loss=-0.8702 val_loss=0.0000 scale=2.0000 norm=0.8512
[iter 400] loss=-1.1081 val_loss=0.0000 scale=2.0000 norm=0.8918
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4611 val_loss=0.0000 scale=1.0000 norm=0.5438
[iter 200] loss=-0.0368 val_loss=0.0000 scale=2.0000 norm=0.9715
[iter 300] loss=-0.4745 val_loss=0.0000 scale=1.0000 norm=0.4621
[iter 400] loss=-0.6575 val_loss=0.0000 scale=2.0000 norm=0.9119
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5835 val_loss=0.0000 scale=2.0000 norm=1.1707
[iter 200] loss=0.0478 val_loss=0.0000 scale=2.0000 norm=1.0089
[iter 300] loss=-0.3420 val_loss=0.0000 scale=2.0000 norm=0.9724
[iter 400] loss=-0.6008 val_loss=0.0000 scale=2.0000 norm=0.9563
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3610 val_loss=0.0000 scale=2.0000 norm=1.0574
[iter 200] loss=-0.2208 val_loss=0.0000 scale=2.0000 norm=0.9826
[iter 300] loss=-0.6474 val_loss=0.0000 scale=1.0000 norm=0.4707
[iter 400] loss=-0.9042 val_loss=0.0000 scale=0.5000 norm=0.2329
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4659 val_loss=0.0000 scale=2.0000 norm=1.0616
[iter 200] loss=-0.3160 val_loss=0.0000 scale=2.0000 norm=0.9783
[iter 300] loss=-0.9564 val_loss=0.0000 scale=2.0000 norm=0.9582
[iter 400] loss=-1.4634 val_loss=0.0000 scale=2.0000 norm=0.9072
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3981 val_loss=0.0000 scale=2.0000 norm=1.0787
[iter 200] loss=-0.1808 val_loss=0.0000 scale=2.0000 norm=0.9574
[iter 300] loss=-0.5541 val_loss=0.0000 scale=2.0000 norm=0.9238
[iter 400] loss=-0.8596 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2796 val_loss=0.0000 scale=2.0000 norm=1.0114
[iter 200] loss=-0.3290 val_loss=0.0000 scale=2.0000 norm=0.9390
[iter 300] loss=-0.8131 val_loss=0.0000 scale=2.0000 norm=0.9195
[iter 400] loss=-1.2153 val_loss=0.0000 scale=2.0000 norm=0.8727
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3503 val_loss=0.0000 scale=2.0000 norm=1.0755
[iter 200] loss=-0.4048 val_loss=0.0000 scale=2.0000 norm=0.9569
[iter 300] loss=-0.9988 val_loss=0.0000 scale=2.0000 norm=0.8750
[iter 400] loss=-1.4396 val_loss=0.0000 scale=2.0000 norm=0.8162
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4990 val_loss=0.0000 scale=2.0000 norm=1.1187
[iter 200] loss=-0.1293 val_loss=0.0000 scale=2.0000 norm=0.9755
[iter 300] loss=-0.5791 val_loss=0.0000 scale=2.0000 norm=0.9416
[iter 400] loss=-0.9458 val_loss=0.0000 scale=1.0000 norm=0.4630
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3935 val_loss=0.0000 scale=2.0000 norm=1.0995
[iter 200] loss=-0.1801 val_loss=0.0000 scale=2.0000 norm=1.0279
[iter 300] loss=-0.6102 val_loss=0.0000 scale=1.0000 norm=0.4813
[iter 400] loss=-0.8505 val_loss=0.0000 scale=0.5000 norm=0.2453
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5515 val_loss=0.0000 scale=2.0000 norm=1.1189
[iter 200] loss=-0.0675 val_loss=0.0000 scale=2.0000 norm=1.0173
[iter 300] loss=-0.6085 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 400] loss=-1.0054 val_loss=0.0000 scale=2.0000 norm=0.8948
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3403 val_loss=0.0000 scale=2.0000 norm=1.0418
[iter 200] loss=-0.2655 val_loss=0.0000 scale=2.0000 norm=0.9379
[iter 300] loss=-0.6252 val_loss=0.0000 scale=2.0000 norm=0.8998
[iter 400] loss=-0.8407 val_loss=0.0000 scale=2.0000 norm=0.8810
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2700 val_loss=0.0000 scale=2.0000 norm=1.0238
[iter 200] loss=-0.3707 val_loss=0.0000 scale=2.0000 norm=0.9321
[iter 300] loss=-0.8632 val_loss=0.0000 scale=2.0000 norm=0.8726
[iter 400] loss=-1.1839 val_loss=0.0000 scale=1.0000 norm=0.4222
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7552 val_loss=0.0000 scale=2.0000 norm=1.2446
[iter 200] loss=0.2667 val_loss=0.0000 scale=2.0000 norm=1.0872
[iter 300] loss=-0.0559 val_loss=0.0000 scale=1.0000 norm=0.5265
[iter 400] loss=-0.3127 val_loss=0.0000 scale=2.0000 norm=1.0417
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1359 val_loss=0.0000 scale=2.0000 norm=0.9825
[iter 200] loss=-0.7979 val_loss=0.0000 scale=2.0000 norm=0.9354
[iter 300] loss=-1.6830 val_loss=0.0000 scale=2.0000 norm=0.9048
[iter 400] loss=-2.5437 val_loss=0.0000 scale=2.0000 norm=0.8861
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3028 val_loss=0.0000 scale=2.0000 norm=1.0088
[iter 200] loss=-0.3198 val_loss=0.0000 scale=2.0000 norm=0.9647
[iter 300] loss=-0.8529 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 400] loss=-1.2846 val_loss=0.0000 scale=2.0000 norm=0.9315
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3505 val_loss=0.0000 scale=2.0000 norm=1.0586
[iter 200] loss=-0.2733 val_loss=0.0000 scale=2.0000 norm=0.9875
[iter 300] loss=-0.7720 val_loss=0.0000 scale=1.0000 norm=0.4775
[iter 400] loss=-1.0397 val_loss=0.0000 scale=2.0000 norm=0.9081
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 200] loss=-0.6425 val_loss=0.0000 scale=2.0000 norm=0.8688
[iter 300] loss=-1.3411 val_loss=0.0000 scale=2.0000 norm=0.8274
[iter 400] loss=-2.0692 val_loss=0.0000 scale=2.0000 norm=0.7733
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5065 val_loss=0.0000 scale=2.0000 norm=1.1167
[iter 200] loss=0.0251 val_loss=0.0000 scale=2.0000 norm=1.0221
[iter 300] loss=-0.3884 val_loss=0.0000 scale=2.0000 norm=0.9187
[iter 400] loss=-0.6622 val_loss=0.0000 scale=1.0000 norm=0.4429
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4303 val_loss=0.0000 scale=2.0000 norm=1.1106
[iter 200] loss=-0.1750 val_loss=0.0000 scale=2.0000 norm=0.9963
[iter 300] loss=-0.6496 val_loss=0.0000 scale=2.0000 norm=0.9335
[iter 400] loss=-0.9935 val_loss=0.0000 scale=1.0000 norm=0.4440
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5484 val_loss=0.0000 scale=2.0000 norm=1.1981
[iter 200] loss=0.0100 val_loss=0.0000 scale=2.0000 norm=1.0696
[iter 300] loss=-0.3996 val_loss=0.0000 scale=1.0000 norm=0.5047
[iter 400] loss=-0.6444 val_loss=0.0000 scale=2.0000 norm=0.9633
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3736 val_loss=0.0000 scale=2.0000 norm=1.0730
[iter 200] loss=-0.2288 val_loss=0.0000 scale=2.0000 norm=0.9690
[iter 300] loss=-0.7149 val_loss=0.0000 scale=2.0000 norm=0.9349
[iter 400] loss=-1.0659 val_loss=0.0000 scale=1.0000 norm=0.4541
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2873 val_loss=0.0000 scale=2.0000 norm=1.0148
[iter 200] loss=-0.3574 val_loss=0.0000 scale=2.0000 norm=0.9139
[iter 300] loss=-0.8423 val_loss=0.0000 scale=2.0000 norm=0.8590
[iter 400] loss=-1.1668 val_loss=0.0000 scale=1.0000 norm=0.4068
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3922 val_loss=0.0000 scale=2.0000 norm=1.0710
[iter 200] loss=-0.2112 val_loss=0.0000 scale=2.0000 norm=0.9803
[iter 300] loss=-0.6379 val_loss=0.0000 scale=1.0000 norm=0.4724
[iter 400] loss=-0.8880 val_loss=0.0000 scale=2.0000 norm=0.9247
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4418 val_loss=0.0000 scale=2.0000 norm=1.0828
[iter 200] loss=-0.2143 val_loss=0.0000 scale=2.0000 norm=0.9514
[iter 300] loss=-0.6760 val_loss=0.0000 scale=1.0000 norm=0.4498
[iter 400] loss=-0.9637 val_loss=0.0000 scale=2.0000 norm=0.8749
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3544 val_loss=0.0000 scale=2.0000 norm=1.0944
[iter 200] loss=-0.2400 val_loss=0.0000 scale=2.0000 norm=0.9698
[iter 300] loss=-0.6569 val_loss=0.0000 scale=2.0000 norm=0.8754
[iter 400] loss=-0.9815 val_loss=0.0000 scale=1.0000 norm=0.4099
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3378 val_loss=0.0000 scale=2.0000 norm=1.0624
[iter 200] loss=-0.3065 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 300] loss=-0.7381 val_loss=0.0000 scale=1.0000 norm=0.4465
[iter 400] loss=-0.9930 val_loss=0.0000 scale=1.0000 norm=0.4242
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2383 val_loss=0.0000 scale=2.0000 norm=0.9927
[iter 200] loss=-0.5156 val_loss=0.0000 scale=2.0000 norm=0.9481
[iter 300] loss=-1.1666 val_loss=0.0000 scale=2.0000 norm=0.8924
[iter 400] loss=-1.6815 val_loss=0.0000 scale=2.0000 norm=0.8486
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3940 val_loss=0.0000 scale=2.0000 norm=1.0882
[iter 200] loss=-0.1307 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 300] loss=-0.4772 val_loss=0.0000 scale=1.0000 norm=0.4712
[iter 400] loss=-0.7068 val_loss=0.0000 scale=1.0000 norm=0.4565
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5584 val_loss=0.0000 scale=2.0000 norm=1.0266
[iter 200] loss=-0.1027 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 300] loss=-0.5996 val_loss=0.0000 scale=2.0000 norm=0.9311
[iter 400] loss=-0.9913 val_loss=0.0000 scale=2.0000 norm=0.8960
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4889 val_loss=0.0000 scale=2.0000 norm=1.1394
[iter 200] loss=-0.0113 val_loss=0.0000 scale=1.0000 norm=0.5054
[iter 300] loss=-0.3711 val_loss=0.0000 scale=1.0000 norm=0.4948
[iter 400] loss=-0.6231 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2334 val_loss=0.0000 scale=2.0000 norm=0.9848
[iter 200] loss=-0.5270 val_loss=0.0000 scale=2.0000 norm=0.8884
[iter 300] loss=-1.1401 val_loss=0.0000 scale=2.0000 norm=0.8160
[iter 400] loss=-1.6035 val_loss=0.0000 scale=2.0000 norm=0.7720
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2413 val_loss=0.0000 scale=2.0000 norm=1.0019
[iter 200] loss=-0.4676 val_loss=0.0000 scale=2.0000 norm=0.9046
[iter 300] loss=-0.9768 val_loss=0.0000 scale=2.0000 norm=0.8846
[iter 400] loss=-1.3248 val_loss=0.0000 scale=2.0000 norm=0.9043
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3384 val_loss=0.0000 scale=2.0000 norm=1.0536
[iter 200] loss=-0.2930 val_loss=0.0000 scale=2.0000 norm=0.9865
[iter 300] loss=-0.7480 val_loss=0.0000 scale=2.0000 norm=0.9409
[iter 400] loss=-1.0216 val_loss=0.0000 scale=1.0000 norm=0.4580
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3367 val_loss=0.0000 scale=2.0000 norm=1.0453
[iter 200] loss=-0.2712 val_loss=0.0000 scale=2.0000 norm=0.9995
[iter 300] loss=-0.7090 val_loss=0.0000 scale=1.0000 norm=0.4916
[iter 400] loss=-0.9558 val_loss=0.0000 scale=1.0000 norm=0.4812
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1667 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.5902 val_loss=0.0000 scale=2.0000 norm=0.9219
[iter 300] loss=-1.6406 val_loss=0.0000 scale=4.0000 norm=1.7220
[iter 400] loss=-2.6893 val_loss=0.0000 scale=4.0000 norm=1.5187
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3197 val_loss=0.0000 scale=2.0000 norm=1.0281
[iter 200] loss=-0.2772 val_loss=0.0000 scale=2.0000 norm=0.9425
[iter 300] loss=-0.6488 val_loss=0.0000 scale=1.0000 norm=0.4624
[iter 400] loss=-0.8592 val_loss=0.0000 scale=0.5000 norm=0.2237
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4474 val_loss=0.0000 scale=2.0000 norm=1.1201
[iter 200] loss=-0.1051 val_loss=0.0000 scale=2.0000 norm=0.9972
[iter 300] loss=-0.5030 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 400] loss=-0.7348 val_loss=0.0000 scale=1.0000 norm=0.4600
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3665 val_loss=0.0000 scale=2.0000 norm=1.0531
[iter 200] loss=-0.2201 val_loss=0.0000 scale=2.0000 norm=0.9546
[iter 300] loss=-0.5920 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 400] loss=-0.8379 val_loss=0.0000 scale=1.0000 norm=0.4473
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2450 val_loss=0.0000 scale=2.0000 norm=0.9915
[iter 200] loss=-0.4013 val_loss=0.0000 scale=2.0000 norm=0.9363
[iter 300] loss=-0.8666 val_loss=0.0000 scale=2.0000 norm=0.9493
[iter 400] loss=-1.2369 val_loss=0.0000 scale=1.0000 norm=0.4520
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4963 val_loss=0.0000 scale=2.0000 norm=1.1016
[iter 200] loss=-0.0532 val_loss=0.0000 scale=2.0000 norm=0.9828
[iter 300] loss=-0.4094 val_loss=0.0000 scale=1.0000 norm=0.4825
[iter 400] loss=-0.6108 val_loss=0.0000 scale=1.0000 norm=0.4820
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4620 val_loss=0.0000 scale=2.0000 norm=1.0555
[iter 200] loss=-0.3029 val_loss=0.0000 scale=2.0000 norm=0.9356
[iter 300] loss=-0.9945 val_loss=0.0000 scale=2.0000 norm=0.8574
[iter 400] loss=-1.5594 val_loss=0.0000 scale=2.0000 norm=0.8190
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2615 val_loss=0.0000 scale=2.0000 norm=1.0298
[iter 200] loss=-0.3705 val_loss=0.0000 scale=2.0000 norm=0.9578
[iter 300] loss=-0.8553 val_loss=0.0000 scale=2.0000 norm=0.9373
[iter 400] loss=-1.1418 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3939 val_loss=0.0000 scale=2.0000 norm=1.0718
[iter 200] loss=-0.1694 val_loss=0.0000 scale=2.0000 norm=0.9642
[iter 300] loss=-0.5241 val_loss=0.0000 scale=1.0000 norm=0.4714
[iter 400] loss=-0.7783 val_loss=0.0000 scale=2.0000 norm=0.9417
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4092 val_loss=0.0000 scale=2.0000 norm=1.0746
[iter 200] loss=-0.1522 val_loss=0.0000 scale=2.0000 norm=0.9558
[iter 300] loss=-0.5489 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 400] loss=-0.7618 val_loss=0.0000 scale=1.0000 norm=0.4531
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2957 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.3686 val_loss=0.0000 scale=2.0000 norm=0.9285
[iter 300] loss=-0.8612 val_loss=0.0000 scale=1.0000 norm=0.4495
[iter 400] loss=-1.2055 val_loss=0.0000 scale=1.0000 norm=0.4430
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6179 val_loss=0.0000 scale=2.0000 norm=1.1788
[iter 200] loss=0.0230 val_loss=0.0000 scale=2.0000 norm=1.0297
[iter 300] loss=-0.3653 val_loss=0.0000 scale=2.0000 norm=0.9908
[iter 400] loss=-0.6167 val_loss=0.0000 scale=1.0000 norm=0.4965
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2990 val_loss=0.0000 scale=2.0000 norm=1.0083
[iter 200] loss=-0.3353 val_loss=0.0000 scale=2.0000 norm=0.9270
[iter 300] loss=-0.7653 val_loss=0.0000 scale=2.0000 norm=0.9075
[iter 400] loss=-1.0025 val_loss=0.0000 scale=2.0000 norm=0.9514
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3621 val_loss=0.0000 scale=2.0000 norm=1.0524
[iter 200] loss=-0.1910 val_loss=0.0000 scale=1.0000 norm=0.4856
[iter 300] loss=-0.5523 val_loss=0.0000 scale=2.0000 norm=0.9511
[iter 400] loss=-0.7916 val_loss=0.0000 scale=2.0000 norm=0.9148
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5257 val_loss=0.0000 scale=2.0000 norm=1.2160
[iter 200] loss=-0.1832 val_loss=0.0000 scale=2.0000 norm=1.1398
[iter 300] loss=-0.7256 val_loss=0.0000 scale=2.0000 norm=1.0639
[iter 400] loss=-1.1107 val_loss=0.0000 scale=2.0000 norm=1.0799
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5174 val_loss=0.0000 scale=2.0000 norm=1.1423
[iter 200] loss=0.0400 val_loss=0.0000 scale=2.0000 norm=1.0034
[iter 300] loss=-0.2903 val_loss=0.0000 scale=1.0000 norm=0.4706
[iter 400] loss=-0.4984 val_loss=0.0000 scale=1.0000 norm=0.4582
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2903 val_loss=0.0000 scale=2.0000 norm=1.0280
[iter 200] loss=-0.3668 val_loss=0.0000 scale=2.0000 norm=0.9282
[iter 300] loss=-0.8589 val_loss=0.0000 scale=2.0000 norm=0.8738
[iter 400] loss=-1.1656 val_loss=0.0000 scale=1.0000 norm=0.4124
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4269 val_loss=0.0000 scale=2.0000 norm=0.9912
[iter 200] loss=-0.5136 val_loss=0.0000 scale=2.0000 norm=0.9306
[iter 300] loss=-1.3571 val_loss=0.0000 scale=2.0000 norm=0.8498
[iter 400] loss=-2.5516 val_loss=0.0000 scale=4.0000 norm=1.5770
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3513 val_loss=0.0000 scale=2.0000 norm=1.0634
[iter 200] loss=-0.2377 val_loss=0.0000 scale=2.0000 norm=0.9627
[iter 300] loss=-0.6654 val_loss=0.0000 scale=1.0000 norm=0.4685
[iter 400] loss=-0.9250 val_loss=0.0000 scale=1.0000 norm=0.4695
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3759 val_loss=0.0000 scale=2.0000 norm=1.0511
[iter 200] loss=-0.1847 val_loss=0.0000 scale=2.0000 norm=0.9454
[iter 300] loss=-0.5412 val_loss=0.0000 scale=2.0000 norm=0.8920
[iter 400] loss=-0.7773 val_loss=0.0000 scale=2.0000 norm=0.8561
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3589 val_loss=0.0000 scale=2.0000 norm=1.0493
[iter 200] loss=-0.2047 val_loss=0.0000 scale=1.0000 norm=0.4787
[iter 300] loss=-0.6348 val_loss=0.0000 scale=2.0000 norm=0.9062
[iter 400] loss=-0.8730 val_loss=0.0000 scale=2.0000 norm=0.9049
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3547 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 200] loss=-0.3183 val_loss=0.0000 scale=2.0000 norm=0.9579
[iter 300] loss=-0.8581 val_loss=0.0000 scale=2.0000 norm=0.8961
[iter 400] loss=-1.2603 val_loss=0.0000 scale=2.0000 norm=0.8891
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3045 val_loss=0.0000 scale=2.0000 norm=1.0702
[iter 200] loss=-0.4193 val_loss=0.0000 scale=2.0000 norm=0.9512
[iter 300] loss=-1.0589 val_loss=0.0000 scale=2.0000 norm=0.8782
[iter 400] loss=-1.5197 val_loss=0.0000 scale=2.0000 norm=0.8050
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5188 val_loss=0.0000 scale=2.0000 norm=1.1412
[iter 200] loss=0.0174 val_loss=0.0000 scale=2.0000 norm=1.0500
[iter 300] loss=-0.3517 val_loss=0.0000 scale=1.0000 norm=0.5073
[iter 400] loss=-0.5971 val_loss=0.0000 scale=1.0000 norm=0.5005
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4066 val_loss=0.0000 scale=2.0000 norm=1.0870
[iter 200] loss=-0.1980 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 300] loss=-0.6102 val_loss=0.0000 scale=1.0000 norm=0.4478
[iter 400] loss=-0.8804 val_loss=0.0000 scale=1.0000 norm=0.4176
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3744 val_loss=0.0000 scale=2.0000 norm=1.0664
[iter 200] loss=-0.2508 val_loss=0.0000 scale=2.0000 norm=0.9498
[iter 300] loss=-0.7097 val_loss=0.0000 scale=2.0000 norm=0.9020
[iter 400] loss=-1.0158 val_loss=0.0000 scale=1.0000 norm=0.4292
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5167 val_loss=0.0000 scale=2.0000 norm=1.0941
[iter 200] loss=-0.0638 val_loss=0.0000 scale=2.0000 norm=0.9094
[iter 300] loss=-0.5250 val_loss=0.0000 scale=1.0000 norm=0.4057
[iter 400] loss=-0.8209 val_loss=0.0000 scale=1.0000 norm=0.3817
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3523 val_loss=0.0000 scale=2.0000 norm=1.0569
[iter 200] loss=-0.3801 val_loss=0.0000 scale=2.0000 norm=1.0158
[iter 300] loss=-1.2856 val_loss=0.0000 scale=4.0000 norm=2.1213
[iter 400] loss=-2.2787 val_loss=0.0000 scale=4.0000 norm=1.9942
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3867 val_loss=0.0000 scale=2.0000 norm=1.0665
[iter 200] loss=-0.1566 val_loss=0.0000 scale=2.0000 norm=0.9818
[iter 300] loss=-0.5163 val_loss=0.0000 scale=2.0000 norm=0.9582
[iter 400] loss=-0.7770 val_loss=0.0000 scale=1.0000 norm=0.4711
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3174 val_loss=0.0000 scale=2.0000 norm=1.0235
[iter 200] loss=-0.2994 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 300] loss=-0.7481 val_loss=0.0000 scale=2.0000 norm=0.9198
[iter 400] loss=-1.0083 val_loss=0.0000 scale=1.0000 norm=0.4519
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3032 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 200] loss=-0.3594 val_loss=0.0000 scale=2.0000 norm=0.9911
[iter 300] loss=-0.9027 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 400] loss=-1.2964 val_loss=0.0000 scale=2.0000 norm=0.8978
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3655 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.4351 val_loss=0.0000 scale=2.0000 norm=1.0192
[iter 300] loss=-1.2732 val_loss=0.0000 scale=2.0000 norm=1.0588
[iter 400] loss=-2.0394 val_loss=0.0000 scale=2.0000 norm=1.0608
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5196 val_loss=0.0000 scale=2.0000 norm=1.1265
[iter 200] loss=0.0890 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 300] loss=-0.1757 val_loss=0.0000 scale=1.0000 norm=0.4689
[iter 400] loss=-0.3799 val_loss=0.0000 scale=1.0000 norm=0.4527
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3188 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.2753 val_loss=0.0000 scale=2.0000 norm=0.9449
[iter 300] loss=-0.6505 val_loss=0.0000 scale=2.0000 norm=0.9085
[iter 400] loss=-0.9776 val_loss=0.0000 scale=1.0000 norm=0.4437
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3650 val_loss=0.0000 scale=2.0000 norm=1.0509
[iter 200] loss=-0.2392 val_loss=0.0000 scale=2.0000 norm=0.9647
[iter 300] loss=-0.6060 val_loss=0.0000 scale=2.0000 norm=0.9524
[iter 400] loss=-0.8422 val_loss=0.0000 scale=0.5000 norm=0.2329
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2925 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3347 val_loss=0.0000 scale=2.0000 norm=0.8957
[iter 300] loss=-0.7738 val_loss=0.0000 scale=1.0000 norm=0.4124
[iter 400] loss=-1.0396 val_loss=0.0000 scale=2.0000 norm=0.8099
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2827 val_loss=0.0000 scale=2.0000 norm=1.0017
[iter 200] loss=-0.3409 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 300] loss=-0.8683 val_loss=0.0000 scale=2.0000 norm=0.9031
[iter 400] loss=-1.2710 val_loss=0.0000 scale=1.0000 norm=0.4380
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4241 val_loss=0.0000 scale=2.0000 norm=1.0780
[iter 200] loss=-0.1570 val_loss=0.0000 scale=2.0000 norm=0.9724
[iter 300] loss=-0.5358 val_loss=0.0000 scale=2.0000 norm=0.9624
[iter 400] loss=-0.7809 val_loss=0.0000 scale=1.0000 norm=0.4853
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3926 val_loss=0.0000 scale=2.0000 norm=1.0621
[iter 200] loss=-0.3056 val_loss=0.0000 scale=2.0000 norm=0.9287
[iter 300] loss=-0.8480 val_loss=0.0000 scale=1.0000 norm=0.4363
[iter 400] loss=-1.1828 val_loss=0.0000 scale=2.0000 norm=0.8446
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3593 val_loss=0.0000 scale=2.0000 norm=1.0654
[iter 200] loss=-0.2164 val_loss=0.0000 scale=2.0000 norm=0.9780
[iter 300] loss=-0.5752 val_loss=0.0000 scale=2.0000 norm=0.9595
[iter 400] loss=-0.8080 val_loss=0.0000 scale=1.0000 norm=0.4634
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5233 val_loss=0.0000 scale=2.0000 norm=1.1032
[iter 200] loss=-0.0328 val_loss=0.0000 scale=2.0000 norm=0.9695
[iter 300] loss=-0.5868 val_loss=0.0000 scale=1.0000 norm=0.4443
[iter 400] loss=-1.0626 val_loss=0.0000 scale=2.0000 norm=0.8401
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3125 val_loss=0.0000 scale=2.0000 norm=1.0237
[iter 200] loss=-0.3178 val_loss=0.0000 scale=2.0000 norm=0.9926
[iter 300] loss=-0.8292 val_loss=0.0000 scale=2.0000 norm=0.9520
[iter 400] loss=-1.1323 val_loss=0.0000 scale=1.0000 norm=0.4835
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3074 val_loss=0.0000 scale=2.0000 norm=1.0237
[iter 200] loss=-0.3413 val_loss=0.0000 scale=2.0000 norm=0.9208
[iter 300] loss=-0.7608 val_loss=0.0000 scale=2.0000 norm=0.9244
[iter 400] loss=-1.0732 val_loss=0.0000 scale=2.0000 norm=0.9030
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4473 val_loss=0.0000 scale=2.0000 norm=1.1152
[iter 200] loss=-0.0631 val_loss=0.0000 scale=2.0000 norm=1.0035
[iter 300] loss=-0.4147 val_loss=0.0000 scale=1.0000 norm=0.4781
[iter 400] loss=-0.6232 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3266 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2782 val_loss=0.0000 scale=2.0000 norm=0.9360
[iter 300] loss=-0.7114 val_loss=0.0000 scale=2.0000 norm=0.9227
[iter 400] loss=-0.9488 val_loss=0.0000 scale=1.0000 norm=0.4508
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3458 val_loss=0.0000 scale=2.0000 norm=1.0360
[iter 200] loss=-0.2813 val_loss=0.0000 scale=2.0000 norm=0.9153
[iter 300] loss=-0.7292 val_loss=0.0000 scale=2.0000 norm=0.8739
[iter 400] loss=-1.0016 val_loss=0.0000 scale=2.0000 norm=0.8485
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6783 val_loss=0.0000 scale=1.0000 norm=0.5965
[iter 200] loss=0.1716 val_loss=0.0000 scale=2.0000 norm=1.0451
[iter 300] loss=-0.2660 val_loss=0.0000 scale=2.0000 norm=0.9634
[iter 400] loss=-0.5135 val_loss=0.0000 scale=1.0000 norm=0.4576
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3254 val_loss=0.0000 scale=2.0000 norm=0.9669
[iter 200] loss=-0.6469 val_loss=0.0000 scale=2.0000 norm=0.9621
[iter 300] loss=-1.6708 val_loss=0.0000 scale=2.0000 norm=0.9294
[iter 400] loss=-2.5304 val_loss=0.0000 scale=2.0000 norm=0.8704
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5226 val_loss=0.0000 scale=2.0000 norm=1.1578
[iter 200] loss=-0.0125 val_loss=0.0000 scale=2.0000 norm=1.0470
[iter 300] loss=-0.3798 val_loss=0.0000 scale=1.0000 norm=0.4838
[iter 400] loss=-0.5450 val_loss=0.0000 scale=0.5000 norm=0.2346
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3412 val_loss=0.0000 scale=2.0000 norm=1.0416
[iter 200] loss=-0.2593 val_loss=0.0000 scale=2.0000 norm=0.9438
[iter 300] loss=-0.6743 val_loss=0.0000 scale=2.0000 norm=0.9268
[iter 400] loss=-0.9005 val_loss=0.0000 scale=1.0000 norm=0.4491

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n12>
Subject: Job 861714: <structure_numerical_ecfp3binery_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_ecfp3binery_NGB_generalizibility> was submitted from host <c205n12> by user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:00 2024
Job was executed on host(s) <4*c207n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:00 2024
                            <4*c207n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Thu Oct 24 11:35:00 2024
Terminated at Thu Oct 24 11:38:18 2024
Results reported at Thu Oct 24 11:38:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 7:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_ecfp3binery_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py ecfp --regressor_type NGB --radius 3 --vector binary --target "Rg1 (nm)" --oligo_type "Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1975.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.12 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   198 sec.
    Turnaround time :                            198 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err> for stderr output of this job.

polymer representation: RRU Dimer
Trimer_scaler
Filename: (ECFP3.binary.512-Mw-PDI)_NGB_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer_scaler/(ECFP3.binary.512-Mw-PDI)_NGB_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5159 val_loss=0.0000 scale=2.0000 norm=1.1795
[iter 200] loss=-0.0123 val_loss=0.0000 scale=2.0000 norm=1.0784
[iter 300] loss=-0.4356 val_loss=0.0000 scale=2.0000 norm=1.0301
[iter 400] loss=-0.6959 val_loss=0.0000 scale=1.0000 norm=0.4916
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2086 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 200] loss=-0.6637 val_loss=0.0000 scale=2.0000 norm=0.8957
[iter 300] loss=-1.5072 val_loss=0.0000 scale=2.0000 norm=0.8807
[iter 400] loss=-2.3413 val_loss=0.0000 scale=2.0000 norm=0.8802
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3012 val_loss=0.0000 scale=2.0000 norm=1.0282
[iter 200] loss=-0.3246 val_loss=0.0000 scale=2.0000 norm=0.9610
[iter 300] loss=-0.7752 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 400] loss=-1.0572 val_loss=0.0000 scale=1.0000 norm=0.4441
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5155 val_loss=0.0000 scale=2.0000 norm=1.1423
[iter 200] loss=0.0029 val_loss=0.0000 scale=2.0000 norm=1.0455
[iter 300] loss=-0.3495 val_loss=0.0000 scale=1.0000 norm=0.5053
[iter 400] loss=-0.6423 val_loss=0.0000 scale=1.0000 norm=0.4835
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4040 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.2087 val_loss=0.0000 scale=2.0000 norm=0.9538
[iter 300] loss=-0.6365 val_loss=0.0000 scale=1.0000 norm=0.4403
[iter 400] loss=-0.8753 val_loss=0.0000 scale=1.0000 norm=0.4105
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6475 val_loss=0.0000 scale=2.0000 norm=1.1072
[iter 200] loss=-0.0175 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 300] loss=-0.5835 val_loss=0.0000 scale=2.0000 norm=0.9853
[iter 400] loss=-0.9917 val_loss=0.0000 scale=2.0000 norm=0.9370
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4349 val_loss=0.0000 scale=2.0000 norm=1.0653
[iter 200] loss=-0.2387 val_loss=0.0000 scale=2.0000 norm=0.8945
[iter 300] loss=-0.6734 val_loss=0.0000 scale=1.0000 norm=0.4092
[iter 400] loss=-0.9639 val_loss=0.0000 scale=1.0000 norm=0.3869
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2712 val_loss=0.0000 scale=2.0000 norm=1.0244
[iter 200] loss=-0.3708 val_loss=0.0000 scale=2.0000 norm=0.9327
[iter 300] loss=-0.8667 val_loss=0.0000 scale=2.0000 norm=0.8710
[iter 400] loss=-1.1923 val_loss=0.0000 scale=1.0000 norm=0.4229
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6980 val_loss=0.0000 scale=2.0000 norm=1.2270
[iter 200] loss=0.0861 val_loss=0.0000 scale=2.0000 norm=1.0402
[iter 300] loss=-0.4397 val_loss=0.0000 scale=2.0000 norm=0.9584
[iter 400] loss=-0.8378 val_loss=0.0000 scale=2.0000 norm=0.9212
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1929 val_loss=0.0000 scale=2.0000 norm=0.9923
[iter 200] loss=-0.5695 val_loss=0.0000 scale=2.0000 norm=0.9319
[iter 300] loss=-1.1682 val_loss=0.0000 scale=2.0000 norm=0.8825
[iter 400] loss=-1.5964 val_loss=0.0000 scale=2.0000 norm=0.8688
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2299 val_loss=0.0000 scale=2.0000 norm=0.9731
[iter 200] loss=-0.7279 val_loss=0.0000 scale=2.0000 norm=0.9612
[iter 300] loss=-1.8005 val_loss=0.0000 scale=4.0000 norm=1.8801
[iter 400] loss=-3.0629 val_loss=0.0000 scale=2.0000 norm=0.8839
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2890 val_loss=0.0000 scale=2.0000 norm=1.0202
[iter 200] loss=-0.4410 val_loss=0.0000 scale=2.0000 norm=0.9409
[iter 300] loss=-1.0485 val_loss=0.0000 scale=2.0000 norm=0.8855
[iter 400] loss=-1.5214 val_loss=0.0000 scale=1.0000 norm=0.4339
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4662 val_loss=0.0000 scale=2.0000 norm=1.0905
[iter 200] loss=-0.2456 val_loss=0.0000 scale=2.0000 norm=0.9743
[iter 300] loss=-0.8894 val_loss=0.0000 scale=2.0000 norm=0.9703
[iter 400] loss=-1.4410 val_loss=0.0000 scale=2.0000 norm=0.8898
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2892 val_loss=0.0000 scale=2.0000 norm=1.0164
[iter 200] loss=-0.3554 val_loss=0.0000 scale=2.0000 norm=0.9177
[iter 300] loss=-0.8221 val_loss=0.0000 scale=2.0000 norm=0.8686
[iter 400] loss=-1.1284 val_loss=0.0000 scale=1.0000 norm=0.4163
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5503 val_loss=0.0000 scale=2.0000 norm=1.1674
[iter 200] loss=-0.1281 val_loss=0.0000 scale=2.0000 norm=1.0837
[iter 300] loss=-0.6404 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 400] loss=-0.9573 val_loss=0.0000 scale=1.0000 norm=0.5320
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1899 val_loss=0.0000 scale=2.0000 norm=0.9854
[iter 200] loss=-0.7104 val_loss=0.0000 scale=2.0000 norm=0.9274
[iter 300] loss=-1.5212 val_loss=0.0000 scale=2.0000 norm=0.8794
[iter 400] loss=-2.2949 val_loss=0.0000 scale=2.0000 norm=0.8595
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4575 val_loss=0.0000 scale=2.0000 norm=1.1080
[iter 200] loss=-0.0671 val_loss=0.0000 scale=2.0000 norm=1.0282
[iter 300] loss=-0.4192 val_loss=0.0000 scale=1.0000 norm=0.4901
[iter 400] loss=-0.6521 val_loss=0.0000 scale=1.0000 norm=0.4706
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6058 val_loss=0.0000 scale=2.0000 norm=1.1372
[iter 200] loss=0.0196 val_loss=0.0000 scale=2.0000 norm=1.0155
[iter 300] loss=-0.4619 val_loss=0.0000 scale=2.0000 norm=1.0007
[iter 400] loss=-0.8157 val_loss=0.0000 scale=2.0000 norm=0.9437
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3127 val_loss=0.0000 scale=2.0000 norm=1.0238
[iter 200] loss=-0.3169 val_loss=0.0000 scale=2.0000 norm=0.9921
[iter 300] loss=-0.8209 val_loss=0.0000 scale=2.0000 norm=0.9530
[iter 400] loss=-1.1381 val_loss=0.0000 scale=1.0000 norm=0.4747
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3724 val_loss=0.0000 scale=2.0000 norm=1.0475
[iter 200] loss=-0.1837 val_loss=0.0000 scale=2.0000 norm=0.9363
[iter 300] loss=-0.5682 val_loss=0.0000 scale=1.0000 norm=0.4674
[iter 400] loss=-0.8179 val_loss=0.0000 scale=1.0000 norm=0.4501
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3577 val_loss=0.0000 scale=2.0000 norm=1.0504
[iter 200] loss=-0.2236 val_loss=0.0000 scale=2.0000 norm=0.9815
[iter 300] loss=-0.6046 val_loss=0.0000 scale=2.0000 norm=0.9267
[iter 400] loss=-0.8444 val_loss=0.0000 scale=2.0000 norm=0.8949
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3561 val_loss=0.0000 scale=2.0000 norm=1.0318
[iter 200] loss=-0.3337 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 300] loss=-0.8249 val_loss=0.0000 scale=2.0000 norm=0.9376
[iter 400] loss=-1.1657 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3614 val_loss=0.0000 scale=2.0000 norm=1.0501
[iter 200] loss=-0.1923 val_loss=0.0000 scale=1.0000 norm=0.4850
[iter 300] loss=-0.5612 val_loss=0.0000 scale=2.0000 norm=0.9694
[iter 400] loss=-0.8751 val_loss=0.0000 scale=2.0000 norm=0.9263
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2675 val_loss=0.0000 scale=2.0000 norm=1.0331
[iter 200] loss=-0.3956 val_loss=0.0000 scale=2.0000 norm=0.9867
[iter 300] loss=-0.9168 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 400] loss=-1.2090 val_loss=0.0000 scale=1.0000 norm=0.4446
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5124 val_loss=0.0000 scale=2.0000 norm=1.1497
[iter 200] loss=0.0417 val_loss=0.0000 scale=2.0000 norm=1.0334
[iter 300] loss=-0.2867 val_loss=0.0000 scale=1.0000 norm=0.4823
[iter 400] loss=-0.4691 val_loss=0.0000 scale=0.5000 norm=0.2306
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4047 val_loss=0.0000 scale=2.0000 norm=1.1310
[iter 200] loss=-0.1952 val_loss=0.0000 scale=2.0000 norm=1.0835
[iter 300] loss=-0.6808 val_loss=0.0000 scale=2.0000 norm=1.0677
[iter 400] loss=-1.0565 val_loss=0.0000 scale=2.0000 norm=1.0318
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3790 val_loss=0.0000 scale=2.0000 norm=1.0788
[iter 200] loss=-0.2427 val_loss=0.0000 scale=1.0000 norm=0.4803
[iter 300] loss=-0.6433 val_loss=0.0000 scale=1.0000 norm=0.4572
[iter 400] loss=-0.9425 val_loss=0.0000 scale=2.0000 norm=0.8811
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2788 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 200] loss=-0.3413 val_loss=0.0000 scale=1.0000 norm=0.4677
[iter 300] loss=-0.7434 val_loss=0.0000 scale=1.0000 norm=0.4525
[iter 400] loss=-1.0669 val_loss=0.0000 scale=2.0000 norm=0.8102
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3547 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 200] loss=-0.3209 val_loss=0.0000 scale=2.0000 norm=0.9624
[iter 300] loss=-0.8639 val_loss=0.0000 scale=2.0000 norm=0.8953
[iter 400] loss=-1.2260 val_loss=0.0000 scale=1.0000 norm=0.4359
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3792 val_loss=0.0000 scale=2.0000 norm=1.0407
[iter 200] loss=-0.2270 val_loss=0.0000 scale=2.0000 norm=0.9349
[iter 300] loss=-0.6399 val_loss=0.0000 scale=2.0000 norm=0.9047
[iter 400] loss=-0.8891 val_loss=0.0000 scale=1.0000 norm=0.4453
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2897 val_loss=0.0000 scale=2.0000 norm=1.0228
[iter 200] loss=-0.3677 val_loss=0.0000 scale=2.0000 norm=0.9155
[iter 300] loss=-0.8654 val_loss=0.0000 scale=2.0000 norm=0.8624
[iter 400] loss=-1.1708 val_loss=0.0000 scale=1.0000 norm=0.4204
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6200 val_loss=0.0000 scale=2.0000 norm=1.1280
[iter 200] loss=-0.0120 val_loss=0.0000 scale=2.0000 norm=1.0245
[iter 300] loss=-0.4866 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 400] loss=-0.7903 val_loss=0.0000 scale=2.0000 norm=0.9057
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3065 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3424 val_loss=0.0000 scale=2.0000 norm=0.9218
[iter 300] loss=-0.7825 val_loss=0.0000 scale=2.0000 norm=0.9168
[iter 400] loss=-1.0719 val_loss=0.0000 scale=1.0000 norm=0.4491
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6747 val_loss=0.0000 scale=2.0000 norm=1.1968
[iter 200] loss=0.2104 val_loss=0.0000 scale=1.0000 norm=0.5311
[iter 300] loss=-0.0695 val_loss=0.0000 scale=1.0000 norm=0.5050
[iter 400] loss=-0.2516 val_loss=0.0000 scale=1.0000 norm=0.4904
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3727 val_loss=0.0000 scale=2.0000 norm=1.0599
[iter 200] loss=-0.1862 val_loss=0.0000 scale=1.0000 norm=0.4875
[iter 300] loss=-0.6017 val_loss=0.0000 scale=1.0000 norm=0.4601
[iter 400] loss=-0.8556 val_loss=0.0000 scale=1.0000 norm=0.4362
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3596 val_loss=0.0000 scale=2.0000 norm=1.0297
[iter 200] loss=-0.2326 val_loss=0.0000 scale=2.0000 norm=0.9325
[iter 300] loss=-0.6787 val_loss=0.0000 scale=2.0000 norm=0.9181
[iter 400] loss=-0.9543 val_loss=0.0000 scale=2.0000 norm=0.9424
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2099 val_loss=0.0000 scale=2.0000 norm=0.9708
[iter 200] loss=-0.6149 val_loss=0.0000 scale=2.0000 norm=0.8964
[iter 300] loss=-1.3679 val_loss=0.0000 scale=2.0000 norm=0.8492
[iter 400] loss=-2.3781 val_loss=0.0000 scale=4.0000 norm=1.6926
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5248 val_loss=0.0000 scale=2.0000 norm=1.2155
[iter 200] loss=-0.1842 val_loss=0.0000 scale=2.0000 norm=1.1393
[iter 300] loss=-0.7346 val_loss=0.0000 scale=2.0000 norm=1.0466
[iter 400] loss=-1.1148 val_loss=0.0000 scale=2.0000 norm=1.0825
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4849 val_loss=0.0000 scale=2.0000 norm=1.0239
[iter 200] loss=-0.3742 val_loss=0.0000 scale=2.0000 norm=0.8869
[iter 300] loss=-1.0706 val_loss=0.0000 scale=2.0000 norm=0.8072
[iter 400] loss=-1.6962 val_loss=0.0000 scale=2.0000 norm=0.7808
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3496 val_loss=0.0000 scale=2.0000 norm=1.0472
[iter 200] loss=-0.3414 val_loss=0.0000 scale=2.0000 norm=0.9425
[iter 300] loss=-0.9000 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 400] loss=-1.2600 val_loss=0.0000 scale=2.0000 norm=0.8847
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2592 val_loss=0.0000 scale=2.0000 norm=1.0134
[iter 200] loss=-0.4361 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 300] loss=-1.0404 val_loss=0.0000 scale=2.0000 norm=0.8774
[iter 400] loss=-1.4978 val_loss=0.0000 scale=2.0000 norm=0.8014
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1632 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 200] loss=-0.7202 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 300] loss=-1.6585 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 400] loss=-2.4145 val_loss=0.0000 scale=2.0000 norm=0.8686
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4284 val_loss=0.0000 scale=2.0000 norm=1.0867
[iter 200] loss=-0.1566 val_loss=0.0000 scale=2.0000 norm=0.9701
[iter 300] loss=-0.5743 val_loss=0.0000 scale=2.0000 norm=0.9435
[iter 400] loss=-0.7975 val_loss=0.0000 scale=1.0000 norm=0.4676
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4378 val_loss=0.0000 scale=2.0000 norm=1.0812
[iter 200] loss=-0.1414 val_loss=0.0000 scale=2.0000 norm=0.9638
[iter 300] loss=-0.6138 val_loss=0.0000 scale=2.0000 norm=0.9106
[iter 400] loss=-0.8934 val_loss=0.0000 scale=2.0000 norm=0.9008
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3532 val_loss=0.0000 scale=2.0000 norm=1.0702
[iter 200] loss=-0.2281 val_loss=0.0000 scale=2.0000 norm=0.9847
[iter 300] loss=-0.5877 val_loss=0.0000 scale=1.0000 norm=0.4723
[iter 400] loss=-0.8043 val_loss=0.0000 scale=1.0000 norm=0.4712
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5897 val_loss=0.0000 scale=2.0000 norm=1.1840
[iter 200] loss=0.0818 val_loss=0.0000 scale=1.0000 norm=0.5421
[iter 300] loss=-0.1959 val_loss=0.0000 scale=1.0000 norm=0.5242
[iter 400] loss=-0.4115 val_loss=0.0000 scale=1.0000 norm=0.5043
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3113 val_loss=0.0000 scale=2.0000 norm=1.0134
[iter 200] loss=-0.3332 val_loss=0.0000 scale=2.0000 norm=0.9410
[iter 300] loss=-0.7961 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 400] loss=-1.0849 val_loss=0.0000 scale=1.0000 norm=0.4450
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4342 val_loss=0.0000 scale=2.0000 norm=1.0866
[iter 200] loss=-0.1011 val_loss=0.0000 scale=2.0000 norm=0.9704
[iter 300] loss=-0.4604 val_loss=0.0000 scale=2.0000 norm=0.9485
[iter 400] loss=-0.6946 val_loss=0.0000 scale=2.0000 norm=0.9228
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1286 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 200] loss=-0.7766 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-1.6605 val_loss=0.0000 scale=2.0000 norm=0.8486
[iter 400] loss=-2.9146 val_loss=0.0000 scale=4.0000 norm=1.5998
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3720 val_loss=0.0000 scale=2.0000 norm=1.0438
[iter 200] loss=-0.2132 val_loss=0.0000 scale=2.0000 norm=0.9307
[iter 300] loss=-0.6086 val_loss=0.0000 scale=2.0000 norm=0.9164
[iter 400] loss=-0.8877 val_loss=0.0000 scale=1.0000 norm=0.4421
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3980 val_loss=0.0000 scale=2.0000 norm=1.0302
[iter 200] loss=-0.2121 val_loss=0.0000 scale=2.0000 norm=0.9244
[iter 300] loss=-0.6548 val_loss=0.0000 scale=2.0000 norm=0.8914
[iter 400] loss=-0.9849 val_loss=0.0000 scale=1.0000 norm=0.4378
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1667 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.5902 val_loss=0.0000 scale=2.0000 norm=0.9219
[iter 300] loss=-1.6406 val_loss=0.0000 scale=4.0000 norm=1.7220
[iter 400] loss=-2.6893 val_loss=0.0000 scale=4.0000 norm=1.5187
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3265 val_loss=0.0000 scale=2.0000 norm=1.0327
[iter 200] loss=-0.3064 val_loss=0.0000 scale=2.0000 norm=0.9690
[iter 300] loss=-0.7748 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 400] loss=-1.0587 val_loss=0.0000 scale=2.0000 norm=0.8885
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3691 val_loss=0.0000 scale=2.0000 norm=1.0539
[iter 200] loss=-0.2365 val_loss=0.0000 scale=2.0000 norm=0.9528
[iter 300] loss=-0.6624 val_loss=0.0000 scale=2.0000 norm=0.9268
[iter 400] loss=-0.8937 val_loss=0.0000 scale=1.0000 norm=0.4505
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3470 val_loss=0.0000 scale=2.0000 norm=1.0423
[iter 200] loss=-0.2480 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 300] loss=-0.6651 val_loss=0.0000 scale=2.0000 norm=0.9133
[iter 400] loss=-0.9075 val_loss=0.0000 scale=1.0000 norm=0.4479
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2260 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 200] loss=-0.6401 val_loss=0.0000 scale=2.0000 norm=0.9160
[iter 300] loss=-1.4245 val_loss=0.0000 scale=2.0000 norm=0.8598
[iter 400] loss=-2.1706 val_loss=0.0000 scale=2.0000 norm=0.8377
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3869 val_loss=0.0000 scale=2.0000 norm=1.0974
[iter 200] loss=-0.1797 val_loss=0.0000 scale=2.0000 norm=1.0234
[iter 300] loss=-0.6092 val_loss=0.0000 scale=2.0000 norm=0.9482
[iter 400] loss=-0.8351 val_loss=0.0000 scale=1.0000 norm=0.4795
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4057 val_loss=0.0000 scale=2.0000 norm=1.0897
[iter 200] loss=-0.1797 val_loss=0.0000 scale=2.0000 norm=0.9715
[iter 300] loss=-0.6109 val_loss=0.0000 scale=2.0000 norm=0.8998
[iter 400] loss=-0.8395 val_loss=0.0000 scale=1.0000 norm=0.4242
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3372 val_loss=0.0000 scale=2.0000 norm=0.9898
[iter 200] loss=-0.4908 val_loss=0.0000 scale=2.0000 norm=0.9157
[iter 300] loss=-1.2748 val_loss=0.0000 scale=2.0000 norm=0.8943
[iter 400] loss=-2.0647 val_loss=0.0000 scale=2.0000 norm=0.8974
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2159 val_loss=0.0000 scale=2.0000 norm=1.0196
[iter 200] loss=-0.4741 val_loss=0.0000 scale=2.0000 norm=0.9920
[iter 300] loss=-1.0201 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 400] loss=-1.3902 val_loss=0.0000 scale=2.0000 norm=0.8656
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3447 val_loss=0.0000 scale=2.0000 norm=1.0348
[iter 200] loss=-0.2875 val_loss=0.0000 scale=2.0000 norm=0.9174
[iter 300] loss=-0.7445 val_loss=0.0000 scale=1.0000 norm=0.4411
[iter 400] loss=-1.0195 val_loss=0.0000 scale=2.0000 norm=0.8690
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4561 val_loss=0.0000 scale=2.0000 norm=1.1063
[iter 200] loss=-0.1966 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 300] loss=-0.6839 val_loss=0.0000 scale=2.0000 norm=0.9743
[iter 400] loss=-1.0660 val_loss=0.0000 scale=2.0000 norm=0.9737
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2139 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 200] loss=-0.5558 val_loss=0.0000 scale=2.0000 norm=0.9494
[iter 300] loss=-1.1956 val_loss=0.0000 scale=2.0000 norm=0.9097
[iter 400] loss=-1.6652 val_loss=0.0000 scale=2.0000 norm=0.8396
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2721 val_loss=0.0000 scale=2.0000 norm=1.0720
[iter 200] loss=-0.4555 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 300] loss=-1.0551 val_loss=0.0000 scale=2.0000 norm=0.8788
[iter 400] loss=-1.5220 val_loss=0.0000 scale=2.0000 norm=0.8275
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3633 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 200] loss=-0.2002 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 300] loss=-0.5717 val_loss=0.0000 scale=2.0000 norm=0.9270
[iter 400] loss=-0.8138 val_loss=0.0000 scale=1.0000 norm=0.4369
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3420 val_loss=0.0000 scale=2.0000 norm=1.0233
[iter 200] loss=-0.2721 val_loss=0.0000 scale=2.0000 norm=0.9361
[iter 300] loss=-0.6876 val_loss=0.0000 scale=1.0000 norm=0.4394
[iter 400] loss=-0.8971 val_loss=0.0000 scale=1.0000 norm=0.4302
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3026 val_loss=0.0000 scale=2.0000 norm=1.0497
[iter 200] loss=-0.3159 val_loss=0.0000 scale=2.0000 norm=0.9774
[iter 300] loss=-0.7542 val_loss=0.0000 scale=1.0000 norm=0.4672
[iter 400] loss=-1.0299 val_loss=0.0000 scale=1.0000 norm=0.4402
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4990 val_loss=0.0000 scale=2.0000 norm=1.1187
[iter 200] loss=-0.1205 val_loss=0.0000 scale=2.0000 norm=0.9812
[iter 300] loss=-0.5276 val_loss=0.0000 scale=2.0000 norm=0.9305
[iter 400] loss=-0.8407 val_loss=0.0000 scale=1.0000 norm=0.4517
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2630 val_loss=0.0000 scale=2.0000 norm=1.0319
[iter 200] loss=-0.3670 val_loss=0.0000 scale=2.0000 norm=0.9592
[iter 300] loss=-0.8533 val_loss=0.0000 scale=2.0000 norm=0.9236
[iter 400] loss=-1.1300 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4622 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 200] loss=-0.2350 val_loss=0.0000 scale=2.0000 norm=0.9288
[iter 300] loss=-0.8645 val_loss=0.0000 scale=2.0000 norm=0.8489
[iter 400] loss=-1.3865 val_loss=0.0000 scale=2.0000 norm=0.7926
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2420 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.5057 val_loss=0.0000 scale=2.0000 norm=0.9443
[iter 300] loss=-1.1638 val_loss=0.0000 scale=2.0000 norm=0.8955
[iter 400] loss=-1.6775 val_loss=0.0000 scale=2.0000 norm=0.8474
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4125 val_loss=0.0000 scale=2.0000 norm=1.0917
[iter 200] loss=-0.1451 val_loss=0.0000 scale=2.0000 norm=0.9873
[iter 300] loss=-0.5844 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 400] loss=-0.8512 val_loss=0.0000 scale=2.0000 norm=0.8907
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2362 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 200] loss=-0.3960 val_loss=0.0000 scale=2.0000 norm=0.9725
[iter 300] loss=-0.9003 val_loss=0.0000 scale=2.0000 norm=0.9359
[iter 400] loss=-1.2128 val_loss=0.0000 scale=2.0000 norm=0.8949
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1358 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.7981 val_loss=0.0000 scale=2.0000 norm=0.9355
[iter 300] loss=-1.6832 val_loss=0.0000 scale=2.0000 norm=0.9047
[iter 400] loss=-2.5438 val_loss=0.0000 scale=2.0000 norm=0.8861
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3094 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.3111 val_loss=0.0000 scale=2.0000 norm=0.9415
[iter 300] loss=-0.6969 val_loss=0.0000 scale=2.0000 norm=0.9331
[iter 400] loss=-0.9945 val_loss=0.0000 scale=2.0000 norm=0.9046
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4982 val_loss=0.0000 scale=2.0000 norm=1.0996
[iter 200] loss=-0.0082 val_loss=0.0000 scale=2.0000 norm=0.9881
[iter 300] loss=-0.3840 val_loss=0.0000 scale=1.0000 norm=0.4698
[iter 400] loss=-0.5734 val_loss=0.0000 scale=1.0000 norm=0.4660
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4099 val_loss=0.0000 scale=2.0000 norm=1.0751
[iter 200] loss=-0.1329 val_loss=0.0000 scale=2.0000 norm=1.0045
[iter 300] loss=-0.5891 val_loss=0.0000 scale=2.0000 norm=0.9656
[iter 400] loss=-0.8784 val_loss=0.0000 scale=1.0000 norm=0.4660
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5446 val_loss=0.0000 scale=2.0000 norm=1.1766
[iter 200] loss=-0.0318 val_loss=0.0000 scale=2.0000 norm=1.0674
[iter 300] loss=-0.4404 val_loss=0.0000 scale=1.0000 norm=0.5065
[iter 400] loss=-0.7340 val_loss=0.0000 scale=2.0000 norm=0.9857
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4062 val_loss=0.0000 scale=1.0000 norm=0.5406
[iter 200] loss=-0.1740 val_loss=0.0000 scale=2.0000 norm=0.9584
[iter 300] loss=-0.5693 val_loss=0.0000 scale=1.0000 norm=0.4619
[iter 400] loss=-0.8694 val_loss=0.0000 scale=2.0000 norm=0.8919
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3901 val_loss=0.0000 scale=2.0000 norm=1.0533
[iter 200] loss=-0.1579 val_loss=0.0000 scale=2.0000 norm=0.9706
[iter 300] loss=-0.5343 val_loss=0.0000 scale=2.0000 norm=0.9731
[iter 400] loss=-0.7867 val_loss=0.0000 scale=1.0000 norm=0.4816
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3372 val_loss=0.0000 scale=2.0000 norm=1.0421
[iter 200] loss=-0.2614 val_loss=0.0000 scale=2.0000 norm=0.9569
[iter 300] loss=-0.6944 val_loss=0.0000 scale=1.0000 norm=0.4720
[iter 400] loss=-0.9405 val_loss=0.0000 scale=1.0000 norm=0.4525
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4438 val_loss=0.0000 scale=2.0000 norm=1.1007
[iter 200] loss=-0.1069 val_loss=0.0000 scale=2.0000 norm=1.0061
[iter 300] loss=-0.5102 val_loss=0.0000 scale=1.0000 norm=0.4848
[iter 400] loss=-0.7363 val_loss=0.0000 scale=1.0000 norm=0.4764
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0333
[iter 200] loss=-0.2862 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 300] loss=-0.7241 val_loss=0.0000 scale=2.0000 norm=0.9185
[iter 400] loss=-1.0245 val_loss=0.0000 scale=2.0000 norm=0.8840
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3249 val_loss=0.0000 scale=2.0000 norm=1.0239
[iter 200] loss=-0.2452 val_loss=0.0000 scale=2.0000 norm=0.9431
[iter 300] loss=-0.6146 val_loss=0.0000 scale=2.0000 norm=0.9300
[iter 400] loss=-0.8842 val_loss=0.0000 scale=1.0000 norm=0.4457
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2919 val_loss=0.0000 scale=2.0000 norm=1.0251
[iter 200] loss=-0.3706 val_loss=0.0000 scale=2.0000 norm=0.9294
[iter 300] loss=-0.8798 val_loss=0.0000 scale=2.0000 norm=0.9001
[iter 400] loss=-1.2510 val_loss=0.0000 scale=1.0000 norm=0.4361
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4890 val_loss=0.0000 scale=2.0000 norm=1.1514
[iter 200] loss=-0.0311 val_loss=0.0000 scale=2.0000 norm=1.0484
[iter 300] loss=-0.4290 val_loss=0.0000 scale=2.0000 norm=1.0081
[iter 400] loss=-0.6701 val_loss=0.0000 scale=2.0000 norm=0.9752
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3581 val_loss=0.0000 scale=2.0000 norm=1.0552
[iter 200] loss=-0.2655 val_loss=0.0000 scale=2.0000 norm=0.9603
[iter 300] loss=-0.7608 val_loss=0.0000 scale=2.0000 norm=0.9237
[iter 400] loss=-1.1196 val_loss=0.0000 scale=1.0000 norm=0.4554
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3864 val_loss=0.0000 scale=2.0000 norm=1.0697
[iter 200] loss=-0.2286 val_loss=0.0000 scale=2.0000 norm=0.9886
[iter 300] loss=-0.7069 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 400] loss=-0.9637 val_loss=0.0000 scale=1.0000 norm=0.4529
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5160 val_loss=0.0000 scale=2.0000 norm=1.1333
[iter 200] loss=0.0333 val_loss=0.0000 scale=2.0000 norm=1.0016
[iter 300] loss=-0.2850 val_loss=0.0000 scale=1.0000 norm=0.4631
[iter 400] loss=-0.4564 val_loss=0.0000 scale=2.0000 norm=0.9133
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3053 val_loss=0.0000 scale=2.0000 norm=1.0422
[iter 200] loss=-0.3181 val_loss=0.0000 scale=2.0000 norm=0.9546
[iter 300] loss=-0.8152 val_loss=0.0000 scale=2.0000 norm=0.8794
[iter 400] loss=-1.1494 val_loss=0.0000 scale=2.0000 norm=0.8432
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3853 val_loss=0.0000 scale=2.0000 norm=1.0792
[iter 200] loss=-0.2710 val_loss=0.0000 scale=2.0000 norm=0.9528
[iter 300] loss=-0.7466 val_loss=0.0000 scale=2.0000 norm=0.9122
[iter 400] loss=-1.0572 val_loss=0.0000 scale=1.0000 norm=0.4301
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1629 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.6838 val_loss=0.0000 scale=2.0000 norm=0.9689
[iter 300] loss=-1.4393 val_loss=0.0000 scale=2.0000 norm=0.9563
[iter 400] loss=-2.0688 val_loss=0.0000 scale=2.0000 norm=0.9228
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2230 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 200] loss=-0.6284 val_loss=0.0000 scale=4.0000 norm=2.0475
[iter 300] loss=-1.6403 val_loss=0.0000 scale=2.0000 norm=0.9711
[iter 400] loss=-2.5833 val_loss=0.0000 scale=2.0000 norm=0.9098
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3095 val_loss=0.0000 scale=2.0000 norm=1.0607
[iter 200] loss=-0.4444 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 300] loss=-1.0015 val_loss=0.0000 scale=2.0000 norm=0.8914
[iter 400] loss=-1.4709 val_loss=0.0000 scale=1.0000 norm=0.4099
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3380 val_loss=0.0000 scale=2.0000 norm=0.9858
[iter 200] loss=-0.6226 val_loss=0.0000 scale=2.0000 norm=0.9567
[iter 300] loss=-1.8145 val_loss=0.0000 scale=4.0000 norm=1.7217
[iter 400] loss=-3.1966 val_loss=0.0000 scale=4.0000 norm=1.7312
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3968 val_loss=0.0000 scale=2.0000 norm=1.0726
[iter 200] loss=-0.1612 val_loss=0.0000 scale=2.0000 norm=0.9657
[iter 300] loss=-0.5219 val_loss=0.0000 scale=2.0000 norm=0.9431
[iter 400] loss=-0.7351 val_loss=0.0000 scale=1.0000 norm=0.4668
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3929 val_loss=0.0000 scale=2.0000 norm=1.0708
[iter 200] loss=-0.1970 val_loss=0.0000 scale=2.0000 norm=0.9623
[iter 300] loss=-0.6382 val_loss=0.0000 scale=1.0000 norm=0.4526
[iter 400] loss=-0.8620 val_loss=0.0000 scale=0.5000 norm=0.2285
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1692 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 200] loss=-0.5602 val_loss=0.0000 scale=2.0000 norm=0.9774
[iter 300] loss=-1.1372 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 400] loss=-1.6319 val_loss=0.0000 scale=2.0000 norm=0.9041
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7070 val_loss=0.0000 scale=2.0000 norm=1.2233
[iter 200] loss=0.1540 val_loss=0.0000 scale=1.0000 norm=0.5275
[iter 300] loss=-0.2101 val_loss=0.0000 scale=1.0000 norm=0.4973
[iter 400] loss=-0.5548 val_loss=0.0000 scale=2.0000 norm=0.9112
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0525 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 200] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-1.8273 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 400] loss=-2.8310 val_loss=0.0000 scale=2.0000 norm=0.8464
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3072 val_loss=0.0000 scale=2.0000 norm=1.0309
[iter 200] loss=-0.2945 val_loss=0.0000 scale=2.0000 norm=0.9400
[iter 300] loss=-0.6451 val_loss=0.0000 scale=1.0000 norm=0.4690
[iter 400] loss=-0.8963 val_loss=0.0000 scale=2.0000 norm=0.9140
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6500 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 200] loss=0.1073 val_loss=0.0000 scale=2.0000 norm=0.9706
[iter 300] loss=-0.3129 val_loss=0.0000 scale=2.0000 norm=0.9324
[iter 400] loss=-0.5875 val_loss=0.0000 scale=2.0000 norm=0.9410
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3748 val_loss=0.0000 scale=2.0000 norm=1.0503
[iter 200] loss=-0.2271 val_loss=0.0000 scale=2.0000 norm=0.9670
[iter 300] loss=-0.6479 val_loss=0.0000 scale=1.0000 norm=0.4760
[iter 400] loss=-0.9622 val_loss=0.0000 scale=2.0000 norm=0.9067
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4487 val_loss=0.0000 scale=2.0000 norm=1.1270
[iter 200] loss=-0.0913 val_loss=0.0000 scale=2.0000 norm=0.9989
[iter 300] loss=-0.4699 val_loss=0.0000 scale=2.0000 norm=0.9662
[iter 400] loss=-0.7279 val_loss=0.0000 scale=2.0000 norm=0.9125
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2905 val_loss=0.0000 scale=2.0000 norm=1.0014
[iter 200] loss=-0.3637 val_loss=0.0000 scale=2.0000 norm=0.9136
[iter 300] loss=-0.7615 val_loss=0.0000 scale=2.0000 norm=0.8488
[iter 400] loss=-1.0754 val_loss=0.0000 scale=1.0000 norm=0.4071
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2447 val_loss=0.0000 scale=2.0000 norm=0.9994
[iter 200] loss=-0.4228 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 300] loss=-0.9212 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 400] loss=-1.2830 val_loss=0.0000 scale=1.0000 norm=0.4442
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4705 val_loss=0.0000 scale=2.0000 norm=1.0972
[iter 200] loss=-0.0308 val_loss=0.0000 scale=1.0000 norm=0.5069
[iter 300] loss=-0.3435 val_loss=0.0000 scale=2.0000 norm=0.9573
[iter 400] loss=-0.5880 val_loss=0.0000 scale=1.0000 norm=0.4688
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3534 val_loss=0.0000 scale=2.0000 norm=1.0623
[iter 200] loss=-0.2716 val_loss=0.0000 scale=2.0000 norm=0.9525
[iter 300] loss=-0.6839 val_loss=0.0000 scale=2.0000 norm=0.8944
[iter 400] loss=-0.9361 val_loss=0.0000 scale=1.0000 norm=0.4355
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3589 val_loss=0.0000 scale=2.0000 norm=1.0662
[iter 200] loss=-0.2172 val_loss=0.0000 scale=2.0000 norm=0.9826
[iter 300] loss=-0.5763 val_loss=0.0000 scale=2.0000 norm=0.9571
[iter 400] loss=-0.7924 val_loss=0.0000 scale=2.0000 norm=0.9418
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3350 val_loss=0.0000 scale=2.0000 norm=1.0661
[iter 200] loss=-0.3058 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 300] loss=-0.7271 val_loss=0.0000 scale=2.0000 norm=0.8937
[iter 400] loss=-0.9675 val_loss=0.0000 scale=0.5000 norm=0.2138
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4101 val_loss=0.0000 scale=2.0000 norm=1.0762
[iter 200] loss=-0.1482 val_loss=0.0000 scale=1.0000 norm=0.4802
[iter 300] loss=-0.5600 val_loss=0.0000 scale=2.0000 norm=0.9194
[iter 400] loss=-0.7930 val_loss=0.0000 scale=1.0000 norm=0.4601
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3647 val_loss=0.0000 scale=2.0000 norm=1.0398
[iter 200] loss=-0.1980 val_loss=0.0000 scale=2.0000 norm=0.9299
[iter 300] loss=-0.5639 val_loss=0.0000 scale=1.0000 norm=0.4522
[iter 400] loss=-0.7965 val_loss=0.0000 scale=1.0000 norm=0.4433
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5319 val_loss=0.0000 scale=2.0000 norm=1.1661
[iter 200] loss=0.0208 val_loss=0.0000 scale=2.0000 norm=1.0591
[iter 300] loss=-0.3458 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 400] loss=-0.5804 val_loss=0.0000 scale=0.5000 norm=0.2418
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3449 val_loss=0.0000 scale=2.0000 norm=1.0421
[iter 200] loss=-0.2559 val_loss=0.0000 scale=2.0000 norm=0.9186
[iter 300] loss=-0.6697 val_loss=0.0000 scale=2.0000 norm=0.8668
[iter 400] loss=-0.9041 val_loss=0.0000 scale=1.0000 norm=0.4226
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2588 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.4654 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 300] loss=-1.1404 val_loss=0.0000 scale=4.0000 norm=1.8933
[iter 400] loss=-2.0801 val_loss=0.0000 scale=4.0000 norm=1.8913
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4202 val_loss=0.0000 scale=2.0000 norm=1.0765
[iter 200] loss=-0.1852 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 300] loss=-0.5680 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 400] loss=-0.8437 val_loss=0.0000 scale=1.0000 norm=0.4598
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4428 val_loss=0.0000 scale=2.0000 norm=1.1098
[iter 200] loss=-0.1085 val_loss=0.0000 scale=2.0000 norm=0.9948
[iter 300] loss=-0.4814 val_loss=0.0000 scale=2.0000 norm=0.9256
[iter 400] loss=-0.6617 val_loss=0.0000 scale=1.0000 norm=0.4609
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3419 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 200] loss=-0.5734 val_loss=0.0000 scale=2.0000 norm=0.9261
[iter 300] loss=-1.4134 val_loss=0.0000 scale=2.0000 norm=0.8455
[iter 400] loss=-2.6327 val_loss=0.0000 scale=4.0000 norm=1.5705
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2413 val_loss=0.0000 scale=2.0000 norm=1.0043
[iter 200] loss=-0.4372 val_loss=0.0000 scale=2.0000 norm=0.9138
[iter 300] loss=-0.9027 val_loss=0.0000 scale=2.0000 norm=0.8758
[iter 400] loss=-1.2502 val_loss=0.0000 scale=1.0000 norm=0.4013
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3397 val_loss=0.0000 scale=2.0000 norm=1.0370
[iter 200] loss=-0.2442 val_loss=0.0000 scale=2.0000 norm=0.9418
[iter 300] loss=-0.6683 val_loss=0.0000 scale=2.0000 norm=0.9117
[iter 400] loss=-0.9463 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3350 val_loss=0.0000 scale=2.0000 norm=0.9965
[iter 200] loss=-0.4525 val_loss=0.0000 scale=2.0000 norm=0.9294
[iter 300] loss=-1.1771 val_loss=0.0000 scale=2.0000 norm=0.9104
[iter 400] loss=-1.7518 val_loss=0.0000 scale=2.0000 norm=0.9110
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3303 val_loss=0.0000 scale=2.0000 norm=1.0485
[iter 200] loss=-0.2931 val_loss=0.0000 scale=2.0000 norm=0.9484
[iter 300] loss=-0.7164 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 400] loss=-0.9983 val_loss=0.0000 scale=1.0000 norm=0.4393
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2979 val_loss=0.0000 scale=2.0000 norm=1.0154
[iter 200] loss=-0.3141 val_loss=0.0000 scale=2.0000 norm=1.0008
[iter 300] loss=-0.7611 val_loss=0.0000 scale=2.0000 norm=1.0015
[iter 400] loss=-1.1387 val_loss=0.0000 scale=2.0000 norm=0.9167
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3984 val_loss=0.0000 scale=2.0000 norm=1.0868
[iter 200] loss=-0.1664 val_loss=0.0000 scale=2.0000 norm=0.9717
[iter 300] loss=-0.5569 val_loss=0.0000 scale=2.0000 norm=0.9489
[iter 400] loss=-0.7788 val_loss=0.0000 scale=1.0000 norm=0.4561
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7164 val_loss=0.0000 scale=2.0000 norm=1.2297
[iter 200] loss=0.2326 val_loss=0.0000 scale=1.0000 norm=0.5425
[iter 300] loss=-0.1068 val_loss=0.0000 scale=1.0000 norm=0.5210
[iter 400] loss=-0.3554 val_loss=0.0000 scale=2.0000 norm=1.0464
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7498 val_loss=0.0000 scale=2.0000 norm=1.2320
[iter 200] loss=-0.0142 val_loss=0.0000 scale=2.0000 norm=1.0565
[iter 300] loss=-0.7595 val_loss=0.0000 scale=2.0000 norm=0.9950
[iter 400] loss=-1.3040 val_loss=0.0000 scale=2.0000 norm=0.9061
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3778 val_loss=0.0000 scale=2.0000 norm=1.0509
[iter 200] loss=-0.2054 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 300] loss=-0.5720 val_loss=0.0000 scale=1.0000 norm=0.4537
[iter 400] loss=-0.7700 val_loss=0.0000 scale=0.5000 norm=0.2259
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3447 val_loss=0.0000 scale=2.0000 norm=1.0545
[iter 200] loss=-0.2952 val_loss=0.0000 scale=2.0000 norm=0.9859
[iter 300] loss=-0.7900 val_loss=0.0000 scale=2.0000 norm=0.9484
[iter 400] loss=-1.0723 val_loss=0.0000 scale=1.0000 norm=0.4621
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3753 val_loss=0.0000 scale=2.0000 norm=1.0713
[iter 200] loss=-0.1934 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 300] loss=-0.5926 val_loss=0.0000 scale=1.0000 norm=0.4789
[iter 400] loss=-0.7845 val_loss=0.0000 scale=1.0000 norm=0.4740
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3378 val_loss=0.0000 scale=2.0000 norm=1.0423
[iter 200] loss=-0.3086 val_loss=0.0000 scale=2.0000 norm=0.9778
[iter 300] loss=-0.8388 val_loss=0.0000 scale=2.0000 norm=0.9282
[iter 400] loss=-1.1976 val_loss=0.0000 scale=1.0000 norm=0.4443
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3815 val_loss=0.0000 scale=2.0000 norm=1.0461
[iter 200] loss=-0.1675 val_loss=0.0000 scale=2.0000 norm=0.9475
[iter 300] loss=-0.5431 val_loss=0.0000 scale=2.0000 norm=0.8950
[iter 400] loss=-0.7566 val_loss=0.0000 scale=2.0000 norm=0.9068
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3505 val_loss=0.0000 scale=2.0000 norm=1.0525
[iter 200] loss=-0.2741 val_loss=0.0000 scale=1.0000 norm=0.4694
[iter 300] loss=-0.7217 val_loss=0.0000 scale=1.0000 norm=0.4438
[iter 400] loss=-1.0014 val_loss=0.0000 scale=1.0000 norm=0.4207
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3439 val_loss=0.0000 scale=2.0000 norm=1.0349
[iter 200] loss=-0.2495 val_loss=0.0000 scale=1.0000 norm=0.4697
[iter 300] loss=-0.6245 val_loss=0.0000 scale=2.0000 norm=0.9016
[iter 400] loss=-0.9101 val_loss=0.0000 scale=1.0000 norm=0.4384
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4469 val_loss=0.0000 scale=2.0000 norm=1.0959
[iter 200] loss=-0.0938 val_loss=0.0000 scale=2.0000 norm=1.0064
[iter 300] loss=-0.4722 val_loss=0.0000 scale=1.0000 norm=0.4886
[iter 400] loss=-0.6960 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4436 val_loss=0.0000 scale=1.0000 norm=0.5622
[iter 200] loss=-0.1131 val_loss=0.0000 scale=1.0000 norm=0.5127
[iter 300] loss=-0.6917 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 400] loss=-1.1933 val_loss=0.0000 scale=2.0000 norm=0.8999
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4589 val_loss=0.0000 scale=2.0000 norm=1.0956
[iter 200] loss=-0.0475 val_loss=0.0000 scale=2.0000 norm=1.0183
[iter 300] loss=-0.3749 val_loss=0.0000 scale=1.0000 norm=0.4823
[iter 400] loss=-0.5479 val_loss=0.0000 scale=1.0000 norm=0.4582
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4468 val_loss=0.0000 scale=2.0000 norm=1.1234
[iter 200] loss=-0.1977 val_loss=0.0000 scale=2.0000 norm=1.0025
[iter 300] loss=-0.6928 val_loss=0.0000 scale=1.0000 norm=0.4853
[iter 400] loss=-0.9877 val_loss=0.0000 scale=2.0000 norm=0.9526
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3793 val_loss=0.0000 scale=2.0000 norm=1.0544
[iter 200] loss=-0.2147 val_loss=0.0000 scale=2.0000 norm=0.9757
[iter 300] loss=-0.6212 val_loss=0.0000 scale=1.0000 norm=0.4740
[iter 400] loss=-0.8412 val_loss=0.0000 scale=2.0000 norm=0.9530
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8531 val_loss=0.0000 scale=1.0000 norm=0.6523
[iter 200] loss=0.2864 val_loss=0.0000 scale=2.0000 norm=1.0374
[iter 300] loss=-0.3264 val_loss=0.0000 scale=2.0000 norm=0.9493
[iter 400] loss=-0.7753 val_loss=0.0000 scale=1.0000 norm=0.4712
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3803 val_loss=0.0000 scale=2.0000 norm=1.0631
[iter 200] loss=-0.1946 val_loss=0.0000 scale=2.0000 norm=0.9753
[iter 300] loss=-0.5171 val_loss=0.0000 scale=1.0000 norm=0.4752
[iter 400] loss=-0.7665 val_loss=0.0000 scale=2.0000 norm=0.9108
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2958 val_loss=0.0000 scale=2.0000 norm=1.0080
[iter 200] loss=-0.3426 val_loss=0.0000 scale=2.0000 norm=0.9238
[iter 300] loss=-0.7814 val_loss=0.0000 scale=2.0000 norm=0.9046
[iter 400] loss=-1.0673 val_loss=0.0000 scale=1.0000 norm=0.4479
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4179 val_loss=0.0000 scale=2.0000 norm=1.0612
[iter 200] loss=-0.1264 val_loss=0.0000 scale=2.0000 norm=0.9551
[iter 300] loss=-0.5629 val_loss=0.0000 scale=2.0000 norm=0.8759
[iter 400] loss=-0.8633 val_loss=0.0000 scale=2.0000 norm=0.8462
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3655 val_loss=0.0000 scale=2.0000 norm=0.9914
[iter 200] loss=-0.4352 val_loss=0.0000 scale=2.0000 norm=1.0193
[iter 300] loss=-1.2733 val_loss=0.0000 scale=2.0000 norm=1.0589
[iter 400] loss=-2.0400 val_loss=0.0000 scale=2.0000 norm=1.0614
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5142 val_loss=0.0000 scale=2.0000 norm=1.1470
[iter 200] loss=0.0050 val_loss=0.0000 scale=1.0000 norm=0.5038
[iter 300] loss=-0.2597 val_loss=0.0000 scale=2.0000 norm=0.9589
[iter 400] loss=-0.4917 val_loss=0.0000 scale=1.0000 norm=0.4707
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3521 val_loss=0.0000 scale=2.0000 norm=1.0646
[iter 200] loss=-0.2339 val_loss=0.0000 scale=2.0000 norm=0.9664
[iter 300] loss=-0.6738 val_loss=0.0000 scale=2.0000 norm=0.9292
[iter 400] loss=-0.9390 val_loss=0.0000 scale=2.0000 norm=0.9269
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3356 val_loss=0.0000 scale=2.0000 norm=1.0332
[iter 200] loss=-0.2687 val_loss=0.0000 scale=2.0000 norm=0.9416
[iter 300] loss=-0.6528 val_loss=0.0000 scale=1.0000 norm=0.4405
[iter 400] loss=-0.9096 val_loss=0.0000 scale=1.0000 norm=0.4331
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4058 val_loss=0.0000 scale=2.0000 norm=1.0662
[iter 200] loss=-0.1346 val_loss=0.0000 scale=1.0000 norm=0.4830
[iter 300] loss=-0.4720 val_loss=0.0000 scale=2.0000 norm=0.9471
[iter 400] loss=-0.6781 val_loss=0.0000 scale=0.5000 norm=0.2361
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3863 val_loss=0.0000 scale=1.0000 norm=0.5386
[iter 200] loss=-0.3408 val_loss=0.0000 scale=2.0000 norm=0.9569
[iter 300] loss=-0.9649 val_loss=0.0000 scale=2.0000 norm=0.8564
[iter 400] loss=-1.3921 val_loss=0.0000 scale=1.0000 norm=0.3981
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3199 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 200] loss=-0.3024 val_loss=0.0000 scale=2.0000 norm=0.9421
[iter 300] loss=-0.7460 val_loss=0.0000 scale=2.0000 norm=0.9053
[iter 400] loss=-1.0147 val_loss=0.0000 scale=2.0000 norm=0.8661
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3583 val_loss=0.0000 scale=2.0000 norm=1.0431
[iter 200] loss=-0.1961 val_loss=0.0000 scale=2.0000 norm=0.9529
[iter 300] loss=-0.5396 val_loss=0.0000 scale=1.0000 norm=0.4737
[iter 400] loss=-0.7719 val_loss=0.0000 scale=2.0000 norm=0.9106
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2691 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.3800 val_loss=0.0000 scale=2.0000 norm=0.9289
[iter 300] loss=-0.8403 val_loss=0.0000 scale=2.0000 norm=0.9299
[iter 400] loss=-1.1478 val_loss=0.0000 scale=1.0000 norm=0.4432
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3285 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 200] loss=-0.2847 val_loss=0.0000 scale=2.0000 norm=0.9315
[iter 300] loss=-0.6760 val_loss=0.0000 scale=1.0000 norm=0.4656
[iter 400] loss=-0.9383 val_loss=0.0000 scale=1.0000 norm=0.4487
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6963 val_loss=0.0000 scale=2.0000 norm=1.2231
[iter 200] loss=0.2487 val_loss=0.0000 scale=2.0000 norm=1.1095
[iter 300] loss=-0.0842 val_loss=0.0000 scale=1.0000 norm=0.5304
[iter 400] loss=-0.3006 val_loss=0.0000 scale=2.0000 norm=1.0092
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3114 val_loss=0.0000 scale=2.0000 norm=0.9624
[iter 200] loss=-0.5613 val_loss=0.0000 scale=2.0000 norm=0.8840
[iter 300] loss=-1.3548 val_loss=0.0000 scale=2.0000 norm=0.8202
[iter 400] loss=-2.0786 val_loss=0.0000 scale=2.0000 norm=0.8023
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2952 val_loss=0.0000 scale=2.0000 norm=0.9999
[iter 200] loss=-0.3757 val_loss=0.0000 scale=2.0000 norm=0.9221
[iter 300] loss=-0.8241 val_loss=0.0000 scale=1.0000 norm=0.4266
[iter 400] loss=-1.0123 val_loss=0.0000 scale=1.0000 norm=0.4194
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4240 val_loss=0.0000 scale=2.0000 norm=1.0832
[iter 200] loss=-0.1277 val_loss=0.0000 scale=2.0000 norm=0.9769
[iter 300] loss=-0.5049 val_loss=0.0000 scale=1.0000 norm=0.4617
[iter 400] loss=-0.6959 val_loss=0.0000 scale=1.0000 norm=0.4491
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3027 val_loss=0.0000 scale=2.0000 norm=1.0418
[iter 200] loss=-0.3258 val_loss=0.0000 scale=2.0000 norm=0.9830
[iter 300] loss=-0.7932 val_loss=0.0000 scale=1.0000 norm=0.4700
[iter 400] loss=-1.0702 val_loss=0.0000 scale=1.0000 norm=0.4514
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4246 val_loss=0.0000 scale=2.0000 norm=1.1120
[iter 200] loss=-0.1424 val_loss=0.0000 scale=2.0000 norm=1.0124
[iter 300] loss=-0.5688 val_loss=0.0000 scale=1.0000 norm=0.4923
[iter 400] loss=-0.7759 val_loss=0.0000 scale=0.5000 norm=0.2381
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3074 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.4242 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 300] loss=-1.0020 val_loss=0.0000 scale=2.0000 norm=0.9374
[iter 400] loss=-1.3780 val_loss=0.0000 scale=2.0000 norm=0.8903
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2925 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3233 val_loss=0.0000 scale=2.0000 norm=0.8884
[iter 300] loss=-0.7012 val_loss=0.0000 scale=2.0000 norm=0.8166
[iter 400] loss=-0.9411 val_loss=0.0000 scale=1.0000 norm=0.4037
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2220 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 200] loss=-0.5250 val_loss=0.0000 scale=2.0000 norm=0.8726
[iter 300] loss=-1.0605 val_loss=0.0000 scale=2.0000 norm=0.7552
[iter 400] loss=-1.3832 val_loss=0.0000 scale=2.0000 norm=0.7350
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4964 val_loss=0.0000 scale=2.0000 norm=1.1137
[iter 200] loss=-0.0260 val_loss=0.0000 scale=2.0000 norm=0.9917
[iter 300] loss=-0.3326 val_loss=0.0000 scale=1.0000 norm=0.4769
[iter 400] loss=-0.5408 val_loss=0.0000 scale=1.0000 norm=0.4689
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3422 val_loss=0.0000 scale=2.0000 norm=1.0761
[iter 200] loss=-0.3211 val_loss=0.0000 scale=2.0000 norm=0.9536
[iter 300] loss=-0.8465 val_loss=0.0000 scale=2.0000 norm=0.8946
[iter 400] loss=-1.1502 val_loss=0.0000 scale=2.0000 norm=0.8558
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4580 val_loss=0.0000 scale=2.0000 norm=1.0818
[iter 200] loss=-0.1206 val_loss=0.0000 scale=1.0000 norm=0.4941
[iter 300] loss=-0.5014 val_loss=0.0000 scale=2.0000 norm=0.9320
[iter 400] loss=-0.7482 val_loss=0.0000 scale=1.0000 norm=0.4711
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3630 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.2473 val_loss=0.0000 scale=2.0000 norm=0.9776
[iter 300] loss=-0.6955 val_loss=0.0000 scale=1.0000 norm=0.4720
[iter 400] loss=-0.9359 val_loss=0.0000 scale=1.0000 norm=0.4626
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4467 val_loss=0.0000 scale=2.0000 norm=1.0813
[iter 200] loss=-0.2110 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 300] loss=-0.6451 val_loss=0.0000 scale=1.0000 norm=0.4450
[iter 400] loss=-0.9073 val_loss=0.0000 scale=1.0000 norm=0.4300
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3895 val_loss=0.0000 scale=2.0000 norm=1.0669
[iter 200] loss=-0.1688 val_loss=0.0000 scale=2.0000 norm=0.9569
[iter 300] loss=-0.5864 val_loss=0.0000 scale=2.0000 norm=0.9201
[iter 400] loss=-0.8515 val_loss=0.0000 scale=0.5000 norm=0.2273
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1992 val_loss=0.0000 scale=2.0000 norm=1.0083
[iter 200] loss=-0.4883 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 300] loss=-1.0491 val_loss=0.0000 scale=2.0000 norm=0.9383
[iter 400] loss=-1.4335 val_loss=0.0000 scale=2.0000 norm=0.8933
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2966 val_loss=0.0000 scale=2.0000 norm=1.0219
[iter 200] loss=-0.3643 val_loss=0.0000 scale=2.0000 norm=0.9319
[iter 300] loss=-0.9013 val_loss=0.0000 scale=2.0000 norm=0.9049
[iter 400] loss=-1.2540 val_loss=0.0000 scale=1.0000 norm=0.4295
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4549 val_loss=0.0000 scale=2.0000 norm=1.0795
[iter 200] loss=-0.0829 val_loss=0.0000 scale=2.0000 norm=0.9690
[iter 300] loss=-0.4870 val_loss=0.0000 scale=2.0000 norm=0.9152
[iter 400] loss=-0.7198 val_loss=0.0000 scale=1.0000 norm=0.4542
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3362 val_loss=0.0000 scale=2.0000 norm=1.0476
[iter 200] loss=-0.2696 val_loss=0.0000 scale=2.0000 norm=0.9914
[iter 300] loss=-0.7056 val_loss=0.0000 scale=2.0000 norm=0.9699
[iter 400] loss=-0.9639 val_loss=0.0000 scale=1.0000 norm=0.4771
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5777 val_loss=0.0000 scale=2.0000 norm=1.1180
[iter 200] loss=-0.0488 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 300] loss=-0.5525 val_loss=0.0000 scale=2.0000 norm=1.0104
[iter 400] loss=-1.0142 val_loss=0.0000 scale=0.5000 norm=0.2356
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1058 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.8630 val_loss=0.0000 scale=2.0000 norm=0.9692
[iter 300] loss=-1.8257 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 400] loss=-2.7361 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3408 val_loss=0.0000 scale=2.0000 norm=1.0383
[iter 200] loss=-0.2412 val_loss=0.0000 scale=2.0000 norm=0.9341
[iter 300] loss=-0.6393 val_loss=0.0000 scale=2.0000 norm=0.8917
[iter 400] loss=-0.9182 val_loss=0.0000 scale=2.0000 norm=0.8559
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2796 val_loss=0.0000 scale=2.0000 norm=1.0114
[iter 200] loss=-0.3340 val_loss=0.0000 scale=2.0000 norm=0.9457
[iter 300] loss=-0.8407 val_loss=0.0000 scale=2.0000 norm=0.9280
[iter 400] loss=-1.2177 val_loss=0.0000 scale=2.0000 norm=0.8906
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0949 val_loss=0.0000 scale=2.0000 norm=1.0010
[iter 200] loss=-0.8694 val_loss=0.0000 scale=2.0000 norm=0.9662
[iter 300] loss=-1.8197 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 400] loss=-2.7008 val_loss=0.0000 scale=2.0000 norm=0.8796
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5530 val_loss=0.0000 scale=2.0000 norm=1.1941
[iter 200] loss=0.0722 val_loss=0.0000 scale=2.0000 norm=1.0865
[iter 300] loss=-0.3211 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 400] loss=-0.6303 val_loss=0.0000 scale=1.0000 norm=0.4823
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1606 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 200] loss=-0.7738 val_loss=0.0000 scale=2.0000 norm=0.9345
[iter 300] loss=-1.6343 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 400] loss=-2.4624 val_loss=0.0000 scale=2.0000 norm=0.9142
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6061 val_loss=0.0000 scale=2.0000 norm=1.2008
[iter 200] loss=0.0876 val_loss=0.0000 scale=1.0000 norm=0.5410
[iter 300] loss=-0.2460 val_loss=0.0000 scale=1.0000 norm=0.5194
[iter 400] loss=-0.4757 val_loss=0.0000 scale=1.0000 norm=0.5044
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3441 val_loss=0.0000 scale=2.0000 norm=1.0224
[iter 200] loss=-0.2486 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 300] loss=-0.6721 val_loss=0.0000 scale=2.0000 norm=0.9365
[iter 400] loss=-0.9144 val_loss=0.0000 scale=1.0000 norm=0.4574
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2628 val_loss=0.0000 scale=2.0000 norm=0.9633
[iter 200] loss=-0.6686 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 300] loss=-1.5574 val_loss=0.0000 scale=2.0000 norm=0.8805
[iter 400] loss=-2.3235 val_loss=0.0000 scale=2.0000 norm=0.7791
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3279 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2734 val_loss=0.0000 scale=2.0000 norm=0.9368
[iter 300] loss=-0.6941 val_loss=0.0000 scale=2.0000 norm=0.9162
[iter 400] loss=-0.9574 val_loss=0.0000 scale=2.0000 norm=0.8873
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1440 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 200] loss=-0.7035 val_loss=0.0000 scale=2.0000 norm=0.8817
[iter 300] loss=-1.4388 val_loss=0.0000 scale=2.0000 norm=0.8413
[iter 400] loss=-1.9826 val_loss=0.0000 scale=2.0000 norm=0.8074
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3032 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 200] loss=-0.3594 val_loss=0.0000 scale=2.0000 norm=0.9911
[iter 300] loss=-0.9055 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 400] loss=-1.3377 val_loss=0.0000 scale=2.0000 norm=0.8828
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3434 val_loss=0.0000 scale=2.0000 norm=1.0632
[iter 200] loss=-0.3258 val_loss=0.0000 scale=2.0000 norm=1.0049
[iter 300] loss=-0.8358 val_loss=0.0000 scale=2.0000 norm=0.9347
[iter 400] loss=-1.1564 val_loss=0.0000 scale=1.0000 norm=0.4474
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4110 val_loss=0.0000 scale=2.0000 norm=1.1056
[iter 200] loss=-0.1587 val_loss=0.0000 scale=2.0000 norm=1.0410
[iter 300] loss=-0.6050 val_loss=0.0000 scale=2.0000 norm=0.9758
[iter 400] loss=-0.8845 val_loss=0.0000 scale=1.0000 norm=0.4732
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3815 val_loss=0.0000 scale=2.0000 norm=1.0483
[iter 200] loss=-0.1910 val_loss=0.0000 scale=2.0000 norm=0.9577
[iter 300] loss=-0.6189 val_loss=0.0000 scale=2.0000 norm=0.9143
[iter 400] loss=-0.8537 val_loss=0.0000 scale=1.0000 norm=0.4420
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4272 val_loss=0.0000 scale=2.0000 norm=1.0776
[iter 200] loss=-0.0631 val_loss=0.0000 scale=1.0000 norm=0.4972
[iter 300] loss=-0.4633 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 400] loss=-0.7436 val_loss=0.0000 scale=1.0000 norm=0.4499
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3721 val_loss=0.0000 scale=2.0000 norm=1.0629
[iter 200] loss=-0.2580 val_loss=0.0000 scale=2.0000 norm=0.9782
[iter 300] loss=-0.7747 val_loss=0.0000 scale=2.0000 norm=0.9466
[iter 400] loss=-1.1052 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3383 val_loss=0.0000 scale=2.0000 norm=1.0254
[iter 200] loss=-0.2687 val_loss=0.0000 scale=2.0000 norm=0.9329
[iter 300] loss=-0.6940 val_loss=0.0000 scale=1.0000 norm=0.4539
[iter 400] loss=-0.9428 val_loss=0.0000 scale=1.0000 norm=0.4261
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1537 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 200] loss=-0.6484 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 300] loss=-1.3647 val_loss=0.0000 scale=2.0000 norm=0.8090
[iter 400] loss=-1.9192 val_loss=0.0000 scale=2.0000 norm=0.7955
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2164 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 200] loss=-0.6750 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 300] loss=-1.5126 val_loss=0.0000 scale=2.0000 norm=0.9013
[iter 400] loss=-2.2922 val_loss=0.0000 scale=2.0000 norm=0.8483
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2859 val_loss=0.0000 scale=2.0000 norm=1.0033
[iter 200] loss=-0.3602 val_loss=0.0000 scale=2.0000 norm=0.9401
[iter 300] loss=-0.8118 val_loss=0.0000 scale=2.0000 norm=0.9280
[iter 400] loss=-1.0824 val_loss=0.0000 scale=1.0000 norm=0.4445
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4251 val_loss=0.0000 scale=2.0000 norm=1.0992
[iter 200] loss=-0.1320 val_loss=0.0000 scale=2.0000 norm=0.9657
[iter 300] loss=-0.5711 val_loss=0.0000 scale=1.0000 norm=0.4636
[iter 400] loss=-0.8555 val_loss=0.0000 scale=1.0000 norm=0.4546
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3140 val_loss=0.0000 scale=2.0000 norm=1.0455
[iter 200] loss=-0.2611 val_loss=0.0000 scale=2.0000 norm=0.9700
[iter 300] loss=-0.6796 val_loss=0.0000 scale=2.0000 norm=0.9319
[iter 400] loss=-0.9079 val_loss=0.0000 scale=2.0000 norm=0.9015
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2974 val_loss=0.0000 scale=2.0000 norm=1.0241
[iter 200] loss=-0.3269 val_loss=0.0000 scale=1.0000 norm=0.4604
[iter 300] loss=-0.7045 val_loss=0.0000 scale=2.0000 norm=0.9224
[iter 400] loss=-0.9690 val_loss=0.0000 scale=2.0000 norm=0.9103
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3821 val_loss=0.0000 scale=2.0000 norm=1.0551
[iter 200] loss=-0.1650 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 300] loss=-0.6038 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-0.9087 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4329 val_loss=0.0000 scale=2.0000 norm=1.0914
[iter 200] loss=-0.0475 val_loss=0.0000 scale=2.0000 norm=0.9683
[iter 300] loss=-0.3993 val_loss=0.0000 scale=1.0000 norm=0.4671
[iter 400] loss=-0.6466 val_loss=0.0000 scale=1.0000 norm=0.4586
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3946 val_loss=0.0000 scale=2.0000 norm=1.0722
[iter 200] loss=-0.1946 val_loss=0.0000 scale=2.0000 norm=0.9991
[iter 300] loss=-0.5505 val_loss=0.0000 scale=1.0000 norm=0.4880
[iter 400] loss=-0.8254 val_loss=0.0000 scale=1.0000 norm=0.4717
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3833 val_loss=0.0000 scale=2.0000 norm=1.1055
[iter 200] loss=-0.2501 val_loss=0.0000 scale=2.0000 norm=0.9736
[iter 300] loss=-0.7467 val_loss=0.0000 scale=2.0000 norm=0.8759
[iter 400] loss=-1.0616 val_loss=0.0000 scale=1.0000 norm=0.4248
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.1221
[iter 200] loss=-0.4232 val_loss=0.0000 scale=2.0000 norm=1.0781
[iter 300] loss=-1.1821 val_loss=0.0000 scale=2.0000 norm=1.0521
[iter 400] loss=-1.9048 val_loss=0.0000 scale=2.0000 norm=1.0077
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3842 val_loss=0.0000 scale=2.0000 norm=1.0397
[iter 200] loss=-0.1742 val_loss=0.0000 scale=2.0000 norm=0.9475
[iter 300] loss=-0.5160 val_loss=0.0000 scale=1.0000 norm=0.4612
[iter 400] loss=-0.7875 val_loss=0.0000 scale=0.5000 norm=0.2216
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3393 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.3047 val_loss=0.0000 scale=2.0000 norm=0.9705
[iter 300] loss=-0.7846 val_loss=0.0000 scale=2.0000 norm=0.9291
[iter 400] loss=-1.0585 val_loss=0.0000 scale=0.5000 norm=0.2242
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4069 val_loss=0.0000 scale=2.0000 norm=1.0744
[iter 200] loss=-0.1905 val_loss=0.0000 scale=2.0000 norm=0.9719
[iter 300] loss=-0.5908 val_loss=0.0000 scale=1.0000 norm=0.4518
[iter 400] loss=-0.8885 val_loss=0.0000 scale=1.0000 norm=0.4277
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5055 val_loss=0.0000 scale=2.0000 norm=1.1096
[iter 200] loss=-0.0568 val_loss=0.0000 scale=2.0000 norm=1.0235
[iter 300] loss=-0.4692 val_loss=0.0000 scale=2.0000 norm=0.9887
[iter 400] loss=-0.7556 val_loss=0.0000 scale=1.0000 norm=0.4931
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3610 val_loss=0.0000 scale=2.0000 norm=1.0581
[iter 200] loss=-0.2535 val_loss=0.0000 scale=2.0000 norm=0.9802
[iter 300] loss=-0.7126 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 400] loss=-0.9817 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5937 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 200] loss=-0.0053 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 300] loss=-0.3917 val_loss=0.0000 scale=1.0000 norm=0.4421
[iter 400] loss=-0.8030 val_loss=0.0000 scale=1.0000 norm=0.4450
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5432 val_loss=0.0000 scale=2.0000 norm=1.1313
[iter 200] loss=-0.0469 val_loss=0.0000 scale=2.0000 norm=0.9897
[iter 300] loss=-0.4367 val_loss=0.0000 scale=2.0000 norm=0.9449
[iter 400] loss=-0.6575 val_loss=0.0000 scale=1.0000 norm=0.4574
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2827 val_loss=0.0000 scale=2.0000 norm=0.9982
[iter 200] loss=-0.4386 val_loss=0.0000 scale=2.0000 norm=0.9196
[iter 300] loss=-0.9912 val_loss=0.0000 scale=2.0000 norm=0.8440
[iter 400] loss=-1.2885 val_loss=0.0000 scale=2.0000 norm=0.8342
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4130 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.3170 val_loss=0.0000 scale=2.0000 norm=0.9625
[iter 300] loss=-0.8817 val_loss=0.0000 scale=2.0000 norm=0.9194
[iter 400] loss=-1.3503 val_loss=0.0000 scale=2.0000 norm=0.9605
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6066 val_loss=0.0000 scale=2.0000 norm=1.1517
[iter 200] loss=0.0534 val_loss=0.0000 scale=2.0000 norm=1.0542
[iter 300] loss=-0.4093 val_loss=0.0000 scale=1.0000 norm=0.5084
[iter 400] loss=-0.7914 val_loss=0.0000 scale=1.0000 norm=0.4773
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4143 val_loss=0.0000 scale=2.0000 norm=1.1163
[iter 200] loss=-0.3906 val_loss=0.0000 scale=4.0000 norm=2.2490
[iter 300] loss=-1.8072 val_loss=0.0000 scale=4.0000 norm=2.1115
[iter 400] loss=-2.8041 val_loss=0.0000 scale=4.0000 norm=2.0427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3377 val_loss=0.0000 scale=2.0000 norm=1.0204
[iter 200] loss=-0.2606 val_loss=0.0000 scale=2.0000 norm=0.9342
[iter 300] loss=-0.6989 val_loss=0.0000 scale=1.0000 norm=0.4476
[iter 400] loss=-0.9588 val_loss=0.0000 scale=2.0000 norm=0.8646
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1303 val_loss=0.0000 scale=2.0000 norm=0.9742
[iter 200] loss=-0.7765 val_loss=0.0000 scale=2.0000 norm=0.9156
[iter 300] loss=-1.6333 val_loss=0.0000 scale=2.0000 norm=0.8579
[iter 400] loss=-2.4094 val_loss=0.0000 scale=2.0000 norm=0.7840
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3877 val_loss=0.0000 scale=2.0000 norm=1.0676
[iter 200] loss=-0.2076 val_loss=0.0000 scale=2.0000 norm=0.9815
[iter 300] loss=-0.6277 val_loss=0.0000 scale=2.0000 norm=0.9449
[iter 400] loss=-0.8593 val_loss=0.0000 scale=2.0000 norm=0.9160
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4218 val_loss=0.0000 scale=2.0000 norm=1.0596
[iter 200] loss=-0.1264 val_loss=0.0000 scale=2.0000 norm=0.9834
[iter 300] loss=-0.4629 val_loss=0.0000 scale=1.0000 norm=0.4805
[iter 400] loss=-0.7417 val_loss=0.0000 scale=1.0000 norm=0.4625
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4101 val_loss=0.0000 scale=2.0000 norm=1.0955
[iter 200] loss=-0.3137 val_loss=0.0000 scale=2.0000 norm=1.0358
[iter 300] loss=-0.9264 val_loss=0.0000 scale=2.0000 norm=1.0462
[iter 400] loss=-1.4316 val_loss=0.0000 scale=2.0000 norm=1.0452
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5170 val_loss=0.0000 scale=2.0000 norm=1.0945
[iter 200] loss=-0.0884 val_loss=0.0000 scale=2.0000 norm=0.9068
[iter 300] loss=-0.4859 val_loss=0.0000 scale=1.0000 norm=0.4092
[iter 400] loss=-0.7258 val_loss=0.0000 scale=1.0000 norm=0.3952
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3700 val_loss=0.0000 scale=2.0000 norm=1.0616
[iter 200] loss=-0.2169 val_loss=0.0000 scale=2.0000 norm=0.9529
[iter 300] loss=-0.6172 val_loss=0.0000 scale=2.0000 norm=0.8929
[iter 400] loss=-0.9151 val_loss=0.0000 scale=1.0000 norm=0.4408
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1734 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.5695 val_loss=0.0000 scale=2.0000 norm=0.9206
[iter 300] loss=-1.1602 val_loss=0.0000 scale=2.0000 norm=0.8731
[iter 400] loss=-1.6009 val_loss=0.0000 scale=2.0000 norm=0.8219
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3395 val_loss=0.0000 scale=2.0000 norm=1.0384
[iter 200] loss=-0.2615 val_loss=0.0000 scale=2.0000 norm=0.9409
[iter 300] loss=-0.6404 val_loss=0.0000 scale=2.0000 norm=0.9001
[iter 400] loss=-0.8549 val_loss=0.0000 scale=1.0000 norm=0.4529
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2934 val_loss=0.0000 scale=2.0000 norm=1.0182
[iter 200] loss=-0.3684 val_loss=0.0000 scale=2.0000 norm=0.9530
[iter 300] loss=-0.9313 val_loss=0.0000 scale=2.0000 norm=0.9651
[iter 400] loss=-1.3969 val_loss=0.0000 scale=1.0000 norm=0.4702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3837 val_loss=0.0000 scale=2.0000 norm=1.0715
[iter 200] loss=-0.1905 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-0.6095 val_loss=0.0000 scale=1.0000 norm=0.4748
[iter 400] loss=-0.8221 val_loss=0.0000 scale=1.0000 norm=0.4628
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6135 val_loss=0.0000 scale=2.0000 norm=1.1201
[iter 200] loss=-0.1578 val_loss=0.0000 scale=2.0000 norm=0.9878
[iter 300] loss=-0.8206 val_loss=0.0000 scale=2.0000 norm=0.9546
[iter 400] loss=-1.3897 val_loss=0.0000 scale=2.0000 norm=0.9701
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4983 val_loss=0.0000 scale=2.0000 norm=1.0719
[iter 200] loss=-0.2911 val_loss=0.0000 scale=2.0000 norm=0.9625
[iter 300] loss=-0.9179 val_loss=0.0000 scale=1.0000 norm=0.4688
[iter 400] loss=-1.3881 val_loss=0.0000 scale=2.0000 norm=0.9302
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2093 val_loss=0.0000 scale=2.0000 norm=1.0523
[iter 200] loss=-0.6777 val_loss=0.0000 scale=2.0000 norm=1.0357
[iter 300] loss=-1.5523 val_loss=0.0000 scale=2.0000 norm=1.0371
[iter 400] loss=-2.4147 val_loss=0.0000 scale=2.0000 norm=1.0230
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3098 val_loss=0.0000 scale=2.0000 norm=1.0338
[iter 200] loss=-0.4280 val_loss=0.0000 scale=2.0000 norm=0.9348
[iter 300] loss=-1.0139 val_loss=0.0000 scale=2.0000 norm=0.9066
[iter 400] loss=-1.5746 val_loss=0.0000 scale=2.0000 norm=0.8650
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4196 val_loss=0.0000 scale=2.0000 norm=1.0714
[iter 200] loss=-0.3738 val_loss=0.0000 scale=2.0000 norm=0.9665
[iter 300] loss=-1.1157 val_loss=0.0000 scale=2.0000 norm=0.9482
[iter 400] loss=-1.8072 val_loss=0.0000 scale=2.0000 norm=0.9164
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3908 val_loss=0.0000 scale=2.0000 norm=1.0620
[iter 200] loss=-0.3039 val_loss=0.0000 scale=2.0000 norm=0.9365
[iter 300] loss=-0.8483 val_loss=0.0000 scale=2.0000 norm=0.8626
[iter 400] loss=-1.2122 val_loss=0.0000 scale=1.0000 norm=0.4057
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4835 val_loss=0.0000 scale=2.0000 norm=1.0986
[iter 200] loss=-0.0303 val_loss=0.0000 scale=2.0000 norm=1.0056
[iter 300] loss=-0.3423 val_loss=0.0000 scale=1.0000 norm=0.4755
[iter 400] loss=-0.5385 val_loss=0.0000 scale=2.0000 norm=0.9241
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6759 val_loss=0.0000 scale=2.0000 norm=1.2351
[iter 200] loss=0.1249 val_loss=0.0000 scale=1.0000 norm=0.5433
[iter 300] loss=-0.2481 val_loss=0.0000 scale=1.0000 norm=0.5009
[iter 400] loss=-0.5262 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4033 val_loss=0.0000 scale=2.0000 norm=1.0750
[iter 200] loss=-0.1791 val_loss=0.0000 scale=2.0000 norm=0.9595
[iter 300] loss=-0.6037 val_loss=0.0000 scale=1.0000 norm=0.4482
[iter 400] loss=-0.7886 val_loss=0.0000 scale=1.0000 norm=0.4390
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3523 val_loss=0.0000 scale=2.0000 norm=1.0569
[iter 200] loss=-0.3804 val_loss=0.0000 scale=2.0000 norm=1.0160
[iter 300] loss=-1.2866 val_loss=0.0000 scale=4.0000 norm=2.1229
[iter 400] loss=-2.2799 val_loss=0.0000 scale=4.0000 norm=1.9945
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4596 val_loss=0.0000 scale=2.0000 norm=1.1054
[iter 200] loss=-0.0647 val_loss=0.0000 scale=2.0000 norm=0.9876
[iter 300] loss=-0.4431 val_loss=0.0000 scale=2.0000 norm=0.9833
[iter 400] loss=-0.7173 val_loss=0.0000 scale=2.0000 norm=0.9910
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3161 val_loss=0.0000 scale=2.0000 norm=1.0246
[iter 200] loss=-0.3030 val_loss=0.0000 scale=2.0000 norm=0.9370
[iter 300] loss=-0.7567 val_loss=0.0000 scale=2.0000 norm=0.9235
[iter 400] loss=-1.0186 val_loss=0.0000 scale=2.0000 norm=0.9273
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3653 val_loss=0.0000 scale=2.0000 norm=1.0790
[iter 200] loss=-0.2688 val_loss=0.0000 scale=2.0000 norm=1.0031
[iter 300] loss=-0.7768 val_loss=0.0000 scale=2.0000 norm=0.9516
[iter 400] loss=-1.1374 val_loss=0.0000 scale=1.0000 norm=0.4530
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5162 val_loss=0.0000 scale=2.0000 norm=1.1169
[iter 200] loss=0.0181 val_loss=0.0000 scale=2.0000 norm=0.9978
[iter 300] loss=-0.3189 val_loss=0.0000 scale=1.0000 norm=0.4667
[iter 400] loss=-0.4912 val_loss=0.0000 scale=2.0000 norm=0.9068
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3314 val_loss=0.0000 scale=2.0000 norm=1.0317
[iter 200] loss=-0.2588 val_loss=0.0000 scale=2.0000 norm=0.9587
[iter 300] loss=-0.6413 val_loss=0.0000 scale=2.0000 norm=0.9329
[iter 400] loss=-0.8936 val_loss=0.0000 scale=1.0000 norm=0.4527
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3374 val_loss=0.0000 scale=2.0000 norm=1.0312
[iter 200] loss=-0.2885 val_loss=0.0000 scale=2.0000 norm=0.9575
[iter 300] loss=-0.7398 val_loss=0.0000 scale=2.0000 norm=0.9331
[iter 400] loss=-0.9901 val_loss=0.0000 scale=1.0000 norm=0.4526
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3743 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.1710 val_loss=0.0000 scale=2.0000 norm=0.9454
[iter 300] loss=-0.5293 val_loss=0.0000 scale=1.0000 norm=0.4442
[iter 400] loss=-0.7721 val_loss=0.0000 scale=1.0000 norm=0.4253
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3084 val_loss=0.0000 scale=2.0000 norm=1.0339
[iter 200] loss=-0.2829 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-0.7956 val_loss=0.0000 scale=2.0000 norm=0.9188
[iter 400] loss=-1.1990 val_loss=0.0000 scale=2.0000 norm=0.8709
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3890 val_loss=0.0000 scale=2.0000 norm=1.0844
[iter 200] loss=-0.1733 val_loss=0.0000 scale=2.0000 norm=0.9646
[iter 300] loss=-0.5363 val_loss=0.0000 scale=2.0000 norm=0.9297
[iter 400] loss=-0.7148 val_loss=0.0000 scale=2.0000 norm=0.9057
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2784 val_loss=0.0000 scale=2.0000 norm=0.9592
[iter 200] loss=-0.5400 val_loss=0.0000 scale=2.0000 norm=0.8696
[iter 300] loss=-1.1764 val_loss=0.0000 scale=2.0000 norm=0.7379
[iter 400] loss=-1.6402 val_loss=0.0000 scale=2.0000 norm=0.6602
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4041 val_loss=0.0000 scale=2.0000 norm=1.0882
[iter 200] loss=-0.1447 val_loss=0.0000 scale=2.0000 norm=0.9974
[iter 300] loss=-0.5116 val_loss=0.0000 scale=2.0000 norm=0.9446
[iter 400] loss=-0.7188 val_loss=0.0000 scale=2.0000 norm=0.9199
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3772 val_loss=0.0000 scale=2.0000 norm=1.0683
[iter 200] loss=-0.2587 val_loss=0.0000 scale=2.0000 norm=0.9422
[iter 300] loss=-0.7068 val_loss=0.0000 scale=2.0000 norm=0.8712
[iter 400] loss=-0.9908 val_loss=0.0000 scale=1.0000 norm=0.4284
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3311 val_loss=0.0000 scale=2.0000 norm=1.0385
[iter 200] loss=-0.2938 val_loss=0.0000 scale=2.0000 norm=0.9431
[iter 300] loss=-0.7534 val_loss=0.0000 scale=1.0000 norm=0.4396
[iter 400] loss=-0.9829 val_loss=0.0000 scale=0.5000 norm=0.2143
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2839 val_loss=0.0000 scale=2.0000 norm=1.0236
[iter 200] loss=-0.3433 val_loss=0.0000 scale=2.0000 norm=0.9290
[iter 300] loss=-0.8454 val_loss=0.0000 scale=2.0000 norm=0.8781
[iter 400] loss=-1.1957 val_loss=0.0000 scale=2.0000 norm=0.8300
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1370 val_loss=0.0000 scale=2.0000 norm=0.9794
[iter 200] loss=-0.6898 val_loss=0.0000 scale=2.0000 norm=0.9306
[iter 300] loss=-1.3636 val_loss=0.0000 scale=2.0000 norm=0.8855
[iter 400] loss=-1.8998 val_loss=0.0000 scale=2.0000 norm=0.8600
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3018 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 200] loss=-0.3320 val_loss=0.0000 scale=2.0000 norm=0.9176
[iter 300] loss=-0.7900 val_loss=0.0000 scale=2.0000 norm=0.8668
[iter 400] loss=-1.0469 val_loss=0.0000 scale=2.0000 norm=0.8493
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6772 val_loss=0.0000 scale=2.0000 norm=1.1926
[iter 200] loss=0.1723 val_loss=0.0000 scale=2.0000 norm=1.0474
[iter 300] loss=-0.2603 val_loss=0.0000 scale=2.0000 norm=0.9737
[iter 400] loss=-0.5812 val_loss=0.0000 scale=1.0000 norm=0.4592
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4866 val_loss=0.0000 scale=2.0000 norm=1.0874
[iter 200] loss=-0.0686 val_loss=0.0000 scale=2.0000 norm=0.9771
[iter 300] loss=-0.4263 val_loss=0.0000 scale=1.0000 norm=0.4763
[iter 400] loss=-0.6719 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3603 val_loss=0.0000 scale=2.0000 norm=1.0583
[iter 200] loss=-0.2341 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 300] loss=-0.6504 val_loss=0.0000 scale=2.0000 norm=0.9546
[iter 400] loss=-0.8921 val_loss=0.0000 scale=2.0000 norm=0.9119
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3341 val_loss=0.0000 scale=2.0000 norm=1.0551
[iter 200] loss=-0.3696 val_loss=0.0000 scale=2.0000 norm=0.9669
[iter 300] loss=-0.9383 val_loss=0.0000 scale=1.0000 norm=0.4594
[iter 400] loss=-1.2593 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3999 val_loss=0.0000 scale=2.0000 norm=1.0758
[iter 200] loss=-0.1917 val_loss=0.0000 scale=2.0000 norm=0.9469
[iter 300] loss=-0.5834 val_loss=0.0000 scale=2.0000 norm=0.9007
[iter 400] loss=-0.8312 val_loss=0.0000 scale=1.0000 norm=0.4450
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3589 val_loss=0.0000 scale=2.0000 norm=1.0493
[iter 200] loss=-0.2084 val_loss=0.0000 scale=1.0000 norm=0.4779
[iter 300] loss=-0.6311 val_loss=0.0000 scale=2.0000 norm=0.9010
[iter 400] loss=-0.8809 val_loss=0.0000 scale=1.0000 norm=0.4409
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4291 val_loss=0.0000 scale=2.0000 norm=1.0350
[iter 200] loss=-0.3310 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 300] loss=-1.0022 val_loss=0.0000 scale=2.0000 norm=0.8570
[iter 400] loss=-1.5252 val_loss=0.0000 scale=1.0000 norm=0.4018
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2202 val_loss=0.0000 scale=2.0000 norm=1.0271
[iter 200] loss=-0.4901 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 300] loss=-1.0347 val_loss=0.0000 scale=2.0000 norm=0.8232
[iter 400] loss=-1.4098 val_loss=0.0000 scale=1.0000 norm=0.3675
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5590 val_loss=0.0000 scale=2.0000 norm=1.1063
[iter 200] loss=-0.1666 val_loss=0.0000 scale=2.0000 norm=1.0819
[iter 300] loss=-0.8660 val_loss=0.0000 scale=2.0000 norm=1.0780
[iter 400] loss=-1.5337 val_loss=0.0000 scale=2.0000 norm=1.0428
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3846 val_loss=0.0000 scale=2.0000 norm=1.1313
[iter 200] loss=-0.3648 val_loss=0.0000 scale=2.0000 norm=1.0926
[iter 300] loss=-1.0149 val_loss=0.0000 scale=2.0000 norm=1.0499
[iter 400] loss=-1.6570 val_loss=0.0000 scale=4.0000 norm=2.1560
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3993 val_loss=0.0000 scale=2.0000 norm=1.0685
[iter 200] loss=-0.2061 val_loss=0.0000 scale=2.0000 norm=0.9399
[iter 300] loss=-0.6711 val_loss=0.0000 scale=1.0000 norm=0.4456
[iter 400] loss=-0.9901 val_loss=0.0000 scale=1.0000 norm=0.4289
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2328 val_loss=0.0000 scale=2.0000 norm=0.9848
[iter 200] loss=-0.5276 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 300] loss=-1.1394 val_loss=0.0000 scale=2.0000 norm=0.8160
[iter 400] loss=-1.6149 val_loss=0.0000 scale=2.0000 norm=0.7739
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3028 val_loss=0.0000 scale=2.0000 norm=1.0088
[iter 200] loss=-0.3185 val_loss=0.0000 scale=2.0000 norm=0.9631
[iter 300] loss=-0.8420 val_loss=0.0000 scale=2.0000 norm=0.9353
[iter 400] loss=-1.2726 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6133 val_loss=0.0000 scale=2.0000 norm=1.1544
[iter 200] loss=0.0270 val_loss=0.0000 scale=1.0000 norm=0.4897
[iter 300] loss=-0.3210 val_loss=0.0000 scale=2.0000 norm=0.9607
[iter 400] loss=-0.5957 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3191 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.2718 val_loss=0.0000 scale=2.0000 norm=0.9468
[iter 300] loss=-0.7108 val_loss=0.0000 scale=2.0000 norm=0.9104
[iter 400] loss=-1.0199 val_loss=0.0000 scale=2.0000 norm=0.8819
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3595 val_loss=0.0000 scale=2.0000 norm=1.0393
[iter 200] loss=-0.3401 val_loss=0.0000 scale=2.0000 norm=0.9685
[iter 300] loss=-0.9152 val_loss=0.0000 scale=2.0000 norm=0.9327
[iter 400] loss=-1.4240 val_loss=0.0000 scale=2.0000 norm=0.9019
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3262 val_loss=0.0000 scale=2.0000 norm=1.0187
[iter 200] loss=-0.2559 val_loss=0.0000 scale=2.0000 norm=0.9263
[iter 300] loss=-0.6514 val_loss=0.0000 scale=1.0000 norm=0.4345
[iter 400] loss=-0.8624 val_loss=0.0000 scale=2.0000 norm=0.8172
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3686 val_loss=0.0000 scale=2.0000 norm=1.0334
[iter 200] loss=-0.1894 val_loss=0.0000 scale=2.0000 norm=0.9429
[iter 300] loss=-0.5627 val_loss=0.0000 scale=1.0000 norm=0.4538
[iter 400] loss=-0.7876 val_loss=0.0000 scale=1.0000 norm=0.4543
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3388 val_loss=0.0000 scale=2.0000 norm=1.0350
[iter 200] loss=-0.3121 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 300] loss=-0.7972 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 400] loss=-1.1245 val_loss=0.0000 scale=2.0000 norm=0.8822
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2732 val_loss=0.0000 scale=2.0000 norm=1.0084
[iter 200] loss=-0.4565 val_loss=0.0000 scale=2.0000 norm=0.8925
[iter 300] loss=-0.9973 val_loss=0.0000 scale=2.0000 norm=0.8151
[iter 400] loss=-1.4156 val_loss=0.0000 scale=2.0000 norm=0.7495
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3483 val_loss=0.0000 scale=2.0000 norm=1.0925
[iter 200] loss=-0.2604 val_loss=0.0000 scale=1.0000 norm=0.4833
[iter 300] loss=-0.6715 val_loss=0.0000 scale=2.0000 norm=0.8856
[iter 400] loss=-1.0307 val_loss=0.0000 scale=2.0000 norm=0.8226
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4192 val_loss=0.0000 scale=2.0000 norm=1.0814
[iter 200] loss=-0.1322 val_loss=0.0000 scale=2.0000 norm=0.9958
[iter 300] loss=-0.5240 val_loss=0.0000 scale=2.0000 norm=0.9475
[iter 400] loss=-0.7230 val_loss=0.0000 scale=1.0000 norm=0.4478
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3025 val_loss=0.0000 scale=2.0000 norm=1.0399
[iter 200] loss=-0.3377 val_loss=0.0000 scale=2.0000 norm=0.9312
[iter 300] loss=-0.8026 val_loss=0.0000 scale=2.0000 norm=0.8435
[iter 400] loss=-1.1463 val_loss=0.0000 scale=2.0000 norm=0.8203
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6142 val_loss=0.0000 scale=2.0000 norm=1.1759
[iter 200] loss=0.1309 val_loss=0.0000 scale=2.0000 norm=1.0405
[iter 300] loss=-0.2596 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 400] loss=-0.5025 val_loss=0.0000 scale=2.0000 norm=0.9578
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3302 val_loss=0.0000 scale=2.0000 norm=1.0351
[iter 200] loss=-0.2654 val_loss=0.0000 scale=2.0000 norm=0.9403
[iter 300] loss=-0.6838 val_loss=0.0000 scale=2.0000 norm=0.9065
[iter 400] loss=-0.9421 val_loss=0.0000 scale=1.0000 norm=0.4406
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3142 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 200] loss=-0.4300 val_loss=0.0000 scale=2.0000 norm=0.9060
[iter 300] loss=-1.0906 val_loss=0.0000 scale=2.0000 norm=0.8649
[iter 400] loss=-1.6721 val_loss=0.0000 scale=2.0000 norm=0.8744
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2363 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 200] loss=-0.4609 val_loss=0.0000 scale=2.0000 norm=0.9799
[iter 300] loss=-1.0386 val_loss=0.0000 scale=2.0000 norm=0.9636
[iter 400] loss=-1.4009 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4308 val_loss=0.0000 scale=2.0000 norm=1.1082
[iter 200] loss=-0.1932 val_loss=0.0000 scale=2.0000 norm=0.9925
[iter 300] loss=-0.6669 val_loss=0.0000 scale=2.0000 norm=0.9306
[iter 400] loss=-1.0034 val_loss=0.0000 scale=2.0000 norm=0.8919
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4342 val_loss=0.0000 scale=2.0000 norm=1.1156
[iter 200] loss=-0.1160 val_loss=0.0000 scale=2.0000 norm=0.9920
[iter 300] loss=-0.4987 val_loss=0.0000 scale=1.0000 norm=0.4625
[iter 400] loss=-0.7529 val_loss=0.0000 scale=1.0000 norm=0.4404
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1896 val_loss=0.0000 scale=2.0000 norm=1.0224
[iter 200] loss=-0.6319 val_loss=0.0000 scale=2.0000 norm=0.9584
[iter 300] loss=-1.3610 val_loss=0.0000 scale=2.0000 norm=0.9105
[iter 400] loss=-1.9844 val_loss=0.0000 scale=2.0000 norm=0.8638
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4009 val_loss=0.0000 scale=2.0000 norm=1.0676
[iter 200] loss=-0.2312 val_loss=0.0000 scale=2.0000 norm=0.9816
[iter 300] loss=-0.7279 val_loss=0.0000 scale=1.0000 norm=0.4679
[iter 400] loss=-1.0153 val_loss=0.0000 scale=2.0000 norm=0.8870
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4104 val_loss=0.0000 scale=2.0000 norm=1.0875
[iter 200] loss=-0.1793 val_loss=0.0000 scale=1.0000 norm=0.5035
[iter 300] loss=-0.6396 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 400] loss=-0.9082 val_loss=0.0000 scale=1.0000 norm=0.4842
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4249 val_loss=0.0000 scale=2.0000 norm=1.0700
[iter 200] loss=-0.4092 val_loss=0.0000 scale=2.0000 norm=1.0235
[iter 300] loss=-1.1017 val_loss=0.0000 scale=2.0000 norm=0.8918
[iter 400] loss=-1.6412 val_loss=0.0000 scale=4.0000 norm=1.7070
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3899 val_loss=0.0000 scale=2.0000 norm=1.0531
[iter 200] loss=-0.2103 val_loss=0.0000 scale=2.0000 norm=0.9351
[iter 300] loss=-0.5572 val_loss=0.0000 scale=1.0000 norm=0.4500
[iter 400] loss=-0.7941 val_loss=0.0000 scale=1.0000 norm=0.4344
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4328 val_loss=0.0000 scale=2.0000 norm=0.9945
[iter 200] loss=-0.1973 val_loss=0.0000 scale=2.0000 norm=0.9235
[iter 300] loss=-0.6940 val_loss=0.0000 scale=2.0000 norm=0.9272
[iter 400] loss=-1.0895 val_loss=0.0000 scale=2.0000 norm=0.9178
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3397 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 200] loss=-0.2374 val_loss=0.0000 scale=2.0000 norm=0.9668
[iter 300] loss=-0.6499 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-0.8714 val_loss=0.0000 scale=1.0000 norm=0.4632
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2414 val_loss=0.0000 scale=2.0000 norm=1.0020
[iter 200] loss=-0.4684 val_loss=0.0000 scale=2.0000 norm=0.9054
[iter 300] loss=-1.0008 val_loss=0.0000 scale=2.0000 norm=0.8877
[iter 400] loss=-1.3575 val_loss=0.0000 scale=2.0000 norm=0.8984
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3517 val_loss=0.0000 scale=2.0000 norm=1.0589
[iter 200] loss=-0.2680 val_loss=0.0000 scale=2.0000 norm=0.9870
[iter 300] loss=-0.7542 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 400] loss=-1.0628 val_loss=0.0000 scale=2.0000 norm=0.9004
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5360 val_loss=0.0000 scale=2.0000 norm=1.1516
[iter 200] loss=0.0317 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 300] loss=-0.2803 val_loss=0.0000 scale=1.0000 norm=0.4868
[iter 400] loss=-0.5000 val_loss=0.0000 scale=1.0000 norm=0.4694
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3460 val_loss=0.0000 scale=2.0000 norm=1.0438
[iter 200] loss=-0.2447 val_loss=0.0000 scale=2.0000 norm=0.9433
[iter 300] loss=-0.6579 val_loss=0.0000 scale=1.0000 norm=0.4641
[iter 400] loss=-0.8752 val_loss=0.0000 scale=1.0000 norm=0.4471
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3659 val_loss=0.0000 scale=2.0000 norm=1.0514
[iter 200] loss=-0.2398 val_loss=0.0000 scale=2.0000 norm=0.9589
[iter 300] loss=-0.5987 val_loss=0.0000 scale=2.0000 norm=0.9416
[iter 400] loss=-0.8108 val_loss=0.0000 scale=0.5000 norm=0.2303
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3768 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3417 val_loss=0.0000 scale=2.0000 norm=0.9122
[iter 300] loss=-0.8779 val_loss=0.0000 scale=2.0000 norm=0.8360
[iter 400] loss=-1.3387 val_loss=0.0000 scale=2.0000 norm=0.7684
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3608 val_loss=0.0000 scale=2.0000 norm=1.0537
[iter 200] loss=-0.2181 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 300] loss=-0.5652 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 400] loss=-0.7802 val_loss=0.0000 scale=1.0000 norm=0.4717
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5193 val_loss=0.0000 scale=2.0000 norm=1.1518
[iter 200] loss=0.0209 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 300] loss=-0.3238 val_loss=0.0000 scale=2.0000 norm=1.0222
[iter 400] loss=-0.5077 val_loss=0.0000 scale=1.0000 norm=0.4999
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6572 val_loss=0.0000 scale=2.0000 norm=1.1596
[iter 200] loss=0.0363 val_loss=0.0000 scale=2.0000 norm=1.0183
[iter 300] loss=-0.5117 val_loss=0.0000 scale=2.0000 norm=0.9700
[iter 400] loss=-0.9224 val_loss=0.0000 scale=2.0000 norm=0.9445
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3400 val_loss=0.0000 scale=2.0000 norm=1.0433
[iter 200] loss=-0.2671 val_loss=0.0000 scale=2.0000 norm=0.9371
[iter 300] loss=-0.6346 val_loss=0.0000 scale=2.0000 norm=0.8896
[iter 400] loss=-0.8579 val_loss=0.0000 scale=1.0000 norm=0.4415
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5914 val_loss=0.0000 scale=2.0000 norm=1.1297
[iter 200] loss=0.1574 val_loss=0.0000 scale=2.0000 norm=1.0141
[iter 300] loss=-0.2107 val_loss=0.0000 scale=2.0000 norm=0.9778
[iter 400] loss=-0.4956 val_loss=0.0000 scale=1.0000 norm=0.4729
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.1565
[iter 200] loss=-0.4137 val_loss=0.0000 scale=2.0000 norm=1.1430
[iter 300] loss=-1.2506 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 400] loss=-2.3595 val_loss=0.0000 scale=4.0000 norm=2.3123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1854 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 200] loss=-0.6132 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 300] loss=-1.3294 val_loss=0.0000 scale=2.0000 norm=0.9116
[iter 400] loss=-1.9540 val_loss=0.0000 scale=2.0000 norm=0.8780
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4113 val_loss=0.0000 scale=2.0000 norm=1.0604
[iter 200] loss=-0.1135 val_loss=0.0000 scale=2.0000 norm=0.9415
[iter 300] loss=-0.4609 val_loss=0.0000 scale=2.0000 norm=0.9051
[iter 400] loss=-0.7143 val_loss=0.0000 scale=1.0000 norm=0.4504
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 200] loss=-0.6424 val_loss=0.0000 scale=2.0000 norm=0.8689
[iter 300] loss=-1.3412 val_loss=0.0000 scale=2.0000 norm=0.8275
[iter 400] loss=-2.0693 val_loss=0.0000 scale=2.0000 norm=0.7732
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3197 val_loss=0.0000 scale=2.0000 norm=1.0282
[iter 200] loss=-0.2751 val_loss=0.0000 scale=2.0000 norm=0.9409
[iter 300] loss=-0.6738 val_loss=0.0000 scale=2.0000 norm=0.9224
[iter 400] loss=-0.8709 val_loss=0.0000 scale=0.5000 norm=0.2215
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5566 val_loss=0.0000 scale=2.0000 norm=1.1745
[iter 200] loss=0.0136 val_loss=0.0000 scale=2.0000 norm=1.0461
[iter 300] loss=-0.3815 val_loss=0.0000 scale=2.0000 norm=0.9943
[iter 400] loss=-0.5900 val_loss=0.0000 scale=2.0000 norm=0.9534
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3953 val_loss=0.0000 scale=2.0000 norm=1.0727
[iter 200] loss=-0.1513 val_loss=0.0000 scale=2.0000 norm=0.9891
[iter 300] loss=-0.4823 val_loss=0.0000 scale=1.0000 norm=0.4754
[iter 400] loss=-0.6605 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2815 val_loss=0.0000 scale=2.0000 norm=1.0020
[iter 200] loss=-0.3407 val_loss=0.0000 scale=2.0000 norm=0.9260
[iter 300] loss=-0.8646 val_loss=0.0000 scale=2.0000 norm=0.9084
[iter 400] loss=-1.2664 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4041 val_loss=0.0000 scale=2.0000 norm=1.0749
[iter 200] loss=-0.1534 val_loss=0.0000 scale=2.0000 norm=0.9660
[iter 300] loss=-0.5512 val_loss=0.0000 scale=1.0000 norm=0.4626
[iter 400] loss=-0.7903 val_loss=0.0000 scale=1.0000 norm=0.4427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3643 val_loss=0.0000 scale=2.0000 norm=1.0389
[iter 200] loss=-0.2198 val_loss=0.0000 scale=2.0000 norm=0.9462
[iter 300] loss=-0.6439 val_loss=0.0000 scale=2.0000 norm=0.9023
[iter 400] loss=-0.8833 val_loss=0.0000 scale=2.0000 norm=0.8540
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3671 val_loss=0.0000 scale=2.0000 norm=1.0092
[iter 200] loss=-0.3738 val_loss=0.0000 scale=2.0000 norm=0.9226
[iter 300] loss=-1.0019 val_loss=0.0000 scale=2.0000 norm=0.8882
[iter 400] loss=-1.4967 val_loss=0.0000 scale=1.0000 norm=0.4338
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4966 val_loss=0.0000 scale=2.0000 norm=1.1289
[iter 200] loss=-0.1673 val_loss=0.0000 scale=2.0000 norm=1.0055
[iter 300] loss=-0.6581 val_loss=0.0000 scale=2.0000 norm=0.9669
[iter 400] loss=-0.9803 val_loss=0.0000 scale=1.0000 norm=0.4795
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4278 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.3749 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 300] loss=-1.0725 val_loss=0.0000 scale=2.0000 norm=0.8359
[iter 400] loss=-1.7115 val_loss=0.0000 scale=2.0000 norm=0.8145
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4149 val_loss=0.0000 scale=2.0000 norm=1.0751
[iter 200] loss=-0.1178 val_loss=0.0000 scale=2.0000 norm=0.9623
[iter 300] loss=-0.4754 val_loss=0.0000 scale=2.0000 norm=0.9336
[iter 400] loss=-0.7008 val_loss=0.0000 scale=2.0000 norm=0.9006
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4980 val_loss=0.0000 scale=2.0000 norm=1.1206
[iter 200] loss=-0.0980 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-0.5236 val_loss=0.0000 scale=1.0000 norm=0.4615
[iter 400] loss=-0.8512 val_loss=0.0000 scale=1.0000 norm=0.4449
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3659 val_loss=0.0000 scale=2.0000 norm=1.0515
[iter 200] loss=-0.2126 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 300] loss=-0.6191 val_loss=0.0000 scale=1.0000 norm=0.4585
[iter 400] loss=-0.8847 val_loss=0.0000 scale=2.0000 norm=0.8957
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3384 val_loss=0.0000 scale=2.0000 norm=1.0536
[iter 200] loss=-0.2926 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-0.7623 val_loss=0.0000 scale=1.0000 norm=0.4717
[iter 400] loss=-1.0504 val_loss=0.0000 scale=1.0000 norm=0.4587
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5546 val_loss=0.0000 scale=2.0000 norm=1.1327
[iter 200] loss=0.0362 val_loss=0.0000 scale=1.0000 norm=0.5140
[iter 300] loss=-0.3347 val_loss=0.0000 scale=2.0000 norm=0.9445
[iter 400] loss=-0.6279 val_loss=0.0000 scale=2.0000 norm=0.9099
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2908 val_loss=0.0000 scale=2.0000 norm=1.0285
[iter 200] loss=-0.3591 val_loss=0.0000 scale=2.0000 norm=0.9273
[iter 300] loss=-0.8373 val_loss=0.0000 scale=1.0000 norm=0.4344
[iter 400] loss=-1.0752 val_loss=0.0000 scale=0.5000 norm=0.2067

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n12>
Subject: Job 861716: <structure_numerical_ecfp3binery_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_ecfp3binery_NGB_generalizibility> was submitted from host <c205n12> by user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:00 2024
Job was executed on host(s) <4*c205n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:59 2024
                            <4*c205n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Thu Oct 24 11:35:59 2024
Terminated at Thu Oct 24 11:39:09 2024
Results reported at Thu Oct 24 11:39:09 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 7:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_ecfp3binery_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py ecfp --regressor_type NGB --radius 3 --vector binary --target "Rg1 (nm)" --oligo_type "Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2116.31 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.67 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   215 sec.
    Turnaround time :                            249 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err> for stderr output of this job.

Dimer_scaler
Filename: (ECFP3.binary.512-Mw-PDI)_NGB_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer_scaler/(ECFP3.binary.512-Mw-PDI)_NGB_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3074 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.4242 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 300] loss=-1.0020 val_loss=0.0000 scale=2.0000 norm=0.9374
[iter 400] loss=-1.3952 val_loss=0.0000 scale=1.0000 norm=0.4471
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3815 val_loss=0.0000 scale=2.0000 norm=1.0497
[iter 200] loss=-0.1875 val_loss=0.0000 scale=2.0000 norm=0.9579
[iter 300] loss=-0.5968 val_loss=0.0000 scale=2.0000 norm=0.9288
[iter 400] loss=-0.8538 val_loss=0.0000 scale=1.0000 norm=0.4424
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1896 val_loss=0.0000 scale=2.0000 norm=1.0224
[iter 200] loss=-0.6319 val_loss=0.0000 scale=2.0000 norm=0.9584
[iter 300] loss=-1.3595 val_loss=0.0000 scale=2.0000 norm=0.9084
[iter 400] loss=-2.0035 val_loss=0.0000 scale=2.0000 norm=0.8870
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4058 val_loss=0.0000 scale=2.0000 norm=1.0662
[iter 200] loss=-0.1346 val_loss=0.0000 scale=1.0000 norm=0.4830
[iter 300] loss=-0.4542 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 400] loss=-0.6472 val_loss=0.0000 scale=1.0000 norm=0.4755
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3012 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 200] loss=-0.3253 val_loss=0.0000 scale=2.0000 norm=0.9609
[iter 300] loss=-0.7746 val_loss=0.0000 scale=2.0000 norm=0.9251
[iter 400] loss=-1.0457 val_loss=0.0000 scale=2.0000 norm=0.8847
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3381 val_loss=0.0000 scale=2.0000 norm=1.0259
[iter 200] loss=-0.2658 val_loss=0.0000 scale=2.0000 norm=0.9380
[iter 300] loss=-0.6787 val_loss=0.0000 scale=2.0000 norm=0.9173
[iter 400] loss=-0.9396 val_loss=0.0000 scale=2.0000 norm=0.8608
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3432 val_loss=0.0000 scale=2.0000 norm=1.0862
[iter 200] loss=-0.2803 val_loss=0.0000 scale=1.0000 norm=0.4825
[iter 300] loss=-0.7121 val_loss=0.0000 scale=2.0000 norm=0.8710
[iter 400] loss=-1.0356 val_loss=0.0000 scale=1.0000 norm=0.4044
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4622 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 200] loss=-0.2350 val_loss=0.0000 scale=2.0000 norm=0.9288
[iter 300] loss=-0.8645 val_loss=0.0000 scale=2.0000 norm=0.8489
[iter 400] loss=-1.3854 val_loss=0.0000 scale=2.0000 norm=0.7940
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2420 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.5057 val_loss=0.0000 scale=2.0000 norm=0.9443
[iter 300] loss=-1.1632 val_loss=0.0000 scale=2.0000 norm=0.8950
[iter 400] loss=-1.6763 val_loss=0.0000 scale=2.0000 norm=0.8479
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2839 val_loss=0.0000 scale=2.0000 norm=1.0236
[iter 200] loss=-0.3433 val_loss=0.0000 scale=2.0000 norm=0.9290
[iter 300] loss=-0.8462 val_loss=0.0000 scale=2.0000 norm=0.8809
[iter 400] loss=-1.1844 val_loss=0.0000 scale=2.0000 norm=0.8334
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1370 val_loss=0.0000 scale=2.0000 norm=0.9794
[iter 200] loss=-0.6898 val_loss=0.0000 scale=2.0000 norm=0.9306
[iter 300] loss=-1.3636 val_loss=0.0000 scale=2.0000 norm=0.8855
[iter 400] loss=-1.8998 val_loss=0.0000 scale=2.0000 norm=0.8600
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2328 val_loss=0.0000 scale=2.0000 norm=0.9848
[iter 200] loss=-0.5276 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 300] loss=-1.1394 val_loss=0.0000 scale=2.0000 norm=0.8160
[iter 400] loss=-1.6149 val_loss=0.0000 scale=2.0000 norm=0.7739
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4021 val_loss=0.0000 scale=2.0000 norm=1.0575
[iter 200] loss=-0.1295 val_loss=0.0000 scale=2.0000 norm=0.9434
[iter 300] loss=-0.4833 val_loss=0.0000 scale=2.0000 norm=0.8992
[iter 400] loss=-0.6906 val_loss=0.0000 scale=2.0000 norm=0.8805
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4982 val_loss=0.0000 scale=2.0000 norm=1.0997
[iter 200] loss=-0.0083 val_loss=0.0000 scale=2.0000 norm=0.9881
[iter 300] loss=-0.3837 val_loss=0.0000 scale=2.0000 norm=0.9398
[iter 400] loss=-0.5750 val_loss=0.0000 scale=1.0000 norm=0.4676
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5124 val_loss=0.0000 scale=2.0000 norm=1.1497
[iter 200] loss=0.0417 val_loss=0.0000 scale=2.0000 norm=1.0334
[iter 300] loss=-0.2867 val_loss=0.0000 scale=1.0000 norm=0.4823
[iter 400] loss=-0.4622 val_loss=0.0000 scale=1.0000 norm=0.4648
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3659 val_loss=0.0000 scale=2.0000 norm=1.0514
[iter 200] loss=-0.2307 val_loss=0.0000 scale=2.0000 norm=0.9616
[iter 300] loss=-0.6192 val_loss=0.0000 scale=2.0000 norm=0.9417
[iter 400] loss=-0.8391 val_loss=0.0000 scale=0.5000 norm=0.2306
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3743 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.1712 val_loss=0.0000 scale=1.0000 norm=0.4739
[iter 300] loss=-0.5189 val_loss=0.0000 scale=2.0000 norm=0.8882
[iter 400] loss=-0.7635 val_loss=0.0000 scale=2.0000 norm=0.8516
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1303 val_loss=0.0000 scale=2.0000 norm=0.9742
[iter 200] loss=-0.7765 val_loss=0.0000 scale=2.0000 norm=0.9156
[iter 300] loss=-1.6333 val_loss=0.0000 scale=2.0000 norm=0.8579
[iter 400] loss=-2.4094 val_loss=0.0000 scale=2.0000 norm=0.7840
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3901 val_loss=0.0000 scale=2.0000 norm=1.0533
[iter 200] loss=-0.1579 val_loss=0.0000 scale=2.0000 norm=0.9706
[iter 300] loss=-0.5364 val_loss=0.0000 scale=1.0000 norm=0.4865
[iter 400] loss=-0.7965 val_loss=0.0000 scale=0.5000 norm=0.2380
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3372 val_loss=0.0000 scale=2.0000 norm=1.0421
[iter 200] loss=-0.2614 val_loss=0.0000 scale=2.0000 norm=0.9569
[iter 300] loss=-0.6944 val_loss=0.0000 scale=1.0000 norm=0.4720
[iter 400] loss=-0.9550 val_loss=0.0000 scale=2.0000 norm=0.8972
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2784 val_loss=0.0000 scale=2.0000 norm=0.9592
[iter 200] loss=-0.5400 val_loss=0.0000 scale=2.0000 norm=0.8696
[iter 300] loss=-1.1764 val_loss=0.0000 scale=2.0000 norm=0.7379
[iter 400] loss=-1.6402 val_loss=0.0000 scale=2.0000 norm=0.6602
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4104 val_loss=0.0000 scale=2.0000 norm=1.0875
[iter 200] loss=-0.1793 val_loss=0.0000 scale=1.0000 norm=0.5035
[iter 300] loss=-0.6396 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 400] loss=-0.9082 val_loss=0.0000 scale=1.0000 norm=0.4842
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3298 val_loss=0.0000 scale=2.0000 norm=1.0479
[iter 200] loss=-0.2939 val_loss=0.0000 scale=2.0000 norm=0.9505
[iter 300] loss=-0.6631 val_loss=0.0000 scale=2.0000 norm=0.9407
[iter 400] loss=-0.9458 val_loss=0.0000 scale=2.0000 norm=0.8845
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5590 val_loss=0.0000 scale=2.0000 norm=1.1063
[iter 200] loss=-0.1666 val_loss=0.0000 scale=2.0000 norm=1.0819
[iter 300] loss=-0.8655 val_loss=0.0000 scale=2.0000 norm=1.0778
[iter 400] loss=-1.5337 val_loss=0.0000 scale=2.0000 norm=1.0436
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3302 val_loss=0.0000 scale=2.0000 norm=1.0391
[iter 200] loss=-0.2883 val_loss=0.0000 scale=2.0000 norm=0.9424
[iter 300] loss=-0.7157 val_loss=0.0000 scale=1.0000 norm=0.4347
[iter 400] loss=-0.9522 val_loss=0.0000 scale=1.0000 norm=0.4298
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5432 val_loss=0.0000 scale=2.0000 norm=1.1313
[iter 200] loss=-0.0370 val_loss=0.0000 scale=2.0000 norm=0.9929
[iter 300] loss=-0.4300 val_loss=0.0000 scale=2.0000 norm=0.9461
[iter 400] loss=-0.6379 val_loss=0.0000 scale=1.0000 norm=0.4600
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7345 val_loss=0.0000 scale=2.0000 norm=1.2331
[iter 200] loss=0.1205 val_loss=0.0000 scale=2.0000 norm=1.0478
[iter 300] loss=-0.3214 val_loss=0.0000 scale=1.0000 norm=0.4826
[iter 400] loss=-0.7026 val_loss=0.0000 scale=1.0000 norm=0.4441
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3581 val_loss=0.0000 scale=2.0000 norm=1.0551
[iter 200] loss=-0.2655 val_loss=0.0000 scale=2.0000 norm=0.9602
[iter 300] loss=-0.7630 val_loss=0.0000 scale=1.0000 norm=0.4657
[iter 400] loss=-1.0919 val_loss=0.0000 scale=2.0000 norm=0.9202
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3384 val_loss=0.0000 scale=2.0000 norm=1.0536
[iter 200] loss=-0.2926 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-0.7633 val_loss=0.0000 scale=1.0000 norm=0.4718
[iter 400] loss=-1.0444 val_loss=0.0000 scale=1.0000 norm=0.4582
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2362 val_loss=0.0000 scale=2.0000 norm=1.0187
[iter 200] loss=-0.4618 val_loss=0.0000 scale=2.0000 norm=0.9803
[iter 300] loss=-1.0263 val_loss=0.0000 scale=1.0000 norm=0.4783
[iter 400] loss=-1.3366 val_loss=0.0000 scale=1.0000 norm=0.4588
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4849 val_loss=0.0000 scale=2.0000 norm=1.0239
[iter 200] loss=-0.3746 val_loss=0.0000 scale=2.0000 norm=0.8874
[iter 300] loss=-1.0721 val_loss=0.0000 scale=2.0000 norm=0.8075
[iter 400] loss=-1.6982 val_loss=0.0000 scale=2.0000 norm=0.7811
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4487 val_loss=0.0000 scale=2.0000 norm=1.1270
[iter 200] loss=-0.0902 val_loss=0.0000 scale=2.0000 norm=0.9978
[iter 300] loss=-0.4844 val_loss=0.0000 scale=2.0000 norm=0.9636
[iter 400] loss=-0.7474 val_loss=0.0000 scale=2.0000 norm=0.9151
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2905 val_loss=0.0000 scale=2.0000 norm=1.0014
[iter 200] loss=-0.3637 val_loss=0.0000 scale=2.0000 norm=0.9130
[iter 300] loss=-0.7943 val_loss=0.0000 scale=2.0000 norm=0.8549
[iter 400] loss=-1.1042 val_loss=0.0000 scale=1.0000 norm=0.4012
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3084 val_loss=0.0000 scale=2.0000 norm=1.0339
[iter 200] loss=-0.2809 val_loss=0.0000 scale=2.0000 norm=0.9595
[iter 300] loss=-0.7486 val_loss=0.0000 scale=2.0000 norm=0.9102
[iter 400] loss=-1.1024 val_loss=0.0000 scale=1.0000 norm=0.4286
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5503 val_loss=0.0000 scale=2.0000 norm=1.1674
[iter 200] loss=-0.1261 val_loss=0.0000 scale=2.0000 norm=1.0827
[iter 300] loss=-0.6203 val_loss=0.0000 scale=2.0000 norm=1.0387
[iter 400] loss=-0.9180 val_loss=0.0000 scale=1.0000 norm=0.5361
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3422 val_loss=0.0000 scale=2.0000 norm=1.0761
[iter 200] loss=-0.3211 val_loss=0.0000 scale=2.0000 norm=0.9536
[iter 300] loss=-0.8465 val_loss=0.0000 scale=2.0000 norm=0.8946
[iter 400] loss=-1.1564 val_loss=0.0000 scale=1.0000 norm=0.4236
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2630 val_loss=0.0000 scale=2.0000 norm=1.0319
[iter 200] loss=-0.3670 val_loss=0.0000 scale=2.0000 norm=0.9592
[iter 300] loss=-0.8533 val_loss=0.0000 scale=2.0000 norm=0.9236
[iter 400] loss=-1.1300 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6584 val_loss=0.0000 scale=2.0000 norm=1.1600
[iter 200] loss=0.0413 val_loss=0.0000 scale=2.0000 norm=1.0196
[iter 300] loss=-0.5289 val_loss=0.0000 scale=2.0000 norm=0.9708
[iter 400] loss=-0.9599 val_loss=0.0000 scale=2.0000 norm=0.9266
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2691 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.3786 val_loss=0.0000 scale=2.0000 norm=0.9281
[iter 300] loss=-0.8388 val_loss=0.0000 scale=2.0000 norm=0.9242
[iter 400] loss=-1.1301 val_loss=0.0000 scale=2.0000 norm=0.8876
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4349 val_loss=0.0000 scale=2.0000 norm=1.0653
[iter 200] loss=-0.2272 val_loss=0.0000 scale=2.0000 norm=0.8962
[iter 300] loss=-0.6472 val_loss=0.0000 scale=1.0000 norm=0.4072
[iter 400] loss=-0.9533 val_loss=0.0000 scale=1.0000 norm=0.3827
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4125 val_loss=0.0000 scale=2.0000 norm=1.0917
[iter 200] loss=-0.1576 val_loss=0.0000 scale=2.0000 norm=0.9815
[iter 300] loss=-0.6288 val_loss=0.0000 scale=2.0000 norm=0.9243
[iter 400] loss=-0.9333 val_loss=0.0000 scale=2.0000 norm=0.9037
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3279 val_loss=0.0000 scale=2.0000 norm=1.0268
[iter 200] loss=-0.2734 val_loss=0.0000 scale=2.0000 norm=0.9368
[iter 300] loss=-0.6941 val_loss=0.0000 scale=2.0000 norm=0.9162
[iter 400] loss=-0.9568 val_loss=0.0000 scale=1.0000 norm=0.4443
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3394 val_loss=0.0000 scale=2.0000 norm=1.0385
[iter 200] loss=-0.2617 val_loss=0.0000 scale=2.0000 norm=0.9410
[iter 300] loss=-0.6408 val_loss=0.0000 scale=2.0000 norm=0.8997
[iter 400] loss=-0.8640 val_loss=0.0000 scale=2.0000 norm=0.9021
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3720 val_loss=0.0000 scale=2.0000 norm=1.0438
[iter 200] loss=-0.2172 val_loss=0.0000 scale=2.0000 norm=0.9332
[iter 300] loss=-0.6313 val_loss=0.0000 scale=2.0000 norm=0.9111
[iter 400] loss=-0.8908 val_loss=0.0000 scale=1.0000 norm=0.4410
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3434 val_loss=0.0000 scale=2.0000 norm=1.0631
[iter 200] loss=-0.3224 val_loss=0.0000 scale=2.0000 norm=1.0061
[iter 300] loss=-0.8552 val_loss=0.0000 scale=2.0000 norm=0.9405
[iter 400] loss=-1.1858 val_loss=0.0000 scale=1.0000 norm=0.4478
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4425 val_loss=0.0000 scale=2.0000 norm=1.1104
[iter 200] loss=-0.1091 val_loss=0.0000 scale=2.0000 norm=0.9948
[iter 300] loss=-0.4812 val_loss=0.0000 scale=2.0000 norm=0.9295
[iter 400] loss=-0.6814 val_loss=0.0000 scale=2.0000 norm=0.9202
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3595 val_loss=0.0000 scale=2.0000 norm=1.0393
[iter 200] loss=-0.3420 val_loss=0.0000 scale=2.0000 norm=0.9694
[iter 300] loss=-0.9196 val_loss=0.0000 scale=2.0000 norm=0.9307
[iter 400] loss=-1.4167 val_loss=0.0000 scale=2.0000 norm=0.9094
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3053 val_loss=0.0000 scale=2.0000 norm=1.0422
[iter 200] loss=-0.3181 val_loss=0.0000 scale=2.0000 norm=0.9546
[iter 300] loss=-0.8152 val_loss=0.0000 scale=2.0000 norm=0.8794
[iter 400] loss=-1.1494 val_loss=0.0000 scale=2.0000 norm=0.8432
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4061 val_loss=0.0000 scale=1.0000 norm=0.5406
[iter 200] loss=-0.1834 val_loss=0.0000 scale=2.0000 norm=0.9575
[iter 300] loss=-0.5822 val_loss=0.0000 scale=2.0000 norm=0.9212
[iter 400] loss=-0.8786 val_loss=0.0000 scale=2.0000 norm=0.8975
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2915 val_loss=0.0000 scale=2.0000 norm=1.0164
[iter 200] loss=-0.3446 val_loss=0.0000 scale=2.0000 norm=0.9127
[iter 300] loss=-0.8214 val_loss=0.0000 scale=2.0000 norm=0.8761
[iter 400] loss=-1.1551 val_loss=0.0000 scale=2.0000 norm=0.8272
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0949 val_loss=0.0000 scale=2.0000 norm=1.0010
[iter 200] loss=-0.8679 val_loss=0.0000 scale=2.0000 norm=0.9644
[iter 300] loss=-1.8150 val_loss=0.0000 scale=2.0000 norm=0.9430
[iter 400] loss=-2.6898 val_loss=0.0000 scale=2.0000 norm=0.8730
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4636 val_loss=0.0000 scale=1.0000 norm=0.5585
[iter 200] loss=-0.1257 val_loss=0.0000 scale=2.0000 norm=1.0158
[iter 300] loss=-0.7755 val_loss=0.0000 scale=2.0000 norm=0.9532
[iter 400] loss=-1.3590 val_loss=0.0000 scale=2.0000 norm=0.9431
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4869 val_loss=0.0000 scale=2.0000 norm=1.0984
[iter 200] loss=-0.0297 val_loss=0.0000 scale=2.0000 norm=0.9963
[iter 300] loss=-0.3681 val_loss=0.0000 scale=1.0000 norm=0.4760
[iter 400] loss=-0.6004 val_loss=0.0000 scale=0.5000 norm=0.2289
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2164 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 200] loss=-0.6750 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 300] loss=-1.5126 val_loss=0.0000 scale=2.0000 norm=0.9013
[iter 400] loss=-2.2922 val_loss=0.0000 scale=2.0000 norm=0.8483
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4097 val_loss=0.0000 scale=2.0000 norm=1.0766
[iter 200] loss=-0.1488 val_loss=0.0000 scale=1.0000 norm=0.4802
[iter 300] loss=-0.5371 val_loss=0.0000 scale=2.0000 norm=0.9126
[iter 400] loss=-0.7462 val_loss=0.0000 scale=0.5000 norm=0.2285
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3964 val_loss=0.0000 scale=2.0000 norm=1.0753
[iter 200] loss=-0.1586 val_loss=0.0000 scale=2.0000 norm=0.9605
[iter 300] loss=-0.5663 val_loss=0.0000 scale=2.0000 norm=0.9127
[iter 400] loss=-0.8325 val_loss=0.0000 scale=1.0000 norm=0.4400
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2362 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 200] loss=-0.3973 val_loss=0.0000 scale=2.0000 norm=0.9744
[iter 300] loss=-0.8946 val_loss=0.0000 scale=2.0000 norm=0.9336
[iter 400] loss=-1.2105 val_loss=0.0000 scale=1.0000 norm=0.4454
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2966 val_loss=0.0000 scale=2.0000 norm=1.0219
[iter 200] loss=-0.3643 val_loss=0.0000 scale=2.0000 norm=0.9319
[iter 300] loss=-0.9009 val_loss=0.0000 scale=2.0000 norm=0.9057
[iter 400] loss=-1.2400 val_loss=0.0000 scale=1.0000 norm=0.4295
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4174 val_loss=0.0000 scale=2.0000 norm=1.0606
[iter 200] loss=-0.1394 val_loss=0.0000 scale=2.0000 norm=0.9550
[iter 300] loss=-0.5755 val_loss=0.0000 scale=2.0000 norm=0.8831
[iter 400] loss=-0.8748 val_loss=0.0000 scale=2.0000 norm=0.8583
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5248 val_loss=0.0000 scale=2.0000 norm=1.2155
[iter 200] loss=-0.1842 val_loss=0.0000 scale=2.0000 norm=1.1393
[iter 300] loss=-0.7346 val_loss=0.0000 scale=2.0000 norm=1.0466
[iter 400] loss=-1.1148 val_loss=0.0000 scale=2.0000 norm=1.0825
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1667 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.5902 val_loss=0.0000 scale=2.0000 norm=0.9219
[iter 300] loss=-1.6406 val_loss=0.0000 scale=4.0000 norm=1.7220
[iter 400] loss=-2.6893 val_loss=0.0000 scale=4.0000 norm=1.5187
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4983 val_loss=0.0000 scale=2.0000 norm=1.0719
[iter 200] loss=-0.2901 val_loss=0.0000 scale=2.0000 norm=0.9623
[iter 300] loss=-0.8936 val_loss=0.0000 scale=2.0000 norm=0.9366
[iter 400] loss=-1.3804 val_loss=0.0000 scale=2.0000 norm=0.9426
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3505 val_loss=0.0000 scale=2.0000 norm=1.0524
[iter 200] loss=-0.2751 val_loss=0.0000 scale=1.0000 norm=0.4685
[iter 300] loss=-0.7292 val_loss=0.0000 scale=2.0000 norm=0.8808
[iter 400] loss=-1.0327 val_loss=0.0000 scale=1.0000 norm=0.4193
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1632 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 200] loss=-0.7202 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 300] loss=-1.6585 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 400] loss=-2.4145 val_loss=0.0000 scale=2.0000 norm=0.8686
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4284 val_loss=0.0000 scale=2.0000 norm=1.0867
[iter 200] loss=-0.1532 val_loss=0.0000 scale=2.0000 norm=0.9691
[iter 300] loss=-0.5166 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 400] loss=-0.7762 val_loss=0.0000 scale=0.5000 norm=0.2343
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3608 val_loss=0.0000 scale=2.0000 norm=1.0537
[iter 200] loss=-0.2181 val_loss=0.0000 scale=2.0000 norm=0.9808
[iter 300] loss=-0.5593 val_loss=0.0000 scale=2.0000 norm=0.9724
[iter 400] loss=-0.7960 val_loss=0.0000 scale=2.0000 norm=0.9447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2732 val_loss=0.0000 scale=2.0000 norm=1.0084
[iter 200] loss=-0.4565 val_loss=0.0000 scale=2.0000 norm=0.8925
[iter 300] loss=-0.9973 val_loss=0.0000 scale=2.0000 norm=0.8151
[iter 400] loss=-1.4156 val_loss=0.0000 scale=2.0000 norm=0.7495
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5155 val_loss=0.0000 scale=2.0000 norm=1.1423
[iter 200] loss=0.0029 val_loss=0.0000 scale=2.0000 norm=1.0455
[iter 300] loss=-0.3495 val_loss=0.0000 scale=1.0000 norm=0.5053
[iter 400] loss=-0.6423 val_loss=0.0000 scale=1.0000 norm=0.4835
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4049 val_loss=0.0000 scale=2.0000 norm=1.0783
[iter 200] loss=-0.2005 val_loss=0.0000 scale=2.0000 norm=0.9486
[iter 300] loss=-0.6280 val_loss=0.0000 scale=1.0000 norm=0.4411
[iter 400] loss=-0.8953 val_loss=0.0000 scale=1.0000 norm=0.4138
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6061 val_loss=0.0000 scale=2.0000 norm=1.2008
[iter 200] loss=0.0880 val_loss=0.0000 scale=1.0000 norm=0.5413
[iter 300] loss=-0.2293 val_loss=0.0000 scale=1.0000 norm=0.5220
[iter 400] loss=-0.4581 val_loss=0.0000 scale=2.0000 norm=0.9982
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3113 val_loss=0.0000 scale=2.0000 norm=1.0134
[iter 200] loss=-0.3342 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 300] loss=-0.7950 val_loss=0.0000 scale=2.0000 norm=0.9294
[iter 400] loss=-1.0796 val_loss=0.0000 scale=1.0000 norm=0.4445
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3325 val_loss=0.0000 scale=2.0000 norm=1.0332
[iter 200] loss=-0.2857 val_loss=0.0000 scale=2.0000 norm=0.9407
[iter 300] loss=-0.6850 val_loss=0.0000 scale=2.0000 norm=0.9360
[iter 400] loss=-0.9838 val_loss=0.0000 scale=2.0000 norm=0.9111
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1692 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 200] loss=-0.5602 val_loss=0.0000 scale=2.0000 norm=0.9774
[iter 300] loss=-1.1372 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 400] loss=-1.6330 val_loss=0.0000 scale=2.0000 norm=0.9039
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4573 val_loss=0.0000 scale=2.0000 norm=1.1061
[iter 200] loss=-0.0619 val_loss=0.0000 scale=1.0000 norm=0.4936
[iter 300] loss=-0.4620 val_loss=0.0000 scale=2.0000 norm=0.9752
[iter 400] loss=-0.7331 val_loss=0.0000 scale=1.0000 norm=0.4935
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3727 val_loss=0.0000 scale=2.0000 norm=1.0599
[iter 200] loss=-0.1851 val_loss=0.0000 scale=1.0000 norm=0.4883
[iter 300] loss=-0.6004 val_loss=0.0000 scale=1.0000 norm=0.4608
[iter 400] loss=-0.8360 val_loss=0.0000 scale=1.0000 norm=0.4422
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1440 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 200] loss=-0.7035 val_loss=0.0000 scale=2.0000 norm=0.8817
[iter 300] loss=-1.4404 val_loss=0.0000 scale=2.0000 norm=0.8428
[iter 400] loss=-1.9840 val_loss=0.0000 scale=2.0000 norm=0.8067
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3561 val_loss=0.0000 scale=2.0000 norm=1.0318
[iter 200] loss=-0.3337 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 300] loss=-0.8249 val_loss=0.0000 scale=2.0000 norm=0.9376
[iter 400] loss=-1.1608 val_loss=0.0000 scale=1.0000 norm=0.4796
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3864 val_loss=0.0000 scale=2.0000 norm=1.0697
[iter 200] loss=-0.2286 val_loss=0.0000 scale=2.0000 norm=0.9886
[iter 300] loss=-0.7069 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 400] loss=-0.9616 val_loss=0.0000 scale=1.0000 norm=0.4532
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3362 val_loss=0.0000 scale=2.0000 norm=1.0476
[iter 200] loss=-0.2693 val_loss=0.0000 scale=2.0000 norm=0.9904
[iter 300] loss=-0.7012 val_loss=0.0000 scale=2.0000 norm=0.9733
[iter 400] loss=-0.9643 val_loss=0.0000 scale=2.0000 norm=0.9451
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4099 val_loss=0.0000 scale=2.0000 norm=1.0751
[iter 200] loss=-0.1662 val_loss=0.0000 scale=2.0000 norm=1.0086
[iter 300] loss=-0.5833 val_loss=0.0000 scale=2.0000 norm=0.9647
[iter 400] loss=-0.8767 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1058 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.8630 val_loss=0.0000 scale=2.0000 norm=0.9692
[iter 300] loss=-1.8257 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 400] loss=-2.7361 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3878 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.1483 val_loss=0.0000 scale=2.0000 norm=0.9538
[iter 300] loss=-0.5210 val_loss=0.0000 scale=2.0000 norm=0.9039
[iter 400] loss=-0.7621 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3098 val_loss=0.0000 scale=2.0000 norm=1.0337
[iter 200] loss=-0.4279 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 300] loss=-1.0141 val_loss=0.0000 scale=2.0000 norm=0.9057
[iter 400] loss=-1.5786 val_loss=0.0000 scale=2.0000 norm=0.8623
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4810 val_loss=0.0000 scale=2.0000 norm=1.1022
[iter 200] loss=-0.0500 val_loss=0.0000 scale=2.0000 norm=1.0063
[iter 300] loss=-0.3866 val_loss=0.0000 scale=2.0000 norm=0.9688
[iter 400] loss=-0.6225 val_loss=0.0000 scale=2.0000 norm=0.9447
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2260 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 200] loss=-0.6401 val_loss=0.0000 scale=2.0000 norm=0.9160
[iter 300] loss=-1.4245 val_loss=0.0000 scale=2.0000 norm=0.8598
[iter 400] loss=-2.1706 val_loss=0.0000 scale=2.0000 norm=0.8377
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4442 val_loss=0.0000 scale=2.0000 norm=1.1031
[iter 200] loss=-0.1125 val_loss=0.0000 scale=2.0000 norm=1.0072
[iter 300] loss=-0.4959 val_loss=0.0000 scale=2.0000 norm=0.9691
[iter 400] loss=-0.7109 val_loss=0.0000 scale=1.0000 norm=0.4842
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2903 val_loss=0.0000 scale=2.0000 norm=1.0224
[iter 200] loss=-0.3551 val_loss=0.0000 scale=2.0000 norm=0.9135
[iter 300] loss=-0.8408 val_loss=0.0000 scale=2.0000 norm=0.8645
[iter 400] loss=-1.1423 val_loss=0.0000 scale=0.5000 norm=0.2086
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4057 val_loss=0.0000 scale=2.0000 norm=1.0897
[iter 200] loss=-0.1784 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 300] loss=-0.5482 val_loss=0.0000 scale=1.0000 norm=0.4557
[iter 400] loss=-0.7432 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3362 val_loss=0.0000 scale=2.0000 norm=0.9900
[iter 200] loss=-0.4874 val_loss=0.0000 scale=2.0000 norm=0.9148
[iter 300] loss=-1.2658 val_loss=0.0000 scale=2.0000 norm=0.8836
[iter 400] loss=-1.9988 val_loss=0.0000 scale=2.0000 norm=0.8370
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6676 val_loss=0.0000 scale=2.0000 norm=1.1925
[iter 200] loss=0.2017 val_loss=0.0000 scale=2.0000 norm=1.0587
[iter 300] loss=-0.1131 val_loss=0.0000 scale=2.0000 norm=1.0170
[iter 400] loss=-0.3516 val_loss=0.0000 scale=2.0000 norm=0.9963
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2952 val_loss=0.0000 scale=2.0000 norm=0.9999
[iter 200] loss=-0.3762 val_loss=0.0000 scale=2.0000 norm=0.9216
[iter 300] loss=-0.8255 val_loss=0.0000 scale=2.0000 norm=0.8502
[iter 400] loss=-1.0964 val_loss=0.0000 scale=1.0000 norm=0.4302
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3028 val_loss=0.0000 scale=2.0000 norm=1.0088
[iter 200] loss=-0.3185 val_loss=0.0000 scale=2.0000 norm=0.9631
[iter 300] loss=-0.8420 val_loss=0.0000 scale=2.0000 norm=0.9353
[iter 400] loss=-1.2726 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4561 val_loss=0.0000 scale=2.0000 norm=1.1063
[iter 200] loss=-0.1966 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 300] loss=-0.6839 val_loss=0.0000 scale=2.0000 norm=0.9744
[iter 400] loss=-1.0659 val_loss=0.0000 scale=2.0000 norm=0.9740
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3973 val_loss=0.0000 scale=2.0000 norm=1.0732
[iter 200] loss=-0.1727 val_loss=0.0000 scale=2.0000 norm=1.0035
[iter 300] loss=-0.5085 val_loss=0.0000 scale=2.0000 norm=0.9823
[iter 400] loss=-0.7677 val_loss=0.0000 scale=1.0000 norm=0.4841
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4354 val_loss=0.0000 scale=2.0000 norm=1.1168
[iter 200] loss=-0.1132 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 300] loss=-0.4795 val_loss=0.0000 scale=1.0000 norm=0.4654
[iter 400] loss=-0.7004 val_loss=0.0000 scale=1.0000 norm=0.4407
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3356 val_loss=0.0000 scale=2.0000 norm=1.0332
[iter 200] loss=-0.2665 val_loss=0.0000 scale=2.0000 norm=0.9406
[iter 300] loss=-0.6479 val_loss=0.0000 scale=2.0000 norm=0.8838
[iter 400] loss=-0.8896 val_loss=0.0000 scale=2.0000 norm=0.8680
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2220 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 200] loss=-0.5250 val_loss=0.0000 scale=2.0000 norm=0.8726
[iter 300] loss=-1.0605 val_loss=0.0000 scale=2.0000 norm=0.7552
[iter 400] loss=-1.3891 val_loss=0.0000 scale=2.0000 norm=0.7323
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2788 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 200] loss=-0.3267 val_loss=0.0000 scale=1.0000 norm=0.4579
[iter 300] loss=-0.7386 val_loss=0.0000 scale=1.0000 norm=0.4465
[iter 400] loss=-1.1158 val_loss=0.0000 scale=2.0000 norm=0.8109
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3388 val_loss=0.0000 scale=2.0000 norm=1.0350
[iter 200] loss=-0.3121 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 300] loss=-0.7972 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 400] loss=-1.1261 val_loss=0.0000 scale=2.0000 norm=0.8805
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3199 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 200] loss=-0.3036 val_loss=0.0000 scale=2.0000 norm=0.9445
[iter 300] loss=-0.7444 val_loss=0.0000 scale=2.0000 norm=0.9025
[iter 400] loss=-1.0049 val_loss=0.0000 scale=2.0000 norm=0.8549
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3590 val_loss=0.0000 scale=2.0000 norm=1.0662
[iter 200] loss=-0.2168 val_loss=0.0000 scale=2.0000 norm=0.9815
[iter 300] loss=-0.5690 val_loss=0.0000 scale=2.0000 norm=0.9582
[iter 400] loss=-0.7876 val_loss=0.0000 scale=1.0000 norm=0.4715
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3772 val_loss=0.0000 scale=2.0000 norm=1.0683
[iter 200] loss=-0.2587 val_loss=0.0000 scale=2.0000 norm=0.9422
[iter 300] loss=-0.7012 val_loss=0.0000 scale=2.0000 norm=0.8745
[iter 400] loss=-0.9948 val_loss=0.0000 scale=1.0000 norm=0.4310
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3398 val_loss=0.0000 scale=2.0000 norm=1.0436
[iter 200] loss=-0.2673 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 300] loss=-0.6488 val_loss=0.0000 scale=1.0000 norm=0.4459
[iter 400] loss=-0.8693 val_loss=0.0000 scale=1.0000 norm=0.4398
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4386 val_loss=0.0000 scale=2.0000 norm=1.0890
[iter 200] loss=-0.0813 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 300] loss=-0.4418 val_loss=0.0000 scale=2.0000 norm=0.9529
[iter 400] loss=-0.6700 val_loss=0.0000 scale=1.0000 norm=0.4662
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7350 val_loss=0.0000 scale=1.0000 norm=0.6090
[iter 200] loss=-0.0077 val_loss=0.0000 scale=2.0000 norm=1.0495
[iter 300] loss=-0.6998 val_loss=0.0000 scale=2.0000 norm=0.9787
[iter 400] loss=-1.2709 val_loss=0.0000 scale=2.0000 norm=0.8788
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1929 val_loss=0.0000 scale=2.0000 norm=0.9923
[iter 200] loss=-0.5669 val_loss=0.0000 scale=2.0000 norm=0.9330
[iter 300] loss=-1.1632 val_loss=0.0000 scale=2.0000 norm=0.8738
[iter 400] loss=-1.5905 val_loss=0.0000 scale=1.0000 norm=0.4291
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3821 val_loss=0.0000 scale=2.0000 norm=1.0551
[iter 200] loss=-0.1650 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 300] loss=-0.6038 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-0.9345 val_loss=0.0000 scale=2.0000 norm=0.9320
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3655 val_loss=0.0000 scale=2.0000 norm=0.9914
[iter 200] loss=-0.4352 val_loss=0.0000 scale=2.0000 norm=1.0193
[iter 300] loss=-1.2733 val_loss=0.0000 scale=2.0000 norm=1.0589
[iter 400] loss=-2.0400 val_loss=0.0000 scale=2.0000 norm=1.0614
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5360 val_loss=0.0000 scale=2.0000 norm=1.1516
[iter 200] loss=0.0317 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 300] loss=-0.2789 val_loss=0.0000 scale=1.0000 norm=0.4871
[iter 400] loss=-0.4960 val_loss=0.0000 scale=1.0000 norm=0.4686
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3966 val_loss=0.0000 scale=2.0000 norm=0.9843
[iter 200] loss=-0.5521 val_loss=0.0000 scale=2.0000 norm=0.9324
[iter 300] loss=-1.3880 val_loss=0.0000 scale=2.0000 norm=0.8436
[iter 400] loss=-2.3647 val_loss=0.0000 scale=4.0000 norm=1.6180
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3849 val_loss=0.0000 scale=2.0000 norm=1.0777
[iter 200] loss=-0.2718 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 300] loss=-0.7506 val_loss=0.0000 scale=2.0000 norm=0.9156
[iter 400] loss=-1.0067 val_loss=0.0000 scale=1.0000 norm=0.4296
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3439 val_loss=0.0000 scale=2.0000 norm=1.0349
[iter 200] loss=-0.2495 val_loss=0.0000 scale=1.0000 norm=0.4697
[iter 300] loss=-0.6199 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 400] loss=-0.9175 val_loss=0.0000 scale=2.0000 norm=0.8743
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3393 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.3044 val_loss=0.0000 scale=2.0000 norm=0.9696
[iter 300] loss=-0.7818 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 400] loss=-1.0711 val_loss=0.0000 scale=1.0000 norm=0.4503
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3350 val_loss=0.0000 scale=2.0000 norm=0.9965
[iter 200] loss=-0.4457 val_loss=0.0000 scale=2.0000 norm=0.9299
[iter 300] loss=-1.1384 val_loss=0.0000 scale=2.0000 norm=0.9156
[iter 400] loss=-1.7315 val_loss=0.0000 scale=2.0000 norm=0.8953
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3530 val_loss=0.0000 scale=2.0000 norm=1.0712
[iter 200] loss=-0.2377 val_loss=0.0000 scale=2.0000 norm=0.9886
[iter 300] loss=-0.5986 val_loss=0.0000 scale=2.0000 norm=0.9482
[iter 400] loss=-0.8306 val_loss=0.0000 scale=1.0000 norm=0.4588
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3350 val_loss=0.0000 scale=2.0000 norm=1.0661
[iter 200] loss=-0.3044 val_loss=0.0000 scale=2.0000 norm=0.9586
[iter 300] loss=-0.7329 val_loss=0.0000 scale=2.0000 norm=0.8976
[iter 400] loss=-0.9907 val_loss=0.0000 scale=1.0000 norm=0.4265
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3846 val_loss=0.0000 scale=2.0000 norm=1.1313
[iter 200] loss=-0.3648 val_loss=0.0000 scale=2.0000 norm=1.0926
[iter 300] loss=-1.0149 val_loss=0.0000 scale=2.0000 norm=1.0499
[iter 400] loss=-1.6579 val_loss=0.0000 scale=4.0000 norm=2.1550
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4467 val_loss=0.0000 scale=2.0000 norm=1.0813
[iter 200] loss=-0.2110 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 300] loss=-0.6437 val_loss=0.0000 scale=1.0000 norm=0.4459
[iter 400] loss=-0.9140 val_loss=0.0000 scale=1.0000 norm=0.4333
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4149 val_loss=0.0000 scale=2.0000 norm=1.0751
[iter 200] loss=-0.1177 val_loss=0.0000 scale=2.0000 norm=0.9634
[iter 300] loss=-0.4985 val_loss=0.0000 scale=1.0000 norm=0.4702
[iter 400] loss=-0.7175 val_loss=0.0000 scale=2.0000 norm=0.9044
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3140 val_loss=0.0000 scale=2.0000 norm=1.0455
[iter 200] loss=-0.2630 val_loss=0.0000 scale=2.0000 norm=0.9700
[iter 300] loss=-0.6829 val_loss=0.0000 scale=2.0000 norm=0.9321
[iter 400] loss=-0.9102 val_loss=0.0000 scale=1.0000 norm=0.4526
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2960 val_loss=0.0000 scale=2.0000 norm=1.0084
[iter 200] loss=-0.3417 val_loss=0.0000 scale=2.0000 norm=0.9242
[iter 300] loss=-0.7869 val_loss=0.0000 scale=2.0000 norm=0.9071
[iter 400] loss=-1.0886 val_loss=0.0000 scale=1.0000 norm=0.4554
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2588 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.4654 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 300] loss=-1.1404 val_loss=0.0000 scale=4.0000 norm=1.8933
[iter 400] loss=-2.0801 val_loss=0.0000 scale=4.0000 norm=1.8913
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4130 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.3194 val_loss=0.0000 scale=2.0000 norm=0.9620
[iter 300] loss=-0.9032 val_loss=0.0000 scale=2.0000 norm=0.9191
[iter 400] loss=-1.3532 val_loss=0.0000 scale=2.0000 norm=0.9453
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3379 val_loss=0.0000 scale=2.0000 norm=1.0421
[iter 200] loss=-0.3094 val_loss=0.0000 scale=2.0000 norm=0.9763
[iter 300] loss=-0.8376 val_loss=0.0000 scale=2.0000 norm=0.9396
[iter 400] loss=-1.2045 val_loss=0.0000 scale=2.0000 norm=0.8928
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2721 val_loss=0.0000 scale=2.0000 norm=1.0720
[iter 200] loss=-0.4555 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 300] loss=-1.0551 val_loss=0.0000 scale=2.0000 norm=0.8788
[iter 400] loss=-1.5220 val_loss=0.0000 scale=2.0000 norm=0.8275
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3377 val_loss=0.0000 scale=2.0000 norm=1.0204
[iter 200] loss=-0.2619 val_loss=0.0000 scale=2.0000 norm=0.9332
[iter 300] loss=-0.6646 val_loss=0.0000 scale=2.0000 norm=0.8980
[iter 400] loss=-0.9419 val_loss=0.0000 scale=2.0000 norm=0.8640
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3589 val_loss=0.0000 scale=2.0000 norm=1.0493
[iter 200] loss=-0.2095 val_loss=0.0000 scale=2.0000 norm=0.9534
[iter 300] loss=-0.5941 val_loss=0.0000 scale=2.0000 norm=0.9016
[iter 400] loss=-0.8278 val_loss=0.0000 scale=1.0000 norm=0.4386
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3890 val_loss=0.0000 scale=2.0000 norm=1.0846
[iter 200] loss=-0.1759 val_loss=0.0000 scale=2.0000 norm=0.9634
[iter 300] loss=-0.5363 val_loss=0.0000 scale=2.0000 norm=0.9294
[iter 400] loss=-0.7177 val_loss=0.0000 scale=1.0000 norm=0.4537
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4069 val_loss=0.0000 scale=2.0000 norm=1.0744
[iter 200] loss=-0.1933 val_loss=0.0000 scale=2.0000 norm=0.9726
[iter 300] loss=-0.5865 val_loss=0.0000 scale=1.0000 norm=0.4543
[iter 400] loss=-0.8613 val_loss=0.0000 scale=2.0000 norm=0.8290
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4580 val_loss=0.0000 scale=2.0000 norm=1.0818
[iter 200] loss=-0.1292 val_loss=0.0000 scale=2.0000 norm=0.9889
[iter 300] loss=-0.5149 val_loss=0.0000 scale=1.0000 norm=0.4658
[iter 400] loss=-0.7593 val_loss=0.0000 scale=1.0000 norm=0.4667
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3969 val_loss=0.0000 scale=2.0000 norm=1.0726
[iter 200] loss=-0.1506 val_loss=0.0000 scale=2.0000 norm=0.9675
[iter 300] loss=-0.5026 val_loss=0.0000 scale=1.0000 norm=0.4723
[iter 400] loss=-0.7267 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3983 val_loss=0.0000 scale=2.0000 norm=1.0870
[iter 200] loss=-0.1595 val_loss=0.0000 scale=2.0000 norm=0.9727
[iter 300] loss=-0.5300 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 400] loss=-0.7282 val_loss=0.0000 scale=1.0000 norm=0.4693
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4403 val_loss=0.0000 scale=2.0000 norm=0.9908
[iter 200] loss=-0.1881 val_loss=0.0000 scale=2.0000 norm=0.9169
[iter 300] loss=-0.6623 val_loss=0.0000 scale=2.0000 norm=0.8995
[iter 400] loss=-1.0206 val_loss=0.0000 scale=1.0000 norm=0.4343
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1734 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.5695 val_loss=0.0000 scale=2.0000 norm=0.9206
[iter 300] loss=-1.1602 val_loss=0.0000 scale=2.0000 norm=0.8731
[iter 400] loss=-1.6009 val_loss=0.0000 scale=2.0000 norm=0.8219
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3577 val_loss=0.0000 scale=2.0000 norm=1.0504
[iter 200] loss=-0.2236 val_loss=0.0000 scale=2.0000 norm=0.9815
[iter 300] loss=-0.6046 val_loss=0.0000 scale=2.0000 norm=0.9267
[iter 400] loss=-0.8444 val_loss=0.0000 scale=2.0000 norm=0.8949
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3778 val_loss=0.0000 scale=2.0000 norm=1.0510
[iter 200] loss=-0.2062 val_loss=0.0000 scale=2.0000 norm=0.9390
[iter 300] loss=-0.5644 val_loss=0.0000 scale=1.0000 norm=0.4568
[iter 400] loss=-0.7617 val_loss=0.0000 scale=1.0000 norm=0.4468
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3072 val_loss=0.0000 scale=2.0000 norm=1.0309
[iter 200] loss=-0.2945 val_loss=0.0000 scale=2.0000 norm=0.9400
[iter 300] loss=-0.6451 val_loss=0.0000 scale=1.0000 norm=0.4690
[iter 400] loss=-0.8963 val_loss=0.0000 scale=2.0000 norm=0.9140
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3517 val_loss=0.0000 scale=2.0000 norm=1.0589
[iter 200] loss=-0.2680 val_loss=0.0000 scale=2.0000 norm=0.9870
[iter 300] loss=-0.7542 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 400] loss=-1.0624 val_loss=0.0000 scale=1.0000 norm=0.4494
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3980 val_loss=0.0000 scale=2.0000 norm=1.0302
[iter 200] loss=-0.2121 val_loss=0.0000 scale=2.0000 norm=0.9244
[iter 300] loss=-0.6482 val_loss=0.0000 scale=2.0000 norm=0.8918
[iter 400] loss=-0.9839 val_loss=0.0000 scale=1.0000 norm=0.4384
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5162 val_loss=0.0000 scale=2.0000 norm=1.1169
[iter 200] loss=0.0181 val_loss=0.0000 scale=2.0000 norm=0.9978
[iter 300] loss=-0.3261 val_loss=0.0000 scale=1.0000 norm=0.4701
[iter 400] loss=-0.5445 val_loss=0.0000 scale=1.0000 norm=0.4499
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2908 val_loss=0.0000 scale=2.0000 norm=1.0285
[iter 200] loss=-0.3593 val_loss=0.0000 scale=2.0000 norm=0.9275
[iter 300] loss=-0.8407 val_loss=0.0000 scale=2.0000 norm=0.8668
[iter 400] loss=-1.1385 val_loss=0.0000 scale=2.0000 norm=0.8124
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3265 val_loss=0.0000 scale=2.0000 norm=1.0329
[iter 200] loss=-0.3062 val_loss=0.0000 scale=2.0000 norm=0.9694
[iter 300] loss=-0.7751 val_loss=0.0000 scale=2.0000 norm=0.9243
[iter 400] loss=-1.0629 val_loss=0.0000 scale=2.0000 norm=0.8881
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2094 val_loss=0.0000 scale=2.0000 norm=1.0522
[iter 200] loss=-0.6776 val_loss=0.0000 scale=2.0000 norm=1.0357
[iter 300] loss=-1.5534 val_loss=0.0000 scale=2.0000 norm=1.0377
[iter 400] loss=-2.4168 val_loss=0.0000 scale=2.0000 norm=1.0244
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2925 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3253 val_loss=0.0000 scale=2.0000 norm=0.8894
[iter 300] loss=-0.6773 val_loss=0.0000 scale=1.0000 norm=0.4148
[iter 400] loss=-0.9584 val_loss=0.0000 scale=1.0000 norm=0.3993
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4272 val_loss=0.0000 scale=2.0000 norm=1.0776
[iter 200] loss=-0.0631 val_loss=0.0000 scale=1.0000 norm=0.4973
[iter 300] loss=-0.4656 val_loss=0.0000 scale=2.0000 norm=0.9480
[iter 400] loss=-0.7529 val_loss=0.0000 scale=1.0000 norm=0.4499
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3795 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 200] loss=-0.3249 val_loss=0.0000 scale=2.0000 norm=0.9533
[iter 300] loss=-0.9481 val_loss=0.0000 scale=2.0000 norm=0.8591
[iter 400] loss=-1.3452 val_loss=0.0000 scale=2.0000 norm=0.8087
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1899 val_loss=0.0000 scale=2.0000 norm=0.9854
[iter 200] loss=-0.7104 val_loss=0.0000 scale=2.0000 norm=0.9274
[iter 300] loss=-1.5211 val_loss=0.0000 scale=2.0000 norm=0.8799
[iter 400] loss=-2.2945 val_loss=0.0000 scale=2.0000 norm=0.8589
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5211 val_loss=0.0000 scale=2.0000 norm=1.1512
[iter 200] loss=0.0530 val_loss=0.0000 scale=2.0000 norm=1.0697
[iter 300] loss=-0.2997 val_loss=0.0000 scale=2.0000 norm=1.0140
[iter 400] loss=-0.5041 val_loss=0.0000 scale=1.0000 norm=0.4957
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0333
[iter 200] loss=-0.2609 val_loss=0.0000 scale=2.0000 norm=0.9484
[iter 300] loss=-0.6738 val_loss=0.0000 scale=2.0000 norm=0.9343
[iter 400] loss=-0.9906 val_loss=0.0000 scale=2.0000 norm=0.8779
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4192 val_loss=0.0000 scale=2.0000 norm=1.0814
[iter 200] loss=-0.1347 val_loss=0.0000 scale=2.0000 norm=0.9949
[iter 300] loss=-0.5202 val_loss=0.0000 scale=1.0000 norm=0.4738
[iter 400] loss=-0.7376 val_loss=0.0000 scale=1.0000 norm=0.4486
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3442 val_loss=0.0000 scale=2.0000 norm=1.0225
[iter 200] loss=-0.2506 val_loss=0.0000 scale=2.0000 norm=0.9375
[iter 300] loss=-0.7076 val_loss=0.0000 scale=2.0000 norm=0.9487
[iter 400] loss=-0.9546 val_loss=0.0000 scale=1.0000 norm=0.4490
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2919 val_loss=0.0000 scale=2.0000 norm=1.0251
[iter 200] loss=-0.3706 val_loss=0.0000 scale=2.0000 norm=0.9301
[iter 300] loss=-0.8811 val_loss=0.0000 scale=2.0000 norm=0.8997
[iter 400] loss=-1.2526 val_loss=0.0000 scale=2.0000 norm=0.8756
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6070 val_loss=0.0000 scale=2.0000 norm=1.1727
[iter 200] loss=0.1057 val_loss=0.0000 scale=1.0000 norm=0.5179
[iter 300] loss=-0.2802 val_loss=0.0000 scale=1.0000 norm=0.4962
[iter 400] loss=-0.5381 val_loss=0.0000 scale=2.0000 norm=0.9599
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5319 val_loss=0.0000 scale=2.0000 norm=1.1661
[iter 200] loss=0.0184 val_loss=0.0000 scale=1.0000 norm=0.5286
[iter 300] loss=-0.3417 val_loss=0.0000 scale=1.0000 norm=0.5056
[iter 400] loss=-0.5783 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0525 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 200] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-1.8273 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 400] loss=-2.8310 val_loss=0.0000 scale=2.0000 norm=0.8464
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2414 val_loss=0.0000 scale=2.0000 norm=1.0020
[iter 200] loss=-0.4684 val_loss=0.0000 scale=2.0000 norm=0.9054
[iter 300] loss=-0.9884 val_loss=0.0000 scale=2.0000 norm=0.9059
[iter 400] loss=-1.3514 val_loss=0.0000 scale=2.0000 norm=0.9010
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2934 val_loss=0.0000 scale=2.0000 norm=1.0182
[iter 200] loss=-0.3676 val_loss=0.0000 scale=2.0000 norm=0.9581
[iter 300] loss=-0.9407 val_loss=0.0000 scale=2.0000 norm=0.9613
[iter 400] loss=-1.4141 val_loss=0.0000 scale=2.0000 norm=0.9457
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6499 val_loss=0.0000 scale=2.0000 norm=1.1618
[iter 200] loss=0.1191 val_loss=0.0000 scale=1.0000 norm=0.4922
[iter 300] loss=-0.2664 val_loss=0.0000 scale=1.0000 norm=0.4658
[iter 400] loss=-0.5553 val_loss=0.0000 scale=2.0000 norm=0.9201
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3315 val_loss=0.0000 scale=2.0000 norm=1.0325
[iter 200] loss=-0.2629 val_loss=0.0000 scale=2.0000 norm=0.9608
[iter 300] loss=-0.6638 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 400] loss=-0.8929 val_loss=0.0000 scale=2.0000 norm=0.8946
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2885 val_loss=0.0000 scale=2.0000 norm=1.0202
[iter 200] loss=-0.4415 val_loss=0.0000 scale=2.0000 norm=0.9408
[iter 300] loss=-1.0486 val_loss=0.0000 scale=2.0000 norm=0.8858
[iter 400] loss=-1.5213 val_loss=0.0000 scale=1.0000 norm=0.4343
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3833 val_loss=0.0000 scale=2.0000 norm=1.1055
[iter 200] loss=-0.2501 val_loss=0.0000 scale=2.0000 norm=0.9736
[iter 300] loss=-0.7446 val_loss=0.0000 scale=2.0000 norm=0.8764
[iter 400] loss=-1.0585 val_loss=0.0000 scale=1.0000 norm=0.4258
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3783 val_loss=0.0000 scale=2.0000 norm=1.0779
[iter 200] loss=-0.2168 val_loss=0.0000 scale=1.0000 norm=0.4816
[iter 300] loss=-0.6420 val_loss=0.0000 scale=2.0000 norm=0.9164
[iter 400] loss=-0.9711 val_loss=0.0000 scale=1.0000 norm=0.4413
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3768 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3335 val_loss=0.0000 scale=2.0000 norm=0.9139
[iter 300] loss=-0.8861 val_loss=0.0000 scale=2.0000 norm=0.8345
[iter 400] loss=-1.3291 val_loss=0.0000 scale=2.0000 norm=0.7836
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3026 val_loss=0.0000 scale=2.0000 norm=1.0497
[iter 200] loss=-0.3157 val_loss=0.0000 scale=2.0000 norm=0.9768
[iter 300] loss=-0.7427 val_loss=0.0000 scale=2.0000 norm=0.9402
[iter 400] loss=-1.0252 val_loss=0.0000 scale=1.0000 norm=0.4400
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3095 val_loss=0.0000 scale=2.0000 norm=1.0607
[iter 200] loss=-0.4056 val_loss=0.0000 scale=1.0000 norm=0.4792
[iter 300] loss=-0.9981 val_loss=0.0000 scale=2.0000 norm=0.8869
[iter 400] loss=-1.4447 val_loss=0.0000 scale=2.0000 norm=0.8210
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4041 val_loss=0.0000 scale=2.0000 norm=1.0882
[iter 200] loss=-0.1453 val_loss=0.0000 scale=1.0000 norm=0.4989
[iter 300] loss=-0.5039 val_loss=0.0000 scale=1.0000 norm=0.4737
[iter 400] loss=-0.7314 val_loss=0.0000 scale=2.0000 norm=0.9132
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4468 val_loss=0.0000 scale=2.0000 norm=1.1234
[iter 200] loss=-0.1977 val_loss=0.0000 scale=2.0000 norm=1.0025
[iter 300] loss=-0.6904 val_loss=0.0000 scale=2.0000 norm=0.9703
[iter 400] loss=-0.9909 val_loss=0.0000 scale=2.0000 norm=0.9531
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3249 val_loss=0.0000 scale=2.0000 norm=1.0239
[iter 200] loss=-0.2458 val_loss=0.0000 scale=2.0000 norm=0.9447
[iter 300] loss=-0.6147 val_loss=0.0000 scale=2.0000 norm=0.9297
[iter 400] loss=-0.8795 val_loss=0.0000 scale=2.0000 norm=0.8970
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3921 val_loss=0.0000 scale=2.0000 norm=1.0712
[iter 200] loss=-0.1956 val_loss=0.0000 scale=2.0000 norm=0.9621
[iter 300] loss=-0.6447 val_loss=0.0000 scale=2.0000 norm=0.9103
[iter 400] loss=-0.8991 val_loss=0.0000 scale=1.0000 norm=0.4594
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3724 val_loss=0.0000 scale=2.0000 norm=1.0475
[iter 200] loss=-0.2108 val_loss=0.0000 scale=2.0000 norm=0.9284
[iter 300] loss=-0.6080 val_loss=0.0000 scale=2.0000 norm=0.9330
[iter 400] loss=-0.8487 val_loss=0.0000 scale=1.0000 norm=0.4553
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7414 val_loss=0.0000 scale=2.0000 norm=1.2422
[iter 200] loss=0.2237 val_loss=0.0000 scale=2.0000 norm=1.0829
[iter 300] loss=-0.1775 val_loss=0.0000 scale=2.0000 norm=0.9981
[iter 400] loss=-0.4534 val_loss=0.0000 scale=2.0000 norm=0.9035
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3441 val_loss=0.0000 scale=2.0000 norm=1.0413
[iter 200] loss=-0.2515 val_loss=0.0000 scale=2.0000 norm=0.9262
[iter 300] loss=-0.6550 val_loss=0.0000 scale=1.0000 norm=0.4396
[iter 400] loss=-0.9063 val_loss=0.0000 scale=0.5000 norm=0.2171
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4236 val_loss=0.0000 scale=2.0000 norm=1.0837
[iter 200] loss=-0.0803 val_loss=0.0000 scale=2.0000 norm=0.9848
[iter 300] loss=-0.4685 val_loss=0.0000 scale=1.0000 norm=0.4637
[iter 400] loss=-0.6305 val_loss=0.0000 scale=1.0000 norm=0.4648
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 200] loss=-0.6424 val_loss=0.0000 scale=2.0000 norm=0.8689
[iter 300] loss=-1.3412 val_loss=0.0000 scale=2.0000 norm=0.8275
[iter 400] loss=-2.0693 val_loss=0.0000 scale=2.0000 norm=0.7732
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5142 val_loss=0.0000 scale=2.0000 norm=1.1470
[iter 200] loss=0.0050 val_loss=0.0000 scale=1.0000 norm=0.5038
[iter 300] loss=-0.2596 val_loss=0.0000 scale=2.0000 norm=0.9601
[iter 400] loss=-0.4756 val_loss=0.0000 scale=1.0000 norm=0.4660
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3197 val_loss=0.0000 scale=2.0000 norm=1.0282
[iter 200] loss=-0.2764 val_loss=0.0000 scale=2.0000 norm=0.9415
[iter 300] loss=-0.6648 val_loss=0.0000 scale=2.0000 norm=0.9176
[iter 400] loss=-0.8727 val_loss=0.0000 scale=1.0000 norm=0.4462
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5446 val_loss=0.0000 scale=2.0000 norm=1.1766
[iter 200] loss=-0.0318 val_loss=0.0000 scale=2.0000 norm=1.0674
[iter 300] loss=-0.4404 val_loss=0.0000 scale=1.0000 norm=0.5065
[iter 400] loss=-0.7340 val_loss=0.0000 scale=2.0000 norm=0.9857
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3634 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 200] loss=-0.2004 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-0.5959 val_loss=0.0000 scale=2.0000 norm=0.9297
[iter 400] loss=-0.8345 val_loss=0.0000 scale=1.0000 norm=0.4395
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2088 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 200] loss=-0.6621 val_loss=0.0000 scale=2.0000 norm=0.8948
[iter 300] loss=-1.5126 val_loss=0.0000 scale=2.0000 norm=0.8795
[iter 400] loss=-2.3491 val_loss=0.0000 scale=2.0000 norm=0.8779
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3687 val_loss=0.0000 scale=2.0000 norm=1.0333
[iter 200] loss=-0.2137 val_loss=0.0000 scale=2.0000 norm=0.9437
[iter 300] loss=-0.6047 val_loss=0.0000 scale=2.0000 norm=0.9062
[iter 400] loss=-0.8369 val_loss=0.0000 scale=1.0000 norm=0.4621
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4009 val_loss=0.0000 scale=2.0000 norm=1.0676
[iter 200] loss=-0.2312 val_loss=0.0000 scale=2.0000 norm=0.9816
[iter 300] loss=-0.7255 val_loss=0.0000 scale=2.0000 norm=0.9350
[iter 400] loss=-1.0178 val_loss=0.0000 scale=2.0000 norm=0.8879
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4186 val_loss=0.0000 scale=2.0000 norm=1.0580
[iter 200] loss=-0.1143 val_loss=0.0000 scale=2.0000 norm=0.9727
[iter 300] loss=-0.4942 val_loss=0.0000 scale=1.0000 norm=0.4783
[iter 400] loss=-0.7758 val_loss=0.0000 scale=1.0000 norm=0.4582
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1537 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 200] loss=-0.6484 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 300] loss=-1.3647 val_loss=0.0000 scale=2.0000 norm=0.8090
[iter 400] loss=-1.9193 val_loss=0.0000 scale=2.0000 norm=0.7960
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3630 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.2473 val_loss=0.0000 scale=2.0000 norm=0.9776
[iter 300] loss=-0.6955 val_loss=0.0000 scale=1.0000 norm=0.4720
[iter 400] loss=-0.9359 val_loss=0.0000 scale=1.0000 norm=0.4626
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5937 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 200] loss=-0.0053 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 300] loss=-0.4017 val_loss=0.0000 scale=1.0000 norm=0.4423
[iter 400] loss=-0.8148 val_loss=0.0000 scale=1.0000 norm=0.4448
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3700 val_loss=0.0000 scale=2.0000 norm=1.0616
[iter 200] loss=-0.2169 val_loss=0.0000 scale=2.0000 norm=0.9529
[iter 300] loss=-0.6276 val_loss=0.0000 scale=2.0000 norm=0.9049
[iter 400] loss=-0.8650 val_loss=0.0000 scale=2.0000 norm=0.8776
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3397 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 200] loss=-0.2384 val_loss=0.0000 scale=2.0000 norm=0.9664
[iter 300] loss=-0.6516 val_loss=0.0000 scale=2.0000 norm=0.9316
[iter 400] loss=-0.8582 val_loss=0.0000 scale=1.0000 norm=0.4611
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1854 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 200] loss=-0.6132 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 300] loss=-1.3228 val_loss=0.0000 scale=2.0000 norm=0.9064
[iter 400] loss=-1.9425 val_loss=0.0000 scale=2.0000 norm=0.8788
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2099 val_loss=0.0000 scale=2.0000 norm=0.9708
[iter 200] loss=-0.6149 val_loss=0.0000 scale=2.0000 norm=0.8964
[iter 300] loss=-1.3679 val_loss=0.0000 scale=2.0000 norm=0.8492
[iter 400] loss=-2.3781 val_loss=0.0000 scale=4.0000 norm=1.6926
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2675 val_loss=0.0000 scale=2.0000 norm=1.0331
[iter 200] loss=-0.3942 val_loss=0.0000 scale=2.0000 norm=0.9861
[iter 300] loss=-0.9140 val_loss=0.0000 scale=1.0000 norm=0.4744
[iter 400] loss=-1.2042 val_loss=0.0000 scale=1.0000 norm=0.4461
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4219 val_loss=0.0000 scale=2.0000 norm=1.1095
[iter 200] loss=-0.1524 val_loss=0.0000 scale=2.0000 norm=1.0101
[iter 300] loss=-0.5450 val_loss=0.0000 scale=2.0000 norm=0.9657
[iter 400] loss=-0.7503 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3496 val_loss=0.0000 scale=2.0000 norm=1.0472
[iter 200] loss=-0.3414 val_loss=0.0000 scale=2.0000 norm=0.9425
[iter 300] loss=-0.9008 val_loss=0.0000 scale=2.0000 norm=0.9073
[iter 400] loss=-1.2693 val_loss=0.0000 scale=2.0000 norm=0.8826
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.1221
[iter 200] loss=-0.4232 val_loss=0.0000 scale=2.0000 norm=1.0781
[iter 300] loss=-1.1821 val_loss=0.0000 scale=2.0000 norm=1.0521
[iter 400] loss=-1.9048 val_loss=0.0000 scale=2.0000 norm=1.0077
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2450 val_loss=0.0000 scale=2.0000 norm=0.9915
[iter 200] loss=-0.4016 val_loss=0.0000 scale=2.0000 norm=0.9375
[iter 300] loss=-0.8811 val_loss=0.0000 scale=2.0000 norm=0.9630
[iter 400] loss=-1.2994 val_loss=0.0000 scale=1.0000 norm=0.4539
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4958 val_loss=0.0000 scale=2.0000 norm=1.1134
[iter 200] loss=-0.0300 val_loss=0.0000 scale=2.0000 norm=0.9911
[iter 300] loss=-0.3608 val_loss=0.0000 scale=1.0000 norm=0.4769
[iter 400] loss=-0.5571 val_loss=0.0000 scale=1.0000 norm=0.4755
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4990 val_loss=0.0000 scale=2.0000 norm=1.1187
[iter 200] loss=-0.1245 val_loss=0.0000 scale=2.0000 norm=0.9780
[iter 300] loss=-0.5291 val_loss=0.0000 scale=1.0000 norm=0.4651
[iter 400] loss=-0.8359 val_loss=0.0000 scale=2.0000 norm=0.9033
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3869 val_loss=0.0000 scale=2.0000 norm=1.0974
[iter 200] loss=-0.1868 val_loss=0.0000 scale=2.0000 norm=1.0192
[iter 300] loss=-0.6081 val_loss=0.0000 scale=2.0000 norm=0.9550
[iter 400] loss=-0.8296 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6759 val_loss=0.0000 scale=2.0000 norm=1.2351
[iter 200] loss=0.1249 val_loss=0.0000 scale=1.0000 norm=0.5433
[iter 300] loss=-0.2481 val_loss=0.0000 scale=1.0000 norm=0.5009
[iter 400] loss=-0.5262 val_loss=0.0000 scale=1.0000 norm=0.4730
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4278 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.3749 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 300] loss=-1.0725 val_loss=0.0000 scale=2.0000 norm=0.8359
[iter 400] loss=-1.7115 val_loss=0.0000 scale=2.0000 norm=0.8145
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8531 val_loss=0.0000 scale=1.0000 norm=0.6523
[iter 200] loss=0.2864 val_loss=0.0000 scale=2.0000 norm=1.0374
[iter 300] loss=-0.3264 val_loss=0.0000 scale=2.0000 norm=0.9493
[iter 400] loss=-0.7753 val_loss=0.0000 scale=1.0000 norm=0.4712
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3091 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 200] loss=-0.5922 val_loss=0.0000 scale=2.0000 norm=0.9070
[iter 300] loss=-1.4329 val_loss=0.0000 scale=2.0000 norm=0.8726
[iter 400] loss=-2.1891 val_loss=0.0000 scale=2.0000 norm=0.8362
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3018 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 200] loss=-0.3320 val_loss=0.0000 scale=2.0000 norm=0.9176
[iter 300] loss=-0.7900 val_loss=0.0000 scale=2.0000 norm=0.8668
[iter 400] loss=-1.0469 val_loss=0.0000 scale=2.0000 norm=0.8493
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3142 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 200] loss=-0.4299 val_loss=0.0000 scale=2.0000 norm=0.9064
[iter 300] loss=-1.0888 val_loss=0.0000 scale=2.0000 norm=0.8685
[iter 400] loss=-1.6435 val_loss=0.0000 scale=2.0000 norm=0.8810
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3027 val_loss=0.0000 scale=2.0000 norm=1.0418
[iter 200] loss=-0.3258 val_loss=0.0000 scale=2.0000 norm=0.9830
[iter 300] loss=-0.7932 val_loss=0.0000 scale=1.0000 norm=0.4700
[iter 400] loss=-1.0702 val_loss=0.0000 scale=1.0000 norm=0.4514
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3748 val_loss=0.0000 scale=2.0000 norm=1.0503
[iter 200] loss=-0.2273 val_loss=0.0000 scale=2.0000 norm=0.9674
[iter 300] loss=-0.6712 val_loss=0.0000 scale=1.0000 norm=0.4761
[iter 400] loss=-0.9771 val_loss=0.0000 scale=1.0000 norm=0.4585
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5566 val_loss=0.0000 scale=2.0000 norm=1.1745
[iter 200] loss=0.0136 val_loss=0.0000 scale=2.0000 norm=1.0461
[iter 300] loss=-0.3815 val_loss=0.0000 scale=2.0000 norm=0.9943
[iter 400] loss=-0.5900 val_loss=0.0000 scale=2.0000 norm=0.9534
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2592 val_loss=0.0000 scale=2.0000 norm=1.0134
[iter 200] loss=-0.4361 val_loss=0.0000 scale=2.0000 norm=0.9387
[iter 300] loss=-1.0366 val_loss=0.0000 scale=2.0000 norm=0.8711
[iter 400] loss=-1.4808 val_loss=0.0000 scale=2.0000 norm=0.8149
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2796 val_loss=0.0000 scale=2.0000 norm=1.0114
[iter 200] loss=-0.3340 val_loss=0.0000 scale=2.0000 norm=0.9457
[iter 300] loss=-0.8426 val_loss=0.0000 scale=2.0000 norm=0.9359
[iter 400] loss=-1.2212 val_loss=0.0000 scale=2.0000 norm=0.8895
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3877 val_loss=0.0000 scale=2.0000 norm=1.0676
[iter 200] loss=-0.2076 val_loss=0.0000 scale=2.0000 norm=0.9815
[iter 300] loss=-0.6277 val_loss=0.0000 scale=2.0000 norm=0.9449
[iter 400] loss=-0.8594 val_loss=0.0000 scale=2.0000 norm=0.9162
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4378 val_loss=0.0000 scale=2.0000 norm=1.0812
[iter 200] loss=-0.1414 val_loss=0.0000 scale=2.0000 norm=0.9638
[iter 300] loss=-0.6126 val_loss=0.0000 scale=2.0000 norm=0.9122
[iter 400] loss=-0.9002 val_loss=0.0000 scale=2.0000 norm=0.9030
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3671 val_loss=0.0000 scale=2.0000 norm=1.0092
[iter 200] loss=-0.3738 val_loss=0.0000 scale=2.0000 norm=0.9226
[iter 300] loss=-1.0019 val_loss=0.0000 scale=2.0000 norm=0.8882
[iter 400] loss=-1.4967 val_loss=0.0000 scale=1.0000 norm=0.4338
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4291 val_loss=0.0000 scale=2.0000 norm=1.0703
[iter 200] loss=-0.4042 val_loss=0.0000 scale=2.0000 norm=1.0209
[iter 300] loss=-1.0941 val_loss=0.0000 scale=2.0000 norm=0.8917
[iter 400] loss=-1.6031 val_loss=0.0000 scale=2.0000 norm=0.8522
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3127 val_loss=0.0000 scale=2.0000 norm=1.0238
[iter 200] loss=-0.3170 val_loss=0.0000 scale=2.0000 norm=0.9920
[iter 300] loss=-0.8215 val_loss=0.0000 scale=2.0000 norm=0.9500
[iter 400] loss=-1.1263 val_loss=0.0000 scale=2.0000 norm=0.9520
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2712 val_loss=0.0000 scale=2.0000 norm=1.0244
[iter 200] loss=-0.3708 val_loss=0.0000 scale=2.0000 norm=0.9327
[iter 300] loss=-0.8620 val_loss=0.0000 scale=2.0000 norm=0.8739
[iter 400] loss=-1.1672 val_loss=0.0000 scale=1.0000 norm=0.4204
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5914 val_loss=0.0000 scale=2.0000 norm=1.1297
[iter 200] loss=0.2074 val_loss=0.0000 scale=1.0000 norm=0.5087
[iter 300] loss=-0.1567 val_loss=0.0000 scale=2.0000 norm=0.9736
[iter 400] loss=-0.4204 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4890 val_loss=0.0000 scale=2.0000 norm=1.1514
[iter 200] loss=-0.0357 val_loss=0.0000 scale=1.0000 norm=0.5183
[iter 300] loss=-0.4111 val_loss=0.0000 scale=1.0000 norm=0.4999
[iter 400] loss=-0.6545 val_loss=0.0000 scale=2.0000 norm=0.9517
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3670 val_loss=0.0000 scale=2.0000 norm=1.0529
[iter 200] loss=-0.2157 val_loss=0.0000 scale=2.0000 norm=0.9306
[iter 300] loss=-0.6361 val_loss=0.0000 scale=1.0000 norm=0.4448
[iter 400] loss=-0.8352 val_loss=0.0000 scale=1.0000 norm=0.4325
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3447 val_loss=0.0000 scale=2.0000 norm=1.0545
[iter 200] loss=-0.2900 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 300] loss=-0.7567 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 400] loss=-1.0605 val_loss=0.0000 scale=1.0000 norm=0.4608
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3753 val_loss=0.0000 scale=2.0000 norm=1.0713
[iter 200] loss=-0.1952 val_loss=0.0000 scale=2.0000 norm=0.9908
[iter 300] loss=-0.5985 val_loss=0.0000 scale=2.0000 norm=0.9580
[iter 400] loss=-0.8064 val_loss=0.0000 scale=1.0000 norm=0.4699
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3600 val_loss=0.0000 scale=2.0000 norm=1.0582
[iter 200] loss=-0.2329 val_loss=0.0000 scale=2.0000 norm=0.9783
[iter 300] loss=-0.6780 val_loss=0.0000 scale=2.0000 norm=0.9558
[iter 400] loss=-0.9341 val_loss=0.0000 scale=2.0000 norm=0.9112
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4097 val_loss=0.0000 scale=2.0000 norm=1.1051
[iter 200] loss=-0.1596 val_loss=0.0000 scale=2.0000 norm=1.0400
[iter 300] loss=-0.6072 val_loss=0.0000 scale=2.0000 norm=0.9770
[iter 400] loss=-0.8856 val_loss=0.0000 scale=1.0000 norm=0.4725
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4001 val_loss=0.0000 scale=2.0000 norm=1.0749
[iter 200] loss=-0.1908 val_loss=0.0000 scale=2.0000 norm=0.9546
[iter 300] loss=-0.5592 val_loss=0.0000 scale=2.0000 norm=0.9201
[iter 400] loss=-0.8599 val_loss=0.0000 scale=2.0000 norm=0.8867
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3392 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.2503 val_loss=0.0000 scale=2.0000 norm=0.9434
[iter 300] loss=-0.6820 val_loss=0.0000 scale=2.0000 norm=0.9062
[iter 400] loss=-0.9475 val_loss=0.0000 scale=2.0000 norm=0.8799
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3721 val_loss=0.0000 scale=2.0000 norm=1.0629
[iter 200] loss=-0.2580 val_loss=0.0000 scale=2.0000 norm=0.9782
[iter 300] loss=-0.7748 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 400] loss=-1.0998 val_loss=0.0000 scale=2.0000 norm=0.9075
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3641 val_loss=0.0000 scale=2.0000 norm=1.0389
[iter 200] loss=-0.2194 val_loss=0.0000 scale=2.0000 norm=0.9509
[iter 300] loss=-0.6460 val_loss=0.0000 scale=2.0000 norm=0.9062
[iter 400] loss=-0.8644 val_loss=0.0000 scale=1.0000 norm=0.4311
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2231 val_loss=0.0000 scale=2.0000 norm=1.0325
[iter 200] loss=-0.4846 val_loss=0.0000 scale=2.0000 norm=0.9118
[iter 300] loss=-1.0264 val_loss=0.0000 scale=2.0000 norm=0.8056
[iter 400] loss=-1.3308 val_loss=0.0000 scale=1.0000 norm=0.3680
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5897 val_loss=0.0000 scale=2.0000 norm=1.1840
[iter 200] loss=0.0818 val_loss=0.0000 scale=1.0000 norm=0.5421
[iter 300] loss=-0.1952 val_loss=0.0000 scale=1.0000 norm=0.5250
[iter 400] loss=-0.4096 val_loss=0.0000 scale=1.0000 norm=0.5053
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3899 val_loss=0.0000 scale=2.0000 norm=1.0531
[iter 200] loss=-0.2103 val_loss=0.0000 scale=2.0000 norm=0.9348
[iter 300] loss=-0.5562 val_loss=0.0000 scale=1.0000 norm=0.4505
[iter 400] loss=-0.7786 val_loss=0.0000 scale=1.0000 norm=0.4387
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4251 val_loss=0.0000 scale=2.0000 norm=1.0992
[iter 200] loss=-0.1302 val_loss=0.0000 scale=2.0000 norm=0.9684
[iter 300] loss=-0.5665 val_loss=0.0000 scale=2.0000 norm=0.9392
[iter 400] loss=-0.8488 val_loss=0.0000 scale=1.0000 norm=0.4571
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2159 val_loss=0.0000 scale=2.0000 norm=1.0196
[iter 200] loss=-0.4741 val_loss=0.0000 scale=2.0000 norm=0.9920
[iter 300] loss=-1.0201 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 400] loss=-1.3902 val_loss=0.0000 scale=2.0000 norm=0.8656
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2827 val_loss=0.0000 scale=2.0000 norm=0.9982
[iter 200] loss=-0.4383 val_loss=0.0000 scale=2.0000 norm=0.9193
[iter 300] loss=-0.9906 val_loss=0.0000 scale=2.0000 norm=0.8421
[iter 400] loss=-1.2932 val_loss=0.0000 scale=2.0000 norm=0.8358
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3596 val_loss=0.0000 scale=2.0000 norm=1.0297
[iter 200] loss=-0.2326 val_loss=0.0000 scale=2.0000 norm=0.9325
[iter 300] loss=-0.6851 val_loss=0.0000 scale=2.0000 norm=0.9188
[iter 400] loss=-0.9679 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4594 val_loss=0.0000 scale=2.0000 norm=1.0830
[iter 200] loss=-0.0903 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 300] loss=-0.4792 val_loss=0.0000 scale=2.0000 norm=0.9091
[iter 400] loss=-0.7261 val_loss=0.0000 scale=1.0000 norm=0.4517
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6133 val_loss=0.0000 scale=2.0000 norm=1.1544
[iter 200] loss=0.0731 val_loss=0.0000 scale=1.0000 norm=0.4976
[iter 300] loss=-0.3091 val_loss=0.0000 scale=1.0000 norm=0.4780
[iter 400] loss=-0.5675 val_loss=0.0000 scale=1.0000 norm=0.4746
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6390 val_loss=0.0000 scale=1.0000 norm=0.5833
[iter 200] loss=0.0611 val_loss=0.0000 scale=1.0000 norm=0.5244
[iter 300] loss=-0.4010 val_loss=0.0000 scale=1.0000 norm=0.4962
[iter 400] loss=-0.7231 val_loss=0.0000 scale=2.0000 norm=0.9575
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4047 val_loss=0.0000 scale=2.0000 norm=1.1309
[iter 200] loss=-0.1932 val_loss=0.0000 scale=2.0000 norm=1.0837
[iter 300] loss=-0.6823 val_loss=0.0000 scale=2.0000 norm=1.0717
[iter 400] loss=-1.0850 val_loss=0.0000 scale=2.0000 norm=1.0329
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3404 val_loss=0.0000 scale=2.0000 norm=1.0374
[iter 200] loss=-0.2413 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 300] loss=-0.6391 val_loss=0.0000 scale=2.0000 norm=0.9056
[iter 400] loss=-0.9243 val_loss=0.0000 scale=2.0000 norm=0.8515
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3420 val_loss=0.0000 scale=2.0000 norm=1.0233
[iter 200] loss=-0.2724 val_loss=0.0000 scale=2.0000 norm=0.9360
[iter 300] loss=-0.6788 val_loss=0.0000 scale=2.0000 norm=0.8854
[iter 400] loss=-0.9067 val_loss=0.0000 scale=1.0000 norm=0.4291
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4040 val_loss=0.0000 scale=2.0000 norm=1.0749
[iter 200] loss=-0.1623 val_loss=0.0000 scale=2.0000 norm=0.9655
[iter 300] loss=-0.5635 val_loss=0.0000 scale=2.0000 norm=0.9273
[iter 400] loss=-0.8037 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3792 val_loss=0.0000 scale=2.0000 norm=1.0407
[iter 200] loss=-0.2357 val_loss=0.0000 scale=2.0000 norm=0.9394
[iter 300] loss=-0.6605 val_loss=0.0000 scale=2.0000 norm=0.8928
[iter 400] loss=-0.9432 val_loss=0.0000 scale=1.0000 norm=0.4357
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5056 val_loss=0.0000 scale=2.0000 norm=1.1096
[iter 200] loss=-0.0528 val_loss=0.0000 scale=2.0000 norm=1.0228
[iter 300] loss=-0.4754 val_loss=0.0000 scale=2.0000 norm=0.9860
[iter 400] loss=-0.7568 val_loss=0.0000 scale=1.0000 norm=0.4885
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3610 val_loss=0.0000 scale=2.0000 norm=1.0581
[iter 200] loss=-0.2535 val_loss=0.0000 scale=2.0000 norm=0.9802
[iter 300] loss=-0.7151 val_loss=0.0000 scale=1.0000 norm=0.4760
[iter 400] loss=-0.9733 val_loss=0.0000 scale=1.0000 norm=0.4662
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3025 val_loss=0.0000 scale=2.0000 norm=1.0399
[iter 200] loss=-0.3377 val_loss=0.0000 scale=2.0000 norm=0.9312
[iter 300] loss=-0.8026 val_loss=0.0000 scale=2.0000 norm=0.8435
[iter 400] loss=-1.1463 val_loss=0.0000 scale=2.0000 norm=0.8203
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3803 val_loss=0.0000 scale=2.0000 norm=1.0631
[iter 200] loss=-0.1680 val_loss=0.0000 scale=2.0000 norm=0.9772
[iter 300] loss=-0.5475 val_loss=0.0000 scale=1.0000 norm=0.4688
[iter 400] loss=-0.7882 val_loss=0.0000 scale=1.0000 norm=0.4556
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1358 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.7981 val_loss=0.0000 scale=2.0000 norm=0.9355
[iter 300] loss=-1.6832 val_loss=0.0000 scale=2.0000 norm=0.9047
[iter 400] loss=-2.5438 val_loss=0.0000 scale=2.0000 norm=0.8861
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6772 val_loss=0.0000 scale=2.0000 norm=1.1926
[iter 200] loss=0.1734 val_loss=0.0000 scale=2.0000 norm=1.0469
[iter 300] loss=-0.2635 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 400] loss=-0.5065 val_loss=0.0000 scale=1.0000 norm=0.4592
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4329 val_loss=0.0000 scale=2.0000 norm=1.0924
[iter 200] loss=-0.0675 val_loss=0.0000 scale=2.0000 norm=0.9658
[iter 300] loss=-0.3976 val_loss=0.0000 scale=1.0000 norm=0.4743
[iter 400] loss=-0.5846 val_loss=0.0000 scale=1.0000 norm=0.4684
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5733 val_loss=0.0000 scale=2.0000 norm=1.1142
[iter 200] loss=-0.0483 val_loss=0.0000 scale=2.0000 norm=1.0251
[iter 300] loss=-0.5576 val_loss=0.0000 scale=2.0000 norm=1.0058
[iter 400] loss=-1.0137 val_loss=0.0000 scale=2.0000 norm=0.9387
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3374 val_loss=0.0000 scale=2.0000 norm=1.0312
[iter 200] loss=-0.2849 val_loss=0.0000 scale=1.0000 norm=0.4780
[iter 300] loss=-0.7150 val_loss=0.0000 scale=2.0000 norm=0.9356
[iter 400] loss=-0.9969 val_loss=0.0000 scale=1.0000 norm=0.4458
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3953 val_loss=0.0000 scale=2.0000 norm=1.0727
[iter 200] loss=-0.1513 val_loss=0.0000 scale=2.0000 norm=0.9891
[iter 300] loss=-0.4823 val_loss=0.0000 scale=1.0000 norm=0.4754
[iter 400] loss=-0.6609 val_loss=0.0000 scale=0.5000 norm=0.2377
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2815 val_loss=0.0000 scale=2.0000 norm=1.0020
[iter 200] loss=-0.3410 val_loss=0.0000 scale=2.0000 norm=0.9272
[iter 300] loss=-0.8623 val_loss=0.0000 scale=2.0000 norm=0.9038
[iter 400] loss=-1.2644 val_loss=0.0000 scale=2.0000 norm=0.8847
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4551 val_loss=0.0000 scale=2.0000 norm=1.0974
[iter 200] loss=-0.0886 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 300] loss=-0.4684 val_loss=0.0000 scale=1.0000 norm=0.4884
[iter 400] loss=-0.6870 val_loss=0.0000 scale=0.5000 norm=0.2377
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3534 val_loss=0.0000 scale=2.0000 norm=1.0623
[iter 200] loss=-0.2716 val_loss=0.0000 scale=2.0000 norm=0.9519
[iter 300] loss=-0.6823 val_loss=0.0000 scale=2.0000 norm=0.8925
[iter 400] loss=-0.9451 val_loss=0.0000 scale=1.0000 norm=0.4326
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1606 val_loss=0.0000 scale=2.0000 norm=0.9796
[iter 200] loss=-0.7738 val_loss=0.0000 scale=2.0000 norm=0.9345
[iter 300] loss=-1.6343 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 400] loss=-2.4624 val_loss=0.0000 scale=2.0000 norm=0.9142
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6058 val_loss=0.0000 scale=2.0000 norm=1.1372
[iter 200] loss=0.0196 val_loss=0.0000 scale=2.0000 norm=1.0155
[iter 300] loss=-0.4619 val_loss=0.0000 scale=2.0000 norm=1.0007
[iter 400] loss=-0.8157 val_loss=0.0000 scale=2.0000 norm=0.9437
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3065 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3424 val_loss=0.0000 scale=2.0000 norm=0.9218
[iter 300] loss=-0.7825 val_loss=0.0000 scale=2.0000 norm=0.9168
[iter 400] loss=-1.0768 val_loss=0.0000 scale=1.0000 norm=0.4512
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2627 val_loss=0.0000 scale=2.0000 norm=0.9636
[iter 200] loss=-0.6591 val_loss=0.0000 scale=2.0000 norm=0.9285
[iter 300] loss=-1.5431 val_loss=0.0000 scale=2.0000 norm=0.8765
[iter 400] loss=-2.2984 val_loss=0.0000 scale=2.0000 norm=0.7667
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7063 val_loss=0.0000 scale=2.0000 norm=1.2290
[iter 200] loss=0.2136 val_loss=0.0000 scale=2.0000 norm=1.0930
[iter 300] loss=-0.0945 val_loss=0.0000 scale=1.0000 norm=0.5278
[iter 400] loss=-0.3304 val_loss=0.0000 scale=2.0000 norm=1.0295
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4974 val_loss=0.0000 scale=2.0000 norm=1.1228
[iter 200] loss=-0.1089 val_loss=0.0000 scale=2.0000 norm=0.9955
[iter 300] loss=-0.5179 val_loss=0.0000 scale=2.0000 norm=0.9209
[iter 400] loss=-0.8064 val_loss=0.0000 scale=1.0000 norm=0.4380
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3459 val_loss=0.0000 scale=2.0000 norm=1.0365
[iter 200] loss=-0.2635 val_loss=0.0000 scale=2.0000 norm=0.9230
[iter 300] loss=-0.6577 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 400] loss=-0.9390 val_loss=0.0000 scale=1.0000 norm=0.4314
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3626 val_loss=0.0000 scale=2.0000 norm=1.0519
[iter 200] loss=-0.1788 val_loss=0.0000 scale=2.0000 norm=0.9668
[iter 300] loss=-0.5341 val_loss=0.0000 scale=2.0000 norm=0.9571
[iter 400] loss=-0.8126 val_loss=0.0000 scale=2.0000 norm=0.9236
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4865 val_loss=0.0000 scale=2.0000 norm=1.0873
[iter 200] loss=-0.0694 val_loss=0.0000 scale=2.0000 norm=0.9754
[iter 300] loss=-0.4304 val_loss=0.0000 scale=1.0000 norm=0.4773
[iter 400] loss=-0.6677 val_loss=0.0000 scale=1.0000 norm=0.4724
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2126 val_loss=0.0000 scale=2.0000 norm=0.9868
[iter 200] loss=-0.5514 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 300] loss=-1.2003 val_loss=0.0000 scale=2.0000 norm=0.9123
[iter 400] loss=-1.7164 val_loss=0.0000 scale=2.0000 norm=0.8821
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3190 val_loss=0.0000 scale=2.0000 norm=1.0367
[iter 200] loss=-0.2872 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 300] loss=-0.7436 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 400] loss=-1.0131 val_loss=0.0000 scale=1.0000 norm=0.4358
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4143 val_loss=0.0000 scale=2.0000 norm=1.1163
[iter 200] loss=-0.3906 val_loss=0.0000 scale=4.0000 norm=2.2490
[iter 300] loss=-1.8072 val_loss=0.0000 scale=4.0000 norm=2.1115
[iter 400] loss=-2.8041 val_loss=0.0000 scale=4.0000 norm=2.0427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3521 val_loss=0.0000 scale=2.0000 norm=1.0646
[iter 200] loss=-0.2339 val_loss=0.0000 scale=2.0000 norm=0.9664
[iter 300] loss=-0.6695 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 400] loss=-0.9349 val_loss=0.0000 scale=2.0000 norm=0.9255
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2413 val_loss=0.0000 scale=2.0000 norm=1.0043
[iter 200] loss=-0.4371 val_loss=0.0000 scale=2.0000 norm=0.9205
[iter 300] loss=-0.9196 val_loss=0.0000 scale=2.0000 norm=0.8747
[iter 400] loss=-1.2283 val_loss=0.0000 scale=2.0000 norm=0.8177
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4028 val_loss=0.0000 scale=2.0000 norm=1.0490
[iter 200] loss=-0.0943 val_loss=0.0000 scale=1.0000 norm=0.4725
[iter 300] loss=-0.4467 val_loss=0.0000 scale=1.0000 norm=0.4490
[iter 400] loss=-0.6858 val_loss=0.0000 scale=2.0000 norm=0.8857
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3547 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 200] loss=-0.3209 val_loss=0.0000 scale=2.0000 norm=0.9624
[iter 300] loss=-0.8631 val_loss=0.0000 scale=2.0000 norm=0.8946
[iter 400] loss=-1.2423 val_loss=0.0000 scale=2.0000 norm=0.8769
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5583 val_loss=0.0000 scale=2.0000 norm=1.1995
[iter 200] loss=0.0333 val_loss=0.0000 scale=1.0000 norm=0.5384
[iter 300] loss=-0.3521 val_loss=0.0000 scale=1.0000 norm=0.4974
[iter 400] loss=-0.6255 val_loss=0.0000 scale=2.0000 norm=0.9553
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4635 val_loss=0.0000 scale=2.0000 norm=1.1045
[iter 200] loss=-0.0525 val_loss=0.0000 scale=1.0000 norm=0.5090
[iter 300] loss=-0.3435 val_loss=0.0000 scale=1.0000 norm=0.4839
[iter 400] loss=-0.5133 val_loss=0.0000 scale=2.0000 norm=0.9242
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4966 val_loss=0.0000 scale=2.0000 norm=1.1289
[iter 200] loss=-0.1663 val_loss=0.0000 scale=2.0000 norm=1.0146
[iter 300] loss=-0.6328 val_loss=0.0000 scale=2.0000 norm=0.9738
[iter 400] loss=-0.9590 val_loss=0.0000 scale=1.0000 norm=0.4838
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2859 val_loss=0.0000 scale=2.0000 norm=1.0033
[iter 200] loss=-0.3626 val_loss=0.0000 scale=2.0000 norm=0.9392
[iter 300] loss=-0.8378 val_loss=0.0000 scale=2.0000 norm=0.9330
[iter 400] loss=-1.1338 val_loss=0.0000 scale=1.0000 norm=0.4458
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5170 val_loss=0.0000 scale=2.0000 norm=1.0945
[iter 200] loss=-0.0858 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 300] loss=-0.4961 val_loss=0.0000 scale=2.0000 norm=0.8165
[iter 400] loss=-0.7428 val_loss=0.0000 scale=1.0000 norm=0.3935
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3993 val_loss=0.0000 scale=2.0000 norm=1.0685
[iter 200] loss=-0.2061 val_loss=0.0000 scale=2.0000 norm=0.9400
[iter 300] loss=-0.6724 val_loss=0.0000 scale=1.0000 norm=0.4451
[iter 400] loss=-0.9902 val_loss=0.0000 scale=1.0000 norm=0.4289
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7680 val_loss=0.0000 scale=2.0000 norm=1.2619
[iter 200] loss=0.2699 val_loss=0.0000 scale=1.0000 norm=0.5472
[iter 300] loss=-0.0807 val_loss=0.0000 scale=2.0000 norm=1.0609
[iter 400] loss=-0.3247 val_loss=0.0000 scale=2.0000 norm=1.0489
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1286 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 200] loss=-0.7766 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-1.6605 val_loss=0.0000 scale=2.0000 norm=0.8486
[iter 400] loss=-2.9146 val_loss=0.0000 scale=4.0000 norm=1.5998
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2974 val_loss=0.0000 scale=2.0000 norm=1.0241
[iter 200] loss=-0.3274 val_loss=0.0000 scale=1.0000 norm=0.4608
[iter 300] loss=-0.7239 val_loss=0.0000 scale=1.0000 norm=0.4614
[iter 400] loss=-1.0294 val_loss=0.0000 scale=2.0000 norm=0.9110
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3032 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 200] loss=-0.3594 val_loss=0.0000 scale=2.0000 norm=0.9911
[iter 300] loss=-0.9055 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 400] loss=-1.2994 val_loss=0.0000 scale=2.0000 norm=0.8678
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4203 val_loss=0.0000 scale=2.0000 norm=1.0765
[iter 200] loss=-0.1845 val_loss=0.0000 scale=2.0000 norm=0.9590
[iter 300] loss=-0.5690 val_loss=0.0000 scale=2.0000 norm=0.9167
[iter 400] loss=-0.8663 val_loss=0.0000 scale=2.0000 norm=0.9278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5410 val_loss=0.0000 scale=2.0000 norm=1.1270
[iter 200] loss=0.0264 val_loss=0.0000 scale=1.0000 norm=0.5136
[iter 300] loss=-0.3743 val_loss=0.0000 scale=2.0000 norm=0.9347
[iter 400] loss=-0.6865 val_loss=0.0000 scale=2.0000 norm=0.8951
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4308 val_loss=0.0000 scale=2.0000 norm=1.1082
[iter 200] loss=-0.1932 val_loss=0.0000 scale=2.0000 norm=0.9925
[iter 300] loss=-0.6669 val_loss=0.0000 scale=2.0000 norm=0.9294
[iter 400] loss=-1.0395 val_loss=0.0000 scale=2.0000 norm=0.8857
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3341 val_loss=0.0000 scale=2.0000 norm=1.0551
[iter 200] loss=-0.3696 val_loss=0.0000 scale=2.0000 norm=0.9669
[iter 300] loss=-0.9383 val_loss=0.0000 scale=1.0000 norm=0.4594
[iter 400] loss=-1.2593 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4662 val_loss=0.0000 scale=2.0000 norm=1.0905
[iter 200] loss=-0.2456 val_loss=0.0000 scale=2.0000 norm=0.9743
[iter 300] loss=-0.8903 val_loss=0.0000 scale=2.0000 norm=0.9713
[iter 400] loss=-1.4576 val_loss=0.0000 scale=2.0000 norm=0.9051
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3262 val_loss=0.0000 scale=2.0000 norm=1.0187
[iter 200] loss=-0.2556 val_loss=0.0000 scale=2.0000 norm=0.9272
[iter 300] loss=-0.6503 val_loss=0.0000 scale=2.0000 norm=0.8686
[iter 400] loss=-0.8610 val_loss=0.0000 scale=1.0000 norm=0.4124
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1636 val_loss=0.0000 scale=2.0000 norm=0.9905
[iter 200] loss=-0.6807 val_loss=0.0000 scale=2.0000 norm=0.9672
[iter 300] loss=-1.4215 val_loss=0.0000 scale=2.0000 norm=0.9495
[iter 400] loss=-2.0482 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2230 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 200] loss=-0.6359 val_loss=0.0000 scale=2.0000 norm=1.0231
[iter 300] loss=-1.7243 val_loss=0.0000 scale=2.0000 norm=0.9679
[iter 400] loss=-2.8001 val_loss=0.0000 scale=2.0000 norm=0.8953
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4291 val_loss=0.0000 scale=2.0000 norm=1.0350
[iter 200] loss=-0.3310 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 300] loss=-1.0029 val_loss=0.0000 scale=2.0000 norm=0.8563
[iter 400] loss=-1.5409 val_loss=0.0000 scale=2.0000 norm=0.8059
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3380 val_loss=0.0000 scale=2.0000 norm=0.9858
[iter 200] loss=-0.6226 val_loss=0.0000 scale=2.0000 norm=0.9567
[iter 300] loss=-1.8145 val_loss=0.0000 scale=4.0000 norm=1.7217
[iter 400] loss=-3.1966 val_loss=0.0000 scale=4.0000 norm=1.7312
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3583 val_loss=0.0000 scale=2.0000 norm=1.0431
[iter 200] loss=-0.2057 val_loss=0.0000 scale=2.0000 norm=0.9519
[iter 300] loss=-0.5492 val_loss=0.0000 scale=1.0000 norm=0.4737
[iter 400] loss=-0.7907 val_loss=0.0000 scale=1.0000 norm=0.4542
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6475 val_loss=0.0000 scale=2.0000 norm=1.1072
[iter 200] loss=-0.0175 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 300] loss=-0.5834 val_loss=0.0000 scale=2.0000 norm=0.9852
[iter 400] loss=-0.9983 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6226 val_loss=0.0000 scale=2.0000 norm=1.1280
[iter 200] loss=-0.0150 val_loss=0.0000 scale=2.0000 norm=1.0222
[iter 300] loss=-0.5000 val_loss=0.0000 scale=2.0000 norm=0.9464
[iter 400] loss=-0.7562 val_loss=0.0000 scale=2.0000 norm=0.9290
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3789 val_loss=0.0000 scale=2.0000 norm=1.0551
[iter 200] loss=-0.2152 val_loss=0.0000 scale=2.0000 norm=0.9725
[iter 300] loss=-0.6821 val_loss=0.0000 scale=1.0000 norm=0.4669
[iter 400] loss=-0.9282 val_loss=0.0000 scale=1.0000 norm=0.4743
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3523 val_loss=0.0000 scale=2.0000 norm=1.0569
[iter 200] loss=-0.3804 val_loss=0.0000 scale=2.0000 norm=1.0160
[iter 300] loss=-1.2866 val_loss=0.0000 scale=4.0000 norm=2.1229
[iter 400] loss=-2.2799 val_loss=0.0000 scale=4.0000 norm=1.9945
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1992 val_loss=0.0000 scale=2.0000 norm=1.0083
[iter 200] loss=-0.4883 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 300] loss=-1.0491 val_loss=0.0000 scale=2.0000 norm=0.9383
[iter 400] loss=-1.4335 val_loss=0.0000 scale=2.0000 norm=0.8933
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3301 val_loss=0.0000 scale=2.0000 norm=1.0350
[iter 200] loss=-0.2651 val_loss=0.0000 scale=2.0000 norm=0.9407
[iter 300] loss=-0.6856 val_loss=0.0000 scale=2.0000 norm=0.9091
[iter 400] loss=-0.9219 val_loss=0.0000 scale=2.0000 norm=0.8786
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3653 val_loss=0.0000 scale=2.0000 norm=1.0790
[iter 200] loss=-0.2688 val_loss=0.0000 scale=2.0000 norm=1.0031
[iter 300] loss=-0.7843 val_loss=0.0000 scale=2.0000 norm=0.9516
[iter 400] loss=-1.1180 val_loss=0.0000 scale=1.0000 norm=0.4514
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3837 val_loss=0.0000 scale=2.0000 norm=1.0715
[iter 200] loss=-0.1905 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-0.6095 val_loss=0.0000 scale=1.0000 norm=0.4748
[iter 400] loss=-0.8246 val_loss=0.0000 scale=1.0000 norm=0.4620
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6135 val_loss=0.0000 scale=2.0000 norm=1.1201
[iter 200] loss=-0.1578 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 300] loss=-0.8207 val_loss=0.0000 scale=2.0000 norm=0.9545
[iter 400] loss=-1.3840 val_loss=0.0000 scale=2.0000 norm=0.9689
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5159 val_loss=0.0000 scale=2.0000 norm=1.1795
[iter 200] loss=-0.0123 val_loss=0.0000 scale=2.0000 norm=1.0784
[iter 300] loss=-0.4353 val_loss=0.0000 scale=2.0000 norm=1.0299
[iter 400] loss=-0.6890 val_loss=0.0000 scale=2.0000 norm=0.9871
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3691 val_loss=0.0000 scale=2.0000 norm=1.0539
[iter 200] loss=-0.2312 val_loss=0.0000 scale=2.0000 norm=0.9559
[iter 300] loss=-0.6026 val_loss=0.0000 scale=2.0000 norm=0.9312
[iter 400] loss=-0.8423 val_loss=0.0000 scale=2.0000 norm=0.9062
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3473 val_loss=0.0000 scale=2.0000 norm=1.0414
[iter 200] loss=-0.2489 val_loss=0.0000 scale=2.0000 norm=0.9429
[iter 300] loss=-0.6683 val_loss=0.0000 scale=2.0000 norm=0.9142
[iter 400] loss=-0.9060 val_loss=0.0000 scale=1.0000 norm=0.4571
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4196 val_loss=0.0000 scale=2.0000 norm=1.0713
[iter 200] loss=-0.3738 val_loss=0.0000 scale=2.0000 norm=0.9665
[iter 300] loss=-1.1157 val_loss=0.0000 scale=2.0000 norm=0.9482
[iter 400] loss=-1.8073 val_loss=0.0000 scale=2.0000 norm=0.9163
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3908 val_loss=0.0000 scale=2.0000 norm=1.0620
[iter 200] loss=-0.3048 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 300] loss=-0.8519 val_loss=0.0000 scale=2.0000 norm=0.8597
[iter 400] loss=-1.1989 val_loss=0.0000 scale=2.0000 norm=0.8051
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4575 val_loss=0.0000 scale=2.0000 norm=1.1080
[iter 200] loss=-0.0674 val_loss=0.0000 scale=2.0000 norm=1.0299
[iter 300] loss=-0.4118 val_loss=0.0000 scale=1.0000 norm=0.4916
[iter 400] loss=-0.6478 val_loss=0.0000 scale=1.0000 norm=0.4719
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4101 val_loss=0.0000 scale=2.0000 norm=1.0955
[iter 200] loss=-0.3154 val_loss=0.0000 scale=2.0000 norm=1.0403
[iter 300] loss=-0.9154 val_loss=0.0000 scale=2.0000 norm=1.0384
[iter 400] loss=-1.4274 val_loss=0.0000 scale=2.0000 norm=1.0480
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2979 val_loss=0.0000 scale=2.0000 norm=1.0154
[iter 200] loss=-0.3141 val_loss=0.0000 scale=2.0000 norm=1.0008
[iter 300] loss=-0.7617 val_loss=0.0000 scale=2.0000 norm=1.0022
[iter 400] loss=-1.1447 val_loss=0.0000 scale=1.0000 norm=0.4559
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4032 val_loss=0.0000 scale=2.0000 norm=1.0754
[iter 200] loss=-0.1790 val_loss=0.0000 scale=2.0000 norm=0.9598
[iter 300] loss=-0.5908 val_loss=0.0000 scale=2.0000 norm=0.9045
[iter 400] loss=-0.7950 val_loss=0.0000 scale=2.0000 norm=0.8874
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3648 val_loss=0.0000 scale=2.0000 norm=1.0399
[iter 200] loss=-0.1979 val_loss=0.0000 scale=2.0000 norm=0.9296
[iter 300] loss=-0.5532 val_loss=0.0000 scale=2.0000 norm=0.9052
[iter 400] loss=-0.7848 val_loss=0.0000 scale=2.0000 norm=0.8797
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4654 val_loss=0.0000 scale=2.0000 norm=1.1632
[iter 200] loss=-0.3486 val_loss=0.0000 scale=2.0000 norm=1.1398
[iter 300] loss=-1.1844 val_loss=0.0000 scale=2.0000 norm=1.1593
[iter 400] loss=-2.1345 val_loss=0.0000 scale=4.0000 norm=2.3164
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3164 val_loss=0.0000 scale=2.0000 norm=1.0246
[iter 200] loss=-0.3022 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 300] loss=-0.7548 val_loss=0.0000 scale=2.0000 norm=0.9251
[iter 400] loss=-1.0103 val_loss=0.0000 scale=2.0000 norm=0.9358
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3094 val_loss=0.0000 scale=2.0000 norm=1.0366
[iter 200] loss=-0.2987 val_loss=0.0000 scale=2.0000 norm=0.9474
[iter 300] loss=-0.6731 val_loss=0.0000 scale=2.0000 norm=0.9413
[iter 400] loss=-0.9801 val_loss=0.0000 scale=2.0000 norm=0.9165
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2299 val_loss=0.0000 scale=2.0000 norm=0.9731
[iter 200] loss=-0.7279 val_loss=0.0000 scale=2.0000 norm=0.9612
[iter 300] loss=-1.8006 val_loss=0.0000 scale=4.0000 norm=1.8802
[iter 400] loss=-3.0433 val_loss=0.0000 scale=2.0000 norm=0.8824
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5160 val_loss=0.0000 scale=2.0000 norm=1.1333
[iter 200] loss=0.0369 val_loss=0.0000 scale=2.0000 norm=1.0001
[iter 300] loss=-0.2777 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 400] loss=-0.4765 val_loss=0.0000 scale=1.0000 norm=0.4560
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3460 val_loss=0.0000 scale=2.0000 norm=1.0438
[iter 200] loss=-0.2434 val_loss=0.0000 scale=2.0000 norm=0.9449
[iter 300] loss=-0.6276 val_loss=0.0000 scale=2.0000 norm=0.9324
[iter 400] loss=-0.8275 val_loss=0.0000 scale=2.0000 norm=0.8954

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n10>
Subject: Job 861715: <structure_numerical_ecfp3binery_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_ecfp3binery_NGB_generalizibility> was submitted from host <c205n12> by user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:00 2024
Job was executed on host(s) <4*c203n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:01 2024
                            <4*c203n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Thu Oct 24 11:35:01 2024
Terminated at Thu Oct 24 11:39:11 2024
Results reported at Thu Oct 24 11:39:11 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 7:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_ecfp3binery_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py ecfp --regressor_type NGB --radius 3 --vector binary --target "Rg1 (nm)" --oligo_type "Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2071.44 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.73 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   275 sec.
    Turnaround time :                            251 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err> for stderr output of this job.

RRU Monomer_scaler
Filename: (ECFP3.binary.512-Mw-PDI)_NGB_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer_scaler/(ECFP3.binary.512-Mw-PDI)_NGB_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3808 val_loss=0.0000 scale=2.0000 norm=1.0424
[iter 200] loss=-0.3121 val_loss=0.0000 scale=2.0000 norm=0.9664
[iter 300] loss=-0.8850 val_loss=0.0000 scale=2.0000 norm=0.9275
[iter 400] loss=-1.3405 val_loss=0.0000 scale=2.0000 norm=0.9223
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3845 val_loss=0.0000 scale=2.0000 norm=1.1072
[iter 200] loss=-0.2510 val_loss=0.0000 scale=2.0000 norm=0.9769
[iter 300] loss=-0.7311 val_loss=0.0000 scale=2.0000 norm=0.8888
[iter 400] loss=-1.0569 val_loss=0.0000 scale=1.0000 norm=0.4270
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3668 val_loss=0.0000 scale=2.0000 norm=1.0534
[iter 200] loss=-0.2436 val_loss=0.0000 scale=2.0000 norm=0.9554
[iter 300] loss=-0.6569 val_loss=0.0000 scale=1.0000 norm=0.4619
[iter 400] loss=-0.8633 val_loss=0.0000 scale=1.0000 norm=0.4477
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2873 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.3580 val_loss=0.0000 scale=2.0000 norm=0.9149
[iter 300] loss=-0.8475 val_loss=0.0000 scale=2.0000 norm=0.8586
[iter 400] loss=-1.1578 val_loss=0.0000 scale=1.0000 norm=0.4088
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.0671
[iter 200] loss=-0.1495 val_loss=0.0000 scale=2.0000 norm=0.9667
[iter 300] loss=-0.5251 val_loss=0.0000 scale=2.0000 norm=0.9564
[iter 400] loss=-0.7112 val_loss=0.0000 scale=1.0000 norm=0.4858
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3396 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 200] loss=-0.3124 val_loss=0.0000 scale=2.0000 norm=0.9649
[iter 300] loss=-0.8007 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 400] loss=-1.1459 val_loss=0.0000 scale=2.0000 norm=0.8903
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4962 val_loss=0.0000 scale=2.0000 norm=1.1169
[iter 200] loss=-0.1332 val_loss=0.0000 scale=2.0000 norm=0.9781
[iter 300] loss=-0.5846 val_loss=0.0000 scale=2.0000 norm=0.9246
[iter 400] loss=-0.9118 val_loss=0.0000 scale=2.0000 norm=0.8954
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4456 val_loss=0.0000 scale=2.0000 norm=1.1034
[iter 200] loss=-0.1090 val_loss=0.0000 scale=1.0000 norm=0.4993
[iter 300] loss=-0.5008 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 400] loss=-0.7538 val_loss=0.0000 scale=2.0000 norm=0.9512
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4402 val_loss=0.0000 scale=2.0000 norm=1.0629
[iter 200] loss=-0.3859 val_loss=0.0000 scale=2.0000 norm=1.0177
[iter 300] loss=-1.0806 val_loss=0.0000 scale=2.0000 norm=0.8936
[iter 400] loss=-1.6234 val_loss=0.0000 scale=4.0000 norm=1.6957
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5824 val_loss=0.0000 scale=2.0000 norm=1.1150
[iter 200] loss=-0.0469 val_loss=0.0000 scale=2.0000 norm=1.0326
[iter 300] loss=-0.5471 val_loss=0.0000 scale=1.0000 norm=0.4809
[iter 400] loss=-0.8546 val_loss=0.0000 scale=1.0000 norm=0.4521
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4353 val_loss=0.0000 scale=2.0000 norm=1.0655
[iter 200] loss=-0.2466 val_loss=0.0000 scale=1.0000 norm=0.4426
[iter 300] loss=-0.7019 val_loss=0.0000 scale=2.0000 norm=0.7903
[iter 400] loss=-1.0068 val_loss=0.0000 scale=1.0000 norm=0.4069
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4106 val_loss=0.0000 scale=2.0000 norm=1.0883
[iter 200] loss=-0.1550 val_loss=0.0000 scale=2.0000 norm=0.9730
[iter 300] loss=-0.6407 val_loss=0.0000 scale=2.0000 norm=0.9200
[iter 400] loss=-0.9641 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7158 val_loss=0.0000 scale=2.0000 norm=1.2267
[iter 200] loss=0.1950 val_loss=0.0000 scale=1.0000 norm=0.5385
[iter 300] loss=-0.1411 val_loss=0.0000 scale=1.0000 norm=0.5274
[iter 400] loss=-0.4017 val_loss=0.0000 scale=2.0000 norm=1.0483
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3725 val_loss=0.0000 scale=2.0000 norm=1.0597
[iter 200] loss=-0.1806 val_loss=0.0000 scale=1.0000 norm=0.4935
[iter 300] loss=-0.5720 val_loss=0.0000 scale=1.0000 norm=0.4687
[iter 400] loss=-0.7946 val_loss=0.0000 scale=1.0000 norm=0.4512
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1447 val_loss=0.0000 scale=2.0000 norm=0.9757
[iter 200] loss=-0.7261 val_loss=0.0000 scale=2.0000 norm=0.8954
[iter 300] loss=-1.4564 val_loss=0.0000 scale=2.0000 norm=0.8453
[iter 400] loss=-1.9703 val_loss=0.0000 scale=2.0000 norm=0.8116
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3596 val_loss=0.0000 scale=2.0000 norm=1.0297
[iter 200] loss=-0.2419 val_loss=0.0000 scale=2.0000 norm=0.9302
[iter 300] loss=-0.6560 val_loss=0.0000 scale=2.0000 norm=0.9137
[iter 400] loss=-0.9341 val_loss=0.0000 scale=2.0000 norm=0.9179
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3425 val_loss=0.0000 scale=2.0000 norm=1.0527
[iter 200] loss=-0.3049 val_loss=0.0000 scale=2.0000 norm=0.9873
[iter 300] loss=-0.8079 val_loss=0.0000 scale=2.0000 norm=0.9438
[iter 400] loss=-1.0925 val_loss=0.0000 scale=2.0000 norm=0.8902
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3396 val_loss=0.0000 scale=2.0000 norm=1.0456
[iter 200] loss=-0.2637 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 300] loss=-0.7290 val_loss=0.0000 scale=2.0000 norm=0.9670
[iter 400] loss=-0.9872 val_loss=0.0000 scale=1.0000 norm=0.4681
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2061 val_loss=0.0000 scale=2.0000 norm=0.9908
[iter 200] loss=-0.5787 val_loss=0.0000 scale=2.0000 norm=0.9612
[iter 300] loss=-1.2277 val_loss=0.0000 scale=2.0000 norm=0.9348
[iter 400] loss=-1.7068 val_loss=0.0000 scale=2.0000 norm=0.9013
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5611 val_loss=0.0000 scale=2.0000 norm=1.1865
[iter 200] loss=-0.0316 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 300] loss=-0.4492 val_loss=0.0000 scale=1.0000 norm=0.5173
[iter 400] loss=-0.7388 val_loss=0.0000 scale=2.0000 norm=1.0115
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3387 val_loss=0.0000 scale=2.0000 norm=1.0270
[iter 200] loss=-0.2456 val_loss=0.0000 scale=2.0000 norm=0.9342
[iter 300] loss=-0.6866 val_loss=0.0000 scale=2.0000 norm=0.8801
[iter 400] loss=-0.9667 val_loss=0.0000 scale=2.0000 norm=0.8541
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3784 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.1695 val_loss=0.0000 scale=2.0000 norm=0.9556
[iter 300] loss=-0.5795 val_loss=0.0000 scale=1.0000 norm=0.4520
[iter 400] loss=-0.8362 val_loss=0.0000 scale=1.0000 norm=0.4324
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3102 val_loss=0.0000 scale=2.0000 norm=1.0357
[iter 200] loss=-0.2807 val_loss=0.0000 scale=2.0000 norm=0.9586
[iter 300] loss=-0.7811 val_loss=0.0000 scale=1.0000 norm=0.4495
[iter 400] loss=-1.1402 val_loss=0.0000 scale=1.0000 norm=0.4288
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4348 val_loss=0.0000 scale=2.0000 norm=1.1047
[iter 200] loss=-0.1469 val_loss=0.0000 scale=2.0000 norm=0.9771
[iter 300] loss=-0.5329 val_loss=0.0000 scale=2.0000 norm=0.9458
[iter 400] loss=-0.7923 val_loss=0.0000 scale=2.0000 norm=0.9231
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3620 val_loss=0.0000 scale=2.0000 norm=1.0528
[iter 200] loss=-0.2234 val_loss=0.0000 scale=2.0000 norm=0.9780
[iter 300] loss=-0.5655 val_loss=0.0000 scale=1.0000 norm=0.4854
[iter 400] loss=-0.8131 val_loss=0.0000 scale=1.0000 norm=0.4863
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5376 val_loss=0.0000 scale=1.0000 norm=0.5939
[iter 200] loss=0.0911 val_loss=0.0000 scale=2.0000 norm=1.0924
[iter 300] loss=-0.2836 val_loss=0.0000 scale=1.0000 norm=0.5142
[iter 400] loss=-0.5619 val_loss=0.0000 scale=1.0000 norm=0.4892
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3916 val_loss=0.0000 scale=2.0000 norm=1.0955
[iter 200] loss=-0.1762 val_loss=0.0000 scale=2.0000 norm=1.0148
[iter 300] loss=-0.5935 val_loss=0.0000 scale=2.0000 norm=0.9512
[iter 400] loss=-0.8586 val_loss=0.0000 scale=2.0000 norm=0.9163
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5515 val_loss=0.0000 scale=2.0000 norm=1.1190
[iter 200] loss=-0.0718 val_loss=0.0000 scale=2.0000 norm=1.0129
[iter 300] loss=-0.6209 val_loss=0.0000 scale=2.0000 norm=0.9481
[iter 400] loss=-1.0130 val_loss=0.0000 scale=1.0000 norm=0.4489
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3218 val_loss=0.0000 scale=2.0000 norm=1.0226
[iter 200] loss=-0.2714 val_loss=0.0000 scale=2.0000 norm=0.9545
[iter 300] loss=-0.6883 val_loss=0.0000 scale=1.0000 norm=0.4739
[iter 400] loss=-0.9527 val_loss=0.0000 scale=2.0000 norm=0.9186
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5205 val_loss=0.0000 scale=2.0000 norm=1.0960
[iter 200] loss=-0.0804 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 300] loss=-0.5573 val_loss=0.0000 scale=1.0000 norm=0.3974
[iter 400] loss=-0.8330 val_loss=0.0000 scale=2.0000 norm=0.7595
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4136 val_loss=0.0000 scale=2.0000 norm=1.0945
[iter 200] loss=-0.1660 val_loss=0.0000 scale=2.0000 norm=0.9696
[iter 300] loss=-0.5428 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 400] loss=-0.8160 val_loss=0.0000 scale=2.0000 norm=0.9106
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0265
[iter 200] loss=-0.2824 val_loss=0.0000 scale=2.0000 norm=0.9385
[iter 300] loss=-0.7125 val_loss=0.0000 scale=1.0000 norm=0.4553
[iter 400] loss=-0.9605 val_loss=0.0000 scale=2.0000 norm=0.8925
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3345 val_loss=0.0000 scale=2.0000 norm=1.0356
[iter 200] loss=-0.2719 val_loss=0.0000 scale=2.0000 norm=0.9505
[iter 300] loss=-0.7201 val_loss=0.0000 scale=2.0000 norm=0.9239
[iter 400] loss=-0.9873 val_loss=0.0000 scale=2.0000 norm=0.8976
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3029 val_loss=0.0000 scale=2.0000 norm=1.0086
[iter 200] loss=-0.3175 val_loss=0.0000 scale=2.0000 norm=0.9629
[iter 300] loss=-0.8250 val_loss=0.0000 scale=2.0000 norm=0.9400
[iter 400] loss=-1.2267 val_loss=0.0000 scale=2.0000 norm=0.9733
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4263 val_loss=0.0000 scale=2.0000 norm=1.0446
[iter 200] loss=-0.2438 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 300] loss=-0.7904 val_loss=0.0000 scale=2.0000 norm=0.8845
[iter 400] loss=-1.1688 val_loss=0.0000 scale=2.0000 norm=0.8936
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5252 val_loss=0.0000 scale=2.0000 norm=1.1701
[iter 200] loss=0.0367 val_loss=0.0000 scale=1.0000 norm=0.5219
[iter 300] loss=-0.2731 val_loss=0.0000 scale=1.0000 norm=0.4877
[iter 400] loss=-0.5061 val_loss=0.0000 scale=1.0000 norm=0.4716
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1058 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.8630 val_loss=0.0000 scale=2.0000 norm=0.9692
[iter 300] loss=-1.8257 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 400] loss=-2.7388 val_loss=0.0000 scale=2.0000 norm=0.9102
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.1221
[iter 200] loss=-0.4233 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 300] loss=-1.1907 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 400] loss=-1.9869 val_loss=0.0000 scale=4.0000 norm=2.0032
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3971 val_loss=0.0000 scale=2.0000 norm=1.0674
[iter 200] loss=-0.1735 val_loss=0.0000 scale=1.0000 norm=0.4770
[iter 300] loss=-0.5362 val_loss=0.0000 scale=1.0000 norm=0.4494
[iter 400] loss=-0.7432 val_loss=0.0000 scale=1.0000 norm=0.4381
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2981 val_loss=0.0000 scale=2.0000 norm=1.0519
[iter 200] loss=-0.3130 val_loss=0.0000 scale=2.0000 norm=0.9713
[iter 300] loss=-0.7668 val_loss=0.0000 scale=2.0000 norm=0.9176
[iter 400] loss=-1.0226 val_loss=0.0000 scale=2.0000 norm=0.8682
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1847 val_loss=0.0000 scale=2.0000 norm=0.9877
[iter 200] loss=-0.7322 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 300] loss=-1.5482 val_loss=0.0000 scale=2.0000 norm=0.8811
[iter 400] loss=-2.3449 val_loss=0.0000 scale=2.0000 norm=0.8667
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4737 val_loss=0.0000 scale=2.0000 norm=1.1073
[iter 200] loss=-0.0483 val_loss=0.0000 scale=2.0000 norm=1.0244
[iter 300] loss=-0.3499 val_loss=0.0000 scale=1.0000 norm=0.4885
[iter 400] loss=-0.5674 val_loss=0.0000 scale=1.0000 norm=0.4644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3632 val_loss=0.0000 scale=2.0000 norm=1.0577
[iter 200] loss=-0.2529 val_loss=0.0000 scale=2.0000 norm=0.9801
[iter 300] loss=-0.6760 val_loss=0.0000 scale=2.0000 norm=0.9536
[iter 400] loss=-0.9352 val_loss=0.0000 scale=0.5000 norm=0.2351
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3402 val_loss=0.0000 scale=2.0000 norm=1.0422
[iter 200] loss=-0.2668 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 300] loss=-0.6507 val_loss=0.0000 scale=1.0000 norm=0.4458
[iter 400] loss=-0.8929 val_loss=0.0000 scale=0.5000 norm=0.2207
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3523 val_loss=0.0000 scale=2.0000 norm=1.0569
[iter 200] loss=-0.3801 val_loss=0.0000 scale=2.0000 norm=1.0158
[iter 300] loss=-1.2856 val_loss=0.0000 scale=4.0000 norm=2.1213
[iter 400] loss=-2.2787 val_loss=0.0000 scale=4.0000 norm=1.9942
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7047 val_loss=0.0000 scale=2.0000 norm=1.2232
[iter 200] loss=0.1675 val_loss=0.0000 scale=2.0000 norm=1.0779
[iter 300] loss=-0.1726 val_loss=0.0000 scale=2.0000 norm=1.0472
[iter 400] loss=-0.4450 val_loss=0.0000 scale=1.0000 norm=0.5222
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1286 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 200] loss=-0.7766 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-1.6605 val_loss=0.0000 scale=2.0000 norm=0.8486
[iter 400] loss=-2.9066 val_loss=0.0000 scale=4.0000 norm=1.5972
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3565 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 200] loss=-0.3360 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 300] loss=-0.8126 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 400] loss=-1.1153 val_loss=0.0000 scale=1.0000 norm=0.4677
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3645 val_loss=0.0000 scale=2.0000 norm=1.0796
[iter 200] loss=-0.2742 val_loss=0.0000 scale=2.0000 norm=1.0044
[iter 300] loss=-0.7771 val_loss=0.0000 scale=2.0000 norm=0.9476
[iter 400] loss=-1.0807 val_loss=0.0000 scale=1.0000 norm=0.4456
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3861 val_loss=0.0000 scale=2.0000 norm=1.0709
[iter 200] loss=-0.2006 val_loss=0.0000 scale=2.0000 norm=0.9839
[iter 300] loss=-0.6368 val_loss=0.0000 scale=1.0000 norm=0.4756
[iter 400] loss=-0.8553 val_loss=0.0000 scale=1.0000 norm=0.4633
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3682 val_loss=0.0000 scale=2.0000 norm=1.0498
[iter 200] loss=-0.2285 val_loss=0.0000 scale=2.0000 norm=0.9707
[iter 300] loss=-0.7129 val_loss=0.0000 scale=2.0000 norm=0.9395
[iter 400] loss=-1.0328 val_loss=0.0000 scale=1.0000 norm=0.4626
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5813 val_loss=0.0000 scale=2.0000 norm=1.1987
[iter 200] loss=0.0300 val_loss=0.0000 scale=2.0000 norm=1.0485
[iter 300] loss=-0.3520 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 400] loss=-0.6208 val_loss=0.0000 scale=1.0000 norm=0.4807
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3587 val_loss=0.0000 scale=2.0000 norm=1.0303
[iter 200] loss=-0.2088 val_loss=0.0000 scale=2.0000 norm=0.9463
[iter 300] loss=-0.6040 val_loss=0.0000 scale=2.0000 norm=0.9246
[iter 400] loss=-0.8428 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2087 val_loss=0.0000 scale=2.0000 norm=0.9629
[iter 200] loss=-0.6607 val_loss=0.0000 scale=2.0000 norm=0.8930
[iter 300] loss=-1.5114 val_loss=0.0000 scale=2.0000 norm=0.8804
[iter 400] loss=-2.3487 val_loss=0.0000 scale=2.0000 norm=0.8717
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3745 val_loss=0.0000 scale=2.0000 norm=1.0346
[iter 200] loss=-0.2165 val_loss=0.0000 scale=2.0000 norm=0.9294
[iter 300] loss=-0.5682 val_loss=0.0000 scale=2.0000 norm=0.9141
[iter 400] loss=-0.8102 val_loss=0.0000 scale=1.0000 norm=0.4630
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4000 val_loss=0.0000 scale=2.0000 norm=1.0836
[iter 200] loss=-0.1480 val_loss=0.0000 scale=2.0000 norm=0.9738
[iter 300] loss=-0.4962 val_loss=0.0000 scale=2.0000 norm=0.9354
[iter 400] loss=-0.7221 val_loss=0.0000 scale=2.0000 norm=0.8992
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3067 val_loss=0.0000 scale=2.0000 norm=1.0645
[iter 200] loss=-0.4629 val_loss=0.0000 scale=2.0000 norm=0.9599
[iter 300] loss=-1.1070 val_loss=0.0000 scale=2.0000 norm=0.8818
[iter 400] loss=-1.5687 val_loss=0.0000 scale=2.0000 norm=0.8059
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5010 val_loss=0.0000 scale=2.0000 norm=1.1288
[iter 200] loss=-0.0145 val_loss=0.0000 scale=2.0000 norm=1.0130
[iter 300] loss=-0.3359 val_loss=0.0000 scale=2.0000 norm=0.9590
[iter 400] loss=-0.5661 val_loss=0.0000 scale=1.0000 norm=0.4732
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4140 val_loss=0.0000 scale=2.0000 norm=1.0846
[iter 200] loss=-0.3186 val_loss=0.0000 scale=2.0000 norm=1.0509
[iter 300] loss=-0.9555 val_loss=0.0000 scale=2.0000 norm=1.0515
[iter 400] loss=-1.4395 val_loss=0.0000 scale=2.0000 norm=1.0983
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2689 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.3734 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 300] loss=-0.8279 val_loss=0.0000 scale=2.0000 norm=0.9461
[iter 400] loss=-1.1527 val_loss=0.0000 scale=1.0000 norm=0.4598
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3354 val_loss=0.0000 scale=2.0000 norm=1.0344
[iter 200] loss=-0.2619 val_loss=0.0000 scale=2.0000 norm=0.9438
[iter 300] loss=-0.6936 val_loss=0.0000 scale=2.0000 norm=0.9380
[iter 400] loss=-0.9927 val_loss=0.0000 scale=1.0000 norm=0.4714
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4433 val_loss=0.0000 scale=2.0000 norm=1.1050
[iter 200] loss=-0.0447 val_loss=0.0000 scale=1.0000 norm=0.4962
[iter 300] loss=-0.3902 val_loss=0.0000 scale=2.0000 norm=0.9343
[iter 400] loss=-0.5939 val_loss=0.0000 scale=1.0000 norm=0.4671
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6539 val_loss=0.0000 scale=2.0000 norm=1.2059
[iter 200] loss=-0.1419 val_loss=0.0000 scale=2.0000 norm=1.0680
[iter 300] loss=-0.8665 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 400] loss=-1.4692 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2330 val_loss=0.0000 scale=2.0000 norm=0.9850
[iter 200] loss=-0.5277 val_loss=0.0000 scale=2.0000 norm=0.8884
[iter 300] loss=-1.1463 val_loss=0.0000 scale=2.0000 norm=0.8173
[iter 400] loss=-1.5960 val_loss=0.0000 scale=2.0000 norm=0.7577
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2410 val_loss=0.0000 scale=2.0000 norm=1.0023
[iter 200] loss=-0.4692 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 300] loss=-0.9925 val_loss=0.0000 scale=2.0000 norm=0.8821
[iter 400] loss=-1.3445 val_loss=0.0000 scale=2.0000 norm=0.8898
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3370 val_loss=0.0000 scale=2.0000 norm=1.0541
[iter 200] loss=-0.3137 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 300] loss=-0.7891 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 400] loss=-1.0981 val_loss=0.0000 scale=2.0000 norm=0.9426
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2710 val_loss=0.0000 scale=2.0000 norm=1.0327
[iter 200] loss=-0.3923 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-0.9376 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 400] loss=-1.2762 val_loss=0.0000 scale=2.0000 norm=0.8818
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4425 val_loss=0.0000 scale=2.0000 norm=1.1150
[iter 200] loss=-0.1051 val_loss=0.0000 scale=1.0000 norm=0.4968
[iter 300] loss=-0.4595 val_loss=0.0000 scale=1.0000 norm=0.4687
[iter 400] loss=-0.6621 val_loss=0.0000 scale=2.0000 norm=0.9146
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5161 val_loss=0.0000 scale=2.0000 norm=1.1809
[iter 200] loss=-0.0550 val_loss=0.0000 scale=2.0000 norm=1.0754
[iter 300] loss=-0.4454 val_loss=0.0000 scale=2.0000 norm=1.0479
[iter 400] loss=-0.7664 val_loss=0.0000 scale=1.0000 norm=0.4942
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3270 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 200] loss=-0.2502 val_loss=0.0000 scale=2.0000 norm=0.9395
[iter 300] loss=-0.6406 val_loss=0.0000 scale=1.0000 norm=0.4500
[iter 400] loss=-0.9095 val_loss=0.0000 scale=1.0000 norm=0.4229
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2220 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 200] loss=-0.5145 val_loss=0.0000 scale=2.0000 norm=0.8602
[iter 300] loss=-0.9813 val_loss=0.0000 scale=2.0000 norm=0.7634
[iter 400] loss=-1.3369 val_loss=0.0000 scale=2.0000 norm=0.7333
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0949 val_loss=0.0000 scale=2.0000 norm=1.0010
[iter 200] loss=-0.8679 val_loss=0.0000 scale=2.0000 norm=0.9644
[iter 300] loss=-1.8149 val_loss=0.0000 scale=2.0000 norm=0.9430
[iter 400] loss=-2.6920 val_loss=0.0000 scale=2.0000 norm=0.8769
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4584 val_loss=0.0000 scale=2.0000 norm=1.1211
[iter 200] loss=-0.2109 val_loss=0.0000 scale=2.0000 norm=1.0147
[iter 300] loss=-0.8777 val_loss=0.0000 scale=2.0000 norm=0.9705
[iter 400] loss=-1.4686 val_loss=0.0000 scale=2.0000 norm=0.9295
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2562 val_loss=0.0000 scale=2.0000 norm=1.0326
[iter 200] loss=-0.3860 val_loss=0.0000 scale=2.0000 norm=0.9684
[iter 300] loss=-0.8682 val_loss=0.0000 scale=2.0000 norm=0.9517
[iter 400] loss=-1.1452 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3311 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 200] loss=-0.5583 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 300] loss=-1.3894 val_loss=0.0000 scale=2.0000 norm=0.8927
[iter 400] loss=-2.1598 val_loss=0.0000 scale=2.0000 norm=0.8480
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3125 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.3218 val_loss=0.0000 scale=2.0000 norm=1.0023
[iter 300] loss=-0.8383 val_loss=0.0000 scale=2.0000 norm=0.9805
[iter 400] loss=-1.1655 val_loss=0.0000 scale=2.0000 norm=0.9705
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3660 val_loss=0.0000 scale=2.0000 norm=1.0410
[iter 200] loss=-0.2097 val_loss=0.0000 scale=2.0000 norm=0.9339
[iter 300] loss=-0.5938 val_loss=0.0000 scale=1.0000 norm=0.4596
[iter 400] loss=-0.8464 val_loss=0.0000 scale=1.0000 norm=0.4436
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7288 val_loss=0.0000 scale=2.0000 norm=1.2431
[iter 200] loss=0.0991 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 300] loss=-0.3973 val_loss=0.0000 scale=2.0000 norm=0.9753
[iter 400] loss=-0.7980 val_loss=0.0000 scale=1.0000 norm=0.4702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2999 val_loss=0.0000 scale=2.0000 norm=1.0087
[iter 200] loss=-0.3369 val_loss=0.0000 scale=2.0000 norm=0.9260
[iter 300] loss=-0.7891 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 400] loss=-1.0408 val_loss=0.0000 scale=2.0000 norm=0.9310
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3733 val_loss=0.0000 scale=2.0000 norm=1.0459
[iter 200] loss=-0.1910 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 300] loss=-0.5875 val_loss=0.0000 scale=2.0000 norm=0.8891
[iter 400] loss=-0.8041 val_loss=0.0000 scale=2.0000 norm=0.8555
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3655 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.4351 val_loss=0.0000 scale=2.0000 norm=1.0192
[iter 300] loss=-1.2732 val_loss=0.0000 scale=2.0000 norm=1.0588
[iter 400] loss=-2.0453 val_loss=0.0000 scale=2.0000 norm=1.0588
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1667 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.5902 val_loss=0.0000 scale=2.0000 norm=0.9219
[iter 300] loss=-1.6406 val_loss=0.0000 scale=4.0000 norm=1.7220
[iter 400] loss=-2.6893 val_loss=0.0000 scale=4.0000 norm=1.5187
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4399 val_loss=0.0000 scale=2.0000 norm=1.1249
[iter 200] loss=-0.0853 val_loss=0.0000 scale=2.0000 norm=0.9974
[iter 300] loss=-0.4637 val_loss=0.0000 scale=1.0000 norm=0.4800
[iter 400] loss=-0.6870 val_loss=0.0000 scale=0.5000 norm=0.2270
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3955 val_loss=0.0000 scale=2.0000 norm=1.0780
[iter 200] loss=-0.2251 val_loss=0.0000 scale=2.0000 norm=0.9606
[iter 300] loss=-0.6495 val_loss=0.0000 scale=2.0000 norm=0.9228
[iter 400] loss=-0.9514 val_loss=0.0000 scale=2.0000 norm=0.9025
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3426 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.2420 val_loss=0.0000 scale=2.0000 norm=0.9352
[iter 300] loss=-0.6151 val_loss=0.0000 scale=2.0000 norm=0.9011
[iter 400] loss=-0.8990 val_loss=0.0000 scale=1.0000 norm=0.4346
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2230 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 200] loss=-0.6434 val_loss=0.0000 scale=2.0000 norm=1.0230
[iter 300] loss=-1.6837 val_loss=0.0000 scale=4.0000 norm=1.9411
[iter 400] loss=-2.5592 val_loss=0.0000 scale=4.0000 norm=1.8342
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4382 val_loss=0.0000 scale=2.0000 norm=1.0812
[iter 200] loss=-0.1955 val_loss=0.0000 scale=2.0000 norm=0.9578
[iter 300] loss=-0.6472 val_loss=0.0000 scale=2.0000 norm=0.8971
[iter 400] loss=-0.9125 val_loss=0.0000 scale=1.0000 norm=0.4431
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3589 val_loss=0.0000 scale=2.0000 norm=1.0946
[iter 200] loss=-0.2782 val_loss=0.0000 scale=1.0000 norm=0.4781
[iter 300] loss=-0.6676 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 400] loss=-0.9939 val_loss=0.0000 scale=1.0000 norm=0.4075
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3740 val_loss=0.0000 scale=2.0000 norm=1.0665
[iter 200] loss=-0.2542 val_loss=0.0000 scale=2.0000 norm=0.9515
[iter 300] loss=-0.7150 val_loss=0.0000 scale=2.0000 norm=0.8904
[iter 400] loss=-1.0094 val_loss=0.0000 scale=1.0000 norm=0.4200
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3316 val_loss=0.0000 scale=2.0000 norm=1.0400
[iter 200] loss=-0.2833 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 300] loss=-0.6677 val_loss=0.0000 scale=2.0000 norm=0.8691
[iter 400] loss=-0.9097 val_loss=0.0000 scale=2.0000 norm=0.8532
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2695 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.3772 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 300] loss=-0.8748 val_loss=0.0000 scale=2.0000 norm=0.8700
[iter 400] loss=-1.2066 val_loss=0.0000 scale=2.0000 norm=0.8458
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4575 val_loss=0.0000 scale=2.0000 norm=1.1121
[iter 200] loss=-0.0579 val_loss=0.0000 scale=1.0000 norm=0.4960
[iter 300] loss=-0.4337 val_loss=0.0000 scale=1.0000 norm=0.4909
[iter 400] loss=-0.7117 val_loss=0.0000 scale=2.0000 norm=0.9965
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2988 val_loss=0.0000 scale=2.0000 norm=0.9980
[iter 200] loss=-0.3668 val_loss=0.0000 scale=2.0000 norm=0.9253
[iter 300] loss=-0.8772 val_loss=0.0000 scale=2.0000 norm=0.8615
[iter 400] loss=-1.1604 val_loss=0.0000 scale=1.0000 norm=0.4181
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3828 val_loss=0.0000 scale=2.0000 norm=1.0546
[iter 200] loss=-0.1627 val_loss=0.0000 scale=2.0000 norm=0.9752
[iter 300] loss=-0.6038 val_loss=0.0000 scale=2.0000 norm=0.9396
[iter 400] loss=-0.8918 val_loss=0.0000 scale=2.0000 norm=0.9760
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3237 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 200] loss=-0.6141 val_loss=0.0000 scale=2.0000 norm=0.9266
[iter 300] loss=-1.4834 val_loss=0.0000 scale=2.0000 norm=0.8674
[iter 400] loss=-2.2770 val_loss=0.0000 scale=2.0000 norm=0.8224
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4863 val_loss=0.0000 scale=2.0000 norm=1.1098
[iter 200] loss=-0.0724 val_loss=0.0000 scale=2.0000 norm=1.0050
[iter 300] loss=-0.4529 val_loss=0.0000 scale=1.0000 norm=0.4646
[iter 400] loss=-0.7107 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5509 val_loss=0.0000 scale=2.0000 norm=1.1099
[iter 200] loss=-0.0429 val_loss=0.0000 scale=2.0000 norm=1.0303
[iter 300] loss=-0.4954 val_loss=0.0000 scale=1.0000 norm=0.5091
[iter 400] loss=-0.9357 val_loss=0.0000 scale=2.0000 norm=0.9596
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4658 val_loss=0.0000 scale=2.0000 norm=1.0642
[iter 200] loss=-0.2772 val_loss=0.0000 scale=2.0000 norm=0.9614
[iter 300] loss=-0.8968 val_loss=0.0000 scale=2.0000 norm=0.9404
[iter 400] loss=-1.3944 val_loss=0.0000 scale=2.0000 norm=0.9079
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3510 val_loss=0.0000 scale=2.0000 norm=1.0494
[iter 200] loss=-0.2950 val_loss=0.0000 scale=2.0000 norm=0.9307
[iter 300] loss=-0.7347 val_loss=0.0000 scale=2.0000 norm=0.8684
[iter 400] loss=-1.0561 val_loss=0.0000 scale=1.0000 norm=0.4131
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3438 val_loss=0.0000 scale=2.0000 norm=1.0256
[iter 200] loss=-0.2638 val_loss=0.0000 scale=2.0000 norm=0.9347
[iter 300] loss=-0.6770 val_loss=0.0000 scale=2.0000 norm=0.9027
[iter 400] loss=-0.9041 val_loss=0.0000 scale=2.0000 norm=0.8711
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3383 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 200] loss=-0.2535 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 300] loss=-0.6619 val_loss=0.0000 scale=1.0000 norm=0.4720
[iter 400] loss=-0.9366 val_loss=0.0000 scale=1.0000 norm=0.4483
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2732 val_loss=0.0000 scale=2.0000 norm=1.0084
[iter 200] loss=-0.4437 val_loss=0.0000 scale=2.0000 norm=0.8873
[iter 300] loss=-1.0558 val_loss=0.0000 scale=2.0000 norm=0.8059
[iter 400] loss=-1.4986 val_loss=0.0000 scale=2.0000 norm=0.7726
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3584 val_loss=0.0000 scale=2.0000 norm=1.0694
[iter 200] loss=-0.2167 val_loss=0.0000 scale=1.0000 norm=0.4910
[iter 300] loss=-0.5909 val_loss=0.0000 scale=1.0000 norm=0.4713
[iter 400] loss=-0.8317 val_loss=0.0000 scale=1.0000 norm=0.4564
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5173 val_loss=0.0000 scale=2.0000 norm=1.0916
[iter 200] loss=-0.1918 val_loss=0.0000 scale=2.0000 norm=0.9403
[iter 300] loss=-0.7668 val_loss=0.0000 scale=2.0000 norm=0.8655
[iter 400] loss=-1.1594 val_loss=0.0000 scale=2.0000 norm=0.8198
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4109 val_loss=0.0000 scale=2.0000 norm=1.0786
[iter 200] loss=-0.1609 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 300] loss=-0.5815 val_loss=0.0000 scale=2.0000 norm=0.9244
[iter 400] loss=-0.7799 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4138 val_loss=0.0000 scale=2.0000 norm=1.0748
[iter 200] loss=-0.1249 val_loss=0.0000 scale=2.0000 norm=0.9639
[iter 300] loss=-0.5119 val_loss=0.0000 scale=2.0000 norm=0.9413
[iter 400] loss=-0.7039 val_loss=0.0000 scale=0.5000 norm=0.2344
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7039 val_loss=0.0000 scale=2.0000 norm=1.2383
[iter 200] loss=0.1957 val_loss=0.0000 scale=2.0000 norm=1.0561
[iter 300] loss=-0.1819 val_loss=0.0000 scale=1.0000 norm=0.4886
[iter 400] loss=-0.4072 val_loss=0.0000 scale=2.0000 norm=0.9246
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3557 val_loss=0.0000 scale=2.0000 norm=1.0662
[iter 200] loss=-0.2749 val_loss=0.0000 scale=2.0000 norm=0.9573
[iter 300] loss=-0.7786 val_loss=0.0000 scale=1.0000 norm=0.4631
[iter 400] loss=-1.1071 val_loss=0.0000 scale=1.0000 norm=0.4609
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3945 val_loss=0.0000 scale=2.0000 norm=1.0541
[iter 200] loss=-0.1514 val_loss=0.0000 scale=2.0000 norm=0.9515
[iter 300] loss=-0.5727 val_loss=0.0000 scale=1.0000 norm=0.4513
[iter 400] loss=-0.8907 val_loss=0.0000 scale=2.0000 norm=0.8735
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5790 val_loss=0.0000 scale=2.0000 norm=1.1645
[iter 200] loss=0.0728 val_loss=0.0000 scale=1.0000 norm=0.4988
[iter 300] loss=-0.2065 val_loss=0.0000 scale=1.0000 norm=0.4729
[iter 400] loss=-0.4489 val_loss=0.0000 scale=0.5000 norm=0.2321
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6849 val_loss=0.0000 scale=2.0000 norm=1.1421
[iter 200] loss=0.0193 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 300] loss=-0.5820 val_loss=0.0000 scale=1.0000 norm=0.3955
[iter 400] loss=-1.0033 val_loss=0.0000 scale=1.0000 norm=0.3883
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4047 val_loss=0.0000 scale=2.0000 norm=1.1310
[iter 200] loss=-0.1952 val_loss=0.0000 scale=2.0000 norm=1.0835
[iter 300] loss=-0.6859 val_loss=0.0000 scale=2.0000 norm=1.0670
[iter 400] loss=-1.0712 val_loss=0.0000 scale=2.0000 norm=1.0161
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3740 val_loss=0.0000 scale=2.0000 norm=1.0727
[iter 200] loss=-0.2301 val_loss=0.0000 scale=1.0000 norm=0.4833
[iter 300] loss=-0.6379 val_loss=0.0000 scale=1.0000 norm=0.4696
[iter 400] loss=-0.9576 val_loss=0.0000 scale=1.0000 norm=0.4606
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1636 val_loss=0.0000 scale=2.0000 norm=0.9904
[iter 200] loss=-0.6819 val_loss=0.0000 scale=2.0000 norm=0.9677
[iter 300] loss=-1.4145 val_loss=0.0000 scale=2.0000 norm=0.9575
[iter 400] loss=-2.0669 val_loss=0.0000 scale=2.0000 norm=0.9316
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4008 val_loss=0.0000 scale=2.0000 norm=1.0645
[iter 200] loss=-0.2291 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 300] loss=-0.7144 val_loss=0.0000 scale=2.0000 norm=0.9159
[iter 400] loss=-1.0225 val_loss=0.0000 scale=1.0000 norm=0.4472
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2774 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 200] loss=-0.5477 val_loss=0.0000 scale=2.0000 norm=0.8780
[iter 300] loss=-1.1978 val_loss=0.0000 scale=2.0000 norm=0.7570
[iter 400] loss=-2.0824 val_loss=0.0000 scale=4.0000 norm=1.3044
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3595 val_loss=0.0000 scale=2.0000 norm=1.0667
[iter 200] loss=-0.2192 val_loss=0.0000 scale=2.0000 norm=0.9846
[iter 300] loss=-0.5880 val_loss=0.0000 scale=2.0000 norm=0.9717
[iter 400] loss=-0.8324 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4139 val_loss=0.0000 scale=1.0000 norm=0.5540
[iter 200] loss=-0.1513 val_loss=0.0000 scale=2.0000 norm=0.9918
[iter 300] loss=-0.5879 val_loss=0.0000 scale=2.0000 norm=0.9154
[iter 400] loss=-0.8336 val_loss=0.0000 scale=1.0000 norm=0.4366
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2916 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.3703 val_loss=0.0000 scale=2.0000 norm=0.9357
[iter 300] loss=-0.8842 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 400] loss=-1.2956 val_loss=0.0000 scale=2.0000 norm=0.8747
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3144 val_loss=0.0000 scale=2.0000 norm=1.0460
[iter 200] loss=-0.2703 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 300] loss=-0.6911 val_loss=0.0000 scale=2.0000 norm=0.9450
[iter 400] loss=-0.9661 val_loss=0.0000 scale=1.0000 norm=0.4640
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1854 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 200] loss=-0.6132 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 300] loss=-1.3205 val_loss=0.0000 scale=2.0000 norm=0.9041
[iter 400] loss=-1.9339 val_loss=0.0000 scale=2.0000 norm=0.8648
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6880 val_loss=0.0000 scale=2.0000 norm=1.2028
[iter 200] loss=0.1895 val_loss=0.0000 scale=2.0000 norm=1.0462
[iter 300] loss=-0.2526 val_loss=0.0000 scale=2.0000 norm=0.9730
[iter 400] loss=-0.5532 val_loss=0.0000 scale=1.0000 norm=0.4653
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4319 val_loss=0.0000 scale=2.0000 norm=1.1002
[iter 200] loss=-0.0667 val_loss=0.0000 scale=1.0000 norm=0.4833
[iter 300] loss=-0.4494 val_loss=0.0000 scale=1.0000 norm=0.4736
[iter 400] loss=-0.7068 val_loss=0.0000 scale=1.0000 norm=0.4643
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7441 val_loss=0.0000 scale=2.0000 norm=1.2259
[iter 200] loss=-0.0320 val_loss=0.0000 scale=2.0000 norm=0.9922
[iter 300] loss=-0.7024 val_loss=0.0000 scale=2.0000 norm=0.9353
[iter 400] loss=-1.2818 val_loss=0.0000 scale=2.0000 norm=0.9289
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3416 val_loss=0.0000 scale=2.0000 norm=1.0328
[iter 200] loss=-0.2770 val_loss=0.0000 scale=2.0000 norm=0.9501
[iter 300] loss=-0.7340 val_loss=0.0000 scale=2.0000 norm=0.9328
[iter 400] loss=-0.9752 val_loss=0.0000 scale=2.0000 norm=0.8970
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2091 val_loss=0.0000 scale=2.0000 norm=1.0527
[iter 200] loss=-0.6740 val_loss=0.0000 scale=2.0000 norm=1.0344
[iter 300] loss=-1.5411 val_loss=0.0000 scale=2.0000 norm=1.0301
[iter 400] loss=-2.3943 val_loss=0.0000 scale=2.0000 norm=1.0147
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4448 val_loss=0.0000 scale=2.0000 norm=1.0960
[iter 200] loss=-0.0934 val_loss=0.0000 scale=2.0000 norm=0.9722
[iter 300] loss=-0.4711 val_loss=0.0000 scale=1.0000 norm=0.4718
[iter 400] loss=-0.7701 val_loss=0.0000 scale=1.0000 norm=0.4562
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3547 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 200] loss=-0.3202 val_loss=0.0000 scale=2.0000 norm=0.9496
[iter 300] loss=-0.8589 val_loss=0.0000 scale=2.0000 norm=0.8893
[iter 400] loss=-1.2024 val_loss=0.0000 scale=2.0000 norm=0.8628
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4124 val_loss=0.0000 scale=2.0000 norm=1.0724
[iter 200] loss=-0.1875 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 300] loss=-0.6017 val_loss=0.0000 scale=2.0000 norm=0.8697
[iter 400] loss=-0.8365 val_loss=0.0000 scale=2.0000 norm=0.8245
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3670 val_loss=0.0000 scale=2.0000 norm=1.0087
[iter 200] loss=-0.3719 val_loss=0.0000 scale=2.0000 norm=0.9157
[iter 300] loss=-1.0055 val_loss=0.0000 scale=2.0000 norm=0.8826
[iter 400] loss=-1.4262 val_loss=0.0000 scale=2.0000 norm=0.8607
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6267 val_loss=0.0000 scale=2.0000 norm=1.1526
[iter 200] loss=0.0015 val_loss=0.0000 scale=2.0000 norm=1.0262
[iter 300] loss=-0.5148 val_loss=0.0000 scale=2.0000 norm=1.0188
[iter 400] loss=-0.9286 val_loss=0.0000 scale=2.0000 norm=0.9858
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2388 val_loss=0.0000 scale=2.0000 norm=0.9922
[iter 200] loss=-0.5198 val_loss=0.0000 scale=2.0000 norm=0.9525
[iter 300] loss=-1.1724 val_loss=0.0000 scale=2.0000 norm=0.8919
[iter 400] loss=-1.6784 val_loss=0.0000 scale=2.0000 norm=0.8456
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3890 val_loss=0.0000 scale=2.0000 norm=1.0630
[iter 200] loss=-0.2085 val_loss=0.0000 scale=2.0000 norm=0.9416
[iter 300] loss=-0.6528 val_loss=0.0000 scale=1.0000 norm=0.4419
[iter 400] loss=-0.9342 val_loss=0.0000 scale=2.0000 norm=0.8037
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3127 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 200] loss=-0.5560 val_loss=0.0000 scale=2.0000 norm=0.8838
[iter 300] loss=-1.3479 val_loss=0.0000 scale=2.0000 norm=0.8186
[iter 400] loss=-2.0746 val_loss=0.0000 scale=2.0000 norm=0.7986
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3403 val_loss=0.0000 scale=2.0000 norm=1.0390
[iter 200] loss=-0.2587 val_loss=0.0000 scale=1.0000 norm=0.4754
[iter 300] loss=-0.6478 val_loss=0.0000 scale=2.0000 norm=0.9192
[iter 400] loss=-0.9159 val_loss=0.0000 scale=1.0000 norm=0.4553
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2095 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6178 val_loss=0.0000 scale=2.0000 norm=0.8988
[iter 300] loss=-1.3437 val_loss=0.0000 scale=2.0000 norm=0.8420
[iter 400] loss=-2.0493 val_loss=0.0000 scale=2.0000 norm=0.8513
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6204 val_loss=0.0000 scale=2.0000 norm=1.1466
[iter 200] loss=0.0516 val_loss=0.0000 scale=1.0000 norm=0.4870
[iter 300] loss=-0.3240 val_loss=0.0000 scale=1.0000 norm=0.4624
[iter 400] loss=-0.5490 val_loss=0.0000 scale=1.0000 norm=0.4725
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3906 val_loss=0.0000 scale=2.0000 norm=1.0729
[iter 200] loss=-0.1644 val_loss=0.0000 scale=1.0000 norm=0.4983
[iter 300] loss=-0.5371 val_loss=0.0000 scale=1.0000 norm=0.4791
[iter 400] loss=-0.7597 val_loss=0.0000 scale=2.0000 norm=0.9372
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2957 val_loss=0.0000 scale=2.0000 norm=1.0295
[iter 200] loss=-0.4333 val_loss=0.0000 scale=2.0000 norm=0.9530
[iter 300] loss=-0.9910 val_loss=0.0000 scale=2.0000 norm=0.9201
[iter 400] loss=-1.3433 val_loss=0.0000 scale=2.0000 norm=0.8774
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2926 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3262 val_loss=0.0000 scale=2.0000 norm=0.8943
[iter 300] loss=-0.7490 val_loss=0.0000 scale=2.0000 norm=0.8139
[iter 400] loss=-1.0048 val_loss=0.0000 scale=1.0000 norm=0.3980
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3406 val_loss=0.0000 scale=2.0000 norm=1.0379
[iter 200] loss=-0.2434 val_loss=0.0000 scale=2.0000 norm=0.9435
[iter 300] loss=-0.6527 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 400] loss=-0.9639 val_loss=0.0000 scale=1.0000 norm=0.4484
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6058 val_loss=0.0000 scale=2.0000 norm=1.1794
[iter 200] loss=-0.0626 val_loss=0.0000 scale=2.0000 norm=1.0914
[iter 300] loss=-0.5128 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 400] loss=-0.8411 val_loss=0.0000 scale=1.0000 norm=0.5145
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3720 val_loss=0.0000 scale=2.0000 norm=1.0139
[iter 200] loss=-0.4203 val_loss=0.0000 scale=2.0000 norm=0.9179
[iter 300] loss=-1.1532 val_loss=0.0000 scale=2.0000 norm=0.8778
[iter 400] loss=-1.7962 val_loss=0.0000 scale=2.0000 norm=0.8076
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4153 val_loss=0.0000 scale=2.0000 norm=1.1007
[iter 200] loss=-0.1123 val_loss=0.0000 scale=1.0000 norm=0.4921
[iter 300] loss=-0.4917 val_loss=0.0000 scale=2.0000 norm=0.9045
[iter 400] loss=-0.7457 val_loss=0.0000 scale=1.0000 norm=0.4237
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6753 val_loss=0.0000 scale=2.0000 norm=1.2416
[iter 200] loss=0.1214 val_loss=0.0000 scale=2.0000 norm=1.0824
[iter 300] loss=-0.3049 val_loss=0.0000 scale=1.0000 norm=0.4967
[iter 400] loss=-0.5640 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3792 val_loss=0.0000 scale=2.0000 norm=1.0505
[iter 200] loss=-0.2226 val_loss=0.0000 scale=2.0000 norm=0.9724
[iter 300] loss=-0.6491 val_loss=0.0000 scale=1.0000 norm=0.4689
[iter 400] loss=-0.9053 val_loss=0.0000 scale=1.0000 norm=0.4822
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1693 val_loss=0.0000 scale=2.0000 norm=1.0079
[iter 200] loss=-0.5527 val_loss=0.0000 scale=2.0000 norm=0.9779
[iter 300] loss=-1.1305 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 400] loss=-1.6185 val_loss=0.0000 scale=2.0000 norm=0.8937
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1992 val_loss=0.0000 scale=2.0000 norm=1.0083
[iter 200] loss=-0.4875 val_loss=0.0000 scale=2.0000 norm=1.0035
[iter 300] loss=-1.0491 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 400] loss=-1.4347 val_loss=0.0000 scale=2.0000 norm=0.8921
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1929 val_loss=0.0000 scale=2.0000 norm=0.9923
[iter 200] loss=-0.5690 val_loss=0.0000 scale=2.0000 norm=0.9328
[iter 300] loss=-1.1602 val_loss=0.0000 scale=2.0000 norm=0.8621
[iter 400] loss=-1.5870 val_loss=0.0000 scale=2.0000 norm=0.8290
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3142 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 200] loss=-0.4316 val_loss=0.0000 scale=2.0000 norm=0.9097
[iter 300] loss=-1.1044 val_loss=0.0000 scale=2.0000 norm=0.8734
[iter 400] loss=-1.6531 val_loss=0.0000 scale=2.0000 norm=0.8930
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4813 val_loss=0.0000 scale=2.0000 norm=1.1896
[iter 200] loss=-0.2080 val_loss=0.0000 scale=2.0000 norm=1.1349
[iter 300] loss=-0.7478 val_loss=0.0000 scale=2.0000 norm=1.0488
[iter 400] loss=-1.1015 val_loss=0.0000 scale=2.0000 norm=1.0770
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3993 val_loss=0.0000 scale=2.0000 norm=1.0742
[iter 200] loss=-0.1793 val_loss=0.0000 scale=2.0000 norm=1.0138
[iter 300] loss=-0.6395 val_loss=0.0000 scale=2.0000 norm=0.9687
[iter 400] loss=-0.9698 val_loss=0.0000 scale=1.0000 norm=0.4695
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4269 val_loss=0.0000 scale=2.0000 norm=0.9912
[iter 200] loss=-0.5136 val_loss=0.0000 scale=2.0000 norm=0.9306
[iter 300] loss=-1.3572 val_loss=0.0000 scale=2.0000 norm=0.8500
[iter 400] loss=-2.5803 val_loss=0.0000 scale=4.0000 norm=1.6102
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3037 val_loss=0.0000 scale=2.0000 norm=1.0422
[iter 200] loss=-0.3242 val_loss=0.0000 scale=2.0000 norm=0.9519
[iter 300] loss=-0.8195 val_loss=0.0000 scale=2.0000 norm=0.8826
[iter 400] loss=-1.1253 val_loss=0.0000 scale=1.0000 norm=0.4252
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2413 val_loss=0.0000 scale=2.0000 norm=1.0046
[iter 200] loss=-0.4347 val_loss=0.0000 scale=2.0000 norm=0.9145
[iter 300] loss=-0.8705 val_loss=0.0000 scale=1.0000 norm=0.4352
[iter 400] loss=-1.1728 val_loss=0.0000 scale=2.0000 norm=0.8274
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1632 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 200] loss=-0.7202 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 300] loss=-1.6585 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 400] loss=-2.4149 val_loss=0.0000 scale=2.0000 norm=0.8695
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2893 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.2578 val_loss=0.0000 scale=1.0000 norm=0.4608
[iter 300] loss=-0.6606 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 400] loss=-0.9376 val_loss=0.0000 scale=2.0000 norm=0.8410
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3922 val_loss=0.0000 scale=2.0000 norm=1.0707
[iter 200] loss=-0.1869 val_loss=0.0000 scale=1.0000 norm=0.4932
[iter 300] loss=-0.6042 val_loss=0.0000 scale=2.0000 norm=0.9499
[iter 400] loss=-0.8472 val_loss=0.0000 scale=2.0000 norm=0.9223
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4242 val_loss=0.0000 scale=2.0000 norm=1.0479
[iter 200] loss=-0.3440 val_loss=0.0000 scale=2.0000 norm=0.9380
[iter 300] loss=-1.0015 val_loss=0.0000 scale=2.0000 norm=0.8622
[iter 400] loss=-1.5202 val_loss=0.0000 scale=2.0000 norm=0.7910
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5166 val_loss=0.0000 scale=2.0000 norm=1.1399
[iter 200] loss=-0.0181 val_loss=0.0000 scale=2.0000 norm=1.0501
[iter 300] loss=-0.4164 val_loss=0.0000 scale=1.0000 norm=0.5046
[iter 400] loss=-0.6733 val_loss=0.0000 scale=2.0000 norm=0.9820
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2166 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 200] loss=-0.5013 val_loss=0.0000 scale=2.0000 norm=0.9129
[iter 300] loss=-1.0557 val_loss=0.0000 scale=2.0000 norm=0.8099
[iter 400] loss=-1.4078 val_loss=0.0000 scale=2.0000 norm=0.7519
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4467 val_loss=0.0000 scale=2.0000 norm=1.1229
[iter 200] loss=-0.1974 val_loss=0.0000 scale=2.0000 norm=1.0019
[iter 300] loss=-0.6711 val_loss=0.0000 scale=2.0000 norm=0.9734
[iter 400] loss=-0.9809 val_loss=0.0000 scale=2.0000 norm=0.9662
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3096 val_loss=0.0000 scale=2.0000 norm=1.0136
[iter 200] loss=-0.3329 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 300] loss=-0.7995 val_loss=0.0000 scale=2.0000 norm=0.9342
[iter 400] loss=-1.1055 val_loss=0.0000 scale=2.0000 norm=0.8802
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3363 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.4858 val_loss=0.0000 scale=2.0000 norm=0.9138
[iter 300] loss=-1.2641 val_loss=0.0000 scale=2.0000 norm=0.8834
[iter 400] loss=-1.9979 val_loss=0.0000 scale=2.0000 norm=0.8379
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6576 val_loss=0.0000 scale=2.0000 norm=1.1853
[iter 200] loss=0.1994 val_loss=0.0000 scale=1.0000 norm=0.5363
[iter 300] loss=-0.1448 val_loss=0.0000 scale=1.0000 norm=0.5203
[iter 400] loss=-0.3955 val_loss=0.0000 scale=1.0000 norm=0.4892
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4843 val_loss=0.0000 scale=2.0000 norm=1.1518
[iter 200] loss=-0.0290 val_loss=0.0000 scale=1.0000 norm=0.5239
[iter 300] loss=-0.4145 val_loss=0.0000 scale=1.0000 norm=0.5011
[iter 400] loss=-0.6925 val_loss=0.0000 scale=2.0000 norm=0.9613
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3432 val_loss=0.0000 scale=2.0000 norm=1.0403
[iter 200] loss=-0.2626 val_loss=0.0000 scale=2.0000 norm=0.9248
[iter 300] loss=-0.6768 val_loss=0.0000 scale=2.0000 norm=0.8769
[iter 400] loss=-0.9440 val_loss=0.0000 scale=2.0000 norm=0.8434
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4216 val_loss=0.0000 scale=2.0000 norm=1.0833
[iter 200] loss=-0.1258 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 300] loss=-0.5121 val_loss=0.0000 scale=2.0000 norm=0.8944
[iter 400] loss=-0.7650 val_loss=0.0000 scale=2.0000 norm=0.9188
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5724 val_loss=0.0000 scale=2.0000 norm=1.1623
[iter 200] loss=-0.0118 val_loss=0.0000 scale=2.0000 norm=0.9977
[iter 300] loss=-0.3477 val_loss=0.0000 scale=2.0000 norm=0.9771
[iter 400] loss=-0.5976 val_loss=0.0000 scale=1.0000 norm=0.4877
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5200 val_loss=0.0000 scale=2.0000 norm=1.1243
[iter 200] loss=0.1101 val_loss=0.0000 scale=2.0000 norm=1.0039
[iter 300] loss=-0.2371 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 400] loss=-0.4353 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4301 val_loss=0.0000 scale=2.0000 norm=1.1103
[iter 200] loss=-0.2011 val_loss=0.0000 scale=2.0000 norm=0.9895
[iter 300] loss=-0.6956 val_loss=0.0000 scale=1.0000 norm=0.4736
[iter 400] loss=-0.9438 val_loss=0.0000 scale=1.0000 norm=0.4502
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4108 val_loss=0.0000 scale=2.0000 norm=1.1161
[iter 200] loss=-0.1530 val_loss=0.0000 scale=2.0000 norm=1.0392
[iter 300] loss=-0.5317 val_loss=0.0000 scale=1.0000 norm=0.4858
[iter 400] loss=-0.7908 val_loss=0.0000 scale=2.0000 norm=0.9606
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3946 val_loss=0.0000 scale=2.0000 norm=1.0777
[iter 200] loss=-0.1702 val_loss=0.0000 scale=2.0000 norm=0.9759
[iter 300] loss=-0.5207 val_loss=0.0000 scale=2.0000 norm=0.9418
[iter 400] loss=-0.7097 val_loss=0.0000 scale=1.0000 norm=0.4789
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2796 val_loss=0.0000 scale=2.0000 norm=1.0114
[iter 200] loss=-0.3429 val_loss=0.0000 scale=2.0000 norm=0.9448
[iter 300] loss=-0.8460 val_loss=0.0000 scale=2.0000 norm=0.9127
[iter 400] loss=-1.2565 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3440 val_loss=0.0000 scale=2.0000 norm=1.0561
[iter 200] loss=-0.2515 val_loss=0.0000 scale=2.0000 norm=0.9838
[iter 300] loss=-0.7158 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 400] loss=-0.9846 val_loss=0.0000 scale=1.0000 norm=0.4581
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3515 val_loss=0.0000 scale=2.0000 norm=1.0631
[iter 200] loss=-0.2688 val_loss=0.0000 scale=2.0000 norm=0.9493
[iter 300] loss=-0.6775 val_loss=0.0000 scale=2.0000 norm=0.9199
[iter 400] loss=-0.9262 val_loss=0.0000 scale=2.0000 norm=0.8781
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1494 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.6702 val_loss=0.0000 scale=2.0000 norm=0.8971
[iter 300] loss=-1.3943 val_loss=0.0000 scale=2.0000 norm=0.8191
[iter 400] loss=-1.9813 val_loss=0.0000 scale=2.0000 norm=0.8051
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3572 val_loss=0.0000 scale=2.0000 norm=1.0576
[iter 200] loss=-0.2460 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 300] loss=-0.6830 val_loss=0.0000 scale=1.0000 norm=0.4742
[iter 400] loss=-0.9311 val_loss=0.0000 scale=1.0000 norm=0.4650
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3919 val_loss=0.0000 scale=2.0000 norm=1.0558
[iter 200] loss=-0.2153 val_loss=0.0000 scale=2.0000 norm=0.9228
[iter 300] loss=-0.6309 val_loss=0.0000 scale=1.0000 norm=0.4575
[iter 400] loss=-0.8707 val_loss=0.0000 scale=1.0000 norm=0.4507
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2851 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 200] loss=-0.6533 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 300] loss=-1.5601 val_loss=0.0000 scale=2.0000 norm=0.8978
[iter 400] loss=-2.3581 val_loss=0.0000 scale=2.0000 norm=0.8080
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3875 val_loss=0.0000 scale=2.0000 norm=1.0678
[iter 200] loss=-0.1857 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 300] loss=-0.5906 val_loss=0.0000 scale=2.0000 norm=0.9540
[iter 400] loss=-0.8058 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2965 val_loss=0.0000 scale=2.0000 norm=1.0221
[iter 200] loss=-0.3726 val_loss=0.0000 scale=2.0000 norm=0.9345
[iter 300] loss=-0.8955 val_loss=0.0000 scale=2.0000 norm=0.9082
[iter 400] loss=-1.2851 val_loss=0.0000 scale=2.0000 norm=0.8672
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4185 val_loss=0.0000 scale=2.0000 norm=1.0810
[iter 200] loss=-0.1063 val_loss=0.0000 scale=2.0000 norm=0.9694
[iter 300] loss=-0.4800 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 400] loss=-0.6906 val_loss=0.0000 scale=0.5000 norm=0.2310
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3485 val_loss=0.0000 scale=2.0000 norm=1.0601
[iter 200] loss=-0.3022 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 300] loss=-0.8211 val_loss=0.0000 scale=1.0000 norm=0.4697
[iter 400] loss=-1.1200 val_loss=0.0000 scale=1.0000 norm=0.4520
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4213 val_loss=0.0000 scale=2.0000 norm=1.1103
[iter 200] loss=-0.1332 val_loss=0.0000 scale=2.0000 norm=1.0296
[iter 300] loss=-0.5161 val_loss=0.0000 scale=1.0000 norm=0.4854
[iter 400] loss=-0.7617 val_loss=0.0000 scale=1.0000 norm=0.4759
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3270 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.3347 val_loss=0.0000 scale=2.0000 norm=0.9566
[iter 300] loss=-0.8377 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-1.1744 val_loss=0.0000 scale=1.0000 norm=0.4452
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4637 val_loss=0.0000 scale=2.0000 norm=1.0876
[iter 200] loss=-0.2532 val_loss=0.0000 scale=2.0000 norm=0.9635
[iter 300] loss=-0.8834 val_loss=0.0000 scale=2.0000 norm=0.9444
[iter 400] loss=-1.4198 val_loss=0.0000 scale=2.0000 norm=0.8746
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3779 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3396 val_loss=0.0000 scale=2.0000 norm=0.9137
[iter 300] loss=-0.8937 val_loss=0.0000 scale=2.0000 norm=0.8311
[iter 400] loss=-1.3424 val_loss=0.0000 scale=1.0000 norm=0.3879
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3795 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 200] loss=-0.3249 val_loss=0.0000 scale=2.0000 norm=0.9533
[iter 300] loss=-0.9480 val_loss=0.0000 scale=2.0000 norm=0.8589
[iter 400] loss=-1.3518 val_loss=0.0000 scale=1.0000 norm=0.3968
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3708 val_loss=0.0000 scale=2.0000 norm=1.0390
[iter 200] loss=-0.2020 val_loss=0.0000 scale=2.0000 norm=0.9532
[iter 300] loss=-0.5960 val_loss=0.0000 scale=2.0000 norm=0.9070
[iter 400] loss=-0.8550 val_loss=0.0000 scale=2.0000 norm=0.8698
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3297 val_loss=0.0000 scale=2.0000 norm=1.0479
[iter 200] loss=-0.2761 val_loss=0.0000 scale=2.0000 norm=0.9541
[iter 300] loss=-0.7514 val_loss=0.0000 scale=2.0000 norm=0.9168
[iter 400] loss=-0.9893 val_loss=0.0000 scale=1.0000 norm=0.4478
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5951 val_loss=0.0000 scale=2.0000 norm=1.0944
[iter 200] loss=-0.0583 val_loss=0.0000 scale=2.0000 norm=1.0249
[iter 300] loss=-0.6296 val_loss=0.0000 scale=2.0000 norm=0.9918
[iter 400] loss=-1.0978 val_loss=0.0000 scale=1.0000 norm=0.4797
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4042 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 200] loss=-0.1612 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 300] loss=-0.5672 val_loss=0.0000 scale=1.0000 norm=0.4541
[iter 400] loss=-0.8148 val_loss=0.0000 scale=1.0000 norm=0.4569
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2855 val_loss=0.0000 scale=2.0000 norm=1.0235
[iter 200] loss=-0.3455 val_loss=0.0000 scale=2.0000 norm=0.9195
[iter 300] loss=-0.8455 val_loss=0.0000 scale=2.0000 norm=0.8659
[iter 400] loss=-1.1927 val_loss=0.0000 scale=2.0000 norm=0.8673
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3395 val_loss=0.0000 scale=2.0000 norm=1.0490
[iter 200] loss=-0.2474 val_loss=0.0000 scale=2.0000 norm=0.9640
[iter 300] loss=-0.6559 val_loss=0.0000 scale=2.0000 norm=0.9359
[iter 400] loss=-0.9080 val_loss=0.0000 scale=1.0000 norm=0.4552
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3435 val_loss=0.0000 scale=2.0000 norm=1.0378
[iter 200] loss=-0.2873 val_loss=0.0000 scale=2.0000 norm=0.9255
[iter 300] loss=-0.7287 val_loss=0.0000 scale=2.0000 norm=0.8822
[iter 400] loss=-1.0377 val_loss=0.0000 scale=2.0000 norm=0.8484
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3032 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 200] loss=-0.3591 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 300] loss=-0.9052 val_loss=0.0000 scale=2.0000 norm=0.9538
[iter 400] loss=-1.3271 val_loss=0.0000 scale=1.0000 norm=0.4420
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3783 val_loss=0.0000 scale=2.0000 norm=1.0690
[iter 200] loss=-0.1815 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 300] loss=-0.5865 val_loss=0.0000 scale=1.0000 norm=0.4816
[iter 400] loss=-0.8600 val_loss=0.0000 scale=1.0000 norm=0.4637
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3634 val_loss=0.0000 scale=2.0000 norm=1.0556
[iter 200] loss=-0.2176 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 300] loss=-0.5836 val_loss=0.0000 scale=1.0000 norm=0.4811
[iter 400] loss=-0.8135 val_loss=0.0000 scale=1.0000 norm=0.4618
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4363 val_loss=0.0000 scale=2.0000 norm=1.1168
[iter 200] loss=-0.1105 val_loss=0.0000 scale=2.0000 norm=0.9891
[iter 300] loss=-0.4545 val_loss=0.0000 scale=1.0000 norm=0.4661
[iter 400] loss=-0.6725 val_loss=0.0000 scale=0.5000 norm=0.2217
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3740 val_loss=0.0000 scale=2.0000 norm=1.0468
[iter 200] loss=-0.1878 val_loss=0.0000 scale=2.0000 norm=0.9564
[iter 300] loss=-0.5728 val_loss=0.0000 scale=1.0000 norm=0.4666
[iter 400] loss=-0.8244 val_loss=0.0000 scale=1.0000 norm=0.4481
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3371 val_loss=0.0000 scale=2.0000 norm=1.0337
[iter 200] loss=-0.2622 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 300] loss=-0.6356 val_loss=0.0000 scale=2.0000 norm=0.8853
[iter 400] loss=-0.8811 val_loss=0.0000 scale=1.0000 norm=0.4374
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3588 val_loss=0.0000 scale=2.0000 norm=1.0505
[iter 200] loss=-0.2235 val_loss=0.0000 scale=2.0000 norm=0.9538
[iter 300] loss=-0.6265 val_loss=0.0000 scale=2.0000 norm=0.9110
[iter 400] loss=-0.8918 val_loss=0.0000 scale=1.0000 norm=0.4388
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4868 val_loss=0.0000 scale=2.0000 norm=1.1155
[iter 200] loss=-0.0936 val_loss=0.0000 scale=2.0000 norm=0.9738
[iter 300] loss=-0.4666 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 400] loss=-0.7244 val_loss=0.0000 scale=2.0000 norm=0.9243
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2260 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 200] loss=-0.6403 val_loss=0.0000 scale=2.0000 norm=0.9146
[iter 300] loss=-1.4259 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 400] loss=-2.1775 val_loss=0.0000 scale=2.0000 norm=0.8434
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4122 val_loss=0.0000 scale=2.0000 norm=1.0858
[iter 200] loss=-0.1754 val_loss=0.0000 scale=2.0000 norm=1.0078
[iter 300] loss=-0.5937 val_loss=0.0000 scale=2.0000 norm=0.9960
[iter 400] loss=-0.8930 val_loss=0.0000 scale=1.0000 norm=0.4762
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1697 val_loss=0.0000 scale=2.0000 norm=0.9719
[iter 200] loss=-0.7515 val_loss=0.0000 scale=2.0000 norm=0.9232
[iter 300] loss=-1.5976 val_loss=0.0000 scale=2.0000 norm=0.8802
[iter 400] loss=-2.3891 val_loss=0.0000 scale=2.0000 norm=0.9038
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4987 val_loss=0.0000 scale=2.0000 norm=1.1291
[iter 200] loss=-0.1444 val_loss=0.0000 scale=2.0000 norm=1.0179
[iter 300] loss=-0.5919 val_loss=0.0000 scale=2.0000 norm=0.9714
[iter 400] loss=-0.9249 val_loss=0.0000 scale=1.0000 norm=0.4810
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2853 val_loss=0.0000 scale=2.0000 norm=1.0043
[iter 200] loss=-0.3539 val_loss=0.0000 scale=2.0000 norm=0.9437
[iter 300] loss=-0.8088 val_loss=0.0000 scale=2.0000 norm=0.9379
[iter 400] loss=-1.0733 val_loss=0.0000 scale=1.0000 norm=0.4561
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3954 val_loss=0.0000 scale=2.0000 norm=1.0932
[iter 200] loss=-0.1382 val_loss=0.0000 scale=1.0000 norm=0.4926
[iter 300] loss=-0.5058 val_loss=0.0000 scale=1.0000 norm=0.4754
[iter 400] loss=-0.7697 val_loss=0.0000 scale=0.5000 norm=0.2337
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5448 val_loss=0.0000 scale=2.0000 norm=1.1313
[iter 200] loss=-0.0311 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 300] loss=-0.4126 val_loss=0.0000 scale=2.0000 norm=0.9470
[iter 400] loss=-0.6312 val_loss=0.0000 scale=0.5000 norm=0.2317
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1368 val_loss=0.0000 scale=2.0000 norm=0.9794
[iter 200] loss=-0.6897 val_loss=0.0000 scale=2.0000 norm=0.9298
[iter 300] loss=-1.3636 val_loss=0.0000 scale=2.0000 norm=0.8923
[iter 400] loss=-1.8685 val_loss=0.0000 scale=2.0000 norm=0.8991
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5293 val_loss=0.0000 scale=2.0000 norm=1.1611
[iter 200] loss=-0.0054 val_loss=0.0000 scale=1.0000 norm=0.5239
[iter 300] loss=-0.3924 val_loss=0.0000 scale=2.0000 norm=1.0164
[iter 400] loss=-0.5915 val_loss=0.0000 scale=0.2500 norm=0.1235
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3647 val_loss=0.0000 scale=2.0000 norm=1.0500
[iter 200] loss=-0.2304 val_loss=0.0000 scale=1.0000 norm=0.4681
[iter 300] loss=-0.5747 val_loss=0.0000 scale=1.0000 norm=0.4586
[iter 400] loss=-0.8312 val_loss=0.0000 scale=1.0000 norm=0.4457
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2588 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.4654 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 300] loss=-1.1404 val_loss=0.0000 scale=4.0000 norm=1.8933
[iter 400] loss=-2.0801 val_loss=0.0000 scale=4.0000 norm=1.8913
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3850 val_loss=0.0000 scale=2.0000 norm=1.0716
[iter 200] loss=-0.2312 val_loss=0.0000 scale=2.0000 norm=0.9887
[iter 300] loss=-0.6886 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 400] loss=-1.0414 val_loss=0.0000 scale=0.5000 norm=0.2266
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3947 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.2166 val_loss=0.0000 scale=2.0000 norm=0.9254
[iter 300] loss=-0.6482 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 400] loss=-0.9696 val_loss=0.0000 scale=2.0000 norm=0.8861
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5118 val_loss=0.0000 scale=2.0000 norm=1.1391
[iter 200] loss=0.0100 val_loss=0.0000 scale=2.0000 norm=1.0064
[iter 300] loss=-0.2633 val_loss=0.0000 scale=2.0000 norm=0.9480
[iter 400] loss=-0.4051 val_loss=0.0000 scale=0.5000 norm=0.2310
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3187 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.2670 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 300] loss=-0.6946 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-1.0045 val_loss=0.0000 scale=2.0000 norm=0.8944
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3335 val_loss=0.0000 scale=2.0000 norm=1.0528
[iter 200] loss=-0.3699 val_loss=0.0000 scale=2.0000 norm=0.9607
[iter 300] loss=-0.9495 val_loss=0.0000 scale=2.0000 norm=0.9233
[iter 400] loss=-1.3218 val_loss=0.0000 scale=2.0000 norm=0.8771
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2592 val_loss=0.0000 scale=2.0000 norm=1.0134
[iter 200] loss=-0.4500 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 300] loss=-1.0672 val_loss=0.0000 scale=2.0000 norm=0.8868
[iter 400] loss=-1.5325 val_loss=0.0000 scale=2.0000 norm=0.8018
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2449 val_loss=0.0000 scale=2.0000 norm=0.9930
[iter 200] loss=-0.4202 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-0.9048 val_loss=0.0000 scale=2.0000 norm=0.9658
[iter 400] loss=-1.2469 val_loss=0.0000 scale=1.0000 norm=0.4727
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3898 val_loss=0.0000 scale=2.0000 norm=1.0890
[iter 200] loss=-0.1456 val_loss=0.0000 scale=1.0000 norm=0.4882
[iter 300] loss=-0.5203 val_loss=0.0000 scale=1.0000 norm=0.4654
[iter 400] loss=-0.7341 val_loss=0.0000 scale=2.0000 norm=0.9030
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3247 val_loss=0.0000 scale=2.0000 norm=1.0211
[iter 200] loss=-0.2920 val_loss=0.0000 scale=2.0000 norm=0.9490
[iter 300] loss=-0.7312 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-0.9889 val_loss=0.0000 scale=1.0000 norm=0.4297
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2439 val_loss=0.0000 scale=2.0000 norm=0.9784
[iter 200] loss=-0.7071 val_loss=0.0000 scale=2.0000 norm=0.9489
[iter 300] loss=-1.8181 val_loss=0.0000 scale=4.0000 norm=1.7215
[iter 400] loss=-3.1891 val_loss=0.0000 scale=2.0000 norm=0.8639
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3683 val_loss=0.0000 scale=2.0000 norm=1.0677
[iter 200] loss=-0.1896 val_loss=0.0000 scale=2.0000 norm=0.9608
[iter 300] loss=-0.5792 val_loss=0.0000 scale=1.0000 norm=0.4743
[iter 400] loss=-0.8314 val_loss=0.0000 scale=1.0000 norm=0.4527
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5866 val_loss=0.0000 scale=2.0000 norm=1.1142
[iter 200] loss=-0.1323 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 300] loss=-0.8155 val_loss=0.0000 scale=2.0000 norm=1.0607
[iter 400] loss=-1.4591 val_loss=0.0000 scale=2.0000 norm=1.0197
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2991 val_loss=0.0000 scale=2.0000 norm=1.0198
[iter 200] loss=-0.3069 val_loss=0.0000 scale=2.0000 norm=1.0056
[iter 300] loss=-0.7482 val_loss=0.0000 scale=2.0000 norm=0.9896
[iter 400] loss=-1.0870 val_loss=0.0000 scale=1.0000 norm=0.4613
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4278 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.3748 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 300] loss=-1.0700 val_loss=0.0000 scale=2.0000 norm=0.8344
[iter 400] loss=-1.7079 val_loss=0.0000 scale=2.0000 norm=0.8143
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3706 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.2160 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 300] loss=-0.6015 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 400] loss=-0.8439 val_loss=0.0000 scale=1.0000 norm=0.4631
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6127 val_loss=0.0000 scale=2.0000 norm=1.1730
[iter 200] loss=0.0518 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 300] loss=-0.2999 val_loss=0.0000 scale=2.0000 norm=0.9795
[iter 400] loss=-0.5556 val_loss=0.0000 scale=1.0000 norm=0.4840
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2715 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.4553 val_loss=0.0000 scale=2.0000 norm=0.9226
[iter 300] loss=-1.0203 val_loss=0.0000 scale=2.0000 norm=0.8527
[iter 400] loss=-1.3736 val_loss=0.0000 scale=2.0000 norm=0.8307
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3072 val_loss=0.0000 scale=2.0000 norm=1.0309
[iter 200] loss=-0.2958 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 300] loss=-0.6588 val_loss=0.0000 scale=2.0000 norm=0.9349
[iter 400] loss=-0.9438 val_loss=0.0000 scale=2.0000 norm=0.9186
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3908 val_loss=0.0000 scale=2.0000 norm=1.0695
[iter 200] loss=-0.2341 val_loss=0.0000 scale=2.0000 norm=0.9540
[iter 300] loss=-0.6129 val_loss=0.0000 scale=1.0000 norm=0.4638
[iter 400] loss=-0.8620 val_loss=0.0000 scale=1.0000 norm=0.4611
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3341 val_loss=0.0000 scale=2.0000 norm=1.0320
[iter 200] loss=-0.2515 val_loss=0.0000 scale=2.0000 norm=0.9568
[iter 300] loss=-0.6525 val_loss=0.0000 scale=1.0000 norm=0.4654
[iter 400] loss=-0.8662 val_loss=0.0000 scale=1.0000 norm=0.4559
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2718 val_loss=0.0000 scale=2.0000 norm=1.0719
[iter 200] loss=-0.4546 val_loss=0.0000 scale=2.0000 norm=0.9810
[iter 300] loss=-1.0508 val_loss=0.0000 scale=2.0000 norm=0.8791
[iter 400] loss=-1.5059 val_loss=0.0000 scale=2.0000 norm=0.8355
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4003 val_loss=0.0000 scale=2.0000 norm=1.0743
[iter 200] loss=-0.1812 val_loss=0.0000 scale=2.0000 norm=0.9664
[iter 300] loss=-0.5997 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 400] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.8745
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3486 val_loss=0.0000 scale=2.0000 norm=1.0418
[iter 200] loss=-0.2417 val_loss=0.0000 scale=2.0000 norm=0.9448
[iter 300] loss=-0.6742 val_loss=0.0000 scale=1.0000 norm=0.4615
[iter 400] loss=-0.9394 val_loss=0.0000 scale=2.0000 norm=0.9115
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3009 val_loss=0.0000 scale=2.0000 norm=1.0277
[iter 200] loss=-0.3242 val_loss=0.0000 scale=2.0000 norm=0.9629
[iter 300] loss=-0.7832 val_loss=0.0000 scale=2.0000 norm=0.9175
[iter 400] loss=-1.0630 val_loss=0.0000 scale=1.0000 norm=0.4427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3390 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.2614 val_loss=0.0000 scale=2.0000 norm=0.9359
[iter 300] loss=-0.7191 val_loss=0.0000 scale=2.0000 norm=0.9020
[iter 400] loss=-1.0096 val_loss=0.0000 scale=2.0000 norm=0.8695
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4572 val_loss=0.0000 scale=2.0000 norm=1.1094
[iter 200] loss=-0.0715 val_loss=0.0000 scale=2.0000 norm=1.0304
[iter 300] loss=-0.4307 val_loss=0.0000 scale=1.0000 norm=0.4939
[iter 400] loss=-0.6103 val_loss=0.0000 scale=0.5000 norm=0.2440
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3280 val_loss=0.0000 scale=2.0000 norm=1.0340
[iter 200] loss=-0.2750 val_loss=0.0000 scale=2.0000 norm=0.9408
[iter 300] loss=-0.7044 val_loss=0.0000 scale=2.0000 norm=0.9157
[iter 400] loss=-0.9517 val_loss=0.0000 scale=1.0000 norm=0.4476
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4321 val_loss=0.0000 scale=2.0000 norm=1.1110
[iter 200] loss=-0.1365 val_loss=0.0000 scale=2.0000 norm=1.0024
[iter 300] loss=-0.5242 val_loss=0.0000 scale=2.0000 norm=0.9540
[iter 400] loss=-0.7656 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3846 val_loss=0.0000 scale=2.0000 norm=1.1312
[iter 200] loss=-0.3645 val_loss=0.0000 scale=2.0000 norm=1.0928
[iter 300] loss=-1.0322 val_loss=0.0000 scale=2.0000 norm=1.0469
[iter 400] loss=-1.6194 val_loss=0.0000 scale=4.0000 norm=2.1423
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3083 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.3335 val_loss=0.0000 scale=2.0000 norm=0.9161
[iter 300] loss=-0.7672 val_loss=0.0000 scale=2.0000 norm=0.9302
[iter 400] loss=-1.0614 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3654 val_loss=0.0000 scale=2.0000 norm=1.0664
[iter 200] loss=-0.2359 val_loss=0.0000 scale=2.0000 norm=0.9782
[iter 300] loss=-0.6024 val_loss=0.0000 scale=2.0000 norm=0.9056
[iter 400] loss=-0.8415 val_loss=0.0000 scale=2.0000 norm=0.8932
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2151 val_loss=0.0000 scale=2.0000 norm=1.0179
[iter 200] loss=-0.4770 val_loss=0.0000 scale=2.0000 norm=0.9889
[iter 300] loss=-1.0119 val_loss=0.0000 scale=2.0000 norm=0.9478
[iter 400] loss=-1.3866 val_loss=0.0000 scale=2.0000 norm=0.8789
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3576 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.2158 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 300] loss=-0.6323 val_loss=0.0000 scale=2.0000 norm=0.9405
[iter 400] loss=-0.8550 val_loss=0.0000 scale=1.0000 norm=0.4508
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0525 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 200] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-1.8183 val_loss=0.0000 scale=2.0000 norm=0.9111
[iter 400] loss=-2.8090 val_loss=0.0000 scale=2.0000 norm=0.8445
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2979 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.3257 val_loss=0.0000 scale=2.0000 norm=0.9222
[iter 300] loss=-0.7484 val_loss=0.0000 scale=2.0000 norm=0.9137
[iter 400] loss=-1.0085 val_loss=0.0000 scale=1.0000 norm=0.4521
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3473 val_loss=0.0000 scale=2.0000 norm=1.0601
[iter 200] loss=-0.2721 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 300] loss=-0.7390 val_loss=0.0000 scale=2.0000 norm=0.9477
[iter 400] loss=-1.0665 val_loss=0.0000 scale=2.0000 norm=0.9128
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 200] loss=-0.6425 val_loss=0.0000 scale=2.0000 norm=0.8688
[iter 300] loss=-1.3411 val_loss=0.0000 scale=2.0000 norm=0.8274
[iter 400] loss=-2.0692 val_loss=0.0000 scale=2.0000 norm=0.7733
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5363 val_loss=0.0000 scale=2.0000 norm=1.1677
[iter 200] loss=0.0229 val_loss=0.0000 scale=2.0000 norm=1.0223
[iter 300] loss=-0.3093 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 400] loss=-0.5341 val_loss=0.0000 scale=0.5000 norm=0.2271
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3408 val_loss=0.0000 scale=2.0000 norm=1.0417
[iter 200] loss=-0.2543 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 300] loss=-0.6515 val_loss=0.0000 scale=2.0000 norm=0.9230
[iter 400] loss=-0.8818 val_loss=0.0000 scale=2.0000 norm=0.8849
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4143 val_loss=0.0000 scale=2.0000 norm=1.1163
[iter 200] loss=-0.3906 val_loss=0.0000 scale=4.0000 norm=2.2490
[iter 300] loss=-1.8065 val_loss=0.0000 scale=4.0000 norm=2.1097
[iter 400] loss=-2.7583 val_loss=0.0000 scale=8.0000 norm=4.0979
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3968 val_loss=0.0000 scale=2.0000 norm=1.0700
[iter 200] loss=-0.1514 val_loss=0.0000 scale=2.0000 norm=0.9635
[iter 300] loss=-0.5500 val_loss=0.0000 scale=2.0000 norm=0.9158
[iter 400] loss=-0.8120 val_loss=0.0000 scale=2.0000 norm=0.9169
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2915 val_loss=0.0000 scale=2.0000 norm=1.0029
[iter 200] loss=-0.3535 val_loss=0.0000 scale=2.0000 norm=0.9080
[iter 300] loss=-0.7756 val_loss=0.0000 scale=2.0000 norm=0.8484
[iter 400] loss=-1.0548 val_loss=0.0000 scale=1.0000 norm=0.4194
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2821 val_loss=0.0000 scale=2.0000 norm=1.0022
[iter 200] loss=-0.3537 val_loss=0.0000 scale=2.0000 norm=0.9311
[iter 300] loss=-0.8499 val_loss=0.0000 scale=1.0000 norm=0.4486
[iter 400] loss=-1.1881 val_loss=0.0000 scale=1.0000 norm=0.4361
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3918 val_loss=0.0000 scale=2.0000 norm=1.0541
[iter 200] loss=-0.1564 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 300] loss=-0.5490 val_loss=0.0000 scale=2.0000 norm=0.9804
[iter 400] loss=-0.7471 val_loss=0.0000 scale=2.0000 norm=0.9755
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3712 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.2730 val_loss=0.0000 scale=2.0000 norm=0.9626
[iter 300] loss=-0.7655 val_loss=0.0000 scale=2.0000 norm=0.9033
[iter 400] loss=-1.1338 val_loss=0.0000 scale=2.0000 norm=0.8525
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3383 val_loss=0.0000 scale=2.0000 norm=1.0720
[iter 200] loss=-0.3231 val_loss=0.0000 scale=2.0000 norm=0.9548
[iter 300] loss=-0.8330 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 400] loss=-1.2103 val_loss=0.0000 scale=2.0000 norm=0.8599
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5416 val_loss=0.0000 scale=2.0000 norm=1.1581
[iter 200] loss=0.0254 val_loss=0.0000 scale=2.0000 norm=1.0621
[iter 300] loss=-0.3457 val_loss=0.0000 scale=1.0000 norm=0.5060
[iter 400] loss=-0.5460 val_loss=0.0000 scale=1.0000 norm=0.5179
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2913 val_loss=0.0000 scale=2.0000 norm=1.0226
[iter 200] loss=-0.3534 val_loss=0.0000 scale=2.0000 norm=0.9198
[iter 300] loss=-0.8309 val_loss=0.0000 scale=2.0000 norm=0.8695
[iter 400] loss=-1.1085 val_loss=0.0000 scale=1.0000 norm=0.4216
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3378 val_loss=0.0000 scale=2.0000 norm=1.0624
[iter 200] loss=-0.3141 val_loss=0.0000 scale=2.0000 norm=0.9560
[iter 300] loss=-0.7325 val_loss=0.0000 scale=1.0000 norm=0.4457
[iter 400] loss=-1.0074 val_loss=0.0000 scale=2.0000 norm=0.8614
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3437 val_loss=0.0000 scale=2.0000 norm=1.0216
[iter 200] loss=-0.2571 val_loss=0.0000 scale=2.0000 norm=0.9486
[iter 300] loss=-0.6998 val_loss=0.0000 scale=2.0000 norm=0.9560
[iter 400] loss=-0.9953 val_loss=0.0000 scale=1.0000 norm=0.4521
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2881 val_loss=0.0000 scale=2.0000 norm=1.0431
[iter 200] loss=-0.3663 val_loss=0.0000 scale=2.0000 norm=0.9243
[iter 300] loss=-0.8686 val_loss=0.0000 scale=2.0000 norm=0.8386
[iter 400] loss=-1.2540 val_loss=0.0000 scale=2.0000 norm=0.8210
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2329 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.4041 val_loss=0.0000 scale=2.0000 norm=0.9756
[iter 300] loss=-0.9004 val_loss=0.0000 scale=2.0000 norm=0.9309
[iter 400] loss=-1.2044 val_loss=0.0000 scale=2.0000 norm=0.8741
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3034 val_loss=0.0000 scale=2.0000 norm=1.0005
[iter 200] loss=-0.3288 val_loss=0.0000 scale=2.0000 norm=0.9195
[iter 300] loss=-0.7816 val_loss=0.0000 scale=2.0000 norm=0.8780
[iter 400] loss=-1.0724 val_loss=0.0000 scale=1.0000 norm=0.4209
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3117 val_loss=0.0000 scale=2.0000 norm=1.0359
[iter 200] loss=-0.2935 val_loss=0.0000 scale=2.0000 norm=0.9481
[iter 300] loss=-0.6894 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-0.9586 val_loss=0.0000 scale=1.0000 norm=0.4622
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4749 val_loss=0.0000 scale=2.0000 norm=1.0965
[iter 200] loss=-0.1707 val_loss=0.0000 scale=2.0000 norm=0.9736
[iter 300] loss=-0.6499 val_loss=0.0000 scale=2.0000 norm=0.9561
[iter 400] loss=-1.0246 val_loss=0.0000 scale=2.0000 norm=0.9489
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5211 val_loss=0.0000 scale=2.0000 norm=1.1583
[iter 200] loss=0.0100 val_loss=0.0000 scale=2.0000 norm=1.0364
[iter 300] loss=-0.3134 val_loss=0.0000 scale=1.0000 norm=0.4905
[iter 400] loss=-0.5386 val_loss=0.0000 scale=1.0000 norm=0.4635
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3199 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.2856 val_loss=0.0000 scale=2.0000 norm=0.9370
[iter 300] loss=-0.6931 val_loss=0.0000 scale=1.0000 norm=0.4568
[iter 400] loss=-0.9520 val_loss=0.0000 scale=0.5000 norm=0.2186
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2885 val_loss=0.0000 scale=2.0000 norm=1.0202
[iter 200] loss=-0.4415 val_loss=0.0000 scale=2.0000 norm=0.9408
[iter 300] loss=-1.0497 val_loss=0.0000 scale=2.0000 norm=0.8886
[iter 400] loss=-1.5191 val_loss=0.0000 scale=2.0000 norm=0.8692
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3923 val_loss=0.0000 scale=2.0000 norm=1.0814
[iter 200] loss=-0.2504 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 300] loss=-0.7170 val_loss=0.0000 scale=2.0000 norm=0.9039
[iter 400] loss=-0.9858 val_loss=0.0000 scale=1.0000 norm=0.4232
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3140 val_loss=0.0000 scale=2.0000 norm=1.0336
[iter 200] loss=-0.4243 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 300] loss=-1.0186 val_loss=0.0000 scale=2.0000 norm=0.9014
[iter 400] loss=-1.5638 val_loss=0.0000 scale=2.0000 norm=0.8670
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4579 val_loss=0.0000 scale=2.0000 norm=1.1001
[iter 200] loss=-0.0287 val_loss=0.0000 scale=1.0000 norm=0.5120
[iter 300] loss=-0.3762 val_loss=0.0000 scale=1.0000 norm=0.5003
[iter 400] loss=-0.6000 val_loss=0.0000 scale=1.0000 norm=0.4903
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3878 val_loss=0.0000 scale=2.0000 norm=1.0466
[iter 200] loss=-0.2092 val_loss=0.0000 scale=2.0000 norm=0.9450
[iter 300] loss=-0.5987 val_loss=0.0000 scale=2.0000 norm=0.8891
[iter 400] loss=-0.8633 val_loss=0.0000 scale=1.0000 norm=0.4388
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4933 val_loss=0.0000 scale=2.0000 norm=1.0986
[iter 200] loss=-0.1022 val_loss=0.0000 scale=2.0000 norm=1.0021
[iter 300] loss=-0.5355 val_loss=0.0000 scale=2.0000 norm=0.9656
[iter 400] loss=-0.8768 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3941 val_loss=0.0000 scale=2.0000 norm=1.0735
[iter 200] loss=-0.1756 val_loss=0.0000 scale=2.0000 norm=0.9774
[iter 300] loss=-0.5770 val_loss=0.0000 scale=2.0000 norm=0.9516
[iter 400] loss=-0.8245 val_loss=0.0000 scale=1.0000 norm=0.4788
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5652 val_loss=0.0000 scale=2.0000 norm=1.1486
[iter 200] loss=-0.0393 val_loss=0.0000 scale=2.0000 norm=0.9381
[iter 300] loss=-0.4031 val_loss=0.0000 scale=1.0000 norm=0.4443
[iter 400] loss=-0.6629 val_loss=0.0000 scale=2.0000 norm=0.8742
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8521 val_loss=0.0000 scale=1.0000 norm=0.6515
[iter 200] loss=0.3206 val_loss=0.0000 scale=1.0000 norm=0.5218
[iter 300] loss=-0.2900 val_loss=0.0000 scale=2.0000 norm=0.9698
[iter 400] loss=-0.8002 val_loss=0.0000 scale=2.0000 norm=0.9702
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5905 val_loss=0.0000 scale=2.0000 norm=1.1307
[iter 200] loss=0.1944 val_loss=0.0000 scale=1.0000 norm=0.5093
[iter 300] loss=-0.1501 val_loss=0.0000 scale=2.0000 norm=0.9718
[iter 400] loss=-0.3947 val_loss=0.0000 scale=1.0000 norm=0.4615
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4898 val_loss=0.0000 scale=2.0000 norm=1.1240
[iter 200] loss=-0.1045 val_loss=0.0000 scale=2.0000 norm=1.0098
[iter 300] loss=-0.5108 val_loss=0.0000 scale=1.0000 norm=0.4710
[iter 400] loss=-0.8004 val_loss=0.0000 scale=0.5000 norm=0.2236
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3754 val_loss=0.0000 scale=2.0000 norm=1.0583
[iter 200] loss=-0.2012 val_loss=0.0000 scale=2.0000 norm=0.9389
[iter 300] loss=-0.5412 val_loss=0.0000 scale=2.0000 norm=0.9054
[iter 400] loss=-0.7426 val_loss=0.0000 scale=1.0000 norm=0.4463
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2934 val_loss=0.0000 scale=2.0000 norm=1.0182
[iter 200] loss=-0.3690 val_loss=0.0000 scale=2.0000 norm=0.9565
[iter 300] loss=-0.9346 val_loss=0.0000 scale=2.0000 norm=0.9179
[iter 400] loss=-1.3505 val_loss=0.0000 scale=2.0000 norm=0.8927
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3089 val_loss=0.0000 scale=2.0000 norm=1.0387
[iter 200] loss=-0.3211 val_loss=0.0000 scale=2.0000 norm=0.9754
[iter 300] loss=-0.7926 val_loss=0.0000 scale=2.0000 norm=0.9490
[iter 400] loss=-1.1035 val_loss=0.0000 scale=1.0000 norm=0.4564
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7081 val_loss=0.0000 scale=2.0000 norm=1.2047
[iter 200] loss=0.0910 val_loss=0.0000 scale=2.0000 norm=1.0618
[iter 300] loss=-0.3938 val_loss=0.0000 scale=2.0000 norm=1.0151
[iter 400] loss=-0.7710 val_loss=0.0000 scale=1.0000 norm=0.4807
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3495 val_loss=0.0000 scale=2.0000 norm=1.0433
[iter 200] loss=-0.3493 val_loss=0.0000 scale=2.0000 norm=0.9526
[iter 300] loss=-0.8945 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 400] loss=-1.2435 val_loss=0.0000 scale=2.0000 norm=0.9059
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3537 val_loss=0.0000 scale=2.0000 norm=1.0658
[iter 200] loss=-0.2474 val_loss=0.0000 scale=2.0000 norm=0.9702
[iter 300] loss=-0.7181 val_loss=0.0000 scale=2.0000 norm=0.9322
[iter 400] loss=-1.0245 val_loss=0.0000 scale=2.0000 norm=0.9175
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=1.0225
[iter 200] loss=-0.6296 val_loss=0.0000 scale=2.0000 norm=0.9589
[iter 300] loss=-1.3578 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-2.0018 val_loss=0.0000 scale=2.0000 norm=0.8877
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4150 val_loss=0.0000 scale=2.0000 norm=1.0689
[iter 200] loss=-0.3781 val_loss=0.0000 scale=2.0000 norm=0.9643
[iter 300] loss=-1.0983 val_loss=0.0000 scale=2.0000 norm=0.9285
[iter 400] loss=-1.7793 val_loss=0.0000 scale=2.0000 norm=0.8867
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3876 val_loss=0.0000 scale=2.0000 norm=1.0604
[iter 200] loss=-0.3097 val_loss=0.0000 scale=2.0000 norm=0.9291
[iter 300] loss=-0.7753 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 400] loss=-1.1422 val_loss=0.0000 scale=1.0000 norm=0.4192
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3944 val_loss=0.0000 scale=2.0000 norm=1.0891
[iter 200] loss=-0.1570 val_loss=0.0000 scale=1.0000 norm=0.4941
[iter 300] loss=-0.5503 val_loss=0.0000 scale=2.0000 norm=0.9578
[iter 400] loss=-0.7999 val_loss=0.0000 scale=2.0000 norm=0.9257
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6431 val_loss=0.0000 scale=2.0000 norm=1.2218
[iter 200] loss=0.1297 val_loss=0.0000 scale=1.0000 norm=0.5625
[iter 300] loss=-0.2246 val_loss=0.0000 scale=2.0000 norm=1.0498
[iter 400] loss=-0.4857 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3956 val_loss=0.0000 scale=2.0000 norm=1.0739
[iter 200] loss=-0.1775 val_loss=0.0000 scale=2.0000 norm=0.9584
[iter 300] loss=-0.5699 val_loss=0.0000 scale=2.0000 norm=0.9262
[iter 400] loss=-0.8485 val_loss=0.0000 scale=1.0000 norm=0.4667
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.0698
[iter 200] loss=-0.1467 val_loss=0.0000 scale=2.0000 norm=0.9697
[iter 300] loss=-0.5205 val_loss=0.0000 scale=2.0000 norm=0.9148
[iter 400] loss=-0.7569 val_loss=0.0000 scale=0.5000 norm=0.2278
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.1565
[iter 200] loss=-0.4137 val_loss=0.0000 scale=2.0000 norm=1.1430
[iter 300] loss=-1.2506 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 400] loss=-2.3595 val_loss=0.0000 scale=4.0000 norm=2.3123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1359 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.7980 val_loss=0.0000 scale=2.0000 norm=0.9355
[iter 300] loss=-1.6832 val_loss=0.0000 scale=2.0000 norm=0.9047
[iter 400] loss=-2.5436 val_loss=0.0000 scale=2.0000 norm=0.8855
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3620 val_loss=0.0000 scale=2.0000 norm=1.0523
[iter 200] loss=-0.1814 val_loss=0.0000 scale=1.0000 norm=0.4917
[iter 300] loss=-0.5535 val_loss=0.0000 scale=2.0000 norm=0.9623
[iter 400] loss=-0.8007 val_loss=0.0000 scale=2.0000 norm=0.9102
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6133 val_loss=0.0000 scale=2.0000 norm=1.1544
[iter 200] loss=0.0515 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 300] loss=-0.3281 val_loss=0.0000 scale=1.0000 norm=0.4719
[iter 400] loss=-0.5578 val_loss=0.0000 scale=1.0000 norm=0.4701
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2902 val_loss=0.0000 scale=2.0000 norm=1.0282
[iter 200] loss=-0.3662 val_loss=0.0000 scale=2.0000 norm=0.9257
[iter 300] loss=-0.8633 val_loss=0.0000 scale=2.0000 norm=0.8623
[iter 400] loss=-1.1750 val_loss=0.0000 scale=1.0000 norm=0.4144
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3657 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.2217 val_loss=0.0000 scale=2.0000 norm=0.9572
[iter 300] loss=-0.6062 val_loss=0.0000 scale=1.0000 norm=0.4782
[iter 400] loss=-0.8491 val_loss=0.0000 scale=1.0000 norm=0.4659
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3412 val_loss=0.0000 scale=2.0000 norm=1.0232
[iter 200] loss=-0.2053 val_loss=0.0000 scale=2.0000 norm=0.9268
[iter 300] loss=-0.5702 val_loss=0.0000 scale=2.0000 norm=0.8711
[iter 400] loss=-0.8424 val_loss=0.0000 scale=2.0000 norm=0.8684
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1300 val_loss=0.0000 scale=2.0000 norm=0.9746
[iter 200] loss=-0.7759 val_loss=0.0000 scale=2.0000 norm=0.9145
[iter 300] loss=-1.6321 val_loss=0.0000 scale=2.0000 norm=0.8599
[iter 400] loss=-2.3957 val_loss=0.0000 scale=2.0000 norm=0.7675
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4870 val_loss=0.0000 scale=2.0000 norm=1.1336
[iter 200] loss=-0.0986 val_loss=0.0000 scale=2.0000 norm=0.9865
[iter 300] loss=-0.4732 val_loss=0.0000 scale=2.0000 norm=0.9647
[iter 400] loss=-0.7153 val_loss=0.0000 scale=1.0000 norm=0.4911
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4186 val_loss=0.0000 scale=2.0000 norm=1.0787
[iter 200] loss=-0.1402 val_loss=0.0000 scale=2.0000 norm=0.9725
[iter 300] loss=-0.5053 val_loss=0.0000 scale=2.0000 norm=0.9128
[iter 400] loss=-0.7455 val_loss=0.0000 scale=1.0000 norm=0.4356
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4624 val_loss=0.0000 scale=2.0000 norm=1.0825
[iter 200] loss=-0.1367 val_loss=0.0000 scale=2.0000 norm=0.9897
[iter 300] loss=-0.5249 val_loss=0.0000 scale=1.0000 norm=0.4727
[iter 400] loss=-0.7917 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7191 val_loss=0.0000 scale=2.0000 norm=1.2377
[iter 200] loss=0.1692 val_loss=0.0000 scale=2.0000 norm=1.0915
[iter 300] loss=-0.1942 val_loss=0.0000 scale=1.0000 norm=0.5248
[iter 400] loss=-0.4914 val_loss=0.0000 scale=1.0000 norm=0.5001
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4462 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 200] loss=-0.1928 val_loss=0.0000 scale=2.0000 norm=0.9391
[iter 300] loss=-0.6414 val_loss=0.0000 scale=2.0000 norm=0.8904
[iter 400] loss=-0.9179 val_loss=0.0000 scale=1.0000 norm=0.4287
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5600 val_loss=0.0000 scale=2.0000 norm=1.0270
[iter 200] loss=-0.1077 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 300] loss=-0.6155 val_loss=0.0000 scale=2.0000 norm=0.8963
[iter 400] loss=-0.9807 val_loss=0.0000 scale=1.0000 norm=0.4302
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1734 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.5695 val_loss=0.0000 scale=2.0000 norm=0.9206
[iter 300] loss=-1.1588 val_loss=0.0000 scale=2.0000 norm=0.8724
[iter 400] loss=-1.5837 val_loss=0.0000 scale=2.0000 norm=0.7957
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3203 val_loss=0.0000 scale=2.0000 norm=1.0248
[iter 200] loss=-0.2941 val_loss=0.0000 scale=2.0000 norm=0.9418
[iter 300] loss=-0.7342 val_loss=0.0000 scale=2.0000 norm=0.9299
[iter 400] loss=-0.9935 val_loss=0.0000 scale=1.0000 norm=0.4604
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4578 val_loss=0.0000 scale=2.0000 norm=1.0866
[iter 200] loss=-0.0633 val_loss=0.0000 scale=2.0000 norm=0.9638
[iter 300] loss=-0.4425 val_loss=0.0000 scale=2.0000 norm=0.9180
[iter 400] loss=-0.6564 val_loss=0.0000 scale=1.0000 norm=0.4623
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2432 val_loss=0.0000 scale=2.0000 norm=1.0173
[iter 200] loss=-0.4400 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 300] loss=-0.9855 val_loss=0.0000 scale=2.0000 norm=0.9548
[iter 400] loss=-1.3417 val_loss=0.0000 scale=1.0000 norm=0.4563
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3247 val_loss=0.0000 scale=2.0000 norm=1.0413
[iter 200] loss=-0.3028 val_loss=0.0000 scale=1.0000 norm=0.4843
[iter 300] loss=-0.8044 val_loss=0.0000 scale=2.0000 norm=0.9689
[iter 400] loss=-1.2345 val_loss=0.0000 scale=2.0000 norm=0.9004

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n01>
Subject: Job 861717: <structure_numerical_ecfp3binery_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_ecfp3binery_NGB_generalizibility> was submitted from host <c205n12> by user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:00 2024
Job was executed on host(s) <4*c207n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:36:00 2024
                            <4*c207n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Thu Oct 24 11:36:00 2024
Terminated at Thu Oct 24 11:39:18 2024
Results reported at Thu Oct 24 11:39:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 7:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_ecfp3binery_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py ecfp --regressor_type NGB --radius 3 --vector binary --target "Rg1 (nm)" --oligo_type "RRU Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1951.53 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.62 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   198 sec.
    Turnaround time :                            258 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err> for stderr output of this job.

polymer representation: RRU Trimer
RRU Dimer_scaler
Filename: (ECFP3.binary.512-Mw-PDI)_NGB_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer_scaler/(ECFP3.binary.512-Mw-PDI)_NGB_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1058 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.8630 val_loss=0.0000 scale=2.0000 norm=0.9692
[iter 300] loss=-1.8257 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 400] loss=-2.7361 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3328 val_loss=0.0000 scale=2.0000 norm=1.0282
[iter 200] loss=-0.2424 val_loss=0.0000 scale=2.0000 norm=0.9389
[iter 300] loss=-0.6566 val_loss=0.0000 scale=2.0000 norm=0.8963
[iter 400] loss=-0.9258 val_loss=0.0000 scale=1.0000 norm=0.4289
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3372 val_loss=0.0000 scale=2.0000 norm=1.0372
[iter 200] loss=-0.2678 val_loss=0.0000 scale=2.0000 norm=0.9417
[iter 300] loss=-0.6632 val_loss=0.0000 scale=2.0000 norm=0.8813
[iter 400] loss=-0.9348 val_loss=0.0000 scale=1.0000 norm=0.4340
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1301 val_loss=0.0000 scale=2.0000 norm=0.9745
[iter 200] loss=-0.7763 val_loss=0.0000 scale=2.0000 norm=0.9148
[iter 300] loss=-1.6327 val_loss=0.0000 scale=2.0000 norm=0.8601
[iter 400] loss=-2.3960 val_loss=0.0000 scale=2.0000 norm=0.7672
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4244 val_loss=0.0000 scale=2.0000 norm=1.0768
[iter 200] loss=-0.1503 val_loss=0.0000 scale=2.0000 norm=0.9672
[iter 300] loss=-0.4992 val_loss=0.0000 scale=1.0000 norm=0.4707
[iter 400] loss=-0.7101 val_loss=0.0000 scale=1.0000 norm=0.4859
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3860 val_loss=0.0000 scale=2.0000 norm=1.0603
[iter 200] loss=-0.3114 val_loss=0.0000 scale=2.0000 norm=0.9284
[iter 300] loss=-0.8096 val_loss=0.0000 scale=2.0000 norm=0.8837
[iter 400] loss=-1.1906 val_loss=0.0000 scale=2.0000 norm=0.8228
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2603 val_loss=0.0000 scale=2.0000 norm=1.0312
[iter 200] loss=-0.3841 val_loss=0.0000 scale=2.0000 norm=0.9637
[iter 300] loss=-0.8695 val_loss=0.0000 scale=2.0000 norm=0.9373
[iter 400] loss=-1.1791 val_loss=0.0000 scale=2.0000 norm=0.9837
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4377 val_loss=0.0000 scale=2.0000 norm=1.0642
[iter 200] loss=-0.3914 val_loss=0.0000 scale=2.0000 norm=1.0194
[iter 300] loss=-1.0876 val_loss=0.0000 scale=2.0000 norm=0.8932
[iter 400] loss=-1.6156 val_loss=0.0000 scale=4.0000 norm=1.6865
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3095 val_loss=0.0000 scale=2.0000 norm=1.0136
[iter 200] loss=-0.3307 val_loss=0.0000 scale=2.0000 norm=0.9433
[iter 300] loss=-0.7896 val_loss=0.0000 scale=2.0000 norm=0.9337
[iter 400] loss=-1.1214 val_loss=0.0000 scale=2.0000 norm=0.8926
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1679 val_loss=0.0000 scale=2.0000 norm=1.0075
[iter 200] loss=-0.5537 val_loss=0.0000 scale=2.0000 norm=0.9763
[iter 300] loss=-1.1329 val_loss=0.0000 scale=2.0000 norm=0.9481
[iter 400] loss=-1.6320 val_loss=0.0000 scale=2.0000 norm=0.9086
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3249 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 200] loss=-0.2800 val_loss=0.0000 scale=2.0000 norm=0.9352
[iter 300] loss=-0.7109 val_loss=0.0000 scale=1.0000 norm=0.4585
[iter 400] loss=-0.9769 val_loss=0.0000 scale=1.0000 norm=0.4519
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3401 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.2938 val_loss=0.0000 scale=2.0000 norm=0.9225
[iter 300] loss=-0.7442 val_loss=0.0000 scale=1.0000 norm=0.4352
[iter 400] loss=-1.0193 val_loss=0.0000 scale=1.0000 norm=0.4282
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2977 val_loss=0.0000 scale=2.0000 norm=1.0204
[iter 200] loss=-0.3593 val_loss=0.0000 scale=2.0000 norm=0.9535
[iter 300] loss=-0.9253 val_loss=0.0000 scale=2.0000 norm=0.9115
[iter 400] loss=-1.2774 val_loss=0.0000 scale=2.0000 norm=0.8922
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4263 val_loss=0.0000 scale=2.0000 norm=1.0873
[iter 200] loss=-0.0796 val_loss=0.0000 scale=2.0000 norm=0.9599
[iter 300] loss=-0.4021 val_loss=0.0000 scale=1.0000 norm=0.4643
[iter 400] loss=-0.6412 val_loss=0.0000 scale=2.0000 norm=0.9257
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3748 val_loss=0.0000 scale=2.0000 norm=1.0515
[iter 200] loss=-0.1784 val_loss=0.0000 scale=2.0000 norm=0.9811
[iter 300] loss=-0.6095 val_loss=0.0000 scale=2.0000 norm=0.9444
[iter 400] loss=-0.9494 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3266 val_loss=0.0000 scale=2.0000 norm=1.0320
[iter 200] loss=-0.3087 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 300] loss=-0.7648 val_loss=0.0000 scale=1.0000 norm=0.4564
[iter 400] loss=-1.0813 val_loss=0.0000 scale=1.0000 norm=0.4452
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3703 val_loss=0.0000 scale=2.0000 norm=1.0579
[iter 200] loss=-0.2295 val_loss=0.0000 scale=2.0000 norm=0.9596
[iter 300] loss=-0.6139 val_loss=0.0000 scale=2.0000 norm=0.9364
[iter 400] loss=-0.8850 val_loss=0.0000 scale=2.0000 norm=0.9016
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2789 val_loss=0.0000 scale=2.0000 norm=1.0116
[iter 200] loss=-0.3349 val_loss=0.0000 scale=2.0000 norm=0.9404
[iter 300] loss=-0.8362 val_loss=0.0000 scale=2.0000 norm=0.9191
[iter 400] loss=-1.1980 val_loss=0.0000 scale=2.0000 norm=0.8759
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0949 val_loss=0.0000 scale=2.0000 norm=1.0010
[iter 200] loss=-0.8694 val_loss=0.0000 scale=2.0000 norm=0.9662
[iter 300] loss=-1.8198 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 400] loss=-2.7106 val_loss=0.0000 scale=2.0000 norm=0.8904
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3506 val_loss=0.0000 scale=2.0000 norm=1.0628
[iter 200] loss=-0.2302 val_loss=0.0000 scale=2.0000 norm=0.9677
[iter 300] loss=-0.6294 val_loss=0.0000 scale=1.0000 norm=0.4698
[iter 400] loss=-0.8792 val_loss=0.0000 scale=0.5000 norm=0.2225
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3843 val_loss=0.0000 scale=2.0000 norm=1.0934
[iter 200] loss=-0.1845 val_loss=0.0000 scale=2.0000 norm=1.0218
[iter 300] loss=-0.6159 val_loss=0.0000 scale=1.0000 norm=0.4710
[iter 400] loss=-0.8341 val_loss=0.0000 scale=1.0000 norm=0.4759
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3938 val_loss=0.0000 scale=2.0000 norm=1.0730
[iter 200] loss=-0.1678 val_loss=0.0000 scale=1.0000 norm=0.4826
[iter 300] loss=-0.5698 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 400] loss=-0.8239 val_loss=0.0000 scale=2.0000 norm=0.9328
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3314 val_loss=0.0000 scale=2.0000 norm=1.0376
[iter 200] loss=-0.2774 val_loss=0.0000 scale=2.0000 norm=0.9410
[iter 300] loss=-0.6850 val_loss=0.0000 scale=1.0000 norm=0.4388
[iter 400] loss=-0.9348 val_loss=0.0000 scale=1.0000 norm=0.4331
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4353 val_loss=0.0000 scale=2.0000 norm=1.0911
[iter 200] loss=-0.0471 val_loss=0.0000 scale=2.0000 norm=0.9851
[iter 300] loss=-0.4002 val_loss=0.0000 scale=1.0000 norm=0.4702
[iter 400] loss=-0.6392 val_loss=0.0000 scale=1.0000 norm=0.4565
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6802 val_loss=0.0000 scale=2.0000 norm=1.2183
[iter 200] loss=0.0660 val_loss=0.0000 scale=2.0000 norm=1.0372
[iter 300] loss=-0.4376 val_loss=0.0000 scale=2.0000 norm=0.9636
[iter 400] loss=-0.8171 val_loss=0.0000 scale=1.0000 norm=0.4633
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2026 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 200] loss=-0.5400 val_loss=0.0000 scale=2.0000 norm=0.9299
[iter 300] loss=-1.1158 val_loss=0.0000 scale=2.0000 norm=0.8654
[iter 400] loss=-1.4997 val_loss=0.0000 scale=2.0000 norm=0.8274
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3985 val_loss=0.0000 scale=2.0000 norm=1.0628
[iter 200] loss=-0.1462 val_loss=0.0000 scale=2.0000 norm=0.9556
[iter 300] loss=-0.4665 val_loss=0.0000 scale=1.0000 norm=0.4616
[iter 400] loss=-0.6360 val_loss=0.0000 scale=2.0000 norm=0.9291
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2398 val_loss=0.0000 scale=2.0000 norm=1.0179
[iter 200] loss=-0.4477 val_loss=0.0000 scale=2.0000 norm=0.9718
[iter 300] loss=-0.9989 val_loss=0.0000 scale=1.0000 norm=0.4709
[iter 400] loss=-1.3570 val_loss=0.0000 scale=2.0000 norm=0.9174
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1667 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.5902 val_loss=0.0000 scale=2.0000 norm=0.9219
[iter 300] loss=-1.6406 val_loss=0.0000 scale=4.0000 norm=1.7220
[iter 400] loss=-2.6893 val_loss=0.0000 scale=4.0000 norm=1.5187
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4143 val_loss=0.0000 scale=2.0000 norm=1.1163
[iter 200] loss=-0.3906 val_loss=0.0000 scale=4.0000 norm=2.2490
[iter 300] loss=-1.8065 val_loss=0.0000 scale=4.0000 norm=2.1097
[iter 400] loss=-2.7583 val_loss=0.0000 scale=8.0000 norm=4.0979
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2107 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.6727 val_loss=0.0000 scale=2.0000 norm=1.0351
[iter 300] loss=-1.5429 val_loss=0.0000 scale=2.0000 norm=1.0334
[iter 400] loss=-2.3960 val_loss=0.0000 scale=2.0000 norm=1.0154
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3800 val_loss=0.0000 scale=2.0000 norm=1.0534
[iter 200] loss=-0.1664 val_loss=0.0000 scale=2.0000 norm=0.9535
[iter 300] loss=-0.5862 val_loss=0.0000 scale=2.0000 norm=0.8941
[iter 400] loss=-0.8548 val_loss=0.0000 scale=1.0000 norm=0.4240
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3547 val_loss=0.0000 scale=2.0000 norm=1.0495
[iter 200] loss=-0.2265 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-0.6116 val_loss=0.0000 scale=2.0000 norm=0.8889
[iter 400] loss=-0.8299 val_loss=0.0000 scale=1.0000 norm=0.4350
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3502 val_loss=0.0000 scale=2.0000 norm=1.0417
[iter 200] loss=-0.3254 val_loss=0.0000 scale=2.0000 norm=0.9534
[iter 300] loss=-0.8531 val_loss=0.0000 scale=2.0000 norm=0.8765
[iter 400] loss=-1.2072 val_loss=0.0000 scale=2.0000 norm=0.8417
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4040 val_loss=0.0000 scale=2.0000 norm=1.0696
[iter 200] loss=-0.2017 val_loss=0.0000 scale=2.0000 norm=0.9597
[iter 300] loss=-0.6363 val_loss=0.0000 scale=2.0000 norm=0.8770
[iter 400] loss=-0.8768 val_loss=0.0000 scale=1.0000 norm=0.4157
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4491 val_loss=0.0000 scale=2.0000 norm=1.1032
[iter 200] loss=-0.0677 val_loss=0.0000 scale=2.0000 norm=1.0367
[iter 300] loss=-0.4251 val_loss=0.0000 scale=1.0000 norm=0.4990
[iter 400] loss=-0.6177 val_loss=0.0000 scale=1.0000 norm=0.4774
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0499
[iter 200] loss=-0.2644 val_loss=0.0000 scale=1.0000 norm=0.4778
[iter 300] loss=-0.7063 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 400] loss=-0.9938 val_loss=0.0000 scale=1.0000 norm=0.4577
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3833 val_loss=0.0000 scale=2.0000 norm=1.0794
[iter 200] loss=-0.2038 val_loss=0.0000 scale=1.0000 norm=0.4820
[iter 300] loss=-0.5853 val_loss=0.0000 scale=2.0000 norm=0.9183
[iter 400] loss=-0.8553 val_loss=0.0000 scale=1.0000 norm=0.4427
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3952 val_loss=0.0000 scale=2.0000 norm=1.0756
[iter 200] loss=-0.1884 val_loss=0.0000 scale=2.0000 norm=0.9696
[iter 300] loss=-0.5929 val_loss=0.0000 scale=1.0000 norm=0.4605
[iter 400] loss=-0.8274 val_loss=0.0000 scale=1.0000 norm=0.4686
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2828 val_loss=0.0000 scale=2.0000 norm=1.0239
[iter 200] loss=-0.3534 val_loss=0.0000 scale=2.0000 norm=0.9229
[iter 300] loss=-0.8363 val_loss=0.0000 scale=2.0000 norm=0.8617
[iter 400] loss=-1.1771 val_loss=0.0000 scale=2.0000 norm=0.8536
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1992 val_loss=0.0000 scale=2.0000 norm=1.0083
[iter 200] loss=-0.4939 val_loss=0.0000 scale=2.0000 norm=1.0062
[iter 300] loss=-1.0580 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 400] loss=-1.4558 val_loss=0.0000 scale=2.0000 norm=0.8814
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1359 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.8001 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 300] loss=-1.6833 val_loss=0.0000 scale=2.0000 norm=0.9015
[iter 400] loss=-2.5365 val_loss=0.0000 scale=2.0000 norm=0.8770
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2588 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.4654 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 300] loss=-1.1404 val_loss=0.0000 scale=4.0000 norm=1.8933
[iter 400] loss=-2.1109 val_loss=0.0000 scale=4.0000 norm=1.8883
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4480 val_loss=0.0000 scale=2.0000 norm=1.0404
[iter 200] loss=-0.2410 val_loss=0.0000 scale=2.0000 norm=0.9456
[iter 300] loss=-0.7984 val_loss=0.0000 scale=2.0000 norm=0.8828
[iter 400] loss=-1.2354 val_loss=0.0000 scale=2.0000 norm=0.9090
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5197 val_loss=0.0000 scale=2.0000 norm=1.1597
[iter 200] loss=-0.0332 val_loss=0.0000 scale=2.0000 norm=1.0187
[iter 300] loss=-0.3924 val_loss=0.0000 scale=1.0000 norm=0.4848
[iter 400] loss=-0.6006 val_loss=0.0000 scale=1.0000 norm=0.4632
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5980 val_loss=0.0000 scale=2.0000 norm=1.1990
[iter 200] loss=0.0814 val_loss=0.0000 scale=2.0000 norm=1.0620
[iter 300] loss=-0.3019 val_loss=0.0000 scale=2.0000 norm=1.0260
[iter 400] loss=-0.5946 val_loss=0.0000 scale=1.0000 norm=0.4835
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3579 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.2021 val_loss=0.0000 scale=2.0000 norm=0.9432
[iter 300] loss=-0.6022 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 400] loss=-0.8609 val_loss=0.0000 scale=1.0000 norm=0.4474
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1627 val_loss=0.0000 scale=2.0000 norm=0.9911
[iter 200] loss=-0.6832 val_loss=0.0000 scale=2.0000 norm=0.9681
[iter 300] loss=-1.4097 val_loss=0.0000 scale=2.0000 norm=0.9489
[iter 400] loss=-2.0019 val_loss=0.0000 scale=2.0000 norm=0.8995
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3923 val_loss=0.0000 scale=2.0000 norm=1.0569
[iter 200] loss=-0.1519 val_loss=0.0000 scale=1.0000 norm=0.4855
[iter 300] loss=-0.5389 val_loss=0.0000 scale=1.0000 norm=0.4767
[iter 400] loss=-0.7765 val_loss=0.0000 scale=2.0000 norm=0.9190
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3013 val_loss=0.0000 scale=2.0000 norm=1.0291
[iter 200] loss=-0.3272 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 300] loss=-0.7798 val_loss=0.0000 scale=2.0000 norm=0.9200
[iter 400] loss=-1.0670 val_loss=0.0000 scale=2.0000 norm=0.8725
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3386 val_loss=0.0000 scale=2.0000 norm=1.0260
[iter 200] loss=-0.2574 val_loss=0.0000 scale=2.0000 norm=0.9276
[iter 300] loss=-0.6997 val_loss=0.0000 scale=2.0000 norm=0.8927
[iter 400] loss=-0.9917 val_loss=0.0000 scale=2.0000 norm=0.8501
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2160 val_loss=0.0000 scale=2.0000 norm=1.0307
[iter 200] loss=-0.5010 val_loss=0.0000 scale=2.0000 norm=0.9109
[iter 300] loss=-1.0426 val_loss=0.0000 scale=1.0000 norm=0.4012
[iter 400] loss=-1.3544 val_loss=0.0000 scale=1.0000 norm=0.3792
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3623 val_loss=0.0000 scale=2.0000 norm=1.0570
[iter 200] loss=-0.2559 val_loss=0.0000 scale=2.0000 norm=0.9721
[iter 300] loss=-0.7129 val_loss=0.0000 scale=1.0000 norm=0.4767
[iter 400] loss=-1.0061 val_loss=0.0000 scale=1.0000 norm=0.4728
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5648 val_loss=0.0000 scale=2.0000 norm=1.1486
[iter 200] loss=-0.0265 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 300] loss=-0.3965 val_loss=0.0000 scale=1.0000 norm=0.4374
[iter 400] loss=-0.6173 val_loss=0.0000 scale=2.0000 norm=0.8644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3618 val_loss=0.0000 scale=2.0000 norm=1.0660
[iter 200] loss=-0.2249 val_loss=0.0000 scale=2.0000 norm=0.9727
[iter 300] loss=-0.6034 val_loss=0.0000 scale=2.0000 norm=0.9152
[iter 400] loss=-0.8527 val_loss=0.0000 scale=1.0000 norm=0.4530
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.1565
[iter 200] loss=-0.4137 val_loss=0.0000 scale=2.0000 norm=1.1430
[iter 300] loss=-1.2506 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 400] loss=-2.3595 val_loss=0.0000 scale=4.0000 norm=2.3123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2935 val_loss=0.0000 scale=2.0000 norm=1.0217
[iter 200] loss=-0.3739 val_loss=0.0000 scale=2.0000 norm=0.9375
[iter 300] loss=-0.9126 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 400] loss=-1.3159 val_loss=0.0000 scale=1.0000 norm=0.4303
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3766 val_loss=0.0000 scale=2.0000 norm=1.0537
[iter 200] loss=-0.1688 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 300] loss=-0.5986 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 400] loss=-0.8809 val_loss=0.0000 scale=1.0000 norm=0.4915
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5084 val_loss=0.0000 scale=2.0000 norm=1.1417
[iter 200] loss=-0.0471 val_loss=0.0000 scale=2.0000 norm=0.9924
[iter 300] loss=-0.4107 val_loss=0.0000 scale=1.0000 norm=0.4792
[iter 400] loss=-0.6402 val_loss=0.0000 scale=1.0000 norm=0.4715
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2133 val_loss=0.0000 scale=2.0000 norm=0.9891
[iter 200] loss=-0.5571 val_loss=0.0000 scale=2.0000 norm=0.9535
[iter 300] loss=-1.2037 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 400] loss=-1.6748 val_loss=0.0000 scale=2.0000 norm=0.9162
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3114 val_loss=0.0000 scale=2.0000 norm=1.0186
[iter 200] loss=-0.3603 val_loss=0.0000 scale=2.0000 norm=0.9581
[iter 300] loss=-0.9158 val_loss=0.0000 scale=2.0000 norm=0.8950
[iter 400] loss=-1.4210 val_loss=0.0000 scale=2.0000 norm=0.8285
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3437 val_loss=0.0000 scale=2.0000 norm=1.0674
[iter 200] loss=-0.3243 val_loss=0.0000 scale=2.0000 norm=0.9683
[iter 300] loss=-0.8490 val_loss=0.0000 scale=2.0000 norm=0.9127
[iter 400] loss=-1.1860 val_loss=0.0000 scale=1.0000 norm=0.4229
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2904 val_loss=0.0000 scale=2.0000 norm=1.0036
[iter 200] loss=-0.3511 val_loss=0.0000 scale=2.0000 norm=0.9053
[iter 300] loss=-0.7423 val_loss=0.0000 scale=2.0000 norm=0.8558
[iter 400] loss=-1.0088 val_loss=0.0000 scale=1.0000 norm=0.4246
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3341 val_loss=0.0000 scale=2.0000 norm=1.0392
[iter 200] loss=-0.2527 val_loss=0.0000 scale=2.0000 norm=0.9430
[iter 300] loss=-0.7037 val_loss=0.0000 scale=2.0000 norm=0.9149
[iter 400] loss=-1.0025 val_loss=0.0000 scale=1.0000 norm=0.4402
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4161 val_loss=0.0000 scale=2.0000 norm=1.0698
[iter 200] loss=-0.3906 val_loss=0.0000 scale=2.0000 norm=0.9736
[iter 300] loss=-1.1258 val_loss=0.0000 scale=2.0000 norm=0.9398
[iter 400] loss=-1.7712 val_loss=0.0000 scale=1.0000 norm=0.4455
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2260 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 200] loss=-0.6403 val_loss=0.0000 scale=2.0000 norm=0.9146
[iter 300] loss=-1.4259 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 400] loss=-2.1775 val_loss=0.0000 scale=2.0000 norm=0.8434
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4077 val_loss=0.0000 scale=2.0000 norm=1.0872
[iter 200] loss=-0.1901 val_loss=0.0000 scale=2.0000 norm=1.0120
[iter 300] loss=-0.6310 val_loss=0.0000 scale=2.0000 norm=0.9995
[iter 400] loss=-0.8989 val_loss=0.0000 scale=1.0000 norm=0.4958
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3922 val_loss=0.0000 scale=2.0000 norm=1.0783
[iter 200] loss=-0.2096 val_loss=0.0000 scale=2.0000 norm=0.9471
[iter 300] loss=-0.6150 val_loss=0.0000 scale=1.0000 norm=0.4366
[iter 400] loss=-0.8274 val_loss=0.0000 scale=1.0000 norm=0.4176
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3709 val_loss=0.0000 scale=2.0000 norm=1.0740
[iter 200] loss=-0.2117 val_loss=0.0000 scale=1.0000 norm=0.4804
[iter 300] loss=-0.6660 val_loss=0.0000 scale=1.0000 norm=0.4500
[iter 400] loss=-0.9734 val_loss=0.0000 scale=1.0000 norm=0.4237
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4519 val_loss=0.0000 scale=2.0000 norm=1.0750
[iter 200] loss=-0.1974 val_loss=0.0000 scale=2.0000 norm=0.9012
[iter 300] loss=-0.6628 val_loss=0.0000 scale=1.0000 norm=0.4101
[iter 400] loss=-1.0099 val_loss=0.0000 scale=2.0000 norm=0.7968
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3950 val_loss=0.0000 scale=2.0000 norm=1.0810
[iter 200] loss=-0.1597 val_loss=0.0000 scale=2.0000 norm=0.9755
[iter 300] loss=-0.6179 val_loss=0.0000 scale=2.0000 norm=0.9098
[iter 400] loss=-0.9059 val_loss=0.0000 scale=1.0000 norm=0.4350
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6681 val_loss=0.0000 scale=2.0000 norm=1.1997
[iter 200] loss=0.1903 val_loss=0.0000 scale=1.0000 norm=0.5378
[iter 300] loss=-0.1564 val_loss=0.0000 scale=1.0000 norm=0.5172
[iter 400] loss=-0.3771 val_loss=0.0000 scale=1.0000 norm=0.5171
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2705 val_loss=0.0000 scale=2.0000 norm=0.9991
[iter 200] loss=-0.4389 val_loss=0.0000 scale=2.0000 norm=0.9155
[iter 300] loss=-0.9784 val_loss=0.0000 scale=2.0000 norm=0.8369
[iter 400] loss=-1.2453 val_loss=0.0000 scale=1.0000 norm=0.4256
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3088 val_loss=0.0000 scale=2.0000 norm=1.0356
[iter 200] loss=-0.3007 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 300] loss=-0.6763 val_loss=0.0000 scale=2.0000 norm=0.9348
[iter 400] loss=-0.9652 val_loss=0.0000 scale=1.0000 norm=0.4643
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6152 val_loss=0.0000 scale=2.0000 norm=1.1441
[iter 200] loss=0.0549 val_loss=0.0000 scale=2.0000 norm=0.9672
[iter 300] loss=-0.3116 val_loss=0.0000 scale=2.0000 norm=0.9357
[iter 400] loss=-0.5644 val_loss=0.0000 scale=1.0000 norm=0.4669
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4002 val_loss=0.0000 scale=2.0000 norm=1.0732
[iter 200] loss=-0.1736 val_loss=0.0000 scale=1.0000 norm=0.4955
[iter 300] loss=-0.5843 val_loss=0.0000 scale=2.0000 norm=0.9708
[iter 400] loss=-0.9020 val_loss=0.0000 scale=1.0000 norm=0.4707
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3357 val_loss=0.0000 scale=2.0000 norm=1.0484
[iter 200] loss=-0.3574 val_loss=0.0000 scale=2.0000 norm=0.9542
[iter 300] loss=-0.8976 val_loss=0.0000 scale=1.0000 norm=0.4537
[iter 400] loss=-1.2433 val_loss=0.0000 scale=1.0000 norm=0.4378
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3971 val_loss=0.0000 scale=2.0000 norm=1.0784
[iter 200] loss=-0.1959 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 300] loss=-0.5624 val_loss=0.0000 scale=2.0000 norm=0.9122
[iter 400] loss=-0.8696 val_loss=0.0000 scale=2.0000 norm=0.9039
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2817 val_loss=0.0000 scale=2.0000 norm=1.0047
[iter 200] loss=-0.3422 val_loss=0.0000 scale=2.0000 norm=0.9295
[iter 300] loss=-0.8576 val_loss=0.0000 scale=2.0000 norm=0.9094
[iter 400] loss=-1.2700 val_loss=0.0000 scale=2.0000 norm=0.8976
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3758 val_loss=0.0000 scale=2.0000 norm=1.0668
[iter 200] loss=-0.2037 val_loss=0.0000 scale=2.0000 norm=0.9712
[iter 300] loss=-0.5969 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 400] loss=-0.8632 val_loss=0.0000 scale=2.0000 norm=0.9164
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5427 val_loss=0.0000 scale=2.0000 norm=1.1358
[iter 200] loss=-0.0926 val_loss=0.0000 scale=1.0000 norm=0.4907
[iter 300] loss=-0.5835 val_loss=0.0000 scale=2.0000 norm=0.9292
[iter 400] loss=-0.9235 val_loss=0.0000 scale=2.0000 norm=0.8824
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4885 val_loss=0.0000 scale=2.0000 norm=1.0988
[iter 200] loss=-0.1011 val_loss=0.0000 scale=2.0000 norm=1.0126
[iter 300] loss=-0.5343 val_loss=0.0000 scale=2.0000 norm=1.0129
[iter 400] loss=-0.8555 val_loss=0.0000 scale=1.0000 norm=0.5005
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3301 val_loss=0.0000 scale=2.0000 norm=1.0370
[iter 200] loss=-0.2886 val_loss=0.0000 scale=2.0000 norm=0.9470
[iter 300] loss=-0.7694 val_loss=0.0000 scale=1.0000 norm=0.4585
[iter 400] loss=-1.0217 val_loss=0.0000 scale=0.5000 norm=0.2264
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6036 val_loss=0.0000 scale=2.0000 norm=1.0911
[iter 200] loss=-0.0503 val_loss=0.0000 scale=2.0000 norm=1.0188
[iter 300] loss=-0.6019 val_loss=0.0000 scale=2.0000 norm=0.9911
[iter 400] loss=-1.0138 val_loss=0.0000 scale=1.0000 norm=0.4781
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3394 val_loss=0.0000 scale=2.0000 norm=1.0446
[iter 200] loss=-0.2655 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 300] loss=-0.6639 val_loss=0.0000 scale=2.0000 norm=0.8942
[iter 400] loss=-0.8938 val_loss=0.0000 scale=2.0000 norm=0.8764
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3955 val_loss=0.0000 scale=2.0000 norm=1.0933
[iter 200] loss=-0.1868 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 300] loss=-0.5971 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 400] loss=-0.8515 val_loss=0.0000 scale=1.0000 norm=0.4551
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7003 val_loss=0.0000 scale=2.0000 norm=1.2228
[iter 200] loss=0.2094 val_loss=0.0000 scale=2.0000 norm=1.0639
[iter 300] loss=-0.1398 val_loss=0.0000 scale=2.0000 norm=1.0265
[iter 400] loss=-0.4078 val_loss=0.0000 scale=1.0000 norm=0.5138
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7005 val_loss=0.0000 scale=2.0000 norm=1.2279
[iter 200] loss=0.2012 val_loss=0.0000 scale=2.0000 norm=1.0500
[iter 300] loss=-0.1702 val_loss=0.0000 scale=1.0000 norm=0.4765
[iter 400] loss=-0.4117 val_loss=0.0000 scale=1.0000 norm=0.4536
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3367 val_loss=0.0000 scale=2.0000 norm=1.0402
[iter 200] loss=-0.2506 val_loss=0.0000 scale=2.0000 norm=0.9545
[iter 300] loss=-0.6325 val_loss=0.0000 scale=2.0000 norm=0.9218
[iter 400] loss=-0.8749 val_loss=0.0000 scale=2.0000 norm=0.9234
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3956 val_loss=0.0000 scale=2.0000 norm=1.0578
[iter 200] loss=-0.1498 val_loss=0.0000 scale=1.0000 norm=0.4718
[iter 300] loss=-0.5087 val_loss=0.0000 scale=2.0000 norm=0.9113
[iter 400] loss=-0.7580 val_loss=0.0000 scale=2.0000 norm=0.9210
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3982 val_loss=0.0000 scale=2.0000 norm=1.0689
[iter 200] loss=-0.2420 val_loss=0.0000 scale=2.0000 norm=0.9394
[iter 300] loss=-0.6688 val_loss=0.0000 scale=1.0000 norm=0.4623
[iter 400] loss=-0.9283 val_loss=0.0000 scale=2.0000 norm=0.9251
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5099 val_loss=0.0000 scale=2.0000 norm=1.1540
[iter 200] loss=0.0281 val_loss=0.0000 scale=1.0000 norm=0.5177
[iter 300] loss=-0.3059 val_loss=0.0000 scale=2.0000 norm=0.9591
[iter 400] loss=-0.5516 val_loss=0.0000 scale=1.0000 norm=0.4575
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3496 val_loss=0.0000 scale=2.0000 norm=1.0472
[iter 200] loss=-0.3318 val_loss=0.0000 scale=2.0000 norm=0.9372
[iter 300] loss=-0.8317 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 400] loss=-1.1839 val_loss=0.0000 scale=1.0000 norm=0.4538
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3738 val_loss=0.0000 scale=2.0000 norm=1.0498
[iter 200] loss=-0.1921 val_loss=0.0000 scale=2.0000 norm=0.9565
[iter 300] loss=-0.5818 val_loss=0.0000 scale=2.0000 norm=0.9277
[iter 400] loss=-0.8367 val_loss=0.0000 scale=1.0000 norm=0.4549
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3439 val_loss=0.0000 scale=2.0000 norm=1.0267
[iter 200] loss=-0.2319 val_loss=0.0000 scale=2.0000 norm=0.9377
[iter 300] loss=-0.5870 val_loss=0.0000 scale=2.0000 norm=0.9054
[iter 400] loss=-0.8564 val_loss=0.0000 scale=1.0000 norm=0.4421
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2230 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 200] loss=-0.6358 val_loss=0.0000 scale=2.0000 norm=1.0236
[iter 300] loss=-1.6917 val_loss=0.0000 scale=4.0000 norm=1.9398
[iter 400] loss=-2.5711 val_loss=0.0000 scale=4.0000 norm=1.8345
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3595 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.2208 val_loss=0.0000 scale=2.0000 norm=0.9765
[iter 300] loss=-0.5784 val_loss=0.0000 scale=2.0000 norm=0.9726
[iter 400] loss=-0.8082 val_loss=0.0000 scale=1.0000 norm=0.4821
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2558 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 200] loss=-0.5474 val_loss=0.0000 scale=2.0000 norm=0.8565
[iter 300] loss=-1.1752 val_loss=0.0000 scale=2.0000 norm=0.7257
[iter 400] loss=-1.6387 val_loss=0.0000 scale=2.0000 norm=0.6501
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5020 val_loss=0.0000 scale=2.0000 norm=1.1398
[iter 200] loss=-0.0449 val_loss=0.0000 scale=2.0000 norm=1.0483
[iter 300] loss=-0.4304 val_loss=0.0000 scale=1.0000 norm=0.5114
[iter 400] loss=-0.6887 val_loss=0.0000 scale=1.0000 norm=0.5007
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2897 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3417 val_loss=0.0000 scale=1.0000 norm=0.4621
[iter 300] loss=-0.8132 val_loss=0.0000 scale=1.0000 norm=0.4382
[iter 400] loss=-1.1034 val_loss=0.0000 scale=2.0000 norm=0.8290
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4081 val_loss=0.0000 scale=2.0000 norm=1.0908
[iter 200] loss=-0.1360 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 300] loss=-0.5358 val_loss=0.0000 scale=1.0000 norm=0.4716
[iter 400] loss=-0.7579 val_loss=0.0000 scale=2.0000 norm=0.8875
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4278 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.3748 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 300] loss=-1.0700 val_loss=0.0000 scale=2.0000 norm=0.8344
[iter 400] loss=-1.7079 val_loss=0.0000 scale=2.0000 norm=0.8143
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3897 val_loss=0.0000 scale=2.0000 norm=1.0547
[iter 200] loss=-0.2200 val_loss=0.0000 scale=2.0000 norm=0.9244
[iter 300] loss=-0.6163 val_loss=0.0000 scale=2.0000 norm=0.9025
[iter 400] loss=-0.8610 val_loss=0.0000 scale=1.0000 norm=0.4506
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3523 val_loss=0.0000 scale=2.0000 norm=1.0569
[iter 200] loss=-0.3804 val_loss=0.0000 scale=2.0000 norm=1.0160
[iter 300] loss=-1.2866 val_loss=0.0000 scale=4.0000 norm=2.1229
[iter 400] loss=-2.2799 val_loss=0.0000 scale=4.0000 norm=1.9945
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1368 val_loss=0.0000 scale=2.0000 norm=0.9794
[iter 200] loss=-0.6894 val_loss=0.0000 scale=2.0000 norm=0.9287
[iter 300] loss=-1.3573 val_loss=0.0000 scale=2.0000 norm=0.8886
[iter 400] loss=-1.8472 val_loss=0.0000 scale=2.0000 norm=0.9261
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1286 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 200] loss=-0.7766 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-1.6605 val_loss=0.0000 scale=2.0000 norm=0.8486
[iter 400] loss=-2.9066 val_loss=0.0000 scale=4.0000 norm=1.5972
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2400 val_loss=0.0000 scale=2.0000 norm=1.0017
[iter 200] loss=-0.4750 val_loss=0.0000 scale=2.0000 norm=0.9063
[iter 300] loss=-1.0014 val_loss=0.0000 scale=2.0000 norm=0.8748
[iter 400] loss=-1.3691 val_loss=0.0000 scale=2.0000 norm=0.8783
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3399 val_loss=0.0000 scale=2.0000 norm=1.0519
[iter 200] loss=-0.3108 val_loss=0.0000 scale=2.0000 norm=0.9996
[iter 300] loss=-0.7974 val_loss=0.0000 scale=1.0000 norm=0.4835
[iter 400] loss=-1.1390 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3323 val_loss=0.0000 scale=2.0000 norm=1.0452
[iter 200] loss=-0.2763 val_loss=0.0000 scale=2.0000 norm=0.9907
[iter 300] loss=-0.6973 val_loss=0.0000 scale=1.0000 norm=0.4722
[iter 400] loss=-0.9452 val_loss=0.0000 scale=2.0000 norm=0.9205
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3946 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.1632 val_loss=0.0000 scale=2.0000 norm=1.0024
[iter 300] loss=-0.5787 val_loss=0.0000 scale=1.0000 norm=0.4819
[iter 400] loss=-0.8642 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2718 val_loss=0.0000 scale=2.0000 norm=1.0719
[iter 200] loss=-0.4546 val_loss=0.0000 scale=2.0000 norm=0.9810
[iter 300] loss=-1.0518 val_loss=0.0000 scale=2.0000 norm=0.8765
[iter 400] loss=-1.5108 val_loss=0.0000 scale=2.0000 norm=0.8273
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3543 val_loss=0.0000 scale=2.0000 norm=1.0491
[iter 200] loss=-0.2880 val_loss=0.0000 scale=1.0000 norm=0.4648
[iter 300] loss=-0.7084 val_loss=0.0000 scale=2.0000 norm=0.8776
[iter 400] loss=-1.0156 val_loss=0.0000 scale=2.0000 norm=0.8378
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3336 val_loss=0.0000 scale=2.0000 norm=1.0343
[iter 200] loss=-0.2412 val_loss=0.0000 scale=1.0000 norm=0.4666
[iter 300] loss=-0.6024 val_loss=0.0000 scale=1.0000 norm=0.4476
[iter 400] loss=-0.8754 val_loss=0.0000 scale=1.0000 norm=0.4259
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3767 val_loss=0.0000 scale=2.0000 norm=1.0726
[iter 200] loss=-0.3314 val_loss=0.0000 scale=2.0000 norm=0.9541
[iter 300] loss=-0.9509 val_loss=0.0000 scale=2.0000 norm=0.8548
[iter 400] loss=-1.3661 val_loss=0.0000 scale=2.0000 norm=0.8268
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1899 val_loss=0.0000 scale=2.0000 norm=0.9854
[iter 200] loss=-0.7098 val_loss=0.0000 scale=2.0000 norm=0.9272
[iter 300] loss=-1.5210 val_loss=0.0000 scale=2.0000 norm=0.8805
[iter 400] loss=-2.3001 val_loss=0.0000 scale=2.0000 norm=0.8651
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4933 val_loss=0.0000 scale=2.0000 norm=1.1098
[iter 200] loss=-0.0023 val_loss=0.0000 scale=2.0000 norm=1.0304
[iter 300] loss=-0.3348 val_loss=0.0000 scale=1.0000 norm=0.4847
[iter 400] loss=-0.5709 val_loss=0.0000 scale=1.0000 norm=0.4662
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6260 val_loss=0.0000 scale=2.0000 norm=1.1825
[iter 200] loss=0.0836 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 300] loss=-0.2994 val_loss=0.0000 scale=1.0000 norm=0.5128
[iter 400] loss=-0.5127 val_loss=0.0000 scale=1.0000 norm=0.4868
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3846 val_loss=0.0000 scale=2.0000 norm=1.1312
[iter 200] loss=-0.3645 val_loss=0.0000 scale=2.0000 norm=1.0928
[iter 300] loss=-1.0322 val_loss=0.0000 scale=2.0000 norm=1.0469
[iter 400] loss=-1.6190 val_loss=0.0000 scale=2.0000 norm=1.0713
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4433 val_loss=0.0000 scale=2.0000 norm=1.0802
[iter 200] loss=-0.2028 val_loss=0.0000 scale=2.0000 norm=0.9513
[iter 300] loss=-0.6255 val_loss=0.0000 scale=1.0000 norm=0.4483
[iter 400] loss=-0.9235 val_loss=0.0000 scale=2.0000 norm=0.8660
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5599 val_loss=0.0000 scale=2.0000 norm=1.1389
[iter 200] loss=-0.0125 val_loss=0.0000 scale=1.0000 norm=0.4978
[iter 300] loss=-0.4037 val_loss=0.0000 scale=2.0000 norm=0.9506
[iter 400] loss=-0.6350 val_loss=0.0000 scale=1.0000 norm=0.4611
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6601 val_loss=0.0000 scale=2.0000 norm=1.1999
[iter 200] loss=-0.0413 val_loss=0.0000 scale=2.0000 norm=1.0496
[iter 300] loss=-0.7011 val_loss=0.0000 scale=2.0000 norm=0.9775
[iter 400] loss=-1.2403 val_loss=0.0000 scale=2.0000 norm=0.8815
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3306 val_loss=0.0000 scale=2.0000 norm=1.0375
[iter 200] loss=-0.2768 val_loss=0.0000 scale=2.0000 norm=0.9616
[iter 300] loss=-0.7268 val_loss=0.0000 scale=2.0000 norm=0.9257
[iter 400] loss=-0.9774 val_loss=0.0000 scale=1.0000 norm=0.4422
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3029 val_loss=0.0000 scale=2.0000 norm=1.0086
[iter 200] loss=-0.3175 val_loss=0.0000 scale=2.0000 norm=0.9629
[iter 300] loss=-0.8250 val_loss=0.0000 scale=2.0000 norm=0.9400
[iter 400] loss=-1.2175 val_loss=0.0000 scale=4.0000 norm=1.9331
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3510 val_loss=0.0000 scale=2.0000 norm=1.0598
[iter 200] loss=-0.2737 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-0.7349 val_loss=0.0000 scale=2.0000 norm=0.9496
[iter 400] loss=-1.0346 val_loss=0.0000 scale=2.0000 norm=0.9179
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 200] loss=-0.6425 val_loss=0.0000 scale=2.0000 norm=0.8688
[iter 300] loss=-1.3411 val_loss=0.0000 scale=2.0000 norm=0.8274
[iter 400] loss=-2.0692 val_loss=0.0000 scale=2.0000 norm=0.7733
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5102 val_loss=0.0000 scale=2.0000 norm=1.1332
[iter 200] loss=-0.0256 val_loss=0.0000 scale=2.0000 norm=1.0065
[iter 300] loss=-0.3608 val_loss=0.0000 scale=2.0000 norm=0.9522
[iter 400] loss=-0.5601 val_loss=0.0000 scale=2.0000 norm=0.9134
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3074 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.4241 val_loss=0.0000 scale=2.0000 norm=0.9598
[iter 300] loss=-1.0018 val_loss=0.0000 scale=2.0000 norm=0.9364
[iter 400] loss=-1.3875 val_loss=0.0000 scale=1.0000 norm=0.4472
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4576 val_loss=0.0000 scale=2.0000 norm=1.0853
[iter 200] loss=-0.2504 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 300] loss=-0.8802 val_loss=0.0000 scale=2.0000 norm=0.9363
[iter 400] loss=-1.3941 val_loss=0.0000 scale=2.0000 norm=0.8741
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1910 val_loss=0.0000 scale=2.0000 norm=1.0226
[iter 200] loss=-0.6321 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 300] loss=-1.3593 val_loss=0.0000 scale=2.0000 norm=0.9095
[iter 400] loss=-1.9961 val_loss=0.0000 scale=2.0000 norm=0.8825
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3632 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.2115 val_loss=0.0000 scale=2.0000 norm=0.9474
[iter 300] loss=-0.6256 val_loss=0.0000 scale=1.0000 norm=0.4592
[iter 400] loss=-0.8105 val_loss=0.0000 scale=2.0000 norm=0.9269
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3969 val_loss=0.0000 scale=2.0000 norm=1.0665
[iter 200] loss=-0.2288 val_loss=0.0000 scale=2.0000 norm=0.9641
[iter 300] loss=-0.6906 val_loss=0.0000 scale=2.0000 norm=0.9126
[iter 400] loss=-0.9760 val_loss=0.0000 scale=2.0000 norm=0.8737
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3703 val_loss=0.0000 scale=2.0000 norm=1.0393
[iter 200] loss=-0.2121 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 300] loss=-0.6277 val_loss=0.0000 scale=2.0000 norm=0.8809
[iter 400] loss=-0.8651 val_loss=0.0000 scale=1.0000 norm=0.4230
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3866 val_loss=0.0000 scale=2.0000 norm=1.0844
[iter 200] loss=-0.1415 val_loss=0.0000 scale=1.0000 norm=0.4873
[iter 300] loss=-0.5078 val_loss=0.0000 scale=2.0000 norm=0.9236
[iter 400] loss=-0.7045 val_loss=0.0000 scale=0.5000 norm=0.2241
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3578 val_loss=0.0000 scale=2.0000 norm=1.0591
[iter 200] loss=-0.2499 val_loss=0.0000 scale=2.0000 norm=0.9804
[iter 300] loss=-0.6919 val_loss=0.0000 scale=2.0000 norm=0.9543
[iter 400] loss=-0.9519 val_loss=0.0000 scale=2.0000 norm=0.9540
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5205 val_loss=0.0000 scale=2.0000 norm=1.0960
[iter 200] loss=-0.0803 val_loss=0.0000 scale=2.0000 norm=0.9031
[iter 300] loss=-0.5577 val_loss=0.0000 scale=2.0000 norm=0.7962
[iter 400] loss=-0.8351 val_loss=0.0000 scale=1.0000 norm=0.3788
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8217 val_loss=0.0000 scale=2.0000 norm=1.2687
[iter 200] loss=0.0831 val_loss=0.0000 scale=2.0000 norm=1.0061
[iter 300] loss=-0.5201 val_loss=0.0000 scale=2.0000 norm=0.9693
[iter 400] loss=-1.0178 val_loss=0.0000 scale=2.0000 norm=0.9653
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1734 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.5711 val_loss=0.0000 scale=2.0000 norm=0.9207
[iter 300] loss=-1.1638 val_loss=0.0000 scale=2.0000 norm=0.8724
[iter 400] loss=-1.5851 val_loss=0.0000 scale=2.0000 norm=0.8115
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2959 val_loss=0.0000 scale=2.0000 norm=1.0116
[iter 200] loss=-0.3454 val_loss=0.0000 scale=2.0000 norm=0.9362
[iter 300] loss=-0.7806 val_loss=0.0000 scale=2.0000 norm=0.9184
[iter 400] loss=-1.0954 val_loss=0.0000 scale=2.0000 norm=0.9011
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2095 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6176 val_loss=0.0000 scale=2.0000 norm=0.8984
[iter 300] loss=-1.3375 val_loss=0.0000 scale=2.0000 norm=0.8432
[iter 400] loss=-2.0283 val_loss=0.0000 scale=2.0000 norm=0.8547
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6394 val_loss=0.0000 scale=2.0000 norm=1.1665
[iter 200] loss=0.0699 val_loss=0.0000 scale=2.0000 norm=0.9935
[iter 300] loss=-0.2769 val_loss=0.0000 scale=1.0000 norm=0.4721
[iter 400] loss=-0.5142 val_loss=0.0000 scale=1.0000 norm=0.4718
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4563 val_loss=0.0000 scale=2.0000 norm=1.0745
[iter 200] loss=-0.2820 val_loss=0.0000 scale=2.0000 norm=0.9760
[iter 300] loss=-0.9431 val_loss=0.0000 scale=2.0000 norm=0.9470
[iter 400] loss=-1.4823 val_loss=0.0000 scale=2.0000 norm=0.9203
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2464 val_loss=0.0000 scale=2.0000 norm=0.9741
[iter 200] loss=-0.6896 val_loss=0.0000 scale=2.0000 norm=0.9328
[iter 300] loss=-1.5106 val_loss=0.0000 scale=2.0000 norm=0.8362
[iter 400] loss=-2.5317 val_loss=0.0000 scale=4.0000 norm=1.5555
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3916 val_loss=0.0000 scale=2.0000 norm=1.0800
[iter 200] loss=-0.2543 val_loss=0.0000 scale=2.0000 norm=0.9524
[iter 300] loss=-0.7294 val_loss=0.0000 scale=2.0000 norm=0.9088
[iter 400] loss=-1.0059 val_loss=0.0000 scale=2.0000 norm=0.8481
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3291 val_loss=0.0000 scale=2.0000 norm=1.0244
[iter 200] loss=-0.2506 val_loss=0.0000 scale=1.0000 norm=0.4701
[iter 300] loss=-0.6204 val_loss=0.0000 scale=2.0000 norm=0.8850
[iter 400] loss=-0.8677 val_loss=0.0000 scale=0.5000 norm=0.2111
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=0.9843
[iter 200] loss=-0.5812 val_loss=0.0000 scale=2.0000 norm=0.8709
[iter 300] loss=-1.1711 val_loss=0.0000 scale=2.0000 norm=0.8169
[iter 400] loss=-1.5299 val_loss=0.0000 scale=1.0000 norm=0.3831
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4535 val_loss=0.0000 scale=2.0000 norm=1.0927
[iter 200] loss=-0.0851 val_loss=0.0000 scale=2.0000 norm=1.0006
[iter 300] loss=-0.4523 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 400] loss=-0.6913 val_loss=0.0000 scale=2.0000 norm=0.9716
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4231 val_loss=0.0000 scale=2.0000 norm=1.1073
[iter 200] loss=-0.2649 val_loss=0.0000 scale=2.0000 norm=0.9871
[iter 300] loss=-0.8375 val_loss=0.0000 scale=2.0000 norm=0.9432
[iter 400] loss=-1.3489 val_loss=0.0000 scale=2.0000 norm=0.9004
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4368 val_loss=0.0000 scale=2.0000 norm=1.0996
[iter 200] loss=-0.1034 val_loss=0.0000 scale=2.0000 norm=1.0068
[iter 300] loss=-0.4622 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 400] loss=-0.7109 val_loss=0.0000 scale=1.0000 norm=0.4824
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4762 val_loss=0.0000 scale=2.0000 norm=1.0369
[iter 200] loss=-0.2580 val_loss=0.0000 scale=2.0000 norm=0.9431
[iter 300] loss=-0.9456 val_loss=0.0000 scale=2.0000 norm=0.9023
[iter 400] loss=-1.5193 val_loss=0.0000 scale=2.0000 norm=0.8576
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2995 val_loss=0.0000 scale=2.0000 norm=1.0226
[iter 200] loss=-0.3026 val_loss=0.0000 scale=2.0000 norm=0.9843
[iter 300] loss=-0.7347 val_loss=0.0000 scale=2.0000 norm=0.9689
[iter 400] loss=-1.0405 val_loss=0.0000 scale=2.0000 norm=0.9390
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3011 val_loss=0.0000 scale=2.0000 norm=1.0251
[iter 200] loss=-0.3619 val_loss=0.0000 scale=2.0000 norm=0.9253
[iter 300] loss=-0.7908 val_loss=0.0000 scale=2.0000 norm=0.9130
[iter 400] loss=-1.0465 val_loss=0.0000 scale=1.0000 norm=0.4498
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3749 val_loss=0.0000 scale=2.0000 norm=1.0583
[iter 200] loss=-0.1866 val_loss=0.0000 scale=2.0000 norm=0.9568
[iter 300] loss=-0.5903 val_loss=0.0000 scale=1.0000 norm=0.4574
[iter 400] loss=-0.8755 val_loss=0.0000 scale=2.0000 norm=0.8888
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4422 val_loss=0.0000 scale=1.0000 norm=0.5512
[iter 200] loss=-0.0932 val_loss=0.0000 scale=1.0000 norm=0.4963
[iter 300] loss=-0.4851 val_loss=0.0000 scale=1.0000 norm=0.4908
[iter 400] loss=-0.7620 val_loss=0.0000 scale=1.0000 norm=0.4910
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3009 val_loss=0.0000 scale=2.0000 norm=1.0016
[iter 200] loss=-0.3397 val_loss=0.0000 scale=2.0000 norm=0.9212
[iter 300] loss=-0.7974 val_loss=0.0000 scale=2.0000 norm=0.8846
[iter 400] loss=-1.0893 val_loss=0.0000 scale=2.0000 norm=0.8512
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3047 val_loss=0.0000 scale=2.0000 norm=1.0303
[iter 200] loss=-0.2974 val_loss=0.0000 scale=2.0000 norm=0.9380
[iter 300] loss=-0.6600 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 400] loss=-0.9468 val_loss=0.0000 scale=2.0000 norm=0.9191
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3825 val_loss=0.0000 scale=2.0000 norm=1.0729
[iter 200] loss=-0.2259 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 300] loss=-0.6743 val_loss=0.0000 scale=2.0000 norm=0.9433
[iter 400] loss=-1.0305 val_loss=0.0000 scale=2.0000 norm=0.9120
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3981 val_loss=0.0000 scale=2.0000 norm=1.0303
[iter 200] loss=-0.2171 val_loss=0.0000 scale=2.0000 norm=0.9269
[iter 300] loss=-0.6604 val_loss=0.0000 scale=1.0000 norm=0.4451
[iter 400] loss=-0.9876 val_loss=0.0000 scale=2.0000 norm=0.8927
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4086 val_loss=0.0000 scale=2.0000 norm=1.0916
[iter 200] loss=-0.1699 val_loss=0.0000 scale=2.0000 norm=1.0102
[iter 300] loss=-0.5946 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 400] loss=-0.8034 val_loss=0.0000 scale=1.0000 norm=0.4717
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.1076
[iter 200] loss=-0.1571 val_loss=0.0000 scale=2.0000 norm=1.0351
[iter 300] loss=-0.5599 val_loss=0.0000 scale=1.0000 norm=0.4785
[iter 400] loss=-0.8050 val_loss=0.0000 scale=1.0000 norm=0.4600
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3916 val_loss=0.0000 scale=2.0000 norm=1.0628
[iter 200] loss=-0.1495 val_loss=0.0000 scale=2.0000 norm=0.9528
[iter 300] loss=-0.5607 val_loss=0.0000 scale=2.0000 norm=0.8898
[iter 400] loss=-0.8108 val_loss=0.0000 scale=2.0000 norm=0.8911
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2091 val_loss=0.0000 scale=2.0000 norm=0.9640
[iter 200] loss=-0.6737 val_loss=0.0000 scale=2.0000 norm=0.9053
[iter 300] loss=-1.5210 val_loss=0.0000 scale=2.0000 norm=0.8879
[iter 400] loss=-2.3738 val_loss=0.0000 scale=2.0000 norm=0.8837
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4081 val_loss=0.0000 scale=2.0000 norm=1.0663
[iter 200] loss=-0.1486 val_loss=0.0000 scale=2.0000 norm=0.9675
[iter 300] loss=-0.4984 val_loss=0.0000 scale=1.0000 norm=0.4780
[iter 400] loss=-0.7009 val_loss=0.0000 scale=1.0000 norm=0.4811
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3380 val_loss=0.0000 scale=2.0000 norm=1.0443
[iter 200] loss=-0.2471 val_loss=0.0000 scale=2.0000 norm=0.9703
[iter 300] loss=-0.6526 val_loss=0.0000 scale=2.0000 norm=0.9581
[iter 400] loss=-0.9503 val_loss=0.0000 scale=1.0000 norm=0.4586
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2705 val_loss=0.0000 scale=2.0000 norm=1.0093
[iter 200] loss=-0.4471 val_loss=0.0000 scale=2.0000 norm=0.8877
[iter 300] loss=-1.0587 val_loss=0.0000 scale=2.0000 norm=0.8057
[iter 400] loss=-1.4993 val_loss=0.0000 scale=2.0000 norm=0.7761
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4788 val_loss=0.0000 scale=2.0000 norm=1.1099
[iter 200] loss=-0.0444 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 300] loss=-0.3775 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 400] loss=-0.5858 val_loss=0.0000 scale=1.0000 norm=0.4632
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6251 val_loss=0.0000 scale=2.0000 norm=1.1831
[iter 200] loss=0.0505 val_loss=0.0000 scale=2.0000 norm=1.0581
[iter 300] loss=-0.3649 val_loss=0.0000 scale=1.0000 norm=0.5063
[iter 400] loss=-0.6669 val_loss=0.0000 scale=1.0000 norm=0.5082
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3397 val_loss=0.0000 scale=2.0000 norm=1.0228
[iter 200] loss=-0.2775 val_loss=0.0000 scale=2.0000 norm=0.9437
[iter 300] loss=-0.6986 val_loss=0.0000 scale=2.0000 norm=0.9476
[iter 400] loss=-0.9921 val_loss=0.0000 scale=2.0000 norm=0.8920
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3847 val_loss=0.0000 scale=2.0000 norm=1.0541
[iter 200] loss=-0.2181 val_loss=0.0000 scale=2.0000 norm=0.9367
[iter 300] loss=-0.6414 val_loss=0.0000 scale=2.0000 norm=0.8753
[iter 400] loss=-0.9438 val_loss=0.0000 scale=1.0000 norm=0.4065
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6121 val_loss=0.0000 scale=2.0000 norm=1.1681
[iter 200] loss=0.0429 val_loss=0.0000 scale=2.0000 norm=1.0152
[iter 300] loss=-0.3219 val_loss=0.0000 scale=1.0000 norm=0.4844
[iter 400] loss=-0.5797 val_loss=0.0000 scale=2.0000 norm=0.9925
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3549 val_loss=0.0000 scale=2.0000 norm=1.0524
[iter 200] loss=-0.2301 val_loss=0.0000 scale=2.0000 norm=0.9834
[iter 300] loss=-0.6320 val_loss=0.0000 scale=1.0000 norm=0.4675
[iter 400] loss=-0.8655 val_loss=0.0000 scale=1.0000 norm=0.4471
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3378 val_loss=0.0000 scale=2.0000 norm=1.0377
[iter 200] loss=-0.2688 val_loss=0.0000 scale=2.0000 norm=0.9205
[iter 300] loss=-0.6789 val_loss=0.0000 scale=1.0000 norm=0.4353
[iter 400] loss=-0.9275 val_loss=0.0000 scale=1.0000 norm=0.4266
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3588 val_loss=0.0000 scale=2.0000 norm=1.0483
[iter 200] loss=-0.2021 val_loss=0.0000 scale=2.0000 norm=0.9754
[iter 300] loss=-0.5559 val_loss=0.0000 scale=2.0000 norm=0.9607
[iter 400] loss=-0.8499 val_loss=0.0000 scale=2.0000 norm=0.9259
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5667 val_loss=0.0000 scale=2.0000 norm=1.1608
[iter 200] loss=0.0518 val_loss=0.0000 scale=1.0000 norm=0.4976
[iter 300] loss=-0.2330 val_loss=0.0000 scale=2.0000 norm=0.9369
[iter 400] loss=-0.4777 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3314 val_loss=0.0000 scale=2.0000 norm=1.0335
[iter 200] loss=-0.2578 val_loss=0.0000 scale=2.0000 norm=0.9518
[iter 300] loss=-0.6445 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 400] loss=-0.8931 val_loss=0.0000 scale=1.0000 norm=0.4497
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3653 val_loss=0.0000 scale=2.0000 norm=1.0527
[iter 200] loss=-0.2145 val_loss=0.0000 scale=1.0000 norm=0.4783
[iter 300] loss=-0.5606 val_loss=0.0000 scale=2.0000 norm=0.9426
[iter 400] loss=-0.8011 val_loss=0.0000 scale=2.0000 norm=0.9193
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2602 val_loss=0.0000 scale=2.0000 norm=1.0146
[iter 200] loss=-0.4535 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 300] loss=-1.0812 val_loss=0.0000 scale=2.0000 norm=0.8991
[iter 400] loss=-1.5927 val_loss=0.0000 scale=2.0000 norm=0.8137
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2849 val_loss=0.0000 scale=2.0000 norm=1.0163
[iter 200] loss=-0.3623 val_loss=0.0000 scale=2.0000 norm=0.9205
[iter 300] loss=-0.8541 val_loss=0.0000 scale=2.0000 norm=0.8714
[iter 400] loss=-1.1981 val_loss=0.0000 scale=2.0000 norm=0.8169
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3857 val_loss=0.0000 scale=2.0000 norm=1.0781
[iter 200] loss=-0.1606 val_loss=0.0000 scale=2.0000 norm=0.9590
[iter 300] loss=-0.5263 val_loss=0.0000 scale=1.0000 norm=0.4585
[iter 400] loss=-0.7601 val_loss=0.0000 scale=2.0000 norm=0.8896
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5580 val_loss=0.0000 scale=2.0000 norm=1.1975
[iter 200] loss=0.0503 val_loss=0.0000 scale=2.0000 norm=1.0767
[iter 300] loss=-0.3190 val_loss=0.0000 scale=1.0000 norm=0.5019
[iter 400] loss=-0.5865 val_loss=0.0000 scale=1.0000 norm=0.4740
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3556 val_loss=0.0000 scale=2.0000 norm=1.0641
[iter 200] loss=-0.2226 val_loss=0.0000 scale=2.0000 norm=0.9844
[iter 300] loss=-0.6048 val_loss=0.0000 scale=1.0000 norm=0.4808
[iter 400] loss=-0.8225 val_loss=0.0000 scale=2.0000 norm=0.9712
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6501 val_loss=0.0000 scale=2.0000 norm=1.2066
[iter 200] loss=0.1174 val_loss=0.0000 scale=1.0000 norm=0.5376
[iter 300] loss=-0.2832 val_loss=0.0000 scale=1.0000 norm=0.4979
[iter 400] loss=-0.5303 val_loss=0.0000 scale=1.0000 norm=0.4698
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4076 val_loss=0.0000 scale=2.0000 norm=1.0839
[iter 200] loss=-0.1657 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 300] loss=-0.6047 val_loss=0.0000 scale=1.0000 norm=0.4611
[iter 400] loss=-0.8199 val_loss=0.0000 scale=0.5000 norm=0.2348
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3372 val_loss=0.0000 scale=2.0000 norm=0.9898
[iter 200] loss=-0.4899 val_loss=0.0000 scale=2.0000 norm=0.9152
[iter 300] loss=-1.2732 val_loss=0.0000 scale=2.0000 norm=0.8939
[iter 400] loss=-2.0536 val_loss=0.0000 scale=2.0000 norm=0.8840
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6627 val_loss=0.0000 scale=2.0000 norm=1.1860
[iter 200] loss=0.1632 val_loss=0.0000 scale=1.0000 norm=0.5286
[iter 300] loss=-0.1421 val_loss=0.0000 scale=1.0000 norm=0.5134
[iter 400] loss=-0.3568 val_loss=0.0000 scale=1.0000 norm=0.4903
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5302 val_loss=0.0000 scale=2.0000 norm=1.1650
[iter 200] loss=0.0191 val_loss=0.0000 scale=2.0000 norm=1.0353
[iter 300] loss=-0.4095 val_loss=0.0000 scale=1.0000 norm=0.5001
[iter 400] loss=-0.6524 val_loss=0.0000 scale=1.0000 norm=0.4914
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3158 val_loss=0.0000 scale=2.0000 norm=1.0279
[iter 200] loss=-0.3048 val_loss=0.0000 scale=2.0000 norm=0.9558
[iter 300] loss=-0.7459 val_loss=0.0000 scale=2.0000 norm=0.9361
[iter 400] loss=-1.0253 val_loss=0.0000 scale=2.0000 norm=0.9318
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7014 val_loss=0.0000 scale=2.0000 norm=1.2088
[iter 200] loss=0.2070 val_loss=0.0000 scale=2.0000 norm=1.0553
[iter 300] loss=-0.2684 val_loss=0.0000 scale=2.0000 norm=0.9845
[iter 400] loss=-0.6007 val_loss=0.0000 scale=2.0000 norm=0.9287
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4806 val_loss=0.0000 scale=2.0000 norm=1.0971
[iter 200] loss=-0.1688 val_loss=0.0000 scale=2.0000 norm=0.9768
[iter 300] loss=-0.6505 val_loss=0.0000 scale=2.0000 norm=0.9551
[iter 400] loss=-1.0462 val_loss=0.0000 scale=2.0000 norm=0.9551
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4315 val_loss=0.0000 scale=2.0000 norm=1.1023
[iter 200] loss=-0.1039 val_loss=0.0000 scale=1.0000 norm=0.4914
[iter 300] loss=-0.4652 val_loss=0.0000 scale=1.0000 norm=0.4615
[iter 400] loss=-0.6478 val_loss=0.0000 scale=2.0000 norm=0.9163
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5485 val_loss=0.0000 scale=2.0000 norm=1.2019
[iter 200] loss=-0.0555 val_loss=0.0000 scale=2.0000 norm=1.0845
[iter 300] loss=-0.4819 val_loss=0.0000 scale=2.0000 norm=1.0290
[iter 400] loss=-0.7683 val_loss=0.0000 scale=1.0000 norm=0.4865
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.1221
[iter 200] loss=-0.4233 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 300] loss=-1.1907 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 400] loss=-1.9869 val_loss=0.0000 scale=4.0000 norm=2.0032
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3769 val_loss=0.0000 scale=2.0000 norm=1.0246
[iter 200] loss=-0.3292 val_loss=0.0000 scale=2.0000 norm=0.9122
[iter 300] loss=-0.9086 val_loss=0.0000 scale=2.0000 norm=0.8392
[iter 400] loss=-1.3588 val_loss=0.0000 scale=2.0000 norm=0.7762
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4562 val_loss=0.0000 scale=2.0000 norm=1.0856
[iter 200] loss=-0.0611 val_loss=0.0000 scale=2.0000 norm=1.0066
[iter 300] loss=-0.4560 val_loss=0.0000 scale=2.0000 norm=0.9609
[iter 400] loss=-0.6795 val_loss=0.0000 scale=1.0000 norm=0.4613
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4025 val_loss=0.0000 scale=2.0000 norm=1.0355
[iter 200] loss=-0.3840 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 300] loss=-1.0661 val_loss=0.0000 scale=2.0000 norm=0.8735
[iter 400] loss=-1.5798 val_loss=0.0000 scale=1.0000 norm=0.4123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3517 val_loss=0.0000 scale=2.0000 norm=1.0642
[iter 200] loss=-0.2214 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 300] loss=-0.6215 val_loss=0.0000 scale=1.0000 norm=0.4701
[iter 400] loss=-0.8491 val_loss=0.0000 scale=1.0000 norm=0.4511
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4509 val_loss=0.0000 scale=2.0000 norm=1.1232
[iter 200] loss=-0.1758 val_loss=0.0000 scale=2.0000 norm=0.9959
[iter 300] loss=-0.6557 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 400] loss=-0.9621 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2686 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 200] loss=-0.3784 val_loss=0.0000 scale=2.0000 norm=0.9283
[iter 300] loss=-0.8500 val_loss=0.0000 scale=2.0000 norm=0.9337
[iter 400] loss=-1.1769 val_loss=0.0000 scale=2.0000 norm=0.9006
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3911 val_loss=0.0000 scale=2.0000 norm=1.0888
[iter 200] loss=-0.1359 val_loss=0.0000 scale=2.0000 norm=0.9830
[iter 300] loss=-0.5091 val_loss=0.0000 scale=2.0000 norm=0.9445
[iter 400] loss=-0.7824 val_loss=0.0000 scale=2.0000 norm=0.9194
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2368 val_loss=0.0000 scale=2.0000 norm=0.9736
[iter 200] loss=-0.7242 val_loss=0.0000 scale=2.0000 norm=0.9565
[iter 300] loss=-1.6317 val_loss=0.0000 scale=2.0000 norm=0.9033
[iter 400] loss=-2.4298 val_loss=0.0000 scale=2.0000 norm=0.8041
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3781 val_loss=0.0000 scale=2.0000 norm=1.0680
[iter 200] loss=-0.1754 val_loss=0.0000 scale=1.0000 norm=0.4898
[iter 300] loss=-0.5371 val_loss=0.0000 scale=2.0000 norm=0.9602
[iter 400] loss=-0.7839 val_loss=0.0000 scale=2.0000 norm=0.9431
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2329 val_loss=0.0000 scale=2.0000 norm=0.9850
[iter 200] loss=-0.5277 val_loss=0.0000 scale=2.0000 norm=0.8885
[iter 300] loss=-1.1463 val_loss=0.0000 scale=2.0000 norm=0.8176
[iter 400] loss=-1.5870 val_loss=0.0000 scale=2.0000 norm=0.7562
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3548 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.3376 val_loss=0.0000 scale=2.0000 norm=0.9466
[iter 300] loss=-0.8288 val_loss=0.0000 scale=2.0000 norm=0.9325
[iter 400] loss=-1.1464 val_loss=0.0000 scale=1.0000 norm=0.4626
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3442 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.3005 val_loss=0.0000 scale=2.0000 norm=0.9833
[iter 300] loss=-0.8176 val_loss=0.0000 scale=2.0000 norm=0.9431
[iter 400] loss=-1.1030 val_loss=0.0000 scale=1.0000 norm=0.4533
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3735 val_loss=0.0000 scale=2.0000 norm=1.0717
[iter 200] loss=-0.2142 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 300] loss=-0.6458 val_loss=0.0000 scale=2.0000 norm=0.9524
[iter 400] loss=-0.9074 val_loss=0.0000 scale=1.0000 norm=0.4611
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5747 val_loss=0.0000 scale=2.0000 norm=1.1141
[iter 200] loss=-0.0390 val_loss=0.0000 scale=2.0000 norm=1.0388
[iter 300] loss=-0.5778 val_loss=0.0000 scale=2.0000 norm=0.9928
[iter 400] loss=-0.9723 val_loss=0.0000 scale=2.0000 norm=0.9376
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3380 val_loss=0.0000 scale=2.0000 norm=1.0311
[iter 200] loss=-0.2895 val_loss=0.0000 scale=2.0000 norm=0.9510
[iter 300] loss=-0.7195 val_loss=0.0000 scale=2.0000 norm=0.9177
[iter 400] loss=-1.0038 val_loss=0.0000 scale=1.0000 norm=0.4440
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2724 val_loss=0.0000 scale=2.0000 norm=1.0119
[iter 200] loss=-0.4077 val_loss=0.0000 scale=2.0000 norm=0.9163
[iter 300] loss=-0.8681 val_loss=0.0000 scale=1.0000 norm=0.4363
[iter 400] loss=-1.1937 val_loss=0.0000 scale=2.0000 norm=0.8238
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3002 val_loss=0.0000 scale=2.0000 norm=1.0358
[iter 200] loss=-0.2928 val_loss=0.0000 scale=2.0000 norm=0.9571
[iter 300] loss=-0.7757 val_loss=0.0000 scale=2.0000 norm=0.9167
[iter 400] loss=-1.1144 val_loss=0.0000 scale=2.0000 norm=0.8643
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2933 val_loss=0.0000 scale=2.0000 norm=1.0442
[iter 200] loss=-0.3403 val_loss=0.0000 scale=1.0000 norm=0.4825
[iter 300] loss=-0.8188 val_loss=0.0000 scale=2.0000 norm=0.9196
[iter 400] loss=-1.1431 val_loss=0.0000 scale=1.0000 norm=0.4433
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3398 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 200] loss=-0.3195 val_loss=0.0000 scale=2.0000 norm=0.9580
[iter 300] loss=-0.8285 val_loss=0.0000 scale=2.0000 norm=0.8928
[iter 400] loss=-1.1380 val_loss=0.0000 scale=2.0000 norm=0.8525
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2439 val_loss=0.0000 scale=2.0000 norm=0.9784
[iter 200] loss=-0.7072 val_loss=0.0000 scale=2.0000 norm=0.9486
[iter 300] loss=-1.8095 val_loss=0.0000 scale=4.0000 norm=1.7190
[iter 400] loss=-3.1341 val_loss=0.0000 scale=2.0000 norm=0.8654
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5716 val_loss=0.0000 scale=2.0000 norm=1.1303
[iter 200] loss=-0.0637 val_loss=0.0000 scale=2.0000 norm=1.0198
[iter 300] loss=-0.6437 val_loss=0.0000 scale=2.0000 norm=0.9779
[iter 400] loss=-1.1358 val_loss=0.0000 scale=2.0000 norm=0.9538
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2378 val_loss=0.0000 scale=2.0000 norm=0.9930
[iter 200] loss=-0.5161 val_loss=0.0000 scale=2.0000 norm=0.9493
[iter 300] loss=-1.1620 val_loss=0.0000 scale=2.0000 norm=0.8863
[iter 400] loss=-1.6594 val_loss=0.0000 scale=2.0000 norm=0.8449
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3291 val_loss=0.0000 scale=2.0000 norm=1.0335
[iter 200] loss=-0.2829 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 300] loss=-0.6888 val_loss=0.0000 scale=2.0000 norm=0.9444
[iter 400] loss=-0.9382 val_loss=0.0000 scale=1.0000 norm=0.4605
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4324 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.2035 val_loss=0.0000 scale=2.0000 norm=0.9237
[iter 300] loss=-0.6685 val_loss=0.0000 scale=2.0000 norm=0.9093
[iter 400] loss=-0.9758 val_loss=0.0000 scale=2.0000 norm=0.8767
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3085 val_loss=0.0000 scale=2.0000 norm=0.9616
[iter 200] loss=-0.5743 val_loss=0.0000 scale=2.0000 norm=0.8944
[iter 300] loss=-1.3879 val_loss=0.0000 scale=2.0000 norm=0.8403
[iter 400] loss=-2.1195 val_loss=0.0000 scale=2.0000 norm=0.8069
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2824 val_loss=0.0000 scale=2.0000 norm=1.0028
[iter 200] loss=-0.3948 val_loss=0.0000 scale=2.0000 norm=0.9137
[iter 300] loss=-0.8634 val_loss=0.0000 scale=1.0000 norm=0.4320
[iter 400] loss=-1.0870 val_loss=0.0000 scale=2.0000 norm=0.8605
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2958 val_loss=0.0000 scale=2.0000 norm=1.0240
[iter 200] loss=-0.3247 val_loss=0.0000 scale=2.0000 norm=0.9213
[iter 300] loss=-0.7128 val_loss=0.0000 scale=1.0000 norm=0.4579
[iter 400] loss=-0.9955 val_loss=0.0000 scale=1.0000 norm=0.4465
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3665 val_loss=0.0000 scale=2.0000 norm=1.0794
[iter 200] loss=-0.2681 val_loss=0.0000 scale=2.0000 norm=1.0002
[iter 300] loss=-0.7863 val_loss=0.0000 scale=1.0000 norm=0.4748
[iter 400] loss=-1.0930 val_loss=0.0000 scale=1.0000 norm=0.4420
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3816 val_loss=0.0000 scale=2.0000 norm=1.0722
[iter 200] loss=-0.1999 val_loss=0.0000 scale=2.0000 norm=0.9811
[iter 300] loss=-0.5892 val_loss=0.0000 scale=1.0000 norm=0.4723
[iter 400] loss=-0.8283 val_loss=0.0000 scale=1.0000 norm=0.4616
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7414 val_loss=0.0000 scale=2.0000 norm=1.2217
[iter 200] loss=0.1799 val_loss=0.0000 scale=2.0000 norm=1.0659
[iter 300] loss=-0.3257 val_loss=0.0000 scale=2.0000 norm=1.0260
[iter 400] loss=-0.7618 val_loss=0.0000 scale=2.0000 norm=0.9551
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4406 val_loss=0.0000 scale=2.0000 norm=1.1174
[iter 200] loss=-0.0969 val_loss=0.0000 scale=2.0000 norm=0.9984
[iter 300] loss=-0.4557 val_loss=0.0000 scale=1.0000 norm=0.4832
[iter 400] loss=-0.6589 val_loss=0.0000 scale=1.0000 norm=0.4668
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2873 val_loss=0.0000 scale=2.0000 norm=1.0045
[iter 200] loss=-0.3299 val_loss=0.0000 scale=2.0000 norm=0.8864
[iter 300] loss=-0.6912 val_loss=0.0000 scale=2.0000 norm=0.8100
[iter 400] loss=-0.9370 val_loss=0.0000 scale=1.0000 norm=0.4003
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1632 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 200] loss=-0.7202 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 300] loss=-1.6585 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 400] loss=-2.4149 val_loss=0.0000 scale=2.0000 norm=0.8695
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2449 val_loss=0.0000 scale=2.0000 norm=0.9866
[iter 200] loss=-0.4209 val_loss=0.0000 scale=2.0000 norm=0.9093
[iter 300] loss=-0.8610 val_loss=0.0000 scale=2.0000 norm=0.8748
[iter 400] loss=-1.1671 val_loss=0.0000 scale=2.0000 norm=0.8367
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3657 val_loss=0.0000 scale=2.0000 norm=1.0547
[iter 200] loss=-0.2883 val_loss=0.0000 scale=2.0000 norm=0.9603
[iter 300] loss=-0.8128 val_loss=0.0000 scale=2.0000 norm=0.9114
[iter 400] loss=-1.1555 val_loss=0.0000 scale=2.0000 norm=0.8822
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4065 val_loss=0.0000 scale=2.0000 norm=1.0505
[iter 200] loss=-0.1676 val_loss=0.0000 scale=2.0000 norm=0.9476
[iter 300] loss=-0.5333 val_loss=0.0000 scale=2.0000 norm=0.9074
[iter 400] loss=-0.7760 val_loss=0.0000 scale=1.0000 norm=0.4455
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1494 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.6702 val_loss=0.0000 scale=2.0000 norm=0.8971
[iter 300] loss=-1.3867 val_loss=0.0000 scale=2.0000 norm=0.8129
[iter 400] loss=-1.9899 val_loss=0.0000 scale=2.0000 norm=0.8181
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2165 val_loss=0.0000 scale=2.0000 norm=0.9795
[iter 200] loss=-0.6747 val_loss=0.0000 scale=2.0000 norm=0.9392
[iter 300] loss=-1.5122 val_loss=0.0000 scale=2.0000 norm=0.9010
[iter 400] loss=-2.3151 val_loss=0.0000 scale=2.0000 norm=0.8486
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3192 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.2867 val_loss=0.0000 scale=2.0000 norm=0.9522
[iter 300] loss=-0.7091 val_loss=0.0000 scale=2.0000 norm=0.9402
[iter 400] loss=-0.9680 val_loss=0.0000 scale=2.0000 norm=0.9116
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2945 val_loss=0.0000 scale=2.0000 norm=1.0249
[iter 200] loss=-0.3667 val_loss=0.0000 scale=2.0000 norm=0.9330
[iter 300] loss=-0.8813 val_loss=0.0000 scale=2.0000 norm=0.9142
[iter 400] loss=-1.3027 val_loss=0.0000 scale=1.0000 norm=0.4376
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2362 val_loss=0.0000 scale=2.0000 norm=1.0177
[iter 200] loss=-0.3970 val_loss=0.0000 scale=2.0000 norm=0.9721
[iter 300] loss=-0.9087 val_loss=0.0000 scale=2.0000 norm=0.9381
[iter 400] loss=-1.2303 val_loss=0.0000 scale=2.0000 norm=0.8862
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1875 val_loss=0.0000 scale=2.0000 norm=0.9823
[iter 200] loss=-0.6109 val_loss=0.0000 scale=2.0000 norm=0.9512
[iter 300] loss=-1.3202 val_loss=0.0000 scale=2.0000 norm=0.9045
[iter 400] loss=-1.9289 val_loss=0.0000 scale=2.0000 norm=0.8667
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3973 val_loss=0.0000 scale=2.0000 norm=1.0586
[iter 200] loss=-0.1700 val_loss=0.0000 scale=2.0000 norm=0.9526
[iter 300] loss=-0.6070 val_loss=0.0000 scale=2.0000 norm=0.8859
[iter 400] loss=-0.9043 val_loss=0.0000 scale=2.0000 norm=0.8443
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3655 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.4351 val_loss=0.0000 scale=2.0000 norm=1.0192
[iter 300] loss=-1.2732 val_loss=0.0000 scale=2.0000 norm=1.0588
[iter 400] loss=-2.0453 val_loss=0.0000 scale=2.0000 norm=1.0588
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4803 val_loss=0.0000 scale=2.0000 norm=1.1090
[iter 200] loss=-0.0937 val_loss=0.0000 scale=2.0000 norm=0.9964
[iter 300] loss=-0.5182 val_loss=0.0000 scale=2.0000 norm=0.9135
[iter 400] loss=-0.7950 val_loss=0.0000 scale=1.0000 norm=0.4704
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4257 val_loss=0.0000 scale=2.0000 norm=1.1105
[iter 200] loss=-0.1701 val_loss=0.0000 scale=2.0000 norm=0.9990
[iter 300] loss=-0.6658 val_loss=0.0000 scale=1.0000 norm=0.4727
[iter 400] loss=-1.0163 val_loss=0.0000 scale=2.0000 norm=0.9080
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5719 val_loss=0.0000 scale=2.0000 norm=1.0968
[iter 200] loss=-0.2147 val_loss=0.0000 scale=2.0000 norm=0.9732
[iter 300] loss=-0.8712 val_loss=0.0000 scale=2.0000 norm=0.9328
[iter 400] loss=-1.3648 val_loss=0.0000 scale=2.0000 norm=0.9450
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4030 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 200] loss=-0.2067 val_loss=0.0000 scale=1.0000 norm=0.4795
[iter 300] loss=-0.6132 val_loss=0.0000 scale=1.0000 norm=0.4620
[iter 400] loss=-0.8700 val_loss=0.0000 scale=2.0000 norm=0.8836
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4143 val_loss=0.0000 scale=1.0000 norm=0.5325
[iter 200] loss=-0.0991 val_loss=0.0000 scale=1.0000 norm=0.4922
[iter 300] loss=-0.4208 val_loss=0.0000 scale=1.0000 norm=0.4762
[iter 400] loss=-0.6650 val_loss=0.0000 scale=1.0000 norm=0.4626
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3297 val_loss=0.0000 scale=2.0000 norm=1.0531
[iter 200] loss=-0.3052 val_loss=0.0000 scale=2.0000 norm=0.9657
[iter 300] loss=-0.7883 val_loss=0.0000 scale=2.0000 norm=0.9552
[iter 400] loss=-1.0414 val_loss=0.0000 scale=2.0000 norm=0.9151
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4430 val_loss=0.0000 scale=2.0000 norm=1.0797
[iter 200] loss=-0.1962 val_loss=0.0000 scale=2.0000 norm=0.9531
[iter 300] loss=-0.6548 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 400] loss=-0.9188 val_loss=0.0000 scale=1.0000 norm=0.4403
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4560 val_loss=0.0000 scale=2.0000 norm=1.0799
[iter 200] loss=-0.1310 val_loss=0.0000 scale=2.0000 norm=0.9853
[iter 300] loss=-0.5497 val_loss=0.0000 scale=2.0000 norm=0.9296
[iter 400] loss=-0.8200 val_loss=0.0000 scale=1.0000 norm=0.4688
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4329 val_loss=0.0000 scale=2.0000 norm=1.1120
[iter 200] loss=-0.2092 val_loss=0.0000 scale=1.0000 norm=0.4999
[iter 300] loss=-0.6716 val_loss=0.0000 scale=2.0000 norm=0.9728
[iter 400] loss=-1.0292 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3132 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.3180 val_loss=0.0000 scale=2.0000 norm=0.9967
[iter 300] loss=-0.8209 val_loss=0.0000 scale=2.0000 norm=0.9804
[iter 400] loss=-1.1375 val_loss=0.0000 scale=2.0000 norm=0.9803
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3628 val_loss=0.0000 scale=2.0000 norm=1.0401
[iter 200] loss=-0.2212 val_loss=0.0000 scale=2.0000 norm=0.9401
[iter 300] loss=-0.6328 val_loss=0.0000 scale=2.0000 norm=0.9297
[iter 400] loss=-0.8904 val_loss=0.0000 scale=2.0000 norm=0.8836
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4800 val_loss=0.0000 scale=2.0000 norm=1.1226
[iter 200] loss=-0.0891 val_loss=0.0000 scale=2.0000 norm=1.0305
[iter 300] loss=-0.5325 val_loss=0.0000 scale=2.0000 norm=0.9717
[iter 400] loss=-0.8158 val_loss=0.0000 scale=1.0000 norm=0.4647
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3601 val_loss=0.0000 scale=2.0000 norm=1.0471
[iter 200] loss=-0.2494 val_loss=0.0000 scale=1.0000 norm=0.4635
[iter 300] loss=-0.6202 val_loss=0.0000 scale=2.0000 norm=0.9040
[iter 400] loss=-0.8380 val_loss=0.0000 scale=2.0000 norm=0.8954
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4463 val_loss=0.0000 scale=2.0000 norm=1.0817
[iter 200] loss=-0.0945 val_loss=0.0000 scale=2.0000 norm=0.9658
[iter 300] loss=-0.4740 val_loss=0.0000 scale=2.0000 norm=0.9208
[iter 400] loss=-0.7172 val_loss=0.0000 scale=2.0000 norm=0.9197
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2692 val_loss=0.0000 scale=2.0000 norm=1.0339
[iter 200] loss=-0.3816 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 300] loss=-0.8972 val_loss=0.0000 scale=2.0000 norm=0.9454
[iter 400] loss=-1.2081 val_loss=0.0000 scale=2.0000 norm=0.8873
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3567 val_loss=0.0000 scale=2.0000 norm=1.0606
[iter 200] loss=-0.2261 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 300] loss=-0.5751 val_loss=0.0000 scale=2.0000 norm=0.9660
[iter 400] loss=-0.8241 val_loss=0.0000 scale=2.0000 norm=0.9190
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4101 val_loss=0.0000 scale=2.0000 norm=1.1325
[iter 200] loss=-0.1787 val_loss=0.0000 scale=2.0000 norm=1.0794
[iter 300] loss=-0.6470 val_loss=0.0000 scale=2.0000 norm=1.0610
[iter 400] loss=-1.0077 val_loss=0.0000 scale=2.0000 norm=1.0261
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3009 val_loss=0.0000 scale=2.0000 norm=1.0371
[iter 200] loss=-0.3287 val_loss=0.0000 scale=2.0000 norm=0.9470
[iter 300] loss=-0.8262 val_loss=0.0000 scale=2.0000 norm=0.8733
[iter 400] loss=-1.1402 val_loss=0.0000 scale=2.0000 norm=0.8656
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3417 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.2205 val_loss=0.0000 scale=2.0000 norm=0.9343
[iter 300] loss=-0.5725 val_loss=0.0000 scale=1.0000 norm=0.4369
[iter 400] loss=-0.8372 val_loss=0.0000 scale=1.0000 norm=0.4249
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3454 val_loss=0.0000 scale=2.0000 norm=1.0435
[iter 200] loss=-0.2403 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-0.6520 val_loss=0.0000 scale=2.0000 norm=0.9154
[iter 400] loss=-0.9273 val_loss=0.0000 scale=1.0000 norm=0.4540
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3366 val_loss=0.0000 scale=2.0000 norm=1.0341
[iter 200] loss=-0.3152 val_loss=0.0000 scale=2.0000 norm=0.9636
[iter 300] loss=-0.8100 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-1.1554 val_loss=0.0000 scale=2.0000 norm=0.8844
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3239 val_loss=0.0000 scale=2.0000 norm=1.0208
[iter 200] loss=-0.2960 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 300] loss=-0.7455 val_loss=0.0000 scale=2.0000 norm=0.8910
[iter 400] loss=-0.9863 val_loss=0.0000 scale=1.0000 norm=0.4266
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3487 val_loss=0.0000 scale=2.0000 norm=1.0948
[iter 200] loss=-0.2583 val_loss=0.0000 scale=2.0000 norm=0.9521
[iter 300] loss=-0.6587 val_loss=0.0000 scale=1.0000 norm=0.4305
[iter 400] loss=-0.9504 val_loss=0.0000 scale=2.0000 norm=0.8072
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3331 val_loss=0.0000 scale=2.0000 norm=1.0655
[iter 200] loss=-0.3088 val_loss=0.0000 scale=2.0000 norm=0.9589
[iter 300] loss=-0.7266 val_loss=0.0000 scale=2.0000 norm=0.9010
[iter 400] loss=-0.9754 val_loss=0.0000 scale=1.0000 norm=0.4285
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3966 val_loss=0.0000 scale=2.0000 norm=1.0745
[iter 200] loss=-0.1666 val_loss=0.0000 scale=2.0000 norm=0.9656
[iter 300] loss=-0.5814 val_loss=0.0000 scale=1.0000 norm=0.4622
[iter 400] loss=-0.8480 val_loss=0.0000 scale=1.0000 norm=0.4652
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2709 val_loss=0.0000 scale=2.0000 norm=1.0253
[iter 200] loss=-0.3763 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 300] loss=-0.8804 val_loss=0.0000 scale=2.0000 norm=0.8640
[iter 400] loss=-1.2358 val_loss=0.0000 scale=1.0000 norm=0.4216
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3135 val_loss=0.0000 scale=2.0000 norm=1.0470
[iter 200] loss=-0.2683 val_loss=0.0000 scale=2.0000 norm=0.9683
[iter 300] loss=-0.7084 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 400] loss=-0.9778 val_loss=0.0000 scale=1.0000 norm=0.4565
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3485 val_loss=0.0000 scale=2.0000 norm=1.0484
[iter 200] loss=-0.2914 val_loss=0.0000 scale=2.0000 norm=0.9474
[iter 300] loss=-0.7857 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 400] loss=-1.1224 val_loss=0.0000 scale=2.0000 norm=0.9116
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2159 val_loss=0.0000 scale=2.0000 norm=0.9958
[iter 200] loss=-0.5428 val_loss=0.0000 scale=2.0000 norm=0.9246
[iter 300] loss=-1.2345 val_loss=0.0000 scale=2.0000 norm=0.8986
[iter 400] loss=-1.8204 val_loss=0.0000 scale=2.0000 norm=0.9339
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3488 val_loss=0.0000 scale=2.0000 norm=1.0600
[iter 200] loss=-0.2970 val_loss=0.0000 scale=2.0000 norm=0.9964
[iter 300] loss=-0.8144 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 400] loss=-1.1401 val_loss=0.0000 scale=1.0000 norm=0.4581
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5101 val_loss=0.0000 scale=2.0000 norm=1.1344
[iter 200] loss=0.0162 val_loss=0.0000 scale=2.0000 norm=1.0034
[iter 300] loss=-0.2615 val_loss=0.0000 scale=1.0000 norm=0.4699
[iter 400] loss=-0.4394 val_loss=0.0000 scale=1.0000 norm=0.4537
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3180 val_loss=0.0000 scale=2.0000 norm=1.0356
[iter 200] loss=-0.2630 val_loss=0.0000 scale=2.0000 norm=0.9493
[iter 300] loss=-0.7274 val_loss=0.0000 scale=2.0000 norm=0.9052
[iter 400] loss=-1.0164 val_loss=0.0000 scale=1.0000 norm=0.4448
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2889 val_loss=0.0000 scale=2.0000 norm=1.0210
[iter 200] loss=-0.4428 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 300] loss=-1.0539 val_loss=0.0000 scale=2.0000 norm=0.8880
[iter 400] loss=-1.5248 val_loss=0.0000 scale=2.0000 norm=0.8673
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3404 val_loss=0.0000 scale=2.0000 norm=1.0557
[iter 200] loss=-0.2482 val_loss=0.0000 scale=2.0000 norm=0.9588
[iter 300] loss=-0.6778 val_loss=0.0000 scale=2.0000 norm=0.9374
[iter 400] loss=-0.9515 val_loss=0.0000 scale=2.0000 norm=0.9255
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3124 val_loss=0.0000 scale=2.0000 norm=1.0334
[iter 200] loss=-0.4248 val_loss=0.0000 scale=2.0000 norm=0.9338
[iter 300] loss=-0.9926 val_loss=0.0000 scale=2.0000 norm=0.8988
[iter 400] loss=-1.5158 val_loss=0.0000 scale=2.0000 norm=0.8499
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4669 val_loss=0.0000 scale=2.0000 norm=1.0890
[iter 200] loss=-0.0879 val_loss=0.0000 scale=2.0000 norm=0.9836
[iter 300] loss=-0.4677 val_loss=0.0000 scale=2.0000 norm=0.9407
[iter 400] loss=-0.6741 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3433 val_loss=0.0000 scale=2.0000 norm=0.9984
[iter 200] loss=-0.4728 val_loss=0.0000 scale=2.0000 norm=0.9248
[iter 300] loss=-1.2101 val_loss=0.0000 scale=2.0000 norm=0.8834
[iter 400] loss=-1.8679 val_loss=0.0000 scale=2.0000 norm=0.8325
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5269 val_loss=0.0000 scale=2.0000 norm=1.1597
[iter 200] loss=0.0349 val_loss=0.0000 scale=2.0000 norm=1.0747
[iter 300] loss=-0.3708 val_loss=0.0000 scale=2.0000 norm=1.0261
[iter 400] loss=-0.6099 val_loss=0.0000 scale=1.0000 norm=0.5013
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4643 val_loss=0.0000 scale=2.0000 norm=1.0989
[iter 200] loss=-0.2565 val_loss=0.0000 scale=2.0000 norm=1.0355
[iter 300] loss=-0.8643 val_loss=0.0000 scale=2.0000 norm=1.0329
[iter 400] loss=-1.3405 val_loss=0.0000 scale=2.0000 norm=1.0773
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2855 val_loss=0.0000 scale=2.0000 norm=1.0044
[iter 200] loss=-0.3565 val_loss=0.0000 scale=2.0000 norm=0.9456
[iter 300] loss=-0.8253 val_loss=0.0000 scale=1.0000 norm=0.4713
[iter 400] loss=-1.1030 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2881 val_loss=0.0000 scale=2.0000 norm=1.0431
[iter 200] loss=-0.3667 val_loss=0.0000 scale=2.0000 norm=0.9245
[iter 300] loss=-0.8708 val_loss=0.0000 scale=2.0000 norm=0.8385
[iter 400] loss=-1.2681 val_loss=0.0000 scale=1.0000 norm=0.4092
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5955 val_loss=0.0000 scale=2.0000 norm=1.1282
[iter 200] loss=0.1858 val_loss=0.0000 scale=2.0000 norm=1.0161
[iter 300] loss=-0.1494 val_loss=0.0000 scale=1.0000 norm=0.4851
[iter 400] loss=-0.3378 val_loss=0.0000 scale=2.0000 norm=0.9309
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2152 val_loss=0.0000 scale=2.0000 norm=1.0179
[iter 200] loss=-0.4774 val_loss=0.0000 scale=2.0000 norm=0.9896
[iter 300] loss=-1.0111 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 400] loss=-1.3931 val_loss=0.0000 scale=2.0000 norm=0.8686
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3723 val_loss=0.0000 scale=2.0000 norm=1.0589
[iter 200] loss=-0.1998 val_loss=0.0000 scale=2.0000 norm=0.9613
[iter 300] loss=-0.6293 val_loss=0.0000 scale=1.0000 norm=0.4594
[iter 400] loss=-0.8757 val_loss=0.0000 scale=0.5000 norm=0.2199
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1439 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 200] loss=-0.7155 val_loss=0.0000 scale=2.0000 norm=0.8878
[iter 300] loss=-1.4576 val_loss=0.0000 scale=2.0000 norm=0.8505
[iter 400] loss=-1.9842 val_loss=0.0000 scale=2.0000 norm=0.8027
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3558 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.2461 val_loss=0.0000 scale=2.0000 norm=0.9292
[iter 300] loss=-0.6605 val_loss=0.0000 scale=2.0000 norm=0.9105
[iter 400] loss=-0.9430 val_loss=0.0000 scale=2.0000 norm=0.9089
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2771 val_loss=0.0000 scale=2.0000 norm=0.9574
[iter 200] loss=-0.6376 val_loss=0.0000 scale=2.0000 norm=0.9264
[iter 300] loss=-1.5219 val_loss=0.0000 scale=2.0000 norm=0.8820
[iter 400] loss=-2.3272 val_loss=0.0000 scale=2.0000 norm=0.8272
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6857 val_loss=0.0000 scale=2.0000 norm=1.1424
[iter 200] loss=0.0238 val_loss=0.0000 scale=2.0000 norm=0.9028
[iter 300] loss=-0.6590 val_loss=0.0000 scale=1.0000 norm=0.3961
[iter 400] loss=-1.1698 val_loss=0.0000 scale=2.0000 norm=0.7767
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3190 val_loss=0.0000 scale=2.0000 norm=1.0274
[iter 200] loss=-0.2831 val_loss=0.0000 scale=2.0000 norm=0.9373
[iter 300] loss=-0.6728 val_loss=0.0000 scale=2.0000 norm=0.9058
[iter 400] loss=-0.9161 val_loss=0.0000 scale=2.0000 norm=0.8806
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4421 val_loss=0.0000 scale=2.0000 norm=1.1137
[iter 200] loss=-0.1215 val_loss=0.0000 scale=2.0000 norm=0.9915
[iter 300] loss=-0.5119 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 400] loss=-0.7412 val_loss=0.0000 scale=2.0000 norm=0.9040
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3735 val_loss=0.0000 scale=2.0000 norm=1.0717
[iter 200] loss=-0.2492 val_loss=0.0000 scale=2.0000 norm=0.9636
[iter 300] loss=-0.6628 val_loss=0.0000 scale=1.0000 norm=0.4592
[iter 400] loss=-0.9516 val_loss=0.0000 scale=0.5000 norm=0.2164
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3824 val_loss=0.0000 scale=2.0000 norm=1.0406
[iter 200] loss=-0.1780 val_loss=0.0000 scale=2.0000 norm=0.9415
[iter 300] loss=-0.5132 val_loss=0.0000 scale=2.0000 norm=0.8971
[iter 400] loss=-0.7697 val_loss=0.0000 scale=1.0000 norm=0.4247
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3812 val_loss=0.0000 scale=2.0000 norm=1.0596
[iter 200] loss=-0.1616 val_loss=0.0000 scale=2.0000 norm=0.9651
[iter 300] loss=-0.5400 val_loss=0.0000 scale=2.0000 norm=0.9321
[iter 400] loss=-0.7947 val_loss=0.0000 scale=2.0000 norm=0.8988
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3869 val_loss=0.0000 scale=2.0000 norm=1.0473
[iter 200] loss=-0.2063 val_loss=0.0000 scale=2.0000 norm=0.9466
[iter 300] loss=-0.6105 val_loss=0.0000 scale=1.0000 norm=0.4423
[iter 400] loss=-0.8357 val_loss=0.0000 scale=2.0000 norm=0.8632
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1698 val_loss=0.0000 scale=2.0000 norm=0.9719
[iter 200] loss=-0.7635 val_loss=0.0000 scale=2.0000 norm=0.9322
[iter 300] loss=-1.6120 val_loss=0.0000 scale=2.0000 norm=0.8895
[iter 400] loss=-2.3996 val_loss=0.0000 scale=2.0000 norm=0.9172
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6336 val_loss=0.0000 scale=2.0000 norm=1.1566
[iter 200] loss=0.0028 val_loss=0.0000 scale=2.0000 norm=1.0344
[iter 300] loss=-0.5154 val_loss=0.0000 scale=2.0000 norm=1.0364
[iter 400] loss=-0.9455 val_loss=0.0000 scale=2.0000 norm=0.9885
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3688 val_loss=0.0000 scale=2.0000 norm=1.0476
[iter 200] loss=-0.2336 val_loss=0.0000 scale=1.0000 norm=0.4863
[iter 300] loss=-0.6801 val_loss=0.0000 scale=2.0000 norm=0.9311
[iter 400] loss=-0.9385 val_loss=0.0000 scale=1.0000 norm=0.4747
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4053 val_loss=0.0000 scale=2.0000 norm=1.0718
[iter 200] loss=-0.1460 val_loss=0.0000 scale=2.0000 norm=0.9525
[iter 300] loss=-0.5041 val_loss=0.0000 scale=1.0000 norm=0.4595
[iter 400] loss=-0.7278 val_loss=0.0000 scale=2.0000 norm=0.8950
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4896 val_loss=0.0000 scale=2.0000 norm=1.1150
[iter 200] loss=-0.1056 val_loss=0.0000 scale=1.0000 norm=0.4991
[iter 300] loss=-0.5496 val_loss=0.0000 scale=1.0000 norm=0.4694
[iter 400] loss=-0.8271 val_loss=0.0000 scale=1.0000 norm=0.4559
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0525 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 200] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-1.8273 val_loss=0.0000 scale=2.0000 norm=0.9106
[iter 400] loss=-2.8309 val_loss=0.0000 scale=2.0000 norm=0.8464
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3647 val_loss=0.0000 scale=2.0000 norm=1.0413
[iter 200] loss=-0.2197 val_loss=0.0000 scale=2.0000 norm=0.9326
[iter 300] loss=-0.6314 val_loss=0.0000 scale=2.0000 norm=0.8983
[iter 400] loss=-0.8598 val_loss=0.0000 scale=1.0000 norm=0.4428
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4821 val_loss=0.0000 scale=2.0000 norm=1.1892
[iter 200] loss=-0.2086 val_loss=0.0000 scale=2.0000 norm=1.1360
[iter 300] loss=-0.7535 val_loss=0.0000 scale=2.0000 norm=1.0481
[iter 400] loss=-1.1155 val_loss=0.0000 scale=2.0000 norm=1.0827
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5078 val_loss=0.0000 scale=2.0000 norm=1.1229
[iter 200] loss=0.0916 val_loss=0.0000 scale=2.0000 norm=1.0011
[iter 300] loss=-0.2322 val_loss=0.0000 scale=1.0000 norm=0.4585
[iter 400] loss=-0.4270 val_loss=0.0000 scale=1.0000 norm=0.4468
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2889 val_loss=0.0000 scale=2.0000 norm=1.0283
[iter 200] loss=-0.3773 val_loss=0.0000 scale=2.0000 norm=0.9372
[iter 300] loss=-0.8919 val_loss=0.0000 scale=2.0000 norm=0.8658
[iter 400] loss=-1.2005 val_loss=0.0000 scale=1.0000 norm=0.4197
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5495 val_loss=0.0000 scale=2.0000 norm=1.1964
[iter 200] loss=-0.0169 val_loss=0.0000 scale=2.0000 norm=1.0810
[iter 300] loss=-0.4515 val_loss=0.0000 scale=1.0000 norm=0.5116
[iter 400] loss=-0.6656 val_loss=0.0000 scale=1.0000 norm=0.5085
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3887 val_loss=0.0000 scale=2.0000 norm=1.0760
[iter 200] loss=-0.1655 val_loss=0.0000 scale=2.0000 norm=0.9753
[iter 300] loss=-0.5037 val_loss=0.0000 scale=2.0000 norm=0.9441
[iter 400] loss=-0.7285 val_loss=0.0000 scale=2.0000 norm=0.9261
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2428 val_loss=0.0000 scale=2.0000 norm=1.0025
[iter 200] loss=-0.4277 val_loss=0.0000 scale=2.0000 norm=0.9442
[iter 300] loss=-0.9387 val_loss=0.0000 scale=2.0000 norm=0.9387
[iter 400] loss=-1.2769 val_loss=0.0000 scale=2.0000 norm=0.9128
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6047 val_loss=0.0000 scale=2.0000 norm=1.1767
[iter 200] loss=-0.0764 val_loss=0.0000 scale=2.0000 norm=1.0892
[iter 300] loss=-0.6433 val_loss=0.0000 scale=2.0000 norm=1.0351
[iter 400] loss=-0.9753 val_loss=0.0000 scale=2.0000 norm=1.0713
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3018 val_loss=0.0000 scale=2.0000 norm=1.0622
[iter 200] loss=-0.4719 val_loss=0.0000 scale=2.0000 norm=0.9615
[iter 300] loss=-1.1163 val_loss=0.0000 scale=2.0000 norm=0.8769
[iter 400] loss=-1.5860 val_loss=0.0000 scale=1.0000 norm=0.4037
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3689 val_loss=0.0000 scale=2.0000 norm=1.0089
[iter 200] loss=-0.3725 val_loss=0.0000 scale=2.0000 norm=0.9233
[iter 300] loss=-1.0098 val_loss=0.0000 scale=1.0000 norm=0.4441
[iter 400] loss=-1.4820 val_loss=0.0000 scale=2.0000 norm=0.8656
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3607 val_loss=0.0000 scale=2.0000 norm=1.0428
[iter 200] loss=-0.2068 val_loss=0.0000 scale=2.0000 norm=0.9455
[iter 300] loss=-0.5743 val_loss=0.0000 scale=1.0000 norm=0.4679
[iter 400] loss=-0.7883 val_loss=0.0000 scale=1.0000 norm=0.4577
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5866 val_loss=0.0000 scale=2.0000 norm=1.1143
[iter 200] loss=-0.1323 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 300] loss=-0.8154 val_loss=0.0000 scale=2.0000 norm=1.0607
[iter 400] loss=-1.4593 val_loss=0.0000 scale=2.0000 norm=1.0201
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5189 val_loss=0.0000 scale=2.0000 norm=1.0912
[iter 200] loss=-0.0932 val_loss=0.0000 scale=2.0000 norm=1.0126
[iter 300] loss=-0.5515 val_loss=0.0000 scale=2.0000 norm=0.9356
[iter 400] loss=-0.8071 val_loss=0.0000 scale=2.0000 norm=0.8939
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3635 val_loss=0.0000 scale=2.0000 norm=1.0475
[iter 200] loss=-0.2149 val_loss=0.0000 scale=2.0000 norm=0.9446
[iter 300] loss=-0.6057 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 400] loss=-0.8342 val_loss=0.0000 scale=1.0000 norm=0.4518
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3377 val_loss=0.0000 scale=2.0000 norm=1.0478
[iter 200] loss=-0.2410 val_loss=0.0000 scale=2.0000 norm=0.9666
[iter 300] loss=-0.6378 val_loss=0.0000 scale=1.0000 norm=0.4706
[iter 400] loss=-0.8971 val_loss=0.0000 scale=1.0000 norm=0.4638
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3736 val_loss=0.0000 scale=2.0000 norm=1.0568
[iter 200] loss=-0.2068 val_loss=0.0000 scale=1.0000 norm=0.4690
[iter 300] loss=-0.5967 val_loss=0.0000 scale=2.0000 norm=0.9067
[iter 400] loss=-0.8258 val_loss=0.0000 scale=2.0000 norm=0.8851
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3025 val_loss=0.0000 scale=2.0000 norm=1.0484
[iter 200] loss=-0.3559 val_loss=0.0000 scale=2.0000 norm=0.9926
[iter 300] loss=-0.8789 val_loss=0.0000 scale=2.0000 norm=0.9469
[iter 400] loss=-1.2733 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3040 val_loss=0.0000 scale=2.0000 norm=1.0419
[iter 200] loss=-0.3378 val_loss=0.0000 scale=2.0000 norm=0.9819
[iter 300] loss=-0.8273 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-1.0983 val_loss=0.0000 scale=1.0000 norm=0.4433
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3377 val_loss=0.0000 scale=2.0000 norm=1.0423
[iter 200] loss=-0.3027 val_loss=0.0000 scale=2.0000 norm=0.9588
[iter 300] loss=-0.8042 val_loss=0.0000 scale=2.0000 norm=0.9483
[iter 400] loss=-1.1736 val_loss=0.0000 scale=1.0000 norm=0.4477
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3384 val_loss=0.0000 scale=2.0000 norm=1.0364
[iter 200] loss=-0.2623 val_loss=0.0000 scale=2.0000 norm=0.9353
[iter 300] loss=-0.6944 val_loss=0.0000 scale=2.0000 norm=0.9230
[iter 400] loss=-0.9234 val_loss=0.0000 scale=0.5000 norm=0.2238

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n12>
Subject: Job 861718: <structure_numerical_ecfp3binery_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_ecfp3binery_NGB_generalizibility> was submitted from host <c205n12> by user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:00 2024
Job was executed on host(s) <4*c207n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:38:18 2024
                            <4*c207n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Thu Oct 24 11:38:18 2024
Terminated at Thu Oct 24 11:41:29 2024
Results reported at Thu Oct 24 11:41:29 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 7:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_ecfp3binery_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py ecfp --regressor_type NGB --radius 3 --vector binary --target "Rg1 (nm)" --oligo_type "RRU Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1965.64 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.75 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   191 sec.
    Turnaround time :                            389 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err> for stderr output of this job.

RRU Trimer_scaler
Filename: (ECFP3.binary.512-Mw-PDI)_NGB_hypOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer_scaler/(ECFP3.binary.512-Mw-PDI)_NGB_hypOFF_generalizability_scores.json
Done Saving scores!
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3845 val_loss=0.0000 scale=2.0000 norm=1.1072
[iter 200] loss=-0.2510 val_loss=0.0000 scale=2.0000 norm=0.9769
[iter 300] loss=-0.7432 val_loss=0.0000 scale=2.0000 norm=0.8835
[iter 400] loss=-1.0653 val_loss=0.0000 scale=1.0000 norm=0.4242
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3510 val_loss=0.0000 scale=2.0000 norm=1.0494
[iter 200] loss=-0.2934 val_loss=0.0000 scale=2.0000 norm=0.9329
[iter 300] loss=-0.7421 val_loss=0.0000 scale=2.0000 norm=0.8785
[iter 400] loss=-1.0499 val_loss=0.0000 scale=1.0000 norm=0.4194
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2873 val_loss=0.0000 scale=2.0000 norm=1.0149
[iter 200] loss=-0.3580 val_loss=0.0000 scale=2.0000 norm=0.9149
[iter 300] loss=-0.8475 val_loss=0.0000 scale=2.0000 norm=0.8586
[iter 400] loss=-1.1578 val_loss=0.0000 scale=1.0000 norm=0.4088
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4008 val_loss=0.0000 scale=2.0000 norm=1.0645
[iter 200] loss=-0.2291 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 300] loss=-0.7144 val_loss=0.0000 scale=2.0000 norm=0.9159
[iter 400] loss=-1.0216 val_loss=0.0000 scale=1.0000 norm=0.4483
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4122 val_loss=0.0000 scale=2.0000 norm=1.0858
[iter 200] loss=-0.1754 val_loss=0.0000 scale=2.0000 norm=1.0078
[iter 300] loss=-0.5937 val_loss=0.0000 scale=2.0000 norm=0.9960
[iter 400] loss=-0.8930 val_loss=0.0000 scale=1.0000 norm=0.4762
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4304 val_loss=0.0000 scale=2.0000 norm=1.0641
[iter 200] loss=-0.3937 val_loss=0.0000 scale=2.0000 norm=1.0170
[iter 300] loss=-1.0883 val_loss=0.0000 scale=2.0000 norm=0.8882
[iter 400] loss=-1.6710 val_loss=0.0000 scale=4.0000 norm=1.6781
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3919 val_loss=0.0000 scale=2.0000 norm=1.0558
[iter 200] loss=-0.2153 val_loss=0.0000 scale=2.0000 norm=0.9228
[iter 300] loss=-0.6300 val_loss=0.0000 scale=1.0000 norm=0.4577
[iter 400] loss=-0.8797 val_loss=0.0000 scale=1.0000 norm=0.4551
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7158 val_loss=0.0000 scale=2.0000 norm=1.2267
[iter 200] loss=0.1950 val_loss=0.0000 scale=1.0000 norm=0.5385
[iter 300] loss=-0.1411 val_loss=0.0000 scale=1.0000 norm=0.5274
[iter 400] loss=-0.4084 val_loss=0.0000 scale=1.0000 norm=0.5230
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1286 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 200] loss=-0.7766 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 300] loss=-1.6605 val_loss=0.0000 scale=2.0000 norm=0.8486
[iter 400] loss=-2.9066 val_loss=0.0000 scale=4.0000 norm=1.5972
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3072 val_loss=0.0000 scale=2.0000 norm=1.0309
[iter 200] loss=-0.2958 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 300] loss=-0.6588 val_loss=0.0000 scale=2.0000 norm=0.9349
[iter 400] loss=-0.9410 val_loss=0.0000 scale=2.0000 norm=0.9222
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6204 val_loss=0.0000 scale=2.0000 norm=1.1466
[iter 200] loss=0.0516 val_loss=0.0000 scale=1.0000 norm=0.4870
[iter 300] loss=-0.3207 val_loss=0.0000 scale=1.0000 norm=0.4630
[iter 400] loss=-0.5740 val_loss=0.0000 scale=1.0000 norm=0.4649
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3861 val_loss=0.0000 scale=2.0000 norm=1.0441
[iter 200] loss=-0.3079 val_loss=0.0000 scale=2.0000 norm=0.9667
[iter 300] loss=-0.8863 val_loss=0.0000 scale=2.0000 norm=0.9305
[iter 400] loss=-1.3499 val_loss=0.0000 scale=2.0000 norm=0.9199
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4003 val_loss=0.0000 scale=2.0000 norm=1.0743
[iter 200] loss=-0.1941 val_loss=0.0000 scale=2.0000 norm=0.9614
[iter 300] loss=-0.5934 val_loss=0.0000 scale=2.0000 norm=0.9275
[iter 400] loss=-0.8677 val_loss=0.0000 scale=1.0000 norm=0.4314
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2893 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.2578 val_loss=0.0000 scale=1.0000 norm=0.4608
[iter 300] loss=-0.6606 val_loss=0.0000 scale=2.0000 norm=0.8905
[iter 400] loss=-0.9376 val_loss=0.0000 scale=2.0000 norm=0.8410
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3009 val_loss=0.0000 scale=2.0000 norm=1.0277
[iter 200] loss=-0.3242 val_loss=0.0000 scale=2.0000 norm=0.9629
[iter 300] loss=-0.7832 val_loss=0.0000 scale=2.0000 norm=0.9175
[iter 400] loss=-1.0693 val_loss=0.0000 scale=1.0000 norm=0.4441
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5166 val_loss=0.0000 scale=2.0000 norm=1.1399
[iter 200] loss=-0.0181 val_loss=0.0000 scale=2.0000 norm=1.0501
[iter 300] loss=-0.4164 val_loss=0.0000 scale=1.0000 norm=0.5046
[iter 400] loss=-0.6733 val_loss=0.0000 scale=2.0000 norm=0.9820
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2562 val_loss=0.0000 scale=2.0000 norm=1.0326
[iter 200] loss=-0.3860 val_loss=0.0000 scale=2.0000 norm=0.9684
[iter 300] loss=-0.8682 val_loss=0.0000 scale=2.0000 norm=0.9517
[iter 400] loss=-1.1452 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6267 val_loss=0.0000 scale=2.0000 norm=1.1526
[iter 200] loss=0.0015 val_loss=0.0000 scale=2.0000 norm=1.0262
[iter 300] loss=-0.5075 val_loss=0.0000 scale=2.0000 norm=1.0265
[iter 400] loss=-0.9231 val_loss=0.0000 scale=2.0000 norm=0.9880
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2388 val_loss=0.0000 scale=2.0000 norm=0.9922
[iter 200] loss=-0.5199 val_loss=0.0000 scale=2.0000 norm=0.9526
[iter 300] loss=-1.1727 val_loss=0.0000 scale=2.0000 norm=0.8920
[iter 400] loss=-1.6787 val_loss=0.0000 scale=2.0000 norm=0.8454
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3363 val_loss=0.0000 scale=2.0000 norm=0.9899
[iter 200] loss=-0.4858 val_loss=0.0000 scale=2.0000 norm=0.9138
[iter 300] loss=-1.2641 val_loss=0.0000 scale=2.0000 norm=0.8834
[iter 400] loss=-1.9979 val_loss=0.0000 scale=2.0000 norm=0.8379
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4575 val_loss=0.0000 scale=2.0000 norm=1.1121
[iter 200] loss=-0.0579 val_loss=0.0000 scale=1.0000 norm=0.4960
[iter 300] loss=-0.4337 val_loss=0.0000 scale=1.0000 norm=0.4909
[iter 400] loss=-0.7084 val_loss=0.0000 scale=2.0000 norm=0.9958
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2715 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 200] loss=-0.4553 val_loss=0.0000 scale=2.0000 norm=0.9226
[iter 300] loss=-1.0203 val_loss=0.0000 scale=2.0000 norm=0.8527
[iter 400] loss=-1.3736 val_loss=0.0000 scale=2.0000 norm=0.8307
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3620 val_loss=0.0000 scale=2.0000 norm=1.0523
[iter 200] loss=-0.1814 val_loss=0.0000 scale=1.0000 norm=0.4917
[iter 300] loss=-0.5463 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 400] loss=-0.7877 val_loss=0.0000 scale=2.0000 norm=0.9178
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3908 val_loss=0.0000 scale=2.0000 norm=1.0695
[iter 200] loss=-0.2341 val_loss=0.0000 scale=2.0000 norm=0.9540
[iter 300] loss=-0.6129 val_loss=0.0000 scale=1.0000 norm=0.4638
[iter 400] loss=-0.8624 val_loss=0.0000 scale=1.0000 norm=0.4607
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5813 val_loss=0.0000 scale=2.0000 norm=1.1987
[iter 200] loss=0.0300 val_loss=0.0000 scale=2.0000 norm=1.0485
[iter 300] loss=-0.3520 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 400] loss=-0.6209 val_loss=0.0000 scale=2.0000 norm=0.9624
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3740 val_loss=0.0000 scale=2.0000 norm=1.0468
[iter 200] loss=-0.1878 val_loss=0.0000 scale=2.0000 norm=0.9564
[iter 300] loss=-0.5728 val_loss=0.0000 scale=1.0000 norm=0.4666
[iter 400] loss=-0.8244 val_loss=0.0000 scale=1.0000 norm=0.4481
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2449 val_loss=0.0000 scale=2.0000 norm=0.9930
[iter 200] loss=-0.4202 val_loss=0.0000 scale=2.0000 norm=0.9472
[iter 300] loss=-0.9051 val_loss=0.0000 scale=2.0000 norm=0.9654
[iter 400] loss=-1.2280 val_loss=0.0000 scale=1.0000 norm=0.4695
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4242 val_loss=0.0000 scale=2.0000 norm=1.0479
[iter 200] loss=-0.3440 val_loss=0.0000 scale=2.0000 norm=0.9380
[iter 300] loss=-1.0015 val_loss=0.0000 scale=2.0000 norm=0.8622
[iter 400] loss=-1.5202 val_loss=0.0000 scale=2.0000 norm=0.7910
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3572 val_loss=0.0000 scale=2.0000 norm=1.0576
[iter 200] loss=-0.2504 val_loss=0.0000 scale=2.0000 norm=0.9759
[iter 300] loss=-0.6772 val_loss=0.0000 scale=1.0000 norm=0.4739
[iter 400] loss=-0.9157 val_loss=0.0000 scale=2.0000 norm=0.9370
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2695 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.3772 val_loss=0.0000 scale=2.0000 norm=0.9323
[iter 300] loss=-0.8748 val_loss=0.0000 scale=2.0000 norm=0.8700
[iter 400] loss=-1.2102 val_loss=0.0000 scale=2.0000 norm=0.8513
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4843 val_loss=0.0000 scale=2.0000 norm=1.1518
[iter 200] loss=-0.0290 val_loss=0.0000 scale=1.0000 norm=0.5239
[iter 300] loss=-0.4145 val_loss=0.0000 scale=1.0000 norm=0.5011
[iter 400] loss=-0.6913 val_loss=0.0000 scale=2.0000 norm=0.9628
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3565 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 200] loss=-0.3360 val_loss=0.0000 scale=2.0000 norm=0.9479
[iter 300] loss=-0.8126 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 400] loss=-1.1145 val_loss=0.0000 scale=2.0000 norm=0.9334
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4184 val_loss=0.0000 scale=2.0000 norm=1.0810
[iter 200] loss=-0.0961 val_loss=0.0000 scale=2.0000 norm=0.9718
[iter 300] loss=-0.4741 val_loss=0.0000 scale=1.0000 norm=0.4668
[iter 400] loss=-0.6853 val_loss=0.0000 scale=1.0000 norm=0.4694
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2432 val_loss=0.0000 scale=2.0000 norm=1.0173
[iter 200] loss=-0.4400 val_loss=0.0000 scale=2.0000 norm=0.9735
[iter 300] loss=-0.9855 val_loss=0.0000 scale=2.0000 norm=0.9548
[iter 400] loss=-1.3417 val_loss=0.0000 scale=1.0000 norm=0.4563
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5611 val_loss=0.0000 scale=2.0000 norm=1.1865
[iter 200] loss=-0.0316 val_loss=0.0000 scale=2.0000 norm=1.0572
[iter 300] loss=-0.4492 val_loss=0.0000 scale=1.0000 norm=0.5173
[iter 400] loss=-0.7388 val_loss=0.0000 scale=2.0000 norm=1.0115
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3779 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 200] loss=-0.3396 val_loss=0.0000 scale=2.0000 norm=0.9137
[iter 300] loss=-0.8937 val_loss=0.0000 scale=2.0000 norm=0.8311
[iter 400] loss=-1.3424 val_loss=0.0000 scale=1.0000 norm=0.3879
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3876 val_loss=0.0000 scale=2.0000 norm=1.0604
[iter 200] loss=-0.3097 val_loss=0.0000 scale=2.0000 norm=0.9291
[iter 300] loss=-0.7753 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 400] loss=-1.1422 val_loss=0.0000 scale=1.0000 norm=0.4192
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7191 val_loss=0.0000 scale=2.0000 norm=1.2377
[iter 200] loss=0.1692 val_loss=0.0000 scale=2.0000 norm=1.0915
[iter 300] loss=-0.1942 val_loss=0.0000 scale=1.0000 norm=0.5248
[iter 400] loss=-0.4914 val_loss=0.0000 scale=1.0000 norm=0.5001
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5205 val_loss=0.0000 scale=2.0000 norm=1.0960
[iter 200] loss=-0.0804 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 300] loss=-0.5573 val_loss=0.0000 scale=1.0000 norm=0.3974
[iter 400] loss=-0.8330 val_loss=0.0000 scale=2.0000 norm=0.7595
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5600 val_loss=0.0000 scale=2.0000 norm=1.0270
[iter 200] loss=-0.1077 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 300] loss=-0.6155 val_loss=0.0000 scale=2.0000 norm=0.8963
[iter 400] loss=-0.9807 val_loss=0.0000 scale=1.0000 norm=0.4302
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3271 val_loss=0.0000 scale=2.0000 norm=1.0265
[iter 200] loss=-0.2824 val_loss=0.0000 scale=2.0000 norm=0.9385
[iter 300] loss=-0.7125 val_loss=0.0000 scale=1.0000 norm=0.4553
[iter 400] loss=-0.9531 val_loss=0.0000 scale=2.0000 norm=0.8983
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2965 val_loss=0.0000 scale=2.0000 norm=1.0221
[iter 200] loss=-0.3726 val_loss=0.0000 scale=2.0000 norm=0.9345
[iter 300] loss=-0.8918 val_loss=0.0000 scale=2.0000 norm=0.9148
[iter 400] loss=-1.2881 val_loss=0.0000 scale=2.0000 norm=0.8769
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3945 val_loss=0.0000 scale=2.0000 norm=1.0541
[iter 200] loss=-0.1559 val_loss=0.0000 scale=2.0000 norm=0.9520
[iter 300] loss=-0.5983 val_loss=0.0000 scale=2.0000 norm=0.9049
[iter 400] loss=-0.9238 val_loss=0.0000 scale=2.0000 norm=0.8683
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5724 val_loss=0.0000 scale=2.0000 norm=1.1623
[iter 200] loss=-0.0118 val_loss=0.0000 scale=2.0000 norm=0.9977
[iter 300] loss=-0.3477 val_loss=0.0000 scale=2.0000 norm=0.9771
[iter 400] loss=-0.5936 val_loss=0.0000 scale=2.0000 norm=0.9741
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5211 val_loss=0.0000 scale=2.0000 norm=1.1583
[iter 200] loss=0.0100 val_loss=0.0000 scale=2.0000 norm=1.0364
[iter 300] loss=-0.3259 val_loss=0.0000 scale=2.0000 norm=0.9673
[iter 400] loss=-0.5290 val_loss=0.0000 scale=1.0000 norm=0.4636
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2957 val_loss=0.0000 scale=2.0000 norm=1.0295
[iter 200] loss=-0.4333 val_loss=0.0000 scale=2.0000 norm=0.9530
[iter 300] loss=-0.9910 val_loss=0.0000 scale=2.0000 norm=0.9201
[iter 400] loss=-1.3433 val_loss=0.0000 scale=2.0000 norm=0.8774
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4637 val_loss=0.0000 scale=2.0000 norm=1.0876
[iter 200] loss=-0.2532 val_loss=0.0000 scale=2.0000 norm=0.9635
[iter 300] loss=-0.8834 val_loss=0.0000 scale=2.0000 norm=0.9444
[iter 400] loss=-1.4198 val_loss=0.0000 scale=2.0000 norm=0.8746
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3588 val_loss=0.0000 scale=2.0000 norm=1.0505
[iter 200] loss=-0.2235 val_loss=0.0000 scale=2.0000 norm=0.9538
[iter 300] loss=-0.6265 val_loss=0.0000 scale=2.0000 norm=0.9110
[iter 400] loss=-0.8858 val_loss=0.0000 scale=1.0000 norm=0.4408
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4962 val_loss=0.0000 scale=2.0000 norm=1.1169
[iter 200] loss=-0.1332 val_loss=0.0000 scale=2.0000 norm=0.9781
[iter 300] loss=-0.5846 val_loss=0.0000 scale=2.0000 norm=0.9246
[iter 400] loss=-0.9118 val_loss=0.0000 scale=2.0000 norm=0.8954
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3632 val_loss=0.0000 scale=2.0000 norm=1.0577
[iter 200] loss=-0.2529 val_loss=0.0000 scale=2.0000 norm=0.9801
[iter 300] loss=-0.6760 val_loss=0.0000 scale=2.0000 norm=0.9536
[iter 400] loss=-0.9392 val_loss=0.0000 scale=1.0000 norm=0.4702
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4104 val_loss=0.0000 scale=2.0000 norm=1.0884
[iter 200] loss=-0.1557 val_loss=0.0000 scale=2.0000 norm=0.9723
[iter 300] loss=-0.6382 val_loss=0.0000 scale=1.0000 norm=0.4590
[iter 400] loss=-0.9222 val_loss=0.0000 scale=1.0000 norm=0.4378
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7039 val_loss=0.0000 scale=2.0000 norm=1.2383
[iter 200] loss=0.1957 val_loss=0.0000 scale=2.0000 norm=1.0561
[iter 300] loss=-0.1819 val_loss=0.0000 scale=1.0000 norm=0.4886
[iter 400] loss=-0.4072 val_loss=0.0000 scale=2.0000 norm=0.9246
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1447 val_loss=0.0000 scale=2.0000 norm=0.9757
[iter 200] loss=-0.7261 val_loss=0.0000 scale=2.0000 norm=0.8954
[iter 300] loss=-1.4564 val_loss=0.0000 scale=2.0000 norm=0.8453
[iter 400] loss=-1.9747 val_loss=0.0000 scale=2.0000 norm=0.8135
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2934 val_loss=0.0000 scale=2.0000 norm=1.0182
[iter 200] loss=-0.3690 val_loss=0.0000 scale=2.0000 norm=0.9565
[iter 300] loss=-0.9346 val_loss=0.0000 scale=2.0000 norm=0.9179
[iter 400] loss=-1.3505 val_loss=0.0000 scale=2.0000 norm=0.8931
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3783 val_loss=0.0000 scale=2.0000 norm=1.0690
[iter 200] loss=-0.1815 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 300] loss=-0.5865 val_loss=0.0000 scale=1.0000 norm=0.4816
[iter 400] loss=-0.8615 val_loss=0.0000 scale=1.0000 norm=0.4651
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3247 val_loss=0.0000 scale=2.0000 norm=1.0413
[iter 200] loss=-0.3028 val_loss=0.0000 scale=1.0000 norm=0.4843
[iter 300] loss=-0.8044 val_loss=0.0000 scale=2.0000 norm=0.9689
[iter 400] loss=-1.2345 val_loss=0.0000 scale=2.0000 norm=0.9004
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4143 val_loss=0.0000 scale=2.0000 norm=1.1163
[iter 200] loss=-0.3906 val_loss=0.0000 scale=4.0000 norm=2.2490
[iter 300] loss=-1.8065 val_loss=0.0000 scale=4.0000 norm=2.1097
[iter 400] loss=-2.7583 val_loss=0.0000 scale=8.0000 norm=4.0979
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3387 val_loss=0.0000 scale=2.0000 norm=1.0270
[iter 200] loss=-0.2456 val_loss=0.0000 scale=2.0000 norm=0.9342
[iter 300] loss=-0.6867 val_loss=0.0000 scale=2.0000 norm=0.8796
[iter 400] loss=-0.9701 val_loss=0.0000 scale=2.0000 norm=0.8536
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3784 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.1695 val_loss=0.0000 scale=2.0000 norm=0.9556
[iter 300] loss=-0.5795 val_loss=0.0000 scale=1.0000 norm=0.4520
[iter 400] loss=-0.8362 val_loss=0.0000 scale=1.0000 norm=0.4324
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2821 val_loss=0.0000 scale=2.0000 norm=1.0022
[iter 200] loss=-0.3537 val_loss=0.0000 scale=2.0000 norm=0.9311
[iter 300] loss=-0.8499 val_loss=0.0000 scale=1.0000 norm=0.4486
[iter 400] loss=-1.1881 val_loss=0.0000 scale=1.0000 norm=0.4361
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2981 val_loss=0.0000 scale=2.0000 norm=1.0519
[iter 200] loss=-0.3130 val_loss=0.0000 scale=2.0000 norm=0.9713
[iter 300] loss=-0.7668 val_loss=0.0000 scale=2.0000 norm=0.9176
[iter 400] loss=-1.0226 val_loss=0.0000 scale=2.0000 norm=0.8682
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3383 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 200] loss=-0.2535 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 300] loss=-0.6618 val_loss=0.0000 scale=1.0000 norm=0.4719
[iter 400] loss=-0.9112 val_loss=0.0000 scale=1.0000 norm=0.4531
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2774 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 200] loss=-0.5477 val_loss=0.0000 scale=2.0000 norm=0.8780
[iter 300] loss=-1.1978 val_loss=0.0000 scale=2.0000 norm=0.7570
[iter 400] loss=-2.0824 val_loss=0.0000 scale=4.0000 norm=1.3044
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4572 val_loss=0.0000 scale=2.0000 norm=1.1094
[iter 200] loss=-0.0715 val_loss=0.0000 scale=2.0000 norm=1.0304
[iter 300] loss=-0.4307 val_loss=0.0000 scale=1.0000 norm=0.4939
[iter 400] loss=-0.6103 val_loss=0.0000 scale=0.5000 norm=0.2440
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1494 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.6702 val_loss=0.0000 scale=2.0000 norm=0.8971
[iter 300] loss=-1.3943 val_loss=0.0000 scale=2.0000 norm=0.8191
[iter 400] loss=-1.9813 val_loss=0.0000 scale=2.0000 norm=0.8051
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6753 val_loss=0.0000 scale=2.0000 norm=1.2416
[iter 200] loss=0.1214 val_loss=0.0000 scale=2.0000 norm=1.0824
[iter 300] loss=-0.3049 val_loss=0.0000 scale=1.0000 norm=0.4967
[iter 400] loss=-0.5640 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2853 val_loss=0.0000 scale=2.0000 norm=1.0043
[iter 200] loss=-0.3539 val_loss=0.0000 scale=2.0000 norm=0.9437
[iter 300] loss=-0.8088 val_loss=0.0000 scale=2.0000 norm=0.9379
[iter 400] loss=-1.0733 val_loss=0.0000 scale=1.0000 norm=0.4561
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3952 val_loss=0.0000 scale=2.0000 norm=1.0933
[iter 200] loss=-0.1301 val_loss=0.0000 scale=1.0000 norm=0.4936
[iter 300] loss=-0.4911 val_loss=0.0000 scale=2.0000 norm=0.9541
[iter 400] loss=-0.7005 val_loss=0.0000 scale=2.0000 norm=0.9714
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5448 val_loss=0.0000 scale=2.0000 norm=1.1313
[iter 200] loss=-0.0311 val_loss=0.0000 scale=2.0000 norm=0.9879
[iter 300] loss=-0.4202 val_loss=0.0000 scale=1.0000 norm=0.4740
[iter 400] loss=-0.6355 val_loss=0.0000 scale=2.0000 norm=0.9461
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2330 val_loss=0.0000 scale=2.0000 norm=0.9850
[iter 200] loss=-0.5277 val_loss=0.0000 scale=2.0000 norm=0.8884
[iter 300] loss=-1.1463 val_loss=0.0000 scale=2.0000 norm=0.8173
[iter 400] loss=-1.5960 val_loss=0.0000 scale=2.0000 norm=0.7577
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2588 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 200] loss=-0.4654 val_loss=0.0000 scale=2.0000 norm=0.9340
[iter 300] loss=-1.1404 val_loss=0.0000 scale=4.0000 norm=1.8933
[iter 400] loss=-2.0801 val_loss=0.0000 scale=4.0000 norm=1.8913
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4813 val_loss=0.0000 scale=2.0000 norm=1.1896
[iter 200] loss=-0.2080 val_loss=0.0000 scale=2.0000 norm=1.1349
[iter 300] loss=-0.7480 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 400] loss=-1.1009 val_loss=0.0000 scale=2.0000 norm=1.0794
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2060 val_loss=0.0000 scale=2.0000 norm=0.9909
[iter 200] loss=-0.5867 val_loss=0.0000 scale=2.0000 norm=0.9651
[iter 300] loss=-1.2435 val_loss=0.0000 scale=2.0000 norm=0.9466
[iter 400] loss=-1.7729 val_loss=0.0000 scale=2.0000 norm=0.8979
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4398 val_loss=0.0000 scale=2.0000 norm=1.1249
[iter 200] loss=-0.0856 val_loss=0.0000 scale=1.0000 norm=0.4983
[iter 300] loss=-0.4632 val_loss=0.0000 scale=2.0000 norm=0.9608
[iter 400] loss=-0.6931 val_loss=0.0000 scale=1.0000 norm=0.4602
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3587 val_loss=0.0000 scale=2.0000 norm=1.0303
[iter 200] loss=-0.2088 val_loss=0.0000 scale=2.0000 norm=0.9463
[iter 300] loss=-0.6045 val_loss=0.0000 scale=2.0000 norm=0.9251
[iter 400] loss=-0.8440 val_loss=0.0000 scale=1.0000 norm=0.4498
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2220 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 200] loss=-0.5161 val_loss=0.0000 scale=2.0000 norm=0.8608
[iter 300] loss=-0.9731 val_loss=0.0000 scale=2.0000 norm=0.7711
[iter 400] loss=-1.3565 val_loss=0.0000 scale=2.0000 norm=0.7305
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3720 val_loss=0.0000 scale=2.0000 norm=1.0139
[iter 200] loss=-0.4207 val_loss=0.0000 scale=2.0000 norm=0.9181
[iter 300] loss=-1.1535 val_loss=0.0000 scale=2.0000 norm=0.8825
[iter 400] loss=-1.8060 val_loss=0.0000 scale=2.0000 norm=0.8117
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3595 val_loss=0.0000 scale=2.0000 norm=1.0667
[iter 200] loss=-0.2192 val_loss=0.0000 scale=2.0000 norm=0.9846
[iter 300] loss=-0.5880 val_loss=0.0000 scale=2.0000 norm=0.9717
[iter 400] loss=-0.8324 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2991 val_loss=0.0000 scale=2.0000 norm=1.0198
[iter 200] loss=-0.3069 val_loss=0.0000 scale=2.0000 norm=1.0056
[iter 300] loss=-0.7482 val_loss=0.0000 scale=2.0000 norm=0.9896
[iter 400] loss=-1.0793 val_loss=0.0000 scale=1.0000 norm=0.4619
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4462 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 200] loss=-0.1928 val_loss=0.0000 scale=2.0000 norm=0.9391
[iter 300] loss=-0.6414 val_loss=0.0000 scale=2.0000 norm=0.8904
[iter 400] loss=-0.9179 val_loss=0.0000 scale=1.0000 norm=0.4287
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7047 val_loss=0.0000 scale=2.0000 norm=1.2232
[iter 200] loss=0.1675 val_loss=0.0000 scale=2.0000 norm=1.0779
[iter 300] loss=-0.1726 val_loss=0.0000 scale=2.0000 norm=1.0472
[iter 400] loss=-0.4450 val_loss=0.0000 scale=1.0000 norm=0.5222
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1734 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 200] loss=-0.5695 val_loss=0.0000 scale=2.0000 norm=0.9206
[iter 300] loss=-1.1588 val_loss=0.0000 scale=2.0000 norm=0.8724
[iter 400] loss=-1.5837 val_loss=0.0000 scale=2.0000 norm=0.7957
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1929 val_loss=0.0000 scale=2.0000 norm=0.9923
[iter 200] loss=-0.5690 val_loss=0.0000 scale=2.0000 norm=0.9328
[iter 300] loss=-1.1602 val_loss=0.0000 scale=2.0000 norm=0.8621
[iter 400] loss=-1.5870 val_loss=0.0000 scale=2.0000 norm=0.8290
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3425 val_loss=0.0000 scale=2.0000 norm=1.0527
[iter 200] loss=-0.3049 val_loss=0.0000 scale=2.0000 norm=0.9873
[iter 300] loss=-0.8079 val_loss=0.0000 scale=2.0000 norm=0.9438
[iter 400] loss=-1.0925 val_loss=0.0000 scale=2.0000 norm=0.8902
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=0.9661
[iter 200] loss=-0.6425 val_loss=0.0000 scale=2.0000 norm=0.8688
[iter 300] loss=-1.3411 val_loss=0.0000 scale=2.0000 norm=0.8274
[iter 400] loss=-2.0692 val_loss=0.0000 scale=2.0000 norm=0.7733
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5252 val_loss=0.0000 scale=2.0000 norm=1.1701
[iter 200] loss=0.0367 val_loss=0.0000 scale=1.0000 norm=0.5219
[iter 300] loss=-0.2731 val_loss=0.0000 scale=1.0000 norm=0.4877
[iter 400] loss=-0.4833 val_loss=0.0000 scale=1.0000 norm=0.4800
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5161 val_loss=0.0000 scale=2.0000 norm=1.1809
[iter 200] loss=-0.0550 val_loss=0.0000 scale=2.0000 norm=1.0754
[iter 300] loss=-0.4454 val_loss=0.0000 scale=2.0000 norm=1.0479
[iter 400] loss=-0.7660 val_loss=0.0000 scale=1.0000 norm=0.4942
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2926 val_loss=0.0000 scale=2.0000 norm=1.0059
[iter 200] loss=-0.3262 val_loss=0.0000 scale=2.0000 norm=0.8943
[iter 300] loss=-0.7500 val_loss=0.0000 scale=2.0000 norm=0.8158
[iter 400] loss=-1.0122 val_loss=0.0000 scale=2.0000 norm=0.7955
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1632 val_loss=0.0000 scale=2.0000 norm=0.9751
[iter 200] loss=-0.7202 val_loss=0.0000 scale=2.0000 norm=0.9439
[iter 300] loss=-1.6585 val_loss=0.0000 scale=2.0000 norm=0.9308
[iter 400] loss=-2.4149 val_loss=0.0000 scale=2.0000 norm=0.8695
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2230 val_loss=0.0000 scale=2.0000 norm=1.0644
[iter 200] loss=-0.6434 val_loss=0.0000 scale=2.0000 norm=1.0230
[iter 300] loss=-1.6837 val_loss=0.0000 scale=4.0000 norm=1.9411
[iter 400] loss=-2.5592 val_loss=0.0000 scale=4.0000 norm=1.8342
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4000 val_loss=0.0000 scale=2.0000 norm=1.0836
[iter 200] loss=-0.1481 val_loss=0.0000 scale=2.0000 norm=0.9738
[iter 300] loss=-0.4941 val_loss=0.0000 scale=2.0000 norm=0.9348
[iter 400] loss=-0.7298 val_loss=0.0000 scale=1.0000 norm=0.4496
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4124 val_loss=0.0000 scale=2.0000 norm=1.0724
[iter 200] loss=-0.1875 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 300] loss=-0.6021 val_loss=0.0000 scale=2.0000 norm=0.8747
[iter 400] loss=-0.8357 val_loss=0.0000 scale=1.0000 norm=0.4116
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4624 val_loss=0.0000 scale=2.0000 norm=1.0825
[iter 200] loss=-0.1367 val_loss=0.0000 scale=2.0000 norm=0.9897
[iter 300] loss=-0.5249 val_loss=0.0000 scale=1.0000 norm=0.4727
[iter 400] loss=-0.7891 val_loss=0.0000 scale=1.0000 norm=0.4704
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3589 val_loss=0.0000 scale=2.0000 norm=1.0946
[iter 200] loss=-0.2782 val_loss=0.0000 scale=1.0000 norm=0.4781
[iter 300] loss=-0.6676 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 400] loss=-0.9939 val_loss=0.0000 scale=1.0000 norm=0.4075
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3740 val_loss=0.0000 scale=2.0000 norm=1.0665
[iter 200] loss=-0.2548 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 300] loss=-0.7206 val_loss=0.0000 scale=1.0000 norm=0.4447
[iter 400] loss=-1.0066 val_loss=0.0000 scale=0.5000 norm=0.2104
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3437 val_loss=0.0000 scale=2.0000 norm=1.0216
[iter 200] loss=-0.2571 val_loss=0.0000 scale=2.0000 norm=0.9486
[iter 300] loss=-0.6998 val_loss=0.0000 scale=2.0000 norm=0.9560
[iter 400] loss=-0.9934 val_loss=0.0000 scale=1.0000 norm=0.4544
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3523 val_loss=0.0000 scale=2.0000 norm=1.0569
[iter 200] loss=-0.3804 val_loss=0.0000 scale=2.0000 norm=1.0160
[iter 300] loss=-1.2866 val_loss=0.0000 scale=4.0000 norm=2.1229
[iter 400] loss=-2.2799 val_loss=0.0000 scale=4.0000 norm=1.9945
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3127 val_loss=0.0000 scale=2.0000 norm=0.9632
[iter 200] loss=-0.5560 val_loss=0.0000 scale=2.0000 norm=0.8838
[iter 300] loss=-1.3479 val_loss=0.0000 scale=2.0000 norm=0.8186
[iter 400] loss=-2.0746 val_loss=0.0000 scale=2.0000 norm=0.7986
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2999 val_loss=0.0000 scale=2.0000 norm=1.0087
[iter 200] loss=-0.3369 val_loss=0.0000 scale=2.0000 norm=0.9260
[iter 300] loss=-0.7891 val_loss=0.0000 scale=2.0000 norm=0.9107
[iter 400] loss=-1.0408 val_loss=0.0000 scale=2.0000 norm=0.9310
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3850 val_loss=0.0000 scale=2.0000 norm=1.0716
[iter 200] loss=-0.2312 val_loss=0.0000 scale=2.0000 norm=0.9887
[iter 300] loss=-0.6886 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 400] loss=-1.0414 val_loss=0.0000 scale=0.5000 norm=0.2266
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4319 val_loss=0.0000 scale=2.0000 norm=1.1002
[iter 200] loss=-0.0703 val_loss=0.0000 scale=1.0000 norm=0.4829
[iter 300] loss=-0.4341 val_loss=0.0000 scale=1.0000 norm=0.4697
[iter 400] loss=-0.6998 val_loss=0.0000 scale=2.0000 norm=0.9330
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3993 val_loss=0.0000 scale=2.0000 norm=1.0742
[iter 200] loss=-0.1793 val_loss=0.0000 scale=2.0000 norm=1.0138
[iter 300] loss=-0.6395 val_loss=0.0000 scale=2.0000 norm=0.9687
[iter 400] loss=-0.9698 val_loss=0.0000 scale=1.0000 norm=0.4695
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2885 val_loss=0.0000 scale=2.0000 norm=1.0202
[iter 200] loss=-0.4415 val_loss=0.0000 scale=2.0000 norm=0.9408
[iter 300] loss=-1.0497 val_loss=0.0000 scale=2.0000 norm=0.8886
[iter 400] loss=-1.5191 val_loss=0.0000 scale=2.0000 norm=0.8692
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3955 val_loss=0.0000 scale=2.0000 norm=1.0780
[iter 200] loss=-0.2254 val_loss=0.0000 scale=2.0000 norm=0.9602
[iter 300] loss=-0.6501 val_loss=0.0000 scale=2.0000 norm=0.9220
[iter 400] loss=-0.9460 val_loss=0.0000 scale=1.0000 norm=0.4491
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3426 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.2420 val_loss=0.0000 scale=2.0000 norm=0.9352
[iter 300] loss=-0.6142 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 400] loss=-0.8798 val_loss=0.0000 scale=0.5000 norm=0.2182
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1847 val_loss=0.0000 scale=2.0000 norm=0.9877
[iter 200] loss=-0.7318 val_loss=0.0000 scale=2.0000 norm=0.9378
[iter 300] loss=-1.5480 val_loss=0.0000 scale=2.0000 norm=0.8814
[iter 400] loss=-2.3370 val_loss=0.0000 scale=2.0000 norm=0.8662
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3683 val_loss=0.0000 scale=2.0000 norm=1.0677
[iter 200] loss=-0.1896 val_loss=0.0000 scale=2.0000 norm=0.9608
[iter 300] loss=-0.5621 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 400] loss=-0.8248 val_loss=0.0000 scale=2.0000 norm=0.9150
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2689 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.3734 val_loss=0.0000 scale=2.0000 norm=0.9303
[iter 300] loss=-0.8279 val_loss=0.0000 scale=2.0000 norm=0.9461
[iter 400] loss=-1.1537 val_loss=0.0000 scale=2.0000 norm=0.9159
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3125 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.3218 val_loss=0.0000 scale=2.0000 norm=1.0023
[iter 300] loss=-0.8383 val_loss=0.0000 scale=2.0000 norm=0.9805
[iter 400] loss=-1.1755 val_loss=0.0000 scale=1.0000 norm=0.4831
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3083 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.3335 val_loss=0.0000 scale=2.0000 norm=0.9161
[iter 300] loss=-0.7633 val_loss=0.0000 scale=2.0000 norm=0.9314
[iter 400] loss=-1.0571 val_loss=0.0000 scale=2.0000 norm=0.9332
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2851 val_loss=0.0000 scale=2.0000 norm=0.9600
[iter 200] loss=-0.6533 val_loss=0.0000 scale=2.0000 norm=0.9388
[iter 300] loss=-1.5601 val_loss=0.0000 scale=2.0000 norm=0.8978
[iter 400] loss=-2.3581 val_loss=0.0000 scale=2.0000 norm=0.8080
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2151 val_loss=0.0000 scale=2.0000 norm=1.0179
[iter 200] loss=-0.4770 val_loss=0.0000 scale=2.0000 norm=0.9889
[iter 300] loss=-1.0119 val_loss=0.0000 scale=2.0000 norm=0.9478
[iter 400] loss=-1.3866 val_loss=0.0000 scale=2.0000 norm=0.8789
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1854 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 200] loss=-0.6132 val_loss=0.0000 scale=2.0000 norm=0.9508
[iter 300] loss=-1.3205 val_loss=0.0000 scale=2.0000 norm=0.9041
[iter 400] loss=-1.9339 val_loss=0.0000 scale=2.0000 norm=0.8648
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3029 val_loss=0.0000 scale=2.0000 norm=1.0086
[iter 200] loss=-0.3175 val_loss=0.0000 scale=2.0000 norm=0.9629
[iter 300] loss=-0.8250 val_loss=0.0000 scale=2.0000 norm=0.9400
[iter 400] loss=-1.2185 val_loss=0.0000 scale=2.0000 norm=0.9755
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5790 val_loss=0.0000 scale=2.0000 norm=1.1645
[iter 200] loss=0.0728 val_loss=0.0000 scale=1.0000 norm=0.4988
[iter 300] loss=-0.2103 val_loss=0.0000 scale=1.0000 norm=0.4723
[iter 400] loss=-0.4465 val_loss=0.0000 scale=2.0000 norm=0.9310
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7081 val_loss=0.0000 scale=2.0000 norm=1.2047
[iter 200] loss=0.0910 val_loss=0.0000 scale=2.0000 norm=1.0618
[iter 300] loss=-0.3938 val_loss=0.0000 scale=2.0000 norm=1.0151
[iter 400] loss=-0.7710 val_loss=0.0000 scale=1.0000 norm=0.4807
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3270 val_loss=0.0000 scale=2.0000 norm=1.0330
[iter 200] loss=-0.3347 val_loss=0.0000 scale=2.0000 norm=0.9566
[iter 300] loss=-0.8377 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-1.1744 val_loss=0.0000 scale=1.0000 norm=0.4452
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3270 val_loss=0.0000 scale=2.0000 norm=1.0206
[iter 200] loss=-0.2502 val_loss=0.0000 scale=2.0000 norm=0.9395
[iter 300] loss=-0.6504 val_loss=0.0000 scale=2.0000 norm=0.8954
[iter 400] loss=-0.9175 val_loss=0.0000 scale=2.0000 norm=0.8359
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3102 val_loss=0.0000 scale=2.0000 norm=1.0357
[iter 200] loss=-0.2807 val_loss=0.0000 scale=2.0000 norm=0.9586
[iter 300] loss=-0.7811 val_loss=0.0000 scale=1.0000 norm=0.4495
[iter 400] loss=-1.1392 val_loss=0.0000 scale=2.0000 norm=0.8646
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4150 val_loss=0.0000 scale=2.0000 norm=1.0689
[iter 200] loss=-0.3781 val_loss=0.0000 scale=2.0000 norm=0.9643
[iter 300] loss=-1.0983 val_loss=0.0000 scale=2.0000 norm=0.9285
[iter 400] loss=-1.7793 val_loss=0.0000 scale=2.0000 norm=0.8867
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3067 val_loss=0.0000 scale=2.0000 norm=1.0645
[iter 200] loss=-0.4629 val_loss=0.0000 scale=2.0000 norm=0.9599
[iter 300] loss=-1.1070 val_loss=0.0000 scale=2.0000 norm=0.8818
[iter 400] loss=-1.5687 val_loss=0.0000 scale=2.0000 norm=0.8059
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2439 val_loss=0.0000 scale=2.0000 norm=0.9784
[iter 200] loss=-0.7071 val_loss=0.0000 scale=2.0000 norm=0.9489
[iter 300] loss=-1.8181 val_loss=0.0000 scale=4.0000 norm=1.7215
[iter 400] loss=-3.1891 val_loss=0.0000 scale=2.0000 norm=0.8639
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4153 val_loss=0.0000 scale=2.0000 norm=1.1007
[iter 200] loss=-0.1123 val_loss=0.0000 scale=1.0000 norm=0.4921
[iter 300] loss=-0.5010 val_loss=0.0000 scale=2.0000 norm=0.9029
[iter 400] loss=-0.7224 val_loss=0.0000 scale=1.0000 norm=0.4248
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4139 val_loss=0.0000 scale=1.0000 norm=0.5540
[iter 200] loss=-0.1460 val_loss=0.0000 scale=2.0000 norm=0.9930
[iter 300] loss=-0.5824 val_loss=0.0000 scale=2.0000 norm=0.9166
[iter 400] loss=-0.8544 val_loss=0.0000 scale=1.0000 norm=0.4316
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3792 val_loss=0.0000 scale=2.0000 norm=1.0505
[iter 200] loss=-0.2224 val_loss=0.0000 scale=2.0000 norm=0.9727
[iter 300] loss=-0.6530 val_loss=0.0000 scale=2.0000 norm=0.9353
[iter 400] loss=-0.9152 val_loss=0.0000 scale=1.0000 norm=0.4811
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3354 val_loss=0.0000 scale=2.0000 norm=1.0344
[iter 200] loss=-0.2619 val_loss=0.0000 scale=2.0000 norm=0.9438
[iter 300] loss=-0.7003 val_loss=0.0000 scale=2.0000 norm=0.9425
[iter 400] loss=-0.9896 val_loss=0.0000 scale=2.0000 norm=0.9416
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4433 val_loss=0.0000 scale=2.0000 norm=1.1050
[iter 200] loss=-0.0348 val_loss=0.0000 scale=1.0000 norm=0.4993
[iter 300] loss=-0.3722 val_loss=0.0000 scale=2.0000 norm=0.9449
[iter 400] loss=-0.6337 val_loss=0.0000 scale=2.0000 norm=0.9275
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6127 val_loss=0.0000 scale=2.0000 norm=1.1730
[iter 200] loss=0.0518 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 300] loss=-0.2999 val_loss=0.0000 scale=2.0000 norm=0.9795
[iter 400] loss=-0.5556 val_loss=0.0000 scale=1.0000 norm=0.4840
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3034 val_loss=0.0000 scale=2.0000 norm=1.0005
[iter 200] loss=-0.3288 val_loss=0.0000 scale=2.0000 norm=0.9195
[iter 300] loss=-0.7816 val_loss=0.0000 scale=2.0000 norm=0.8780
[iter 400] loss=-1.0616 val_loss=0.0000 scale=1.0000 norm=0.4388
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3370 val_loss=0.0000 scale=2.0000 norm=1.0541
[iter 200] loss=-0.3137 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 300] loss=-0.7891 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 400] loss=-1.0981 val_loss=0.0000 scale=2.0000 norm=0.9426
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3485 val_loss=0.0000 scale=2.0000 norm=1.0601
[iter 200] loss=-0.3022 val_loss=0.0000 scale=2.0000 norm=0.9953
[iter 300] loss=-0.8211 val_loss=0.0000 scale=1.0000 norm=0.4697
[iter 400] loss=-1.1200 val_loss=0.0000 scale=1.0000 norm=0.4520
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6849 val_loss=0.0000 scale=2.0000 norm=1.1421
[iter 200] loss=0.0193 val_loss=0.0000 scale=2.0000 norm=0.8956
[iter 300] loss=-0.5820 val_loss=0.0000 scale=1.0000 norm=0.3955
[iter 400] loss=-1.0033 val_loss=0.0000 scale=1.0000 norm=0.3883
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3416 val_loss=0.0000 scale=2.0000 norm=1.0328
[iter 200] loss=-0.2770 val_loss=0.0000 scale=2.0000 norm=0.9501
[iter 300] loss=-0.7340 val_loss=0.0000 scale=2.0000 norm=0.9328
[iter 400] loss=-0.9752 val_loss=0.0000 scale=2.0000 norm=0.8970
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2413 val_loss=0.0000 scale=2.0000 norm=1.0046
[iter 200] loss=-0.4347 val_loss=0.0000 scale=2.0000 norm=0.9145
[iter 300] loss=-0.8705 val_loss=0.0000 scale=1.0000 norm=0.4352
[iter 400] loss=-1.1727 val_loss=0.0000 scale=2.0000 norm=0.8298
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3438 val_loss=0.0000 scale=2.0000 norm=1.0256
[iter 200] loss=-0.2637 val_loss=0.0000 scale=2.0000 norm=0.9351
[iter 300] loss=-0.6792 val_loss=0.0000 scale=1.0000 norm=0.4498
[iter 400] loss=-0.8976 val_loss=0.0000 scale=1.0000 norm=0.4328
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3440 val_loss=0.0000 scale=2.0000 norm=1.0561
[iter 200] loss=-0.2515 val_loss=0.0000 scale=2.0000 norm=0.9838
[iter 300] loss=-0.7158 val_loss=0.0000 scale=2.0000 norm=0.9585
[iter 400] loss=-0.9846 val_loss=0.0000 scale=1.0000 norm=0.4583
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4382 val_loss=0.0000 scale=2.0000 norm=1.0812
[iter 200] loss=-0.1955 val_loss=0.0000 scale=2.0000 norm=0.9578
[iter 300] loss=-0.6472 val_loss=0.0000 scale=2.0000 norm=0.8971
[iter 400] loss=-0.9129 val_loss=0.0000 scale=2.0000 norm=0.8907
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4737 val_loss=0.0000 scale=2.0000 norm=1.1073
[iter 200] loss=-0.0483 val_loss=0.0000 scale=2.0000 norm=1.0244
[iter 300] loss=-0.3499 val_loss=0.0000 scale=1.0000 norm=0.4885
[iter 400] loss=-0.5674 val_loss=0.0000 scale=1.0000 norm=0.4644
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2913 val_loss=0.0000 scale=2.0000 norm=1.0226
[iter 200] loss=-0.3534 val_loss=0.0000 scale=2.0000 norm=0.9198
[iter 300] loss=-0.8309 val_loss=0.0000 scale=2.0000 norm=0.8695
[iter 400] loss=-1.1085 val_loss=0.0000 scale=1.0000 norm=0.4216
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5866 val_loss=0.0000 scale=2.0000 norm=1.1142
[iter 200] loss=-0.1323 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 300] loss=-0.8201 val_loss=0.0000 scale=2.0000 norm=1.0665
[iter 400] loss=-1.4673 val_loss=0.0000 scale=2.0000 norm=1.0247
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3846 val_loss=0.0000 scale=2.0000 norm=1.1312
[iter 200] loss=-0.3645 val_loss=0.0000 scale=2.0000 norm=1.0928
[iter 300] loss=-1.0322 val_loss=0.0000 scale=2.0000 norm=1.0469
[iter 400] loss=-1.6190 val_loss=0.0000 scale=2.0000 norm=1.0713
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4136 val_loss=0.0000 scale=2.0000 norm=1.0945
[iter 200] loss=-0.1660 val_loss=0.0000 scale=2.0000 norm=0.9695
[iter 300] loss=-0.5413 val_loss=0.0000 scale=1.0000 norm=0.4709
[iter 400] loss=-0.8174 val_loss=0.0000 scale=2.0000 norm=0.9057
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6539 val_loss=0.0000 scale=2.0000 norm=1.2059
[iter 200] loss=-0.1419 val_loss=0.0000 scale=2.0000 norm=1.0680
[iter 300] loss=-0.8665 val_loss=0.0000 scale=2.0000 norm=0.9916
[iter 400] loss=-1.4692 val_loss=0.0000 scale=2.0000 norm=0.9032
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3203 val_loss=0.0000 scale=2.0000 norm=1.0248
[iter 200] loss=-0.2947 val_loss=0.0000 scale=2.0000 norm=0.9417
[iter 300] loss=-0.7606 val_loss=0.0000 scale=2.0000 norm=0.9282
[iter 400] loss=-1.0348 val_loss=0.0000 scale=1.0000 norm=0.4682
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3828 val_loss=0.0000 scale=2.0000 norm=1.0546
[iter 200] loss=-0.1627 val_loss=0.0000 scale=2.0000 norm=0.9752
[iter 300] loss=-0.6038 val_loss=0.0000 scale=2.0000 norm=0.9398
[iter 400] loss=-0.8918 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3655 val_loss=0.0000 scale=2.0000 norm=0.9913
[iter 200] loss=-0.4351 val_loss=0.0000 scale=2.0000 norm=1.0192
[iter 300] loss=-1.2732 val_loss=0.0000 scale=2.0000 norm=1.0588
[iter 400] loss=-2.0453 val_loss=0.0000 scale=2.0000 norm=1.0588
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3199 val_loss=0.0000 scale=2.0000 norm=1.0278
[iter 200] loss=-0.2856 val_loss=0.0000 scale=2.0000 norm=0.9370
[iter 300] loss=-0.6931 val_loss=0.0000 scale=1.0000 norm=0.4568
[iter 400] loss=-0.9520 val_loss=0.0000 scale=0.5000 norm=0.2186
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3335 val_loss=0.0000 scale=2.0000 norm=1.0528
[iter 200] loss=-0.3699 val_loss=0.0000 scale=2.0000 norm=0.9607
[iter 300] loss=-0.9495 val_loss=0.0000 scale=2.0000 norm=0.9233
[iter 400] loss=-1.3218 val_loss=0.0000 scale=2.0000 norm=0.8771
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3923 val_loss=0.0000 scale=2.0000 norm=1.0814
[iter 200] loss=-0.2504 val_loss=0.0000 scale=2.0000 norm=0.9502
[iter 300] loss=-0.7170 val_loss=0.0000 scale=2.0000 norm=0.9039
[iter 400] loss=-0.9858 val_loss=0.0000 scale=1.0000 norm=0.4232
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3971 val_loss=0.0000 scale=2.0000 norm=1.0674
[iter 200] loss=-0.1735 val_loss=0.0000 scale=1.0000 norm=0.4770
[iter 300] loss=-0.5362 val_loss=0.0000 scale=1.0000 norm=0.4494
[iter 400] loss=-0.7387 val_loss=0.0000 scale=1.0000 norm=0.4381
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4348 val_loss=0.0000 scale=2.0000 norm=1.1047
[iter 200] loss=-0.1469 val_loss=0.0000 scale=2.0000 norm=0.9771
[iter 300] loss=-0.5329 val_loss=0.0000 scale=2.0000 norm=0.9458
[iter 400] loss=-0.7899 val_loss=0.0000 scale=1.0000 norm=0.4629
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3795 val_loss=0.0000 scale=2.0000 norm=1.0738
[iter 200] loss=-0.3249 val_loss=0.0000 scale=2.0000 norm=0.9533
[iter 300] loss=-0.9480 val_loss=0.0000 scale=2.0000 norm=0.8589
[iter 400] loss=-1.3518 val_loss=0.0000 scale=1.0000 norm=0.3968
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.5376 val_loss=0.0000 scale=1.0000 norm=0.5939
[iter 200] loss=0.0911 val_loss=0.0000 scale=2.0000 norm=1.0924
[iter 300] loss=-0.2836 val_loss=0.0000 scale=1.0000 norm=0.5142
[iter 400] loss=-0.5619 val_loss=0.0000 scale=1.0000 norm=0.4891
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3916 val_loss=0.0000 scale=2.0000 norm=1.0955
[iter 200] loss=-0.1762 val_loss=0.0000 scale=2.0000 norm=1.0148
[iter 300] loss=-0.5940 val_loss=0.0000 scale=2.0000 norm=0.9518
[iter 400] loss=-0.8587 val_loss=0.0000 scale=1.0000 norm=0.4604
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4467 val_loss=0.0000 scale=2.0000 norm=1.1229
[iter 200] loss=-0.1974 val_loss=0.0000 scale=2.0000 norm=1.0018
[iter 300] loss=-0.6671 val_loss=0.0000 scale=2.0000 norm=0.9720
[iter 400] loss=-0.9726 val_loss=0.0000 scale=1.0000 norm=0.4823
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3956 val_loss=0.0000 scale=2.0000 norm=1.0740
[iter 200] loss=-0.1775 val_loss=0.0000 scale=2.0000 norm=0.9584
[iter 300] loss=-0.5702 val_loss=0.0000 scale=2.0000 norm=0.9260
[iter 400] loss=-0.8496 val_loss=0.0000 scale=1.0000 norm=0.4665
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2855 val_loss=0.0000 scale=2.0000 norm=1.0235
[iter 200] loss=-0.3455 val_loss=0.0000 scale=2.0000 norm=0.9195
[iter 300] loss=-0.8455 val_loss=0.0000 scale=2.0000 norm=0.8659
[iter 400] loss=-1.1927 val_loss=0.0000 scale=2.0000 norm=0.8673
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1368 val_loss=0.0000 scale=2.0000 norm=0.9794
[iter 200] loss=-0.6897 val_loss=0.0000 scale=2.0000 norm=0.9298
[iter 300] loss=-1.3636 val_loss=0.0000 scale=2.0000 norm=0.8923
[iter 400] loss=-1.8685 val_loss=0.0000 scale=2.0000 norm=0.8991
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3403 val_loss=0.0000 scale=2.0000 norm=1.0390
[iter 200] loss=-0.2587 val_loss=0.0000 scale=1.0000 norm=0.4754
[iter 300] loss=-0.6478 val_loss=0.0000 scale=2.0000 norm=0.9192
[iter 400] loss=-0.9184 val_loss=0.0000 scale=1.0000 norm=0.4551
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3237 val_loss=0.0000 scale=2.0000 norm=0.9650
[iter 200] loss=-0.6130 val_loss=0.0000 scale=2.0000 norm=0.9253
[iter 300] loss=-1.4826 val_loss=0.0000 scale=2.0000 norm=0.8683
[iter 400] loss=-2.2737 val_loss=0.0000 scale=2.0000 norm=0.8146
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1667 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.5902 val_loss=0.0000 scale=2.0000 norm=0.9219
[iter 300] loss=-1.6406 val_loss=0.0000 scale=4.0000 norm=1.7220
[iter 400] loss=-2.6893 val_loss=0.0000 scale=4.0000 norm=1.5187
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4363 val_loss=0.0000 scale=2.0000 norm=1.1168
[iter 200] loss=-0.1106 val_loss=0.0000 scale=2.0000 norm=0.9891
[iter 300] loss=-0.4516 val_loss=0.0000 scale=2.0000 norm=0.9330
[iter 400] loss=-0.6704 val_loss=0.0000 scale=1.0000 norm=0.4424
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3140 val_loss=0.0000 scale=2.0000 norm=1.0336
[iter 200] loss=-0.4243 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 300] loss=-1.0186 val_loss=0.0000 scale=2.0000 norm=0.9014
[iter 400] loss=-1.5638 val_loss=0.0000 scale=2.0000 norm=0.8670
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4870 val_loss=0.0000 scale=2.0000 norm=1.1336
[iter 200] loss=-0.0994 val_loss=0.0000 scale=2.0000 norm=0.9868
[iter 300] loss=-0.4976 val_loss=0.0000 scale=2.0000 norm=0.9699
[iter 400] loss=-0.7168 val_loss=0.0000 scale=2.0000 norm=0.9888
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3620 val_loss=0.0000 scale=2.0000 norm=1.0528
[iter 200] loss=-0.2234 val_loss=0.0000 scale=2.0000 norm=0.9780
[iter 300] loss=-0.5655 val_loss=0.0000 scale=1.0000 norm=0.4854
[iter 400] loss=-0.8131 val_loss=0.0000 scale=1.0000 norm=0.4863
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3390 val_loss=0.0000 scale=2.0000 norm=1.0252
[iter 200] loss=-0.2626 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 300] loss=-0.7287 val_loss=0.0000 scale=2.0000 norm=0.9048
[iter 400] loss=-1.0063 val_loss=0.0000 scale=1.0000 norm=0.4380
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3584 val_loss=0.0000 scale=2.0000 norm=1.0694
[iter 200] loss=-0.2166 val_loss=0.0000 scale=1.0000 norm=0.4911
[iter 300] loss=-0.5840 val_loss=0.0000 scale=2.0000 norm=0.9438
[iter 400] loss=-0.8428 val_loss=0.0000 scale=2.0000 norm=0.9122
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3311 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 200] loss=-0.5583 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 300] loss=-1.3894 val_loss=0.0000 scale=2.0000 norm=0.8927
[iter 400] loss=-2.1598 val_loss=0.0000 scale=2.0000 norm=0.8480
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3096 val_loss=0.0000 scale=2.0000 norm=1.0136
[iter 200] loss=-0.3329 val_loss=0.0000 scale=2.0000 norm=0.9465
[iter 300] loss=-0.7995 val_loss=0.0000 scale=2.0000 norm=0.9342
[iter 400] loss=-1.1026 val_loss=0.0000 scale=1.0000 norm=0.4441
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3890 val_loss=0.0000 scale=2.0000 norm=1.0630
[iter 200] loss=-0.2085 val_loss=0.0000 scale=2.0000 norm=0.9416
[iter 300] loss=-0.6528 val_loss=0.0000 scale=1.0000 norm=0.4419
[iter 400] loss=-0.9342 val_loss=0.0000 scale=2.0000 norm=0.8037
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.1565
[iter 200] loss=-0.4137 val_loss=0.0000 scale=2.0000 norm=1.1430
[iter 300] loss=-1.2506 val_loss=0.0000 scale=2.0000 norm=1.1619
[iter 400] loss=-2.3595 val_loss=0.0000 scale=4.0000 norm=2.3123
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1359 val_loss=0.0000 scale=2.0000 norm=0.9824
[iter 200] loss=-0.7980 val_loss=0.0000 scale=2.0000 norm=0.9355
[iter 300] loss=-1.6832 val_loss=0.0000 scale=2.0000 norm=0.9047
[iter 400] loss=-2.5436 val_loss=0.0000 scale=2.0000 norm=0.8855
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6880 val_loss=0.0000 scale=2.0000 norm=1.2028
[iter 200] loss=0.1895 val_loss=0.0000 scale=2.0000 norm=1.0462
[iter 300] loss=-0.2527 val_loss=0.0000 scale=2.0000 norm=0.9729
[iter 400] loss=-0.5541 val_loss=0.0000 scale=1.0000 norm=0.4654
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2710 val_loss=0.0000 scale=2.0000 norm=1.0327
[iter 200] loss=-0.3923 val_loss=0.0000 scale=2.0000 norm=0.9855
[iter 300] loss=-0.9376 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 400] loss=-1.2762 val_loss=0.0000 scale=2.0000 norm=0.8818
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5509 val_loss=0.0000 scale=2.0000 norm=1.1099
[iter 200] loss=-0.0429 val_loss=0.0000 scale=2.0000 norm=1.0303
[iter 300] loss=-0.4954 val_loss=0.0000 scale=1.0000 norm=0.5091
[iter 400] loss=-0.9357 val_loss=0.0000 scale=2.0000 norm=0.9596
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2718 val_loss=0.0000 scale=2.0000 norm=1.0719
[iter 200] loss=-0.4546 val_loss=0.0000 scale=2.0000 norm=0.9810
[iter 300] loss=-1.0508 val_loss=0.0000 scale=2.0000 norm=0.8791
[iter 400] loss=-1.5059 val_loss=0.0000 scale=2.0000 norm=0.8355
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3740 val_loss=0.0000 scale=2.0000 norm=1.0727
[iter 200] loss=-0.2302 val_loss=0.0000 scale=1.0000 norm=0.4832
[iter 300] loss=-0.6296 val_loss=0.0000 scale=2.0000 norm=0.9412
[iter 400] loss=-0.9568 val_loss=0.0000 scale=1.0000 norm=0.4598
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4476 val_loss=0.0000 scale=2.0000 norm=1.0969
[iter 200] loss=-0.0937 val_loss=0.0000 scale=1.0000 norm=0.4861
[iter 300] loss=-0.4697 val_loss=0.0000 scale=1.0000 norm=0.4723
[iter 400] loss=-0.7513 val_loss=0.0000 scale=1.0000 norm=0.4610
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3922 val_loss=0.0000 scale=2.0000 norm=1.0707
[iter 200] loss=-0.1869 val_loss=0.0000 scale=1.0000 norm=0.4932
[iter 300] loss=-0.6042 val_loss=0.0000 scale=2.0000 norm=0.9499
[iter 400] loss=-0.8472 val_loss=0.0000 scale=2.0000 norm=0.9223
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3708 val_loss=0.0000 scale=2.0000 norm=1.0390
[iter 200] loss=-0.1985 val_loss=0.0000 scale=2.0000 norm=0.9538
[iter 300] loss=-0.6097 val_loss=0.0000 scale=1.0000 norm=0.4379
[iter 400] loss=-0.8568 val_loss=0.0000 scale=1.0000 norm=0.4306
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4933 val_loss=0.0000 scale=2.0000 norm=1.0986
[iter 200] loss=-0.1022 val_loss=0.0000 scale=2.0000 norm=1.0021
[iter 300] loss=-0.5355 val_loss=0.0000 scale=2.0000 norm=0.9656
[iter 400] loss=-0.8768 val_loss=0.0000 scale=2.0000 norm=0.9827
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4987 val_loss=0.0000 scale=2.0000 norm=1.1291
[iter 200] loss=-0.1444 val_loss=0.0000 scale=2.0000 norm=1.0179
[iter 300] loss=-0.5920 val_loss=0.0000 scale=2.0000 norm=0.9715
[iter 400] loss=-0.9311 val_loss=0.0000 scale=2.0000 norm=0.9651
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4042 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 200] loss=-0.1612 val_loss=0.0000 scale=2.0000 norm=0.9611
[iter 300] loss=-0.5672 val_loss=0.0000 scale=1.0000 norm=0.4541
[iter 400] loss=-0.8148 val_loss=0.0000 scale=1.0000 norm=0.4569
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3706 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.2160 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 300] loss=-0.6015 val_loss=0.0000 scale=2.0000 norm=0.9393
[iter 400] loss=-0.8396 val_loss=0.0000 scale=1.0000 norm=0.4631
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2329 val_loss=0.0000 scale=2.0000 norm=1.0189
[iter 200] loss=-0.4041 val_loss=0.0000 scale=2.0000 norm=0.9756
[iter 300] loss=-0.9004 val_loss=0.0000 scale=2.0000 norm=0.9309
[iter 400] loss=-1.2044 val_loss=0.0000 scale=2.0000 norm=0.8741
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3432 val_loss=0.0000 scale=2.0000 norm=1.0403
[iter 200] loss=-0.2626 val_loss=0.0000 scale=2.0000 norm=0.9248
[iter 300] loss=-0.6768 val_loss=0.0000 scale=2.0000 norm=0.8770
[iter 400] loss=-0.9463 val_loss=0.0000 scale=1.0000 norm=0.4216
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3142 val_loss=0.0000 scale=2.0000 norm=1.0128
[iter 200] loss=-0.4316 val_loss=0.0000 scale=2.0000 norm=0.9097
[iter 300] loss=-1.1044 val_loss=0.0000 scale=2.0000 norm=0.8734
[iter 400] loss=-1.6531 val_loss=0.0000 scale=2.0000 norm=0.8930
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3089 val_loss=0.0000 scale=2.0000 norm=1.0387
[iter 200] loss=-0.3211 val_loss=0.0000 scale=2.0000 norm=0.9754
[iter 300] loss=-0.7941 val_loss=0.0000 scale=1.0000 norm=0.4745
[iter 400] loss=-1.0926 val_loss=0.0000 scale=1.0000 norm=0.4576
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7441 val_loss=0.0000 scale=2.0000 norm=1.2259
[iter 200] loss=-0.0321 val_loss=0.0000 scale=2.0000 norm=0.9923
[iter 300] loss=-0.7029 val_loss=0.0000 scale=2.0000 norm=0.9354
[iter 400] loss=-1.2807 val_loss=0.0000 scale=2.0000 norm=0.9292
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4658 val_loss=0.0000 scale=2.0000 norm=1.0642
[iter 200] loss=-0.2772 val_loss=0.0000 scale=2.0000 norm=0.9614
[iter 300] loss=-0.8968 val_loss=0.0000 scale=2.0000 norm=0.9404
[iter 400] loss=-1.3944 val_loss=0.0000 scale=2.0000 norm=0.9079
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3946 val_loss=0.0000 scale=2.0000 norm=1.0777
[iter 200] loss=-0.1702 val_loss=0.0000 scale=2.0000 norm=0.9759
[iter 300] loss=-0.5242 val_loss=0.0000 scale=1.0000 norm=0.4713
[iter 400] loss=-0.7302 val_loss=0.0000 scale=2.0000 norm=0.9572
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4068 val_loss=0.0000 scale=2.0000 norm=1.0671
[iter 200] loss=-0.1495 val_loss=0.0000 scale=2.0000 norm=0.9667
[iter 300] loss=-0.5251 val_loss=0.0000 scale=2.0000 norm=0.9564
[iter 400] loss=-0.7055 val_loss=0.0000 scale=2.0000 norm=0.9673
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3383 val_loss=0.0000 scale=2.0000 norm=1.0720
[iter 200] loss=-0.3231 val_loss=0.0000 scale=2.0000 norm=0.9548
[iter 300] loss=-0.8330 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 400] loss=-1.2103 val_loss=0.0000 scale=2.0000 norm=0.8599
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3944 val_loss=0.0000 scale=2.0000 norm=1.0891
[iter 200] loss=-0.1570 val_loss=0.0000 scale=1.0000 norm=0.4941
[iter 300] loss=-0.5503 val_loss=0.0000 scale=2.0000 norm=0.9578
[iter 400] loss=-0.7989 val_loss=0.0000 scale=2.0000 norm=0.9286
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5824 val_loss=0.0000 scale=2.0000 norm=1.1150
[iter 200] loss=-0.0469 val_loss=0.0000 scale=2.0000 norm=1.0326
[iter 300] loss=-0.5471 val_loss=0.0000 scale=1.0000 norm=0.4809
[iter 400] loss=-0.8352 val_loss=0.0000 scale=2.0000 norm=0.9316
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3660 val_loss=0.0000 scale=2.0000 norm=1.0410
[iter 200] loss=-0.2097 val_loss=0.0000 scale=2.0000 norm=0.9339
[iter 300] loss=-0.5933 val_loss=0.0000 scale=2.0000 norm=0.9181
[iter 400] loss=-0.8412 val_loss=0.0000 scale=1.0000 norm=0.4549
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.2988 val_loss=0.0000 scale=2.0000 norm=0.9980
[iter 200] loss=-0.3668 val_loss=0.0000 scale=2.0000 norm=0.9253
[iter 300] loss=-0.8772 val_loss=0.0000 scale=2.0000 norm=0.8615
[iter 400] loss=-1.1604 val_loss=0.0000 scale=1.0000 norm=0.4181
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4578 val_loss=0.0000 scale=2.0000 norm=1.0866
[iter 200] loss=-0.0797 val_loss=0.0000 scale=2.0000 norm=0.9651
[iter 300] loss=-0.4929 val_loss=0.0000 scale=2.0000 norm=0.9209
[iter 400] loss=-0.7039 val_loss=0.0000 scale=1.0000 norm=0.4593
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3947 val_loss=0.0000 scale=2.0000 norm=1.0310
[iter 200] loss=-0.2166 val_loss=0.0000 scale=2.0000 norm=0.9254
[iter 300] loss=-0.6482 val_loss=0.0000 scale=1.0000 norm=0.4418
[iter 400] loss=-0.9696 val_loss=0.0000 scale=2.0000 norm=0.8861
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3682 val_loss=0.0000 scale=2.0000 norm=1.0498
[iter 200] loss=-0.2285 val_loss=0.0000 scale=2.0000 norm=0.9707
[iter 300] loss=-0.7129 val_loss=0.0000 scale=2.0000 norm=0.9395
[iter 400] loss=-1.0328 val_loss=0.0000 scale=1.0000 norm=0.4626
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3495 val_loss=0.0000 scale=2.0000 norm=1.0433
[iter 200] loss=-0.3493 val_loss=0.0000 scale=2.0000 norm=0.9526
[iter 300] loss=-0.8945 val_loss=0.0000 scale=2.0000 norm=0.9182
[iter 400] loss=-1.2435 val_loss=0.0000 scale=2.0000 norm=0.9059
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2592 val_loss=0.0000 scale=2.0000 norm=1.0134
[iter 200] loss=-0.4500 val_loss=0.0000 scale=2.0000 norm=0.9491
[iter 300] loss=-1.0672 val_loss=0.0000 scale=2.0000 norm=0.8868
[iter 400] loss=-1.5325 val_loss=0.0000 scale=2.0000 norm=0.8018
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1300 val_loss=0.0000 scale=2.0000 norm=0.9746
[iter 200] loss=-0.7759 val_loss=0.0000 scale=2.0000 norm=0.9145
[iter 300] loss=-1.6321 val_loss=0.0000 scale=2.0000 norm=0.8599
[iter 400] loss=-2.3957 val_loss=0.0000 scale=2.0000 norm=0.7675
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4579 val_loss=0.0000 scale=2.0000 norm=1.1001
[iter 200] loss=-0.0287 val_loss=0.0000 scale=1.0000 norm=0.5120
[iter 300] loss=-0.3760 val_loss=0.0000 scale=2.0000 norm=1.0010
[iter 400] loss=-0.6028 val_loss=0.0000 scale=1.0000 norm=0.4898
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3878 val_loss=0.0000 scale=2.0000 norm=1.0466
[iter 200] loss=-0.2092 val_loss=0.0000 scale=2.0000 norm=0.9452
[iter 300] loss=-0.5982 val_loss=0.0000 scale=1.0000 norm=0.4437
[iter 400] loss=-0.8613 val_loss=0.0000 scale=2.0000 norm=0.8805
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3297 val_loss=0.0000 scale=2.0000 norm=1.0479
[iter 200] loss=-0.2761 val_loss=0.0000 scale=2.0000 norm=0.9541
[iter 300] loss=-0.7514 val_loss=0.0000 scale=2.0000 norm=0.9168
[iter 400] loss=-0.9893 val_loss=0.0000 scale=1.0000 norm=0.4478
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3218 val_loss=0.0000 scale=2.0000 norm=1.0226
[iter 200] loss=-0.2714 val_loss=0.0000 scale=2.0000 norm=0.9545
[iter 300] loss=-0.6883 val_loss=0.0000 scale=1.0000 norm=0.4739
[iter 400] loss=-0.9562 val_loss=0.0000 scale=2.0000 norm=0.9192
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3316 val_loss=0.0000 scale=2.0000 norm=1.0400
[iter 200] loss=-0.2833 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 300] loss=-0.6677 val_loss=0.0000 scale=2.0000 norm=0.8691
[iter 400] loss=-0.9155 val_loss=0.0000 scale=1.0000 norm=0.4278
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4138 val_loss=0.0000 scale=2.0000 norm=1.0748
[iter 200] loss=-0.1249 val_loss=0.0000 scale=2.0000 norm=0.9639
[iter 300] loss=-0.5187 val_loss=0.0000 scale=2.0000 norm=0.9407
[iter 400] loss=-0.7173 val_loss=0.0000 scale=0.5000 norm=0.2338
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1992 val_loss=0.0000 scale=2.0000 norm=1.0083
[iter 200] loss=-0.4875 val_loss=0.0000 scale=2.0000 norm=1.0035
[iter 300] loss=-1.0491 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 400] loss=-1.4347 val_loss=0.0000 scale=2.0000 norm=0.8921
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3435 val_loss=0.0000 scale=2.0000 norm=1.0378
[iter 200] loss=-0.2873 val_loss=0.0000 scale=2.0000 norm=0.9255
[iter 300] loss=-0.7287 val_loss=0.0000 scale=2.0000 norm=0.8822
[iter 400] loss=-1.0377 val_loss=0.0000 scale=2.0000 norm=0.8484
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3473 val_loss=0.0000 scale=2.0000 norm=1.0601
[iter 200] loss=-0.2721 val_loss=0.0000 scale=2.0000 norm=0.9856
[iter 300] loss=-0.7390 val_loss=0.0000 scale=2.0000 norm=0.9477
[iter 400] loss=-1.0585 val_loss=0.0000 scale=1.0000 norm=0.4579
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3396 val_loss=0.0000 scale=2.0000 norm=1.0456
[iter 200] loss=-0.2637 val_loss=0.0000 scale=2.0000 norm=0.9903
[iter 300] loss=-0.7290 val_loss=0.0000 scale=2.0000 norm=0.9670
[iter 400] loss=-0.9880 val_loss=0.0000 scale=1.0000 norm=0.4718
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3634 val_loss=0.0000 scale=2.0000 norm=1.0556
[iter 200] loss=-0.2177 val_loss=0.0000 scale=2.0000 norm=0.9882
[iter 300] loss=-0.5947 val_loss=0.0000 scale=1.0000 norm=0.4790
[iter 400] loss=-0.8216 val_loss=0.0000 scale=1.0000 norm=0.4612
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3537 val_loss=0.0000 scale=2.0000 norm=1.0658
[iter 200] loss=-0.2474 val_loss=0.0000 scale=2.0000 norm=0.9702
[iter 300] loss=-0.7214 val_loss=0.0000 scale=2.0000 norm=0.9277
[iter 400] loss=-1.0238 val_loss=0.0000 scale=2.0000 norm=0.9131
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3412 val_loss=0.0000 scale=2.0000 norm=1.0232
[iter 200] loss=-0.2053 val_loss=0.0000 scale=2.0000 norm=0.9268
[iter 300] loss=-0.5701 val_loss=0.0000 scale=2.0000 norm=0.8713
[iter 400] loss=-0.8447 val_loss=0.0000 scale=2.0000 norm=0.8645
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3745 val_loss=0.0000 scale=2.0000 norm=1.0346
[iter 200] loss=-0.2167 val_loss=0.0000 scale=2.0000 norm=0.9291
[iter 300] loss=-0.5775 val_loss=0.0000 scale=2.0000 norm=0.9140
[iter 400] loss=-0.8017 val_loss=0.0000 scale=1.0000 norm=0.4769
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3547 val_loss=0.0000 scale=2.0000 norm=1.0425
[iter 200] loss=-0.3202 val_loss=0.0000 scale=2.0000 norm=0.9496
[iter 300] loss=-0.8589 val_loss=0.0000 scale=2.0000 norm=0.8893
[iter 400] loss=-1.2024 val_loss=0.0000 scale=2.0000 norm=0.8628
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2732 val_loss=0.0000 scale=2.0000 norm=1.0084
[iter 200] loss=-0.4437 val_loss=0.0000 scale=2.0000 norm=0.8873
[iter 300] loss=-1.0558 val_loss=0.0000 scale=2.0000 norm=0.8059
[iter 400] loss=-1.4986 val_loss=0.0000 scale=2.0000 norm=0.7726
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4140 val_loss=0.0000 scale=2.0000 norm=1.0846
[iter 200] loss=-0.3186 val_loss=0.0000 scale=2.0000 norm=1.0509
[iter 300] loss=-0.9555 val_loss=0.0000 scale=2.0000 norm=1.0515
[iter 400] loss=-1.4395 val_loss=0.0000 scale=2.0000 norm=1.0983
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4353 val_loss=0.0000 scale=2.0000 norm=1.0656
[iter 200] loss=-0.2399 val_loss=0.0000 scale=2.0000 norm=0.8897
[iter 300] loss=-0.6808 val_loss=0.0000 scale=1.0000 norm=0.3995
[iter 400] loss=-0.9854 val_loss=0.0000 scale=1.0000 norm=0.4063
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.0698
[iter 200] loss=-0.1467 val_loss=0.0000 scale=2.0000 norm=0.9697
[iter 300] loss=-0.5205 val_loss=0.0000 scale=2.0000 norm=0.9148
[iter 400] loss=-0.7680 val_loss=0.0000 scale=1.0000 norm=0.4490
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.7288 val_loss=0.0000 scale=2.0000 norm=1.2431
[iter 200] loss=0.0991 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 300] loss=-0.3973 val_loss=0.0000 scale=2.0000 norm=0.9753
[iter 400] loss=-0.7980 val_loss=0.0000 scale=1.0000 norm=0.4702
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3345 val_loss=0.0000 scale=2.0000 norm=1.0356
[iter 200] loss=-0.2719 val_loss=0.0000 scale=2.0000 norm=0.9505
[iter 300] loss=-0.7205 val_loss=0.0000 scale=2.0000 norm=0.9240
[iter 400] loss=-0.9787 val_loss=0.0000 scale=2.0000 norm=0.9003
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4263 val_loss=0.0000 scale=2.0000 norm=1.0446
[iter 200] loss=-0.2438 val_loss=0.0000 scale=2.0000 norm=0.9459
[iter 300] loss=-0.7904 val_loss=0.0000 scale=2.0000 norm=0.8845
[iter 400] loss=-1.1680 val_loss=0.0000 scale=2.0000 norm=0.8929
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4213 val_loss=0.0000 scale=2.0000 norm=1.1103
[iter 200] loss=-0.1332 val_loss=0.0000 scale=2.0000 norm=1.0296
[iter 300] loss=-0.5161 val_loss=0.0000 scale=1.0000 norm=0.4854
[iter 400] loss=-0.7617 val_loss=0.0000 scale=1.0000 norm=0.4759
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3037 val_loss=0.0000 scale=2.0000 norm=1.0422
[iter 200] loss=-0.3242 val_loss=0.0000 scale=2.0000 norm=0.9519
[iter 300] loss=-0.8202 val_loss=0.0000 scale=2.0000 norm=0.8832
[iter 400] loss=-1.1407 val_loss=0.0000 scale=2.0000 norm=0.8491
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2915 val_loss=0.0000 scale=2.0000 norm=1.0029
[iter 200] loss=-0.3535 val_loss=0.0000 scale=2.0000 norm=0.9080
[iter 300] loss=-0.7756 val_loss=0.0000 scale=2.0000 norm=0.8484
[iter 400] loss=-1.0548 val_loss=0.0000 scale=1.0000 norm=0.4194
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1636 val_loss=0.0000 scale=2.0000 norm=0.9904
[iter 200] loss=-0.6819 val_loss=0.0000 scale=2.0000 norm=0.9677
[iter 300] loss=-1.4145 val_loss=0.0000 scale=2.0000 norm=0.9575
[iter 400] loss=-2.0669 val_loss=0.0000 scale=2.0000 norm=0.9316
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4868 val_loss=0.0000 scale=2.0000 norm=1.1155
[iter 200] loss=-0.0936 val_loss=0.0000 scale=2.0000 norm=0.9738
[iter 300] loss=-0.4667 val_loss=0.0000 scale=2.0000 norm=0.9497
[iter 400] loss=-0.7278 val_loss=0.0000 scale=2.0000 norm=0.9219
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3895 val_loss=0.0000 scale=2.0000 norm=1.0889
[iter 200] loss=-0.1433 val_loss=0.0000 scale=2.0000 norm=0.9767
[iter 300] loss=-0.4896 val_loss=0.0000 scale=1.0000 norm=0.4665
[iter 400] loss=-0.7251 val_loss=0.0000 scale=2.0000 norm=0.9080
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4186 val_loss=0.0000 scale=2.0000 norm=1.0787
[iter 200] loss=-0.1402 val_loss=0.0000 scale=2.0000 norm=0.9722
[iter 300] loss=-0.5027 val_loss=0.0000 scale=1.0000 norm=0.4563
[iter 400] loss=-0.7394 val_loss=0.0000 scale=1.0000 norm=0.4360
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3670 val_loss=0.0000 scale=2.0000 norm=1.0087
[iter 200] loss=-0.3719 val_loss=0.0000 scale=2.0000 norm=0.9157
[iter 300] loss=-1.0055 val_loss=0.0000 scale=2.0000 norm=0.8826
[iter 400] loss=-1.4262 val_loss=0.0000 scale=2.0000 norm=0.8607
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5515 val_loss=0.0000 scale=2.0000 norm=1.1190
[iter 200] loss=-0.0718 val_loss=0.0000 scale=2.0000 norm=1.0129
[iter 300] loss=-0.6212 val_loss=0.0000 scale=2.0000 norm=0.9480
[iter 400] loss=-1.0163 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3402 val_loss=0.0000 scale=2.0000 norm=1.0422
[iter 200] loss=-0.2668 val_loss=0.0000 scale=2.0000 norm=0.9411
[iter 300] loss=-0.6744 val_loss=0.0000 scale=1.0000 norm=0.4454
[iter 400] loss=-0.9095 val_loss=0.0000 scale=0.5000 norm=0.2216
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6576 val_loss=0.0000 scale=2.0000 norm=1.1853
[iter 200] loss=0.1994 val_loss=0.0000 scale=1.0000 norm=0.5363
[iter 300] loss=-0.1448 val_loss=0.0000 scale=1.0000 norm=0.5203
[iter 400] loss=-0.3926 val_loss=0.0000 scale=0.5000 norm=0.2452
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3576 val_loss=0.0000 scale=2.0000 norm=1.0506
[iter 200] loss=-0.2158 val_loss=0.0000 scale=2.0000 norm=0.9849
[iter 300] loss=-0.6323 val_loss=0.0000 scale=2.0000 norm=0.9405
[iter 400] loss=-0.8550 val_loss=0.0000 scale=1.0000 norm=0.4508
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3596 val_loss=0.0000 scale=2.0000 norm=1.0297
[iter 200] loss=-0.2419 val_loss=0.0000 scale=2.0000 norm=0.9302
[iter 300] loss=-0.6560 val_loss=0.0000 scale=2.0000 norm=0.9137
[iter 400] loss=-0.9345 val_loss=0.0000 scale=2.0000 norm=0.9177
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3032 val_loss=0.0000 scale=2.0000 norm=1.0486
[iter 200] loss=-0.3591 val_loss=0.0000 scale=2.0000 norm=0.9902
[iter 300] loss=-0.9042 val_loss=0.0000 scale=2.0000 norm=0.9559
[iter 400] loss=-1.3243 val_loss=0.0000 scale=1.0000 norm=0.4404
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4863 val_loss=0.0000 scale=2.0000 norm=1.1098
[iter 200] loss=-0.0724 val_loss=0.0000 scale=2.0000 norm=1.0050
[iter 300] loss=-0.4529 val_loss=0.0000 scale=1.0000 norm=0.4646
[iter 400] loss=-0.7107 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3906 val_loss=0.0000 scale=2.0000 norm=1.0729
[iter 200] loss=-0.1644 val_loss=0.0000 scale=1.0000 norm=0.4983
[iter 300] loss=-0.5371 val_loss=0.0000 scale=1.0000 norm=0.4791
[iter 400] loss=-0.7597 val_loss=0.0000 scale=2.0000 norm=0.9372
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3657 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 200] loss=-0.2220 val_loss=0.0000 scale=2.0000 norm=0.9570
[iter 300] loss=-0.6016 val_loss=0.0000 scale=1.0000 norm=0.4786
[iter 400] loss=-0.8396 val_loss=0.0000 scale=2.0000 norm=0.9420
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2087 val_loss=0.0000 scale=2.0000 norm=0.9629
[iter 200] loss=-0.6608 val_loss=0.0000 scale=2.0000 norm=0.8931
[iter 300] loss=-1.5116 val_loss=0.0000 scale=2.0000 norm=0.8804
[iter 400] loss=-2.3486 val_loss=0.0000 scale=2.0000 norm=0.8718
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0949 val_loss=0.0000 scale=2.0000 norm=1.0010
[iter 200] loss=-0.8694 val_loss=0.0000 scale=2.0000 norm=0.9662
[iter 300] loss=-1.8196 val_loss=0.0000 scale=2.0000 norm=0.9464
[iter 400] loss=-2.7022 val_loss=0.0000 scale=2.0000 norm=0.8818
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3247 val_loss=0.0000 scale=2.0000 norm=1.0211
[iter 200] loss=-0.2920 val_loss=0.0000 scale=2.0000 norm=0.9490
[iter 300] loss=-0.7312 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-0.9889 val_loss=0.0000 scale=1.0000 norm=0.4297
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3378 val_loss=0.0000 scale=2.0000 norm=1.0624
[iter 200] loss=-0.3141 val_loss=0.0000 scale=2.0000 norm=0.9560
[iter 300] loss=-0.7325 val_loss=0.0000 scale=1.0000 norm=0.4457
[iter 400] loss=-1.0074 val_loss=0.0000 scale=2.0000 norm=0.8614
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2881 val_loss=0.0000 scale=2.0000 norm=1.0431
[iter 200] loss=-0.3663 val_loss=0.0000 scale=2.0000 norm=0.9243
[iter 300] loss=-0.8686 val_loss=0.0000 scale=2.0000 norm=0.8386
[iter 400] loss=-1.2540 val_loss=0.0000 scale=2.0000 norm=0.8210
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3395 val_loss=0.0000 scale=2.0000 norm=1.0490
[iter 200] loss=-0.2474 val_loss=0.0000 scale=2.0000 norm=0.9640
[iter 300] loss=-0.6517 val_loss=0.0000 scale=2.0000 norm=0.9370
[iter 400] loss=-0.8947 val_loss=0.0000 scale=2.0000 norm=0.9231
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3754 val_loss=0.0000 scale=2.0000 norm=1.0583
[iter 200] loss=-0.2012 val_loss=0.0000 scale=2.0000 norm=0.9389
[iter 300] loss=-0.5412 val_loss=0.0000 scale=2.0000 norm=0.9054
[iter 400] loss=-0.7428 val_loss=0.0000 scale=1.0000 norm=0.4468
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2095 val_loss=0.0000 scale=2.0000 norm=0.9710
[iter 200] loss=-0.6178 val_loss=0.0000 scale=2.0000 norm=0.8988
[iter 300] loss=-1.3437 val_loss=0.0000 scale=2.0000 norm=0.8420
[iter 400] loss=-2.0493 val_loss=0.0000 scale=2.0000 norm=0.8513
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6133 val_loss=0.0000 scale=2.0000 norm=1.1544
[iter 200] loss=0.0528 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 300] loss=-0.3250 val_loss=0.0000 scale=1.0000 norm=0.4704
[iter 400] loss=-0.5582 val_loss=0.0000 scale=1.0000 norm=0.4702
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4301 val_loss=0.0000 scale=2.0000 norm=1.1103
[iter 200] loss=-0.2011 val_loss=0.0000 scale=2.0000 norm=0.9895
[iter 300] loss=-0.7092 val_loss=0.0000 scale=1.0000 norm=0.4737
[iter 400] loss=-1.0279 val_loss=0.0000 scale=2.0000 norm=0.8958
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3968 val_loss=0.0000 scale=2.0000 norm=1.0700
[iter 200] loss=-0.1514 val_loss=0.0000 scale=2.0000 norm=0.9635
[iter 300] loss=-0.5512 val_loss=0.0000 scale=2.0000 norm=0.9148
[iter 400] loss=-0.8193 val_loss=0.0000 scale=1.0000 norm=0.4583
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.1920 val_loss=0.0000 scale=2.0000 norm=1.0225
[iter 200] loss=-0.6296 val_loss=0.0000 scale=2.0000 norm=0.9589
[iter 300] loss=-1.3578 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-2.0018 val_loss=0.0000 scale=2.0000 norm=0.8877
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3712 val_loss=0.0000 scale=2.0000 norm=1.0560
[iter 200] loss=-0.2730 val_loss=0.0000 scale=2.0000 norm=0.9626
[iter 300] loss=-0.7655 val_loss=0.0000 scale=2.0000 norm=0.9033
[iter 400] loss=-1.1342 val_loss=0.0000 scale=2.0000 norm=0.8511
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5416 val_loss=0.0000 scale=2.0000 norm=1.1581
[iter 200] loss=0.0254 val_loss=0.0000 scale=2.0000 norm=1.0621
[iter 300] loss=-0.3457 val_loss=0.0000 scale=1.0000 norm=0.5060
[iter 400] loss=-0.5460 val_loss=0.0000 scale=1.0000 norm=0.5179
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1697 val_loss=0.0000 scale=2.0000 norm=0.9719
[iter 200] loss=-0.7519 val_loss=0.0000 scale=2.0000 norm=0.9228
[iter 300] loss=-1.5941 val_loss=0.0000 scale=2.0000 norm=0.8764
[iter 400] loss=-2.3943 val_loss=0.0000 scale=2.0000 norm=0.8986
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5951 val_loss=0.0000 scale=2.0000 norm=1.0944
[iter 200] loss=-0.0583 val_loss=0.0000 scale=2.0000 norm=1.0248
[iter 300] loss=-0.6353 val_loss=0.0000 scale=2.0000 norm=0.9973
[iter 400] loss=-1.1049 val_loss=0.0000 scale=1.0000 norm=0.4779
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5652 val_loss=0.0000 scale=2.0000 norm=1.1486
[iter 200] loss=-0.0393 val_loss=0.0000 scale=2.0000 norm=0.9381
[iter 300] loss=-0.4031 val_loss=0.0000 scale=1.0000 norm=0.4443
[iter 400] loss=-0.6629 val_loss=0.0000 scale=2.0000 norm=0.8742
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5905 val_loss=0.0000 scale=2.0000 norm=1.1307
[iter 200] loss=0.1944 val_loss=0.0000 scale=1.0000 norm=0.5093
[iter 300] loss=-0.1501 val_loss=0.0000 scale=2.0000 norm=0.9718
[iter 400] loss=-0.3947 val_loss=0.0000 scale=1.0000 norm=0.4615
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3144 val_loss=0.0000 scale=2.0000 norm=1.0460
[iter 200] loss=-0.2703 val_loss=0.0000 scale=2.0000 norm=0.9709
[iter 300] loss=-0.6951 val_loss=0.0000 scale=2.0000 norm=0.9462
[iter 400] loss=-0.9592 val_loss=0.0000 scale=1.0000 norm=0.4623
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3647 val_loss=0.0000 scale=2.0000 norm=1.0500
[iter 200] loss=-0.2304 val_loss=0.0000 scale=1.0000 norm=0.4681
[iter 300] loss=-0.5747 val_loss=0.0000 scale=1.0000 norm=0.4586
[iter 400] loss=-0.8366 val_loss=0.0000 scale=2.0000 norm=0.8868
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4749 val_loss=0.0000 scale=2.0000 norm=1.0965
[iter 200] loss=-0.1708 val_loss=0.0000 scale=2.0000 norm=0.9736
[iter 300] loss=-0.6500 val_loss=0.0000 scale=2.0000 norm=0.9563
[iter 400] loss=-1.0201 val_loss=0.0000 scale=2.0000 norm=0.9398
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4425 val_loss=0.0000 scale=2.0000 norm=1.1150
[iter 200] loss=-0.1051 val_loss=0.0000 scale=1.0000 norm=0.4968
[iter 300] loss=-0.4595 val_loss=0.0000 scale=1.0000 norm=0.4687
[iter 400] loss=-0.6415 val_loss=0.0000 scale=2.0000 norm=0.9341
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4269 val_loss=0.0000 scale=2.0000 norm=0.9912
[iter 200] loss=-0.5136 val_loss=0.0000 scale=2.0000 norm=0.9306
[iter 300] loss=-1.3572 val_loss=0.0000 scale=2.0000 norm=0.8500
[iter 400] loss=-2.5803 val_loss=0.0000 scale=4.0000 norm=1.6102
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3371 val_loss=0.0000 scale=2.0000 norm=1.0337
[iter 200] loss=-0.2622 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 300] loss=-0.6356 val_loss=0.0000 scale=2.0000 norm=0.8853
[iter 400] loss=-0.8811 val_loss=0.0000 scale=1.0000 norm=0.4374
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3918 val_loss=0.0000 scale=2.0000 norm=1.0541
[iter 200] loss=-0.1564 val_loss=0.0000 scale=2.0000 norm=0.9549
[iter 300] loss=-0.5525 val_loss=0.0000 scale=1.0000 norm=0.4881
[iter 400] loss=-0.7486 val_loss=0.0000 scale=2.0000 norm=0.9768
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.3396 val_loss=0.0000 scale=2.0000 norm=1.0354
[iter 200] loss=-0.3124 val_loss=0.0000 scale=2.0000 norm=0.9649
[iter 300] loss=-0.8007 val_loss=0.0000 scale=2.0000 norm=0.9467
[iter 400] loss=-1.1290 val_loss=0.0000 scale=2.0000 norm=0.9130
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4456 val_loss=0.0000 scale=2.0000 norm=1.1034
[iter 200] loss=-0.1090 val_loss=0.0000 scale=1.0000 norm=0.4993
[iter 300] loss=-0.5008 val_loss=0.0000 scale=2.0000 norm=0.9652
[iter 400] loss=-0.7538 val_loss=0.0000 scale=2.0000 norm=0.9512
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3941 val_loss=0.0000 scale=2.0000 norm=1.0735
[iter 200] loss=-0.1756 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 300] loss=-0.5761 val_loss=0.0000 scale=2.0000 norm=0.9521
[iter 400] loss=-0.8128 val_loss=0.0000 scale=1.0000 norm=0.4838
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3654 val_loss=0.0000 scale=2.0000 norm=1.0664
[iter 200] loss=-0.2359 val_loss=0.0000 scale=2.0000 norm=0.9782
[iter 300] loss=-0.6024 val_loss=0.0000 scale=2.0000 norm=0.9056
[iter 400] loss=-0.8415 val_loss=0.0000 scale=2.0000 norm=0.8932
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3725 val_loss=0.0000 scale=2.0000 norm=1.0597
[iter 200] loss=-0.1806 val_loss=0.0000 scale=1.0000 norm=0.4935
[iter 300] loss=-0.5712 val_loss=0.0000 scale=1.0000 norm=0.4686
[iter 400] loss=-0.7945 val_loss=0.0000 scale=0.5000 norm=0.2260
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2979 val_loss=0.0000 scale=2.0000 norm=1.0242
[iter 200] loss=-0.3257 val_loss=0.0000 scale=2.0000 norm=0.9222
[iter 300] loss=-0.7484 val_loss=0.0000 scale=2.0000 norm=0.9137
[iter 400] loss=-1.0152 val_loss=0.0000 scale=1.0000 norm=0.4492
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4216 val_loss=0.0000 scale=2.0000 norm=1.0833
[iter 200] loss=-0.1258 val_loss=0.0000 scale=2.0000 norm=0.9492
[iter 300] loss=-0.5166 val_loss=0.0000 scale=2.0000 norm=0.8943
[iter 400] loss=-0.7708 val_loss=0.0000 scale=1.0000 norm=0.4600
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5200 val_loss=0.0000 scale=2.0000 norm=1.1243
[iter 200] loss=0.1101 val_loss=0.0000 scale=2.0000 norm=1.0039
[iter 300] loss=-0.2340 val_loss=0.0000 scale=1.0000 norm=0.4546
[iter 400] loss=-0.4363 val_loss=0.0000 scale=1.0000 norm=0.4503
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3341 val_loss=0.0000 scale=2.0000 norm=1.0320
[iter 200] loss=-0.2515 val_loss=0.0000 scale=2.0000 norm=0.9568
[iter 300] loss=-0.6512 val_loss=0.0000 scale=1.0000 norm=0.4666
[iter 400] loss=-0.8581 val_loss=0.0000 scale=2.0000 norm=0.9133
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4047 val_loss=0.0000 scale=2.0000 norm=1.1310
[iter 200] loss=-0.1952 val_loss=0.0000 scale=2.0000 norm=1.0835
[iter 300] loss=-0.6859 val_loss=0.0000 scale=2.0000 norm=1.0670
[iter 400] loss=-1.0712 val_loss=0.0000 scale=2.0000 norm=1.0161
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3668 val_loss=0.0000 scale=2.0000 norm=1.0534
[iter 200] loss=-0.2436 val_loss=0.0000 scale=2.0000 norm=0.9554
[iter 300] loss=-0.6464 val_loss=0.0000 scale=1.0000 norm=0.4611
[iter 400] loss=-0.8727 val_loss=0.0000 scale=1.0000 norm=0.4494
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2796 val_loss=0.0000 scale=2.0000 norm=1.0114
[iter 200] loss=-0.3429 val_loss=0.0000 scale=2.0000 norm=0.9448
[iter 300] loss=-0.8460 val_loss=0.0000 scale=2.0000 norm=0.9127
[iter 400] loss=-1.2565 val_loss=0.0000 scale=1.0000 norm=0.4375
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6058 val_loss=0.0000 scale=2.0000 norm=1.1794
[iter 200] loss=-0.0626 val_loss=0.0000 scale=2.0000 norm=1.0914
[iter 300] loss=-0.5128 val_loss=0.0000 scale=2.0000 norm=1.0352
[iter 400] loss=-0.8411 val_loss=0.0000 scale=1.0000 norm=0.5145
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2260 val_loss=0.0000 scale=2.0000 norm=0.9807
[iter 200] loss=-0.6403 val_loss=0.0000 scale=2.0000 norm=0.9146
[iter 300] loss=-1.4259 val_loss=0.0000 scale=2.0000 norm=0.8613
[iter 400] loss=-2.1775 val_loss=0.0000 scale=2.0000 norm=0.8434
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5010 val_loss=0.0000 scale=2.0000 norm=1.1289
[iter 200] loss=-0.0145 val_loss=0.0000 scale=2.0000 norm=1.0130
[iter 300] loss=-0.3358 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 400] loss=-0.5662 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3280 val_loss=0.0000 scale=2.0000 norm=1.0340
[iter 200] loss=-0.2750 val_loss=0.0000 scale=2.0000 norm=0.9408
[iter 300] loss=-0.7044 val_loss=0.0000 scale=2.0000 norm=0.9157
[iter 400] loss=-0.9517 val_loss=0.0000 scale=1.0000 norm=0.4476
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4321 val_loss=0.0000 scale=2.0000 norm=1.1110
[iter 200] loss=-0.1363 val_loss=0.0000 scale=2.0000 norm=1.0015
[iter 300] loss=-0.5210 val_loss=0.0000 scale=2.0000 norm=0.9557
[iter 400] loss=-0.7398 val_loss=0.0000 scale=1.0000 norm=0.4538
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4278 val_loss=0.0000 scale=2.0000 norm=0.9893
[iter 200] loss=-0.3748 val_loss=0.0000 scale=2.0000 norm=0.8952
[iter 300] loss=-1.0700 val_loss=0.0000 scale=2.0000 norm=0.8344
[iter 400] loss=-1.7079 val_loss=0.0000 scale=2.0000 norm=0.8143
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.8521 val_loss=0.0000 scale=1.0000 norm=0.6515
[iter 200] loss=0.3197 val_loss=0.0000 scale=1.0000 norm=0.5225
[iter 300] loss=-0.3092 val_loss=0.0000 scale=2.0000 norm=0.9645
[iter 400] loss=-0.8166 val_loss=0.0000 scale=2.0000 norm=0.9671
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3875 val_loss=0.0000 scale=2.0000 norm=1.0678
[iter 200] loss=-0.1857 val_loss=0.0000 scale=2.0000 norm=0.9761
[iter 300] loss=-0.5906 val_loss=0.0000 scale=2.0000 norm=0.9540
[iter 400] loss=-0.8122 val_loss=0.0000 scale=1.0000 norm=0.4710
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3559 val_loss=0.0000 scale=2.0000 norm=1.0670
[iter 200] loss=-0.2751 val_loss=0.0000 scale=2.0000 norm=0.9581
[iter 300] loss=-0.7837 val_loss=0.0000 scale=2.0000 norm=0.9267
[iter 400] loss=-1.1130 val_loss=0.0000 scale=1.0000 norm=0.4612
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3645 val_loss=0.0000 scale=2.0000 norm=1.0796
[iter 200] loss=-0.2742 val_loss=0.0000 scale=2.0000 norm=1.0044
[iter 300] loss=-0.7771 val_loss=0.0000 scale=2.0000 norm=0.9476
[iter 400] loss=-1.0807 val_loss=0.0000 scale=1.0000 norm=0.4456
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5118 val_loss=0.0000 scale=2.0000 norm=1.1391
[iter 200] loss=0.0100 val_loss=0.0000 scale=2.0000 norm=1.0064
[iter 300] loss=-0.2591 val_loss=0.0000 scale=1.0000 norm=0.4729
[iter 400] loss=-0.4236 val_loss=0.0000 scale=2.0000 norm=0.9344
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3187 val_loss=0.0000 scale=2.0000 norm=1.0362
[iter 200] loss=-0.2670 val_loss=0.0000 scale=2.0000 norm=0.9419
[iter 300] loss=-0.6946 val_loss=0.0000 scale=2.0000 norm=0.9087
[iter 400] loss=-1.0045 val_loss=0.0000 scale=2.0000 norm=0.8944
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.4108 val_loss=0.0000 scale=2.0000 norm=1.1161
[iter 200] loss=-0.1530 val_loss=0.0000 scale=2.0000 norm=1.0392
[iter 300] loss=-0.5317 val_loss=0.0000 scale=1.0000 norm=0.4858
[iter 400] loss=-0.7908 val_loss=0.0000 scale=2.0000 norm=0.9606
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2091 val_loss=0.0000 scale=2.0000 norm=1.0527
[iter 200] loss=-0.6740 val_loss=0.0000 scale=2.0000 norm=1.0344
[iter 300] loss=-1.5411 val_loss=0.0000 scale=2.0000 norm=1.0301
[iter 400] loss=-2.3943 val_loss=0.0000 scale=2.0000 norm=1.0147
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3406 val_loss=0.0000 scale=2.0000 norm=1.0379
[iter 200] loss=-0.2434 val_loss=0.0000 scale=2.0000 norm=0.9435
[iter 300] loss=-0.6527 val_loss=0.0000 scale=1.0000 norm=0.4528
[iter 400] loss=-0.9639 val_loss=0.0000 scale=1.0000 norm=0.4484
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3515 val_loss=0.0000 scale=2.0000 norm=1.0631
[iter 200] loss=-0.2688 val_loss=0.0000 scale=2.0000 norm=0.9493
[iter 300] loss=-0.6775 val_loss=0.0000 scale=2.0000 norm=0.9199
[iter 400] loss=-0.9273 val_loss=0.0000 scale=2.0000 norm=0.8779
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5173 val_loss=0.0000 scale=2.0000 norm=1.0916
[iter 200] loss=-0.1918 val_loss=0.0000 scale=2.0000 norm=0.9403
[iter 300] loss=-0.7668 val_loss=0.0000 scale=2.0000 norm=0.8655
[iter 400] loss=-1.1594 val_loss=0.0000 scale=2.0000 norm=0.8198
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2916 val_loss=0.0000 scale=2.0000 norm=1.0250
[iter 200] loss=-0.3703 val_loss=0.0000 scale=2.0000 norm=0.9357
[iter 300] loss=-0.8842 val_loss=0.0000 scale=2.0000 norm=0.9083
[iter 400] loss=-1.2956 val_loss=0.0000 scale=2.0000 norm=0.8747
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5293 val_loss=0.0000 scale=2.0000 norm=1.1611
[iter 200] loss=-0.0054 val_loss=0.0000 scale=1.0000 norm=0.5239
[iter 300] loss=-0.3967 val_loss=0.0000 scale=2.0000 norm=1.0143
[iter 400] loss=-0.5829 val_loss=0.0000 scale=2.0000 norm=0.9842
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2410 val_loss=0.0000 scale=2.0000 norm=1.0023
[iter 200] loss=-0.4691 val_loss=0.0000 scale=2.0000 norm=0.9094
[iter 300] loss=-0.9937 val_loss=0.0000 scale=2.0000 norm=0.8839
[iter 400] loss=-1.3426 val_loss=0.0000 scale=2.0000 norm=0.8973
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3733 val_loss=0.0000 scale=2.0000 norm=1.0459
[iter 200] loss=-0.1910 val_loss=0.0000 scale=2.0000 norm=0.9265
[iter 300] loss=-0.5875 val_loss=0.0000 scale=2.0000 norm=0.8891
[iter 400] loss=-0.8066 val_loss=0.0000 scale=1.0000 norm=0.4275
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.5363 val_loss=0.0000 scale=2.0000 norm=1.1677
[iter 200] loss=0.0229 val_loss=0.0000 scale=2.0000 norm=1.0223
[iter 300] loss=-0.3096 val_loss=0.0000 scale=2.0000 norm=0.9453
[iter 400] loss=-0.5239 val_loss=0.0000 scale=0.5000 norm=0.2266
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3408 val_loss=0.0000 scale=2.0000 norm=1.0417
[iter 200] loss=-0.2543 val_loss=0.0000 scale=1.0000 norm=0.4731
[iter 300] loss=-0.6481 val_loss=0.0000 scale=1.0000 norm=0.4619
[iter 400] loss=-0.8828 val_loss=0.0000 scale=2.0000 norm=0.8916
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1058 val_loss=0.0000 scale=2.0000 norm=0.9892
[iter 200] loss=-0.8630 val_loss=0.0000 scale=2.0000 norm=0.9692
[iter 300] loss=-1.8257 val_loss=0.0000 scale=2.0000 norm=0.9593
[iter 400] loss=-2.7388 val_loss=0.0000 scale=2.0000 norm=0.9102
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3848 val_loss=0.0000 scale=2.0000 norm=1.1221
[iter 200] loss=-0.4233 val_loss=0.0000 scale=2.0000 norm=1.0782
[iter 300] loss=-1.1907 val_loss=0.0000 scale=2.0000 norm=1.0518
[iter 400] loss=-1.9869 val_loss=0.0000 scale=4.0000 norm=2.0032
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3486 val_loss=0.0000 scale=2.0000 norm=1.0418
[iter 200] loss=-0.2417 val_loss=0.0000 scale=2.0000 norm=0.9448
[iter 300] loss=-0.6804 val_loss=0.0000 scale=2.0000 norm=0.9196
[iter 400] loss=-0.9284 val_loss=0.0000 scale=1.0000 norm=0.4554
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4585 val_loss=0.0000 scale=2.0000 norm=1.1210
[iter 200] loss=-0.2080 val_loss=0.0000 scale=2.0000 norm=1.0148
[iter 300] loss=-0.8744 val_loss=0.0000 scale=2.0000 norm=0.9674
[iter 400] loss=-1.4583 val_loss=0.0000 scale=2.0000 norm=0.9285
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2166 val_loss=0.0000 scale=2.0000 norm=1.0316
[iter 200] loss=-0.5013 val_loss=0.0000 scale=2.0000 norm=0.9129
[iter 300] loss=-1.0557 val_loss=0.0000 scale=2.0000 norm=0.8099
[iter 400] loss=-1.4078 val_loss=0.0000 scale=2.0000 norm=0.7519
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.6431 val_loss=0.0000 scale=2.0000 norm=1.2218
[iter 200] loss=0.1297 val_loss=0.0000 scale=1.0000 norm=0.5625
[iter 300] loss=-0.2246 val_loss=0.0000 scale=2.0000 norm=1.0498
[iter 400] loss=-0.4856 val_loss=0.0000 scale=2.0000 norm=0.9874
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4109 val_loss=0.0000 scale=2.0000 norm=1.0786
[iter 200] loss=-0.1609 val_loss=0.0000 scale=2.0000 norm=0.9527
[iter 300] loss=-0.5801 val_loss=0.0000 scale=1.0000 norm=0.4624
[iter 400] loss=-0.7765 val_loss=0.0000 scale=1.0000 norm=0.4577
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.1693 val_loss=0.0000 scale=2.0000 norm=1.0079
[iter 200] loss=-0.5527 val_loss=0.0000 scale=2.0000 norm=0.9779
[iter 300] loss=-1.1305 val_loss=0.0000 scale=2.0000 norm=0.9427
[iter 400] loss=-1.6186 val_loss=0.0000 scale=2.0000 norm=0.8938
[iter 0] loss=1.4189 val_loss=0.0000 scale=1.0000 norm=1.0000
[iter 100] loss=0.4898 val_loss=0.0000 scale=2.0000 norm=1.1240
[iter 200] loss=-0.1045 val_loss=0.0000 scale=2.0000 norm=1.0098
[iter 300] loss=-0.5108 val_loss=0.0000 scale=1.0000 norm=0.4710
[iter 400] loss=-0.8044 val_loss=0.0000 scale=0.5000 norm=0.2226
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.0525 val_loss=0.0000 scale=2.0000 norm=1.0013
[iter 200] loss=-0.9070 val_loss=0.0000 scale=2.0000 norm=0.9594
[iter 300] loss=-1.8183 val_loss=0.0000 scale=2.0000 norm=0.9111
[iter 400] loss=-2.8090 val_loss=0.0000 scale=2.0000 norm=0.8445
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3117 val_loss=0.0000 scale=2.0000 norm=1.0359
[iter 200] loss=-0.2935 val_loss=0.0000 scale=2.0000 norm=0.9481
[iter 300] loss=-0.6894 val_loss=0.0000 scale=2.0000 norm=0.9382
[iter 400] loss=-0.9592 val_loss=0.0000 scale=2.0000 norm=0.9261
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.3861 val_loss=0.0000 scale=2.0000 norm=1.0709
[iter 200] loss=-0.2001 val_loss=0.0000 scale=2.0000 norm=0.9848
[iter 300] loss=-0.6425 val_loss=0.0000 scale=1.0000 norm=0.4746
[iter 400] loss=-0.8818 val_loss=0.0000 scale=2.0000 norm=0.9194
[iter 0] loss=1.4189 val_loss=0.0000 scale=2.0000 norm=2.0000
[iter 100] loss=0.2902 val_loss=0.0000 scale=2.0000 norm=1.0282
[iter 200] loss=-0.3662 val_loss=0.0000 scale=2.0000 norm=0.9257
[iter 300] loss=-0.8633 val_loss=0.0000 scale=2.0000 norm=0.8623
[iter 400] loss=-1.1696 val_loss=0.0000 scale=1.0000 norm=0.4141

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n06>
Subject: Job 861719: <structure_numerical_ecfp3binery_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_ecfp3binery_NGB_generalizibility> was submitted from host <c205n12> by user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:35:00 2024
Job was executed on host(s) <4*c205n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 24 11:39:09 2024
                            <4*c205n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Thu Oct 24 11:39:09 2024
Terminated at Thu Oct 24 11:44:38 2024
Results reported at Thu Oct 24 11:44:38 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 7:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_ecfp3binery_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py ecfp --regressor_type NGB --radius 3 --vector binary --target "Rg1 (nm)" --oligo_type "RRU Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2121.36 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.77 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   329 sec.
    Turnaround time :                            578 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_polysize_ecfp3bin_generalizibili_NGB_wo_hypo.err> for stderr output of this job.

