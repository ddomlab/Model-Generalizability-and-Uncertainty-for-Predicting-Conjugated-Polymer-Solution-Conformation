polymer representationDimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer representationRRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer representationTrimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer representationRRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer representationRRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer representationMonomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.067240081873051e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 151), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 2.7040626397159493e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1035), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Trimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizibility_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n14>
Subject: Job 849615: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c201n06> by user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:55 2024
Job was executed on host(s) <4*c207n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:56 2024
                            <4*c207n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Tue Oct 22 10:25:56 2024
Terminated at Tue Oct 22 10:51:29 2024
Results reported at Tue Oct 22 10:51:29 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 10:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4324.57 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.55 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1533 sec.
    Turnaround time :                            1534 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Dimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizibility_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n10>
Subject: Job 849614: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c201n06> by user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:55 2024
Job was executed on host(s) <4*c205n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:56 2024
                            <4*c205n11>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Tue Oct 22 10:25:56 2024
Terminated at Tue Oct 22 10:52:03 2024
Results reported at Tue Oct 22 10:52:03 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 10:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4307.02 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.06 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1578 sec.
    Turnaround time :                            1568 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


RRU Trimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizibility_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n01>
Subject: Job 849618: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c201n06> by user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:56 2024
Job was executed on host(s) <4*c023n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:56 2024
                            <4*c026n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Tue Oct 22 10:25:56 2024
Terminated at Tue Oct 22 10:52:34 2024
Results reported at Tue Oct 22 10:52:34 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 10:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "RRU Trimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4887.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             2.71 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               60.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   1615 sec.
    Turnaround time :                            1598 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Monomer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizibility_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n10>
Subject: Job 849613: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c201n06> by user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:55 2024
Job was executed on host(s) <4*c202n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:55 2024
                            <4*c202n09>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Tue Oct 22 10:25:55 2024
Terminated at Tue Oct 22 10:55:47 2024
Results reported at Tue Oct 22 10:55:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 10:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4385.33 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.11 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1818 sec.
    Turnaround time :                            1792 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


RRU Dimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizibility_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n09>
Subject: Job 849617: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c201n06> by user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:55 2024
Job was executed on host(s) <4*c207n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:56 2024
                            <4*c207n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Tue Oct 22 10:25:56 2024
Terminated at Tue Oct 22 10:56:39 2024
Results reported at Tue Oct 22 10:56:39 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 10:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "RRU Dimer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5930.37 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.84 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1843 sec.
    Turnaround time :                            1844 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 1.6994636371262764e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00022568250010118822), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 132), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.5646379281883925e-05), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 4.414384491712669e-06), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 479), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000727880237480246), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


RRU Monomer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration-solvent dD-solvent dH-solvent dP)_NGB_mean_generalizibility_scores.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n08>
Subject: Job 849616: <structure_numerical_mordred_NGB_generalizibility> in cluster <Hazel> Done

Job <structure_numerical_mordred_NGB_generalizibility> was submitted from host <c201n06> by user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:55 2024
Job was executed on host(s) <4*c207n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Oct 22 10:25:56 2024
                            <4*c207n11>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_generalizibility> was used as the working directory.
Started at Tue Oct 22 10:25:56 2024
Terminated at Tue Oct 22 11:06:01 2024
Results reported at Tue Oct 22 11:06:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 10:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "structure_numerical_mordred_NGB_generalizibility"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../test_generalizability_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type "RRU Monomer"


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6096.43 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.93 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   2416 sec.
    Turnaround time :                            2406 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_numerical_mordred_generalizibili_NGB.err> for stderr output of this job.

