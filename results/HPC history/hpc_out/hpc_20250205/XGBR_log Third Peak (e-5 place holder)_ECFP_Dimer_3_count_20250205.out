Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14f035635cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03068056636922846), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016934338066392218), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 824), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004258724223586799), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 789), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01669718648827335), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 103), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002823647361884176), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 573), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14f035635cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027446159842421634), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005531748984360694), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 243), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0029259561849591486), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 600), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.020632827385749727), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006103440001814696), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 242), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14f035635cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.023400266158540368), ('regressor__regressor__max_depth', 3570), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017190618842134617), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 99), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007226418092862383), ('regressor__regressor__max_depth', 16), ('regressor__regressor__n_estimators', 236), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0020308725084030184), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 772), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003493555427540045), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 345), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14f035635cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.013121340277331396), ('regressor__regressor__max_depth', 3473), ('regressor__regressor__n_estimators', 98), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02244961641155749), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028642900506540746), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 54), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005903395819329352), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 266), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007333731882162415), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 181), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14f035635cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012150650253185026), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 91), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02379995916483145), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 84), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027254441801700485), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 60), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025836675394679567), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 61), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.013732191230690433), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 130), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14f035635cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.016019011742490718), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011679156628908869), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 130), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027782620869426913), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01756550476737392), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028177430805317264), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14f035635cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.024396288602083333), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00125071632521889), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1145), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0013254418009562938), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1080), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0025915571589769175), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 492), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0026148485045196855), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 567), ('regressor__regressor__n_jobs', -2)])


Average scores:	 r: 0.64±0.1	 r2: 0.39±0.14
Dimer_scaler
Filename: (ECFP3.count.512-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_transformerOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Third Peak (e-5 place holder)/Dimer_scaler/(ECFP3.count.512-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_transformerOFF_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Third Peak (e-5 place holder)/Dimer_scaler/(ECFP3.count.512-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_transformerOFF_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Third Peak (e-5 place holder)/Dimer_scaler/(ECFP3.count.512-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_transformerOFF_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c032n01>
Subject: Job 500584: <XGBR_log Third Peak (e-5 place holder)_ECFP_Dimer_20250205> in cluster <Hazel> Done

Job <XGBR_log Third Peak (e-5 place holder)_ECFP_Dimer_20250205> was submitted from host <c024n02> by user <sdehgha2> in cluster <Hazel> at Wed Feb  5 10:03:50 2025
Job was executed on host(s) <8*c032n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Feb  5 10:03:51 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed Feb  5 10:03:51 2025
Terminated at Wed Feb  5 11:54:50 2025
Results reported at Wed Feb  5 11:54:50 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Third Peak (e-5 place holder)_ECFP_Dimer_20250205"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log Third Peak (e-5 place holder)_ECFP_Dimer_3_count_20250205.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log Third Peak (e-5 place holder)_ECFP_Dimer_3_count_20250205.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_numerical.py --target_features "log Third Peak (e-5 place holder)"                                       --representation "ECFP"                                       --regressor_type "XGBR"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Dimer"                                       --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                       --special_impute 'Mw (g/mol)'                                       --imputer mean 




------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   24684.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             8.67 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               7.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   6673 sec.
    Turnaround time :                            6660 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log Third Peak (e-5 place holder)_ECFP_Dimer_3_count_20250205.err> for stderr output of this job.

