Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14729be65cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007544004561441475), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 234), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.009556991429325569), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 217), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005030956022097245), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 453), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 1848), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14729be65cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0033737929055106955), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 585), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005980881552274491), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 272), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0013179557333240343), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1120), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03878359214834697), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0023244767457723317), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 808), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14729be65cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04181737401982346), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008248959064596814), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 203), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0734997394167007), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014990542193371302), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 120), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017994463762222322), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 114), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14729be65cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.046618403273161836), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07797825748386174), ('regressor__regressor__max_depth', 569), ('regressor__regressor__n_estimators', 186), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028263092934530384), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 71), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.024481458999830993), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 88), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.055286260172320995), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 71), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14729be65cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04868335322794598), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003308363140815508), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 658), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004213671485467601), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 480), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005701668100156804), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 567), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.024501718725929027), ('regressor__regressor__max_depth', 333), ('regressor__regressor__n_estimators', 258), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14729be65cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.055138671910676125), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008443747083073319), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 304), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004183531018131943), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 524), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001947096834067887), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 937), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0019285021718686076), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1146), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14729be65cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0367141221645484), ('regressor__regressor__max_depth', 73), ('regressor__regressor__n_estimators', 66), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011334279427026259), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 168), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.051963702048043785), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005746507938777566), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 865), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04190835055539928), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])


Average scores:	 r: 0.75±0.09	 r2: 0.53±0.15
RRU Dimer_scaler
Filename: (Mordred-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log First Peak wo placeholder/RRU Dimer_scaler/(Mordred-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log First Peak wo placeholder/RRU Dimer_scaler/(Mordred-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log First Peak wo placeholder/RRU Dimer_scaler/(Mordred-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c028n03>
Subject: Job 500533: <XGBR_log First Peak wo placeholder_Mordred_RRU Dimer_20250122> in cluster <Hazel> Done

Job <XGBR_log First Peak wo placeholder_Mordred_RRU Dimer_20250122> was submitted from host <c011n03> by user <sdehgha2> in cluster <Hazel> at Wed Feb  5 09:59:19 2025
Job was executed on host(s) <6*c028n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Feb  5 09:59:21 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed Feb  5 09:59:21 2025
Terminated at Wed Feb  5 19:53:18 2025
Results reported at Wed Feb  5 19:53:18 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log First Peak wo placeholder_Mordred_RRU Dimer_20250122"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log First Peak wo placeholder_Mordred_RRU Dimer_20250122.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log First Peak wo placeholder_Mordred__RRU Dimer_20250122.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_numerical.py --target_features "log First Peak wo placeholder"                                       --representation "Mordred"                                       --regressor_type "XGBR"                                       --oligomer_representation "RRU Dimer"                                       --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                       --special_impute 'Mw (g/mol)'                                       --imputer mean 




------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   157189.00 sec.
    Max Memory :                                 11 GB
    Average Memory :                             10.32 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               5.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   35652 sec.
    Turnaround time :                            35639 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log First Peak wo placeholder_Mordred__RRU Dimer_20250122.err> for stderr output of this job.

