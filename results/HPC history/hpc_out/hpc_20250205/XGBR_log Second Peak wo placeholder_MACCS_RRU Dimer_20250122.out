Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14ffba971cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0073399821404107335), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 106), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004395171412633629), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 152), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017753003150895723), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 60), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022529675558268314), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 555), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0047845287687048365), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 245), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14ffba971cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017878524357603908), ('regressor__regressor__max_depth', 11), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002970442123758466), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 147), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001379005413891251), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 493), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008109715889812505), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 220), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0023281717813856038), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 511), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14ffba971cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0074285248458654364), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 114), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002128225805964455), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 574), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014469012876063813), ('regressor__regressor__max_depth', 7147), ('regressor__regressor__n_estimators', 78), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008575624114020545), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 108), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0010168587136004646), ('regressor__regressor__max_depth', 2841), ('regressor__regressor__n_estimators', 770), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14ffba971cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008689907174729165), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001472606363327799), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 478), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012910095074165484), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 72), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01728463523480272), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 51), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0012893323986617967), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 977), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14ffba971cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019640681428583454), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014436605845673648), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 756), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.018721429212383005), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 64), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01084017126014211), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 74), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004891883265237115), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 268), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14ffba971cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.022649528801772338), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003244590268303846), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 333), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014959718092865299), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 69), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028562674562756935), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 54), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011903803518603949), ('regressor__regressor__max_depth', 4062), ('regressor__regressor__n_estimators', 87), ('regressor__regressor__n_jobs', -2)])


Pipeline(steps=[('Impute feats',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_mean',
                                                  SimpleImputer(),
                                                  ['PDI',
                                                   'Temperature '
                                                   'SANS/SLS/DLS/SEC (K)',
                                                   'Concentration (mg/ml)'])],
                                   verbose_feature_names_out=False)),
                ('Calculate Mw',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('calculator_Mw (g/mol)',
                                                  FunctionTransformer(func=<function...
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('imputer_Mw (g/mol)',
                                                  SimpleImputer(),
                                                  ['Mw (g/mol)'])],
                                   verbose_feature_names_out=False)),
                ('drop Mn',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('Drop Mn column',
                                                  FunctionTransformer(func=<function drop_columns at 0x14ffba971cf0>,
                                                                      kw_args={'columns_to_drop': ['Mn '
                                                                                                   '(g/mol)']}),
                                                  ['Mn (g/mol)'])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003005899191992424), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 194), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0020288371413489516), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 517), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01666000301744671), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 70), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1160), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016768327402967192), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 713), ('regressor__regressor__n_jobs', -2)])


Average scores:	 r: 0.5±0.09	 r2: 0.22±0.1
RRU Dimer_scaler
Filename: (MACCS-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Second Peak wo placeholder/RRU Dimer_scaler/(MACCS-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Second Peak wo placeholder/RRU Dimer_scaler/(MACCS-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Second Peak wo placeholder/RRU Dimer_scaler/(MACCS-PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_transformerOFF_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c039n02>
Subject: Job 500539: <XGBR_log Second Peak wo placeholder_MACCS_RRU Dimer_20250122> in cluster <Hazel> Done

Job <XGBR_log Second Peak wo placeholder_MACCS_RRU Dimer_20250122> was submitted from host <c011n03> by user <sdehgha2> in cluster <Hazel> at Wed Feb  5 09:59:19 2025
Job was executed on host(s) <6*c039n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Feb  5 09:59:21 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed Feb  5 09:59:21 2025
Terminated at Wed Feb  5 10:51:59 2025
Results reported at Wed Feb  5 10:51:59 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "XGBR_log Second Peak wo placeholder_MACCS_RRU Dimer_20250122"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log Second Peak wo placeholder_MACCS_RRU Dimer_20250122.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log Second Peak wo placeholder_MACCS__RRU Dimer_20250122.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_numerical.py --target_features "log Second Peak wo placeholder"                                       --representation "MACCS"                                       --regressor_type "XGBR"                                       --oligomer_representation "RRU Dimer"                                       --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                       --special_impute 'Mw (g/mol)'                                       --imputer mean 




------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   9415.55 sec.
    Max Memory :                                 9 GB
    Average Memory :                             8.52 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               7.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   3173 sec.
    Turnaround time :                            3160 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250205/XGBR_log Second Peak wo placeholder_MACCS__RRU Dimer_20250122.err> for stderr output of this job.

