


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007150226847137212), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.87074438562149e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 69), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0908072687417649), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 79), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.8485190188463777e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009499681943944247), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 380), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007712079399943891), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.6148177035798658e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0972091628969665), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 51), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 9.532543744264323e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004453345559378286), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 907), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.4797444755083803e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0008592161798369592), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 975), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.8545369245803858e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00024754178532986217), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00217292506820665), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 941), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09102224313712833), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1971), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.2404395759439484e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008765058749898713), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 195), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03135436234806306), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 106), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01537948446580078), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 153), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00039118639884156683), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09909658806245562), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 231), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009295029134157658), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00923618246699946), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 489), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.3997158315596087e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007342850517847477), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 260), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00027731920794687624), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.021501198997626484), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 304), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01663285332892568), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 111), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002558837738486116), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 556), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.050487456479725606), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003063484899849753), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0018203471840955079), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01437162698913735), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 142), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013260638020401536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002432716649285746), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006807431324634108), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.921656429892826e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04138416599041046), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04142933945469091), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 85), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04394891843012702), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0901605197112305e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002827219637187335), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1610), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.3434606010560397e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09657921586574329), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0005023657467856598), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012775878563400261), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 191), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003492893687369815), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014423782662658504), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 125), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04407390360743213), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01378061537707908), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 209), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.000424585212950525), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03724324518804451), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 103), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.915182715297203e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008009925131960006), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 266), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 8.928323691766239e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0018073626310710252), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1485), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0010185171890047455), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.2335240784699313e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.050068413402106396), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 66), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00798705283158233), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 147), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00010622867846952912), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03356370083986541), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 86), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.034449943265159426), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 128), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01787159146793528), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 195), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00023236932861764678), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00291007982309656), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.1881515090987364e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09949698477175599), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1791), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0008972282119335852), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0041403437000295355), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 720), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00016456367256344735), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0992918750760948), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1917), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.3842542767070137e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0028417354348990835), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 576), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004684147045897336), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 535), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.988154836760413e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0009311591104713598), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004091265428353369), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 518), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 6.223821522015854e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004371484582007536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.809955146978886e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0075940105619385955), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 330), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006058841238225416), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 179), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00014862745018686505), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003578522489865813), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 643), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00013963064691829556), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.044127460606842236), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 53), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 9.570698424786763e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0653929118405093), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002215734233115942), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 861), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.477674146675779e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003794737933710587), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 849), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.5871897255499115e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03831934012063053), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 58), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03234273329040185), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.575174429091674e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019013554513331286), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 168), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.6980259507827906e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0034569019869171167), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1413), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05889790947231506), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0374514253812812e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [   0.188    0.219 -182.311]±[1.090000e-01 1.250000e-01 1.052591e+03]
[array([   0.18826845,    0.21919895, -182.31074028]), array([7.83952798e+00, 1.39264420e+02, 1.53517851e+05]), array([5.39702634e+00, 9.22370932e+01, 2.04889542e+04])]
{6: {'fit_time': array([53.4918313 , 53.23394132, 53.40872478, 54.01272678, 52.14727139]), 'score_time': array([1.89170671, 1.84008622, 1.93584681, 1.89774489, 1.79501891]), 'test_r2': [array([-0.04400771,  0.35498479, -0.00751014]), array([ 0.23578096,  0.00484642, -0.02609226]), array([  0.18893068,   0.36119367, -61.33612486]), array([ 0.30444357,  0.16343926, -0.05851683]), array([ 0.20205904,  0.22341332, -0.07034078])], 'test_rmse': [array([6.61837959e+00, 1.14457291e+02, 1.72335401e+04]), array([7.65053440e+00, 1.36370838e+02, 3.38436971e+05]), array([7.94648513e+00, 1.48059868e+02, 1.89776901e+05]), array([8.03940393e+00, 1.52644665e+02, 1.33093606e+04]), array([8.56607105e+00, 1.42124785e+02, 2.02846062e+04])], 'test_mae': [array([   4.51846685,   79.70508012, 3865.43194704]), array([5.35016720e+00, 9.29432939e+01, 5.37775300e+04]), array([5.21190642e+00, 9.97500492e+01, 2.21730468e+04]), array([   5.34463468,   89.271242  , 3360.61747645]), array([   5.87945627,   95.0418488 , 4993.49685832])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.002432716649285746, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'fit_time': array([1.51610494, 1.51559162, 1.51000261, 1.53063774, 1.37345123]), 'score_time': array([0.06993651, 0.07659984, 0.07025623, 0.07379174, 0.0720284 ]), 'test_r2': [array([0.26615001, 0.22473771, 0.0140036 ]), array([0.28086615, 0.34018559, 0.02903417]), array([ 0.12144335,  0.17797299, -0.02051321]), array([-0.06048794,  0.24312035, -0.02019902]), array([0.23187691, 0.17862307, 0.00360854])], 'test_rmse': [array([8.40859341e+00, 1.59693035e+02, 8.70408169e+03]), array([7.58388174e+00, 1.31283191e+02, 2.72509866e+04]), array([8.90522304e+00, 1.36475058e+02, 9.45564902e+04]), array([6.63434060e+00, 1.34659265e+02, 3.25531430e+05]), array([7.66625572e+00, 1.31113395e+02, 1.47659829e+04])], 'test_mae': [array([   5.61765778,   99.15635092, 2265.55922329]), array([5.46631997e+00, 8.94370021e+01, 5.83613867e+03]), array([6.32408130e+00, 9.25470908e+01, 1.34095440e+04]), array([4.87959286e+00, 8.68094408e+01, 4.58572452e+04]), array([   5.37343879,   96.46859181, 2360.38426003])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.04394891843012702, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'fit_time': array([3.0338316 , 3.07272243, 3.10516095, 3.07158661, 2.88721275]), 'score_time': array([0.12089705, 0.12416387, 0.12435675, 0.12309122, 0.12292051]), 'test_r2': [array([0.28427315, 0.07061375, 0.42144926]), array([ 0.17698708,  0.28032134, -0.02980669]), array([ 0.18454485,  0.10613944, -0.02150017]), array([ 0.17749813,  0.36953384, -0.03453523]), array([0.09759749, 0.2508581 , 0.08026737])], 'test_rmse': [array([7.62715449e+00, 1.49766714e+02, 1.78396229e+04]), array([7.89363833e+00, 1.41521638e+02, 6.07731699e+04]), array([5.85219128e+00, 1.54377761e+02, 3.33423015e+05]), array([9.25007107e+00, 1.40037033e+02, 1.40326100e+04]), array([8.52120837e+00, 1.16244804e+02, 1.86832016e+04])], 'test_mae': [array([   5.48680495,  107.11118477, 3960.22649286]), array([5.21159362e+00, 8.77354874e+01, 1.02671780e+04]), array([4.32928911e+00, 1.08067338e+02, 4.81801533e+04]), array([   6.13868023,   88.75748682, 2967.0755976 ]), array([   5.99432049,   75.45584979, 3550.24583571])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 103, 'regressor__estimator__learning_rate': 0.03724324518804451, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'fit_time': array([1.91644502, 2.01760125, 2.0089767 , 1.98470259, 1.90988779]), 'score_time': array([0.09117818, 0.08917809, 0.09212041, 0.09211874, 0.08838749]), 'test_r2': [array([ 0.2406014 ,  0.28285019, -0.01833752]), array([ 0.295142  ,  0.09920809, -0.02100406]), array([0.07767827, 0.47079103, 0.03222197]), array([ 0.08563751,  0.11375759, -0.03202251]), array([ 0.21014328,  0.17837077, -0.03506036])], 'test_rmse': [array([6.87192184e+00, 1.39361702e+02, 3.24994030e+05]), array([7.14533904e+00, 1.46513710e+02, 9.45171455e+04]), array([9.75993512e+00, 1.07552829e+02, 3.08029204e+04]), array([8.96465116e+00, 1.46309638e+02, 1.31317097e+04]), array([6.97617164e+00, 1.58456431e+02, 1.19441286e+04])], 'test_mae': [array([4.96455690e+00, 9.51431594e+01, 4.42613726e+04]), array([4.80740406e+00, 9.90866252e+01, 1.37221005e+04]), array([   6.35499361,   77.47779287, 6113.73862728]), array([   5.95388598,   93.08250151, 2593.8946112 ]), array([   5.28154763,   92.74448471, 2239.92712261])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 66, 'regressor__estimator__learning_rate': 0.050068413402106396, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'fit_time': array([54.35993624, 54.68482256, 56.46639299, 57.19151235, 54.18973184]), 'score_time': array([1.83806086, 1.91706944, 1.87371778, 1.89319158, 1.86105394]), 'test_r2': [array([ 0.12516673,  0.16476556, -0.03070567]), array([ 0.3722774 ,  0.44094107, -0.02760269]), array([ 0.47684215,  0.31735182, -0.08226021]), array([ 0.05278967,  0.26289348, -0.01724605]), array([ 0.09675954, -0.06810935, -0.0445156 ])], 'test_rmse': [array([8.26178182e+00, 1.52173003e+02, 1.60493091e+04]), array([7.79576726e+00, 9.30558915e+01, 9.83406418e+04]), array([6.50381654e+00, 1.39290683e+02, 7.74743643e+03]), array([8.11164985e+00, 1.69743229e+02, 3.24756876e+05]), array([7.64399873e+00, 1.34365322e+02, 2.33802727e+04])], 'test_mae': [array([   5.68148727,   91.52950295, 3193.04076983]), array([5.00338170e+00, 6.93527832e+01, 1.63862182e+04]), array([   4.55361992,   97.67751658, 2245.79797773]), array([5.18004349e+00, 1.07376253e+02, 4.21738334e+04]), array([5.41162293e+00, 9.25419727e+01, 5.75183561e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.00291007982309656, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'fit_time': array([1.79789495, 1.84194851, 1.70936775, 1.61294627, 1.70403624]), 'score_time': array([0.07706785, 0.07628965, 0.07713461, 0.07849312, 0.07345796]), 'test_r2': [array([ 0.09220704,  0.2212829 , -0.044545  ]), array([ 0.24892988,  0.00998039, -0.01647425]), array([0.2579275 , 0.43117467, 0.02590721]), array([ 0.07839123,  0.24762399, -0.03849708]), array([ 0.21372607,  0.03900374, -0.02006332])], 'test_rmse': [array([7.15948057e+00, 1.65639178e+02, 3.26759315e+04]), array([7.79484468e+00, 1.33895837e+02, 9.41108444e+04]), array([7.83530938e+00, 9.95448089e+01, 9.17028791e+03]), array([7.79125614e+00, 1.62435861e+02, 1.28674130e+04]), array([9.19250698e+00, 1.40821743e+02, 3.27169751e+05])], 'test_mae': [array([5.26740648e+00, 1.01409420e+02, 7.45674387e+03]), array([5.39351067e+00, 9.58937848e+01, 1.19980084e+04]), array([   5.6834419 ,   75.96417739, 2026.11759106]), array([   5.41158084,  108.13815286, 2493.15533614]), array([6.40871502e+00, 9.27663419e+01, 4.61743285e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 53, 'regressor__estimator__learning_rate': 0.044127460606842236, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'fit_time': array([1.97771835, 2.10295272, 2.23115253, 2.17466593, 2.09215927]), 'score_time': array([0.09310389, 0.10878682, 0.1008122 , 0.09566903, 0.09302068]), 'test_r2': [array([ 1.28706962e-01,  3.30144785e-01, -6.31963021e+03]), array([ 0.20659517,  0.21568228, -0.01397149]), array([ 0.12485339,  0.24184369, -0.01562421]), array([0.33019686, 0.17237254, 0.23549936]), array([ 0.2268679 ,  0.15005024, -0.00462007])], 'test_rmse': [array([8.29254348e+00, 1.06552256e+02, 1.96572403e+06]), array([7.13231115e+00, 1.48007695e+02, 9.36044864e+04]), array([8.42153739e+00, 1.36492832e+02, 3.20535184e+05]), array([7.68874150e+00, 1.78475447e+02, 1.91713638e+04]), array([7.87648292e+00, 1.26737268e+02, 5.78290329e+04])], 'test_mae': [array([5.45209637e+00, 7.32943791e+01, 2.16960594e+05]), array([4.92260745e+00, 8.54310790e+01, 1.08995325e+04]), array([5.47942416e+00, 9.48266617e+01, 3.96928858e+04]), array([5.14514234e+00, 1.06482585e+02, 5.33083315e+03]), array([5.41304279e+00, 8.98217511e+01, 8.57556532e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 73, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 'r2_avg': array([   0.18826845,    0.21919895, -182.31074028]), 'r2_stdev': array([1.08988264e-01, 1.25471835e-01, 1.05259117e+03]), 'rmse_avg': array([7.83952798e+00, 1.39264420e+02, 1.53517851e+05]), 'rmse_stdev': array([8.30232983e-01, 1.90938729e+01, 3.33233883e+05]), 'mae_avg': array([5.39702634e+00, 9.22370932e+01, 2.04889542e+04]), 'mae_stdev': array([4.92974254e-01, 9.87487057e+00, 3.74300541e+04]), 'r2_avg_aggregate': -60.63442429619533, 'r2_stdev_aggregate': 350.94187764489203, 'rmse_avg_aggregate': 51221.65148737282, 'rmse_stdev_aggregate': 111084.6025123028, 'mae_avg_aggregate': 6862.196115558509, 'mae_stdev_aggregate': 12480.14066063093}
scaler
Filename: (PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n01>
Subject: Job 288738: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c039n03> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:03:13 2025
Job was executed on host(s) <6*c201n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:03:15 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:03:15 2025
Terminated at Mon Jan 20 08:57:50 2025
Results reported at Mon Jan 20 08:57:50 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   162433.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.86 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   35676 sec.
    Turnaround time :                            35677 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 6.77026269940746e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05889790947231506), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0374514253812812e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015587017606127069), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.136  0.11  -0.685]±[0.141 0.136 3.805]
[array([ 0.13622772,  0.10995703, -0.68513191]), array([8.06333943e+00, 1.48393872e+02, 9.61977232e+04]), array([5.44133568e+00, 9.66213213e+01, 1.43870593e+04])]
{6: {'fit_time': array([1.56665945, 1.57465792, 1.54702687, 1.59127283, 1.60614228]), 'score_time': array([0.06511855, 0.06709981, 0.0658884 , 0.0702529 , 0.06952214]), 'test_r2': [array([0.06328867, 0.27114936, 0.1084788 ]), array([ 0.23696159, -0.12333829, -0.02609693]), array([ 0.147331  ,  0.16530226, -0.6845135 ]), array([ 0.33649437,  0.10827586, -0.09605416]), array([ 0.13390022,  0.01352543, -0.01242649])], 'test_rmse': [array([6.26906403e+00, 1.21668387e+02, 1.62112172e+04]), array([7.64462250e+00, 1.44887772e+02, 3.38437740e+05]), array([8.14772430e+00, 1.69245595e+02, 3.11968466e+04]), array([7.85199424e+00, 1.57597075e+02, 1.35432943e+04]), array([8.92442526e+00, 1.60183507e+02, 1.97281924e+04])], 'test_mae': [array([   4.32722838,   80.26322526, 3925.05985198]), array([5.17237629e+00, 9.77550304e+01, 5.37961564e+04]), array([5.33836909e+00, 1.08355715e+02, 5.61822776e+03]), array([   5.20440006,   92.64308098, 3626.12370356]), array([   5.9991339 ,  103.03902943, 4802.53456977])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 69, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'fit_time': array([22.36938715, 23.49497128, 22.30139017, 22.39311528, 22.61234403]), 'score_time': array([0.62596416, 0.6538434 , 0.66951513, 0.6355269 , 0.65636873]), 'test_r2': [array([0.25948382, 0.23044052, 0.02358672]), array([ 0.21042121,  0.18703361, -0.02285272]), array([ 0.1774046 ,  0.00213505, -0.0204182 ]), array([-0.19956676,  0.13525206, -0.01946935]), array([0.2141375 , 0.00828287, 0.03329909])], 'test_rmse': [array([8.44669827e+00, 1.59104601e+02, 8.66167995e+03]), array([7.94665615e+00, 1.45725153e+02, 2.79696357e+04]), array([8.61693966e+00, 1.50364782e+02, 9.45520881e+04]), array([7.05597620e+00, 1.43935391e+02, 3.25414994e+05]), array([7.75427456e+00, 1.44068728e+02, 1.45443201e+04])], 'test_mae': [array([   5.78832283,  102.55075115, 2298.55020592]), array([5.44648752e+00, 9.40356225e+01, 5.89085685e+03]), array([5.97899123e+00, 9.74860053e+01, 1.33464466e+04]), array([5.10643698e+00, 9.37111537e+01, 4.56568128e+04]), array([   5.56373389,  101.87410843, 2366.53709976])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 907, 'regressor__estimator__learning_rate': 0.004453345559378286, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'fit_time': array([91.589468  , 96.35226846, 93.87479353, 90.49643779, 90.49085283]), 'score_time': array([1.41407299, 1.39586949, 1.5576582 , 1.50914097, 1.4956615 ]), 'test_r2': [array([ 0.25569037, -0.16930752,  0.34018051]), array([ 0.05253348,  0.16494123, -0.00299366]), array([-0.39181446,  0.09182636, -0.02141487]), array([0.18858507, 0.38630411, 0.20521126]), array([0.18284284, 0.03447739, 0.1687641 ])], 'test_rmse': [array([7.77796005e+00, 1.67989274e+02, 1.90514271e+04]), array([8.46946221e+00, 1.52444604e+02, 5.99767778e+04]), array([7.64555726e+00, 1.55608852e+02, 3.33409093e+05]), array([9.18751624e+00, 1.38162003e+02, 1.22996192e+04]), array([8.10874855e+00, 1.31969245e+02, 1.77616230e+04])], 'test_mae': [array([   5.37333729,  115.29004548, 4324.47863705]), array([5.10179832e+00, 9.61616586e+01, 1.01216402e+04]), array([4.52069707e+00, 1.03602848e+02, 4.83328470e+04]), array([   5.69978399,   85.04039631, 2611.8255678 ]), array([   5.37171278,   83.48716945, 3429.64422312])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1971, 'regressor__estimator__learning_rate': 0.09102224313712833, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'fit_time': array([7.45914412, 8.2724371 , 7.50140476, 7.45006943, 7.41255045]), 'score_time': array([0.25033164, 0.23903775, 0.24655747, 0.24753571, 0.24523973]), 'test_r2': [array([ 0.15656537,  0.15351238, -0.0203566 ]), array([ 0.17904377,  0.00826437, -0.01953245]), array([0.0543362 , 0.34744883, 0.02040787]), array([0.0924592 , 0.09507187, 0.05057094]), array([ 0.14306932,  0.1220796 , -0.03570319])], 'test_rmse': [array([7.24217523e+00, 1.51407994e+02, 3.25316056e+05]), array([7.71137858e+00, 1.53731897e+02, 9.44490057e+04]), array([9.88266540e+00, 1.19430576e+02, 3.09903625e+04]), array([8.93114776e+00, 1.47844004e+02, 1.25952835e+04]), array([7.26634215e+00, 1.63794570e+02, 1.19478370e+04])], 'test_mae': [array([4.99373393e+00, 1.03510053e+02, 4.58780786e+04]), array([5.06752965e+00, 1.04947100e+02, 1.36341995e+04]), array([   6.5241298 ,   78.87616849, 6103.0783288 ]), array([   6.13384339,   91.82660118, 2494.61218761]), array([   5.22077099,   93.89658829, 2257.46737626])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 304, 'regressor__estimator__learning_rate': 0.021501198997626484, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'fit_time': array([85.51338506, 88.78967667, 88.4833107 , 85.97307587, 85.69282818]), 'score_time': array([1.4318893 , 1.5090549 , 1.63278723, 1.43050933, 1.2459445 ]), 'test_r2': [array([0.17163352, 0.05720585, 0.79914762]), array([ 0.3921388 ,  0.18371911, -0.01568244]), array([ 0.22367775,  0.22214855, -0.08107651]), array([-0.04674766,  0.14723824, -0.01723255]), array([-1.12209882e-02, -2.77533043e-01, -2.27754934e+01])], 'test_rmse': [array([   8.03937589,  161.6746212 , 7084.79846815]), array([7.67144529e+00, 1.12443639e+02, 9.77685999e+04]), array([   7.92269479,  148.68663501, 7743.19848727]), array([8.52721047e+00, 1.82574951e+02, 3.24754721e+05]), array([8.08801507e+00, 1.46948586e+02, 1.11546739e+05])], 'test_mae': [array([   5.60156433,   95.3945675 , 1780.1153681 ]), array([4.84029712e+00, 7.72996393e+01, 1.60135995e+04]), array([   4.86064386,   97.01038771, 2233.16634104]), array([5.11026422e+00, 1.12031595e+02, 4.22084010e+04]), array([5.31525563e+00, 9.68212960e+01, 1.73037589e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1917, 'regressor__estimator__learning_rate': 0.0992918750760948, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'fit_time': array([15.39793468, 15.62530422, 14.7288537 , 14.8105011 , 14.96619105]), 'score_time': array([0.4607532 , 0.47337127, 0.44695139, 0.45767879, 0.42771769]), 'test_r2': [array([ 0.15774467,  0.16687818, -0.05046683]), array([ 0.16097752, -0.09945925, -0.01664428]), array([ 0.12659713,  0.23638199, -0.03712291]), array([ 0.03862318,  0.19878752, -0.03479061]), array([ 0.14683286,  0.11791878, -0.02063325])], 'test_rmse': [array([6.89620230e+00, 1.71327653e+02, 3.27684252e+04]), array([8.23861148e+00, 1.41102512e+02, 9.41187154e+04]), array([8.50041809e+00, 1.15336623e+02, 9.46232628e+03]), array([7.95757989e+00, 1.67624810e+02, 1.28444301e+04]), array([9.57555798e+00, 1.34915906e+02, 3.27261137e+05])], 'test_mae': [array([5.43297168e+00, 1.06305950e+02, 7.54106711e+03]), array([5.83597048e+00, 1.02153437e+02, 1.20245645e+04]), array([   6.42325056,   87.00636049, 2156.69223592]), array([   5.85048888,  109.81632719, 2428.21398387]), array([7.09696426e+00, 9.72008209e+01, 4.65733896e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 576, 'regressor__estimator__learning_rate': 0.0028417354348990835, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'fit_time': array([80.80313969, 80.20286727, 85.24774432, 76.42804813, 84.34798121]), 'score_time': array([1.58547211, 1.66607165, 1.50693202, 1.56698036, 1.58677363]), 'test_r2': [array([ 0.11011188,  0.09273138, -1.78554493]), array([ 0.18817546,  0.16849871, -0.01387954]), array([ 0.20442492,  0.266963  , -0.01565222]), array([0.30961757, 0.09492255, 0.10533102]), array([0.10221629, 0.03941716, 0.01145697])], 'test_rmse': [array([8.38056578e+00, 1.24005264e+02, 4.12664814e+04]), array([7.21462811e+00, 1.52394658e+02, 9.36002424e+04]), array([8.02955651e+00, 1.34212640e+02, 3.20539605e+05]), array([7.80596384e+00, 1.86639647e+02, 2.07393563e+04]), array([8.48772584e+00, 1.34733355e+02, 5.73644448e+04])], 'test_mae': [array([5.50963203e+00, 8.50264237e+01, 8.17743860e+03]), array([4.75000047e+00, 8.69507087e+01, 1.09379441e+04]), array([5.38170350e+00, 9.32064465e+01, 3.97388529e+04]), array([5.04042244e+00, 1.12783033e+02, 5.57336686e+03]), array([5.46450209e+00, 9.43869008e+01, 8.34132723e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.015587017606127069, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 'r2_avg': array([ 0.13622772,  0.10995703, -0.68513191]), 'r2_stdev': array([0.14066472, 0.13577375, 3.80537412]), 'rmse_avg': array([8.06333943e+00, 1.48393872e+02, 9.61977232e+04]), 'rmse_stdev': array([7.22864389e-01, 1.75777110e+01, 1.19732806e+05]), 'mae_avg': array([5.44133568e+00, 9.66213213e+01, 1.43870593e+04]), 'mae_stdev': array([5.56352759e-01, 9.58870621e+00, 1.64307482e+04]), 'r2_avg_aggregate': -0.14631571774572547, 'r2_stdev_aggregate': 1.3606041975838499, 'rmse_avg_aggregate': 32118.060148042205, 'rmse_stdev_aggregate': 39917.03547774394, 'mae_avg_aggregate': 4829.707320187689, 'mae_stdev_aggregate': 5480.297758049743}
scaler
Filename: (PDI-Mw-concentration-temperature)_NGB_mean_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature)_NGB_mean_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature)_NGB_mean_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature)_NGB_mean_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c026n01>
Subject: Job 288753: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c023n02> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:11:47 2025
Job was executed on host(s) <6*c026n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:11:49 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:11:49 2025
Terminated at Mon Jan 20 09:42:58 2025
Results reported at Mon Jan 20 09:42:58 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)'                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   173021.05 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.74 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   37890 sec.
    Turnaround time :                            37871 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250119.err> for stderr output of this job.

