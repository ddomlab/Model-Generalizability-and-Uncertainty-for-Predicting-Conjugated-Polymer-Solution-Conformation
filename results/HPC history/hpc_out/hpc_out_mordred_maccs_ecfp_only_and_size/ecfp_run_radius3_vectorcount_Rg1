polymer unit :Monomer with rep of ECFP3 and count



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer unit :Monomer with rep of ECFP3 and count



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6
polymer unit :Monomer with rep of ECFP3 and count



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [None, 'sqrt', 0.05, 0.05, 2000] before, using random point [None, 'log2', 0.9783625509853134, 0.6632764870941991, 94]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [None, 'sqrt', 0.05, 0.05, 2000] before, using random point [None, 'log2', 0.10007874093883351, 0.8319572960064247, 147]
  warnings.warn(
Process LokyProcess-6:
Process LokyProcess-5:
Process LokyProcess-3:
Process LokyProcess-7:
Process LokyProcess-10:
Process LokyProcess-1:


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05090724100894371), ('regressor__regressor__min_samples_split', 0.05388845645205688), ('regressor__regressor__n_estimators', 183)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05058321728457546), ('regressor__regressor__min_samples_split', 0.0513873903508154), ('regressor__regressor__n_estimators', 525)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.051639825680045964), ('regressor__regressor__min_samples_split', 0.06504108448753901), ('regressor__regressor__n_estimators', 1286)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05060301334581676), ('regressor__regressor__min_samples_split', 0.055609912806435235), ('regressor__regressor__n_estimators', 56)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.051621669425973835), ('regressor__regressor__min_samples_split', 0.05586957536472967), ('regressor__regressor__n_estimators', 293)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05147281792725439), ('regressor__regressor__min_samples_split', 0.07682705748212029), ('regressor__regressor__n_estimators', 163)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.0506123654445674), ('regressor__regressor__min_samples_split', 0.07197078550245575), ('regressor__regressor__n_estimators', 69)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.07907214148322617), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05227799828227908), ('regressor__regressor__min_samples_split', 0.06975348900898691), ('regressor__regressor__n_estimators', 305)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 498, in __init__
    _seen = set()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 379, in extract
    linecache.checkcache(filename)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/linecache.py", line 65, in checkcache
    if len(entry) == 1:
KeyboardInterrupt
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
Traceback (most recent call last):
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 370, in extract
    linecache.lazycache(filename, f.f_globals)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/linecache.py", line 179, in lazycache
    get_lines = functools.partial(get_source, name)
KeyboardInterrupt
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
Process LokyProcess-11:
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1703, in _get_outputs
    self._abort()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1614, in _abort
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/executor.py", line 75, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 1303, in shutdown
    executor_manager_thread.join()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/threading.py", line 1088, in join
Process LokyProcess-9:
Process LokyProcess-2:
Process LokyProcess-4:
Process LokyProcess-16:
Process LokyProcess-11:
Process LokyProcess-3:
Process LokyProcess-6:
Process LokyProcess-1:
Process LokyProcess-24:
Process LokyProcess-14:
Process LokyProcess-5:
Process LokyProcess-12:


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.021647755827255845), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015341174014704565), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 60), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004859658929490983), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 496), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007959314967455694), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 126), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05884160460848559), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006170312141766302), ('regressor__regressor__max_depth', 1181), ('regressor__regressor__n_estimators', 76), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0027491852706903793), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 748), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004269756893281897), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 561), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02676467872899652), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 79), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
Traceback (most recent call last):
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
    time.sleep(0.01)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
Traceback (most recent call last):
KeyboardInterrupt
Traceback (most recent call last):
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
    main()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
KeyboardInterrupt
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 134, in format_exception
    value, tb = _parse_value_tb(exc, value, tb)
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 93, in _parse_value_tb
    def _parse_value_tb(exc, value, tb):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 376, in extract
    result.append(FrameSummary(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 274, in __init__
    if lookup_line:
KeyboardInterrupt
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 369, in extract
    fnames.add(filename)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
Traceback (most recent call last):
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 489, in __init__
    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 376, in extract
    result.append(FrameSummary(
KeyboardInterrupt
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 338, in extract
    @classmethod
    main_ecfp_numerical(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 499, in __init__
    _seen.add(id(exc_value))
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
    scores, predictions,data_shapes  = train_regressor(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
KeyboardInterrupt
    if not self._initialized:
Traceback (most recent call last):
KeyboardInterrupt
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
Traceback (most recent call last):
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 353, in extract
    limit = getattr(sys, 'tracebacklimit', None)
KeyboardInterrupt
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
Traceback (most recent call last):
    optim_result, score_name = self._step(
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1703, in _get_outputs
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
    self._abort()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1614, in _abort
Traceback (most recent call last):
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in abort_everything
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
    self._workers.terminate(kill_workers=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/executor.py", line 75, in terminate
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
    self.shutdown(kill_workers=kill_workers)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 1288, in shutdown
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
    mp.util.debug(f"shutting down executor {self}")
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 478, in fit
    trees = [
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 479, in <listcomp>
    self._make_estimator(append=False, random_state=random_state)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/ensemble/_base.py", line 149, in _make_estimator
    _set_random_states(estimator, random_state)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/ensemble/_base.py", line 74, in _set_random_states
    for key in sorted(estimator.get_params(deep=True)):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 243, in get_params
    for key in self._get_param_names():
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 208, in _get_param_names
    init_signature = inspect.signature(init)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/inspect.py", line 3254, in signature
    return Signature.from_callable(obj, follow_wrapped=follow_wrapped,
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/inspect.py", line 3002, in from_callable
    return _signature_from_callable(obj, sigcls=cls,
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/inspect.py", line 2463, in _signature_from_callable
    return _signature_from_function(sigcls, obj,
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/inspect.py", line 2370, in _signature_from_function
    return cls(parameters,
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/inspect.py", line 2969, in __init__
    params = OrderedDict((param.name, param) for param in parameters)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/inspect.py", line 2969, in <genexpr>
    params = OrderedDict((param.name, param) for param in parameters)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 465, in _process_worker
    exc = _ExceptionWithTraceback(e)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 247, in __init__
    tb = traceback.format_exception(type(exc), exc, tb)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 489, in __init__
    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
KeyboardInterrupt


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 142), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 322), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n11>
Subject: Job 806998: <ecfp_radius3_vectorcount_NGB_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius3_vectorcount_NGB_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:24 2024
Job was executed on host(s) <4*c200n11>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
                            <4*c200n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:36:25 2024
Terminated at Thu Oct 10 12:02:05 2024
Results reported at Thu Oct 10 12:02:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius3_vectorcount_NGB_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius3_vectorcount_Rg1 (nm)_NGB_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius3_vectorcount_Rg1 (nm)_NGB_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type NGB --radius 3 --vector count --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   6527.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.89 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1563 sec.
    Turnaround time :                            1541 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n07>
Subject: Job 806990: <ecfp_radius3_vectorcount_RF_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius3_vectorcount_RF_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:24 2024
Job was executed on host(s) <4*c202n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
                            <4*c202n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:36:25 2024
Terminated at Thu Oct 10 12:02:08 2024
Results reported at Thu Oct 10 12:02:08 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius3_vectorcount_RF_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius3_vectorcount_Rg1 (nm)_RF_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius3_vectorcount_Rg1 (nm)_RF_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type RF --radius 3 --vector count --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   4253.28 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.83 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1544 sec.
    Turnaround time :                            1544 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c039n01>
Subject: Job 807006: <ecfp_radius3_vectorcount_XGBR_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius3_vectorcount_XGBR_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
Job was executed on host(s) <4*c039n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:37:23 2024
                            <4*c036n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:37:23 2024
Terminated at Thu Oct 10 12:02:08 2024
Results reported at Thu Oct 10 12:02:08 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius3_vectorcount_XGBR_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius3_vectorcount_Rg1 (nm)_XGBR_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius3_vectorcount_Rg1 (nm)_XGBR_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type XGBR --radius 3 --vector count --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   5520.30 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.32 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               59.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   1507 sec.
    Turnaround time :                            1543 sec.

The output (if any) is above this job summary.

