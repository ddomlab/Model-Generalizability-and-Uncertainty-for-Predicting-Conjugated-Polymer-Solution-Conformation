polymer unit :Monomer with rep of ECFP4 and binary



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer unit :Monomer with rep of ECFP4 and binary



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6
polymer unit :Monomer with rep of ECFP4 and binary



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00012148763873078419, 1, 1668, True, 0.00033307186413965544, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.006618799174953843, 1, 685, True, 2.9055327218130034e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.09557674663573557, 1, 848, True, 4.7988338306357485e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [None, 'sqrt', 0.05, 0.05, 2000] before, using random point [None, 'sqrt', 0.32060222778635444, 0.892932095647164, 157]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
Process LokyProcess-14:
Process LokyProcess-5:
Process LokyProcess-15:
Process LokyProcess-7:
Process LokyProcess-6:
Process LokyProcess-1:
Process LokyProcess-4:
Process LokyProcess-2:


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06743352406811062), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 130), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 489, in __init__
    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 482, in _step
    return (optimizer.tell(params, [-score for score in local_results]), score_name)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py", line 570, in tell
    return self._tell(x, y, fit=fit)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py", line 657, in _tell
    results = Parallel(n_jobs=self.n_jobs)(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1918, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1847, in _get_sequential_output
    res = func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py", line 237, in fmin_l_bfgs_b
    res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py", line 407, in _minimize_lbfgsb
    f, g = func_and_grad(x)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py", line 343, in fun_and_grad
    self._update_fun()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py", line 294, in _update_fun
    fx = self._wrapped_fun(self.x)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py", line 20, in wrapped
    fx = fun(np.copy(x), *args)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/optimize/_optimize.py", line 79, in __call__
    self._compute_if_needed(x, *args)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/optimize/_optimize.py", line 73, in _compute_if_needed
    fg = self.fun(x, *args)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/acquisition.py", line 17, in gaussian_acquisition_1D
    np.expand_dims(X, axis=0),
  File "<__array_function__ internals>", line 180, in expand_dims
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/numpy/lib/shape_base.py", line 597, in expand_dims
    axis = normalize_axis_tuple(axis, out_ndim)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/numpy/core/numeric.py", line 1347, in normalize_axis_tuple
    def normalize_axis_tuple(axis, ndim, argname=None, allow_duplicate=False):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 947, in fit
    with parallel:
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1354, in __exit__
    self._terminate_and_reset()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1386, in _terminate_and_reset
    self._backend.terminate()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 610, in terminate
    self._workers._temp_folder_manager._clean_temporary_resources(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_memmapping_reducer.py", line 621, in _clean_temporary_resources
    for filename in os.listdir(temp_folder):
KeyboardInterrupt


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.020272348582770917), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012978114644367373), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 71), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007479224684413864), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 320), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0011092531652586498), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 927), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n10>
Subject: Job 807009: <ecfp_radius4_vectorbinary_XGBR_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius4_vectorbinary_XGBR_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
Job was executed on host(s) <4*c200n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:37:27 2024
                            <4*c200n09>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:37:27 2024
Terminated at Thu Oct 10 12:02:05 2024
Results reported at Thu Oct 10 12:02:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius4_vectorbinary_XGBR_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius4_vectorbinary_Rg1 (nm)_XGBR_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius4_vectorbinary_Rg1 (nm)_XGBR_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type XGBR --radius 4 --vector binary --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   5719.20 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.87 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1505 sec.
    Turnaround time :                            1540 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n10>
Subject: Job 807001: <ecfp_radius4_vectorbinary_NGB_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius4_vectorbinary_NGB_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
Job was executed on host(s) <4*c203n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
                            <4*c203n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:36:25 2024
Terminated at Thu Oct 10 12:02:08 2024
Results reported at Thu Oct 10 12:02:08 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius4_vectorbinary_NGB_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius4_vectorbinary_Rg1 (nm)_NGB_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius4_vectorbinary_Rg1 (nm)_NGB_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type NGB --radius 4 --vector binary --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   6761.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.85 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1552 sec.
    Turnaround time :                            1543 sec.

The output (if any) is above this job summary.

Process LokyProcess-10:
Process LokyProcess-12:
Process LokyProcess-14:
Process LokyProcess-8:
Process LokyProcess-6:
Process LokyProcess-1:
Process LokyProcess-5:
Process LokyProcess-3:
Process LokyProcess-9:
Process LokyProcess-2:


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.1089166239408921), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.051082124999554876), ('regressor__regressor__min_samples_split', 0.0511383772861644), ('regressor__regressor__n_estimators', 80)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 428)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05060301334581676), ('regressor__regressor__min_samples_split', 0.055609912806435235), ('regressor__regressor__n_estimators', 56)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.08435975597152776), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.0506123654445674), ('regressor__regressor__min_samples_split', 0.07197078550245575), ('regressor__regressor__n_estimators', 69)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.0506123654445674), ('regressor__regressor__min_samples_split', 0.07197078550245575), ('regressor__regressor__n_estimators', 69)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05015965735636034), ('regressor__regressor__min_samples_split', 0.06119120906525351), ('regressor__regressor__n_estimators', 985)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.050765337173992314), ('regressor__regressor__min_samples_split', 0.05198711695416256), ('regressor__regressor__n_estimators', 52)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 465)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05120922553538724), ('regressor__regressor__min_samples_split', 0.07495390795298933), ('regressor__regressor__n_estimators', 112)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 153)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 961)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05320252432511457), ('regressor__regressor__min_samples_split', 0.05747425474783108), ('regressor__regressor__n_estimators', 1884)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 489, in __init__
    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt
KeyboardInterrupt

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 489, in __init__
    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
KeyboardInterrupt
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 499, in __init__
    _seen.add(id(exc_value))
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1703, in _get_outputs
    self._abort()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1614, in _abort
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/executor.py", line 75, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 1290, in shutdown
    self._flags.flag_as_shutting_down(kill_workers)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 156, in flag_as_shutting_down
    with self.shutdown_lock:
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 910, in _fit_and_score
    test_scores = _score(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 971, in _score
    scores = scorer(estimator, X_test, y_test, **score_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 239, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 316, in predict
    pred = self.regressor_.predict(X, **predict_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 1076, in predict
    Parallel(n_jobs=n_jobs, verbose=self.verbose, require="sharedmem")(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1918, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1844, in _get_sequential_output
    for func, args, kwargs in iterable:
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 70, in <genexpr>
    iterable_with_config = (
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 1077, in <genexpr>
    delayed(_accumulate_prediction)(e.predict, X, [y_hat], lock)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 104, in delayed
    @functools.wraps(function)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/functools.py", line 76, in wraps
    return partial(update_wrapper, wrapped=wrapped,
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 465, in _process_worker
    exc = _ExceptionWithTraceback(e)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 247, in __init__
    tb = traceback.format_exception(type(exc), exc, tb)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 353, in extract
    limit = getattr(sys, 'tracebacklimit', None)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n07>
Subject: Job 806993: <ecfp_radius4_vectorbinary_RF_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius4_vectorbinary_RF_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:24 2024
Job was executed on host(s) <4*c205n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
                            <4*c205n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:36:25 2024
Terminated at Thu Oct 10 12:03:52 2024
Results reported at Thu Oct 10 12:03:52 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius4_vectorbinary_RF_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius4_vectorbinary_Rg1 (nm)_RF_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius4_vectorbinary_Rg1 (nm)_RF_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type RF --radius 4 --vector binary --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   4684.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.84 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1662 sec.
    Turnaround time :                            1648 sec.

The output (if any) is above this job summary.

