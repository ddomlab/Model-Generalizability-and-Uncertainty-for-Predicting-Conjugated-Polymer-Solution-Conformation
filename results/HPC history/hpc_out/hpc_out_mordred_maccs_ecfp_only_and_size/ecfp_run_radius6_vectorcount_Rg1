polymer unit :Monomer with rep of ECFP6 and count



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6
polymer unit :Monomer with rep of ECFP6 and count



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
polymer unit :Monomer with rep of ECFP6 and count



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
Process LokyProcess-2:
Process LokyProcess-8:
Process LokyProcess-10:
Process LokyProcess-3:
Process LokyProcess-17:
Process LokyProcess-6:
Process LokyProcess-12:
Process LokyProcess-7:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 353, in extract
    limit = getattr(sys, 'tracebacklimit', None)
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 134, in format_exception
    value, tb = _parse_value_tb(exc, value, tb)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 93, in _parse_value_tb
    def _parse_value_tb(exc, value, tb):
KeyboardInterrupt
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
Process LokyProcess-1:
Process LokyProcess-7:
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 489, in __init__
    def __init__(self, exc_type, exc_value, exc_traceback, *, limit=None,
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 183, in format_exc
    return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 135, in format_exception
    te = TracebackException(type(value), value, tb, limit=limit, compact=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 502, in __init__
    self.stack = StackSummary.extract(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 353, in extract
    limit = getattr(sys, 'tracebacklimit', None)
KeyboardInterrupt
Process LokyProcess-5:
Process LokyProcess-1:
Process LokyProcess-3:
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt
KeyboardInterrupt

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 438, in _process_worker
    previous_tb = traceback.format_exc()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/traceback.py", line 181, in format_exc
    def format_exc(limit=None, chain=True):
KeyboardInterrupt
KeyboardInterrupt


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010660913695544696), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 104), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.018938427341540078), ('regressor__regressor__max_depth', 1923), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 172, in retrieval_context
    yield
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1649, in _get_outputs
    with self._backend.retrieval_context():
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
KeyboardInterrupt
Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n01>
Subject: Job 807004: <ecfp_radius6_vectorcount_NGB_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius6_vectorcount_NGB_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
Job was executed on host(s) <4*c200n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:27 2024
                            <4*c200n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:36:27 2024
Terminated at Thu Oct 10 12:02:05 2024
Results reported at Thu Oct 10 12:02:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius6_vectorcount_NGB_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius6_vectorcount_Rg1 (nm)_NGB_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius6_vectorcount_Rg1 (nm)_NGB_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type NGB --radius 6 --vector count --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   7009.25 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.44 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               60.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1560 sec.
    Turnaround time :                            1540 sec.

The output (if any) is above this job summary.



Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 351)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 50)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 1031)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 2000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05013108970425254), ('regressor__regressor__min_samples_split', 0.08000447378887841), ('regressor__regressor__n_estimators', 203)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05120922553538724), ('regressor__regressor__min_samples_split', 0.07495390795298933), ('regressor__regressor__n_estimators', 112)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.051900151815896654), ('regressor__regressor__min_samples_split', 0.07786988820125088), ('regressor__regressor__n_estimators', 83)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05), ('regressor__regressor__n_estimators', 271)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.051708512530533005), ('regressor__regressor__min_samples_split', 0.07018823747016083), ('regressor__regressor__n_estimators', 583)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05160139326027296), ('regressor__regressor__min_samples_split', 0.07063909478422781), ('regressor__regressor__n_estimators', 256)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR RF 	SEED: 69
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 345, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 338, in main
    perform_model_ecfp(args.regressor_type, args.radius, args.vector, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 297, in perform_model_ecfp
    main_ecfp_numerical(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 262, in main_ecfp_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1703, in _get_outputs
    self._abort()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1614, in _abort
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/executor.py", line 73, in terminate
    def terminate(self, kill_workers=False):
KeyboardInterrupt
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/backend/resource_tracker.py:314: UserWarning: resource_tracker: There appear to be 1 leaked file objects to clean up at shutdown
  warnings.warn(

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 807012: <ecfp_radius6_vectorcount_XGBR_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius6_vectorcount_XGBR_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:38:26 2024
                            <4*c200n11>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:38:26 2024
Terminated at Thu Oct 10 12:02:08 2024
Results reported at Thu Oct 10 12:02:08 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius6_vectorcount_XGBR_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius6_vectorcount_Rg1 (nm)_XGBR_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius6_vectorcount_Rg1 (nm)_XGBR_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type XGBR --radius 6 --vector count --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   6391.26 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.16 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               60.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1423 sec.
    Turnaround time :                            1543 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n07>
Subject: Job 806996: <ecfp_radius6_vectorcount_RF_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_radius6_vectorcount_RF_Rg1 (nm)> was submitted from host <c039n01> by user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:24 2024
Job was executed on host(s) <4*c200n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 10 11:36:25 2024
                            <4*c200n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 10 11:36:25 2024
Terminated at Thu Oct 10 12:02:08 2024
Results reported at Thu Oct 10 12:02:08 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 35:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius6_vectorcount_RF_Rg1 (nm)" # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_run_radius6_vectorcount_Rg1 (nm)_RF_run.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_err_radius6_vectorcount_Rg1 (nm)_RF_err.out

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py ecfp --regressor_type RF --radius 6 --vector count --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   4595.34 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.87 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1563 sec.
    Turnaround time :                            1544 sec.

The output (if any) is above this job summary.

