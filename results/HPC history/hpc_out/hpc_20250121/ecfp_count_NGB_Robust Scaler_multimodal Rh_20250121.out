RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003050040300103604), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 220), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015481571374930525), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005764071518720639), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 92), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0007507766860829504), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003675159975198598), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 220), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0051873139854936665), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 147), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00027040626397159523), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1035), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00022729558072564975), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001595454853888622), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 605), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.044000951064149e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008312543369973576), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 74), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002638815086005759), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011385730591175383), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 380), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0014278425554942488), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 494), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.053138334914783e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014983107069391705), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004006432213438193), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 117), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00022837359920459716), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000333007549273344), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0015204495707214646), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 473), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0022217793894331143), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 380), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005853456356948), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 895), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003469963435529859), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 222), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0044778365119691795), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 175), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0002782235465634277), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00019951736777539737), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1316), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007445196952294189), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 149), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.3039705617661713e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0017801792259366698), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 374), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008923809493898186), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0032533407822505733), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 133), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013299854717280313), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012866758736872793), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00025134676608622853), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00783144017408287), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 88), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0004848913211595146), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011764766589748612), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011150056257411296), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 348), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013587419417853722), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00030828403033975326), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1130), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010768579913627471), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0017957330359619245), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 233), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.127347495962341e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005370108105059309), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1446), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012469912446334624), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 287), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002014247850088372), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 333), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003216593320280599), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012759871892147464), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 360), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00041258578146479796), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1584), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008146450478804865), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003881615425662309), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 131), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006096147469626947), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 128), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0009879399335557717), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 737), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00038271320250010866), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001001446284332006), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 577), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002258048021272318), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 337), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012689754822684769), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.1970467662754752e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0071651010021547635), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 131), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004878579332369015), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 197), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.443067403752825e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005624519971421272), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1132), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012828241673119715), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 577), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016549181630866705), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 464), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001013536947905738), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 946), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.1483278741779377e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003200808474207874), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 117), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0038877577409938296), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 243), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0018045135289987144), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 491), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011518163342839323), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0003177655420778514), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1989), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.071265951126463e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005343741538291644), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 157), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.067435505138453e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0021378593967089983), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 503), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001111273102043389), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 360), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00022242739001586943), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007332703116224851), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 111), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005726255141324721), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 783), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.638629047709413e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005062815318136681), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 99), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.1418211295910033e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0009684613091887549), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 908), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.043  0.063 -0.041]±[0.134 0.073 0.022]
[array([ 0.04319825,  0.06334281, -0.04057306]), array([8.49596924e+00, 1.53036853e+02, 9.38188895e+04]), array([6.42464044e+00, 1.02637751e+02, 1.41216307e+04])]
RRU Dimer
Filename: (ECFP3.count.512)_NGB_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/RRU Dimer/(ECFP3.count.512)_NGB_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/RRU Dimer/(ECFP3.count.512)_NGB_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/RRU Dimer/(ECFP3.count.512)_NGB_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n08>
Subject: Job 296388: <ecfp_NGB_Robust Scaler_multimodal Rh_20250121> in cluster <Hazel> Done

Job <ecfp_NGB_Robust Scaler_multimodal Rh_20250121> was submitted from host <c203n13> by user <sdehgha2> in cluster <Hazel> at Tue Jan 21 14:11:08 2025
Job was executed on host(s) <8*c203n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Jan 21 14:11:10 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Jan 21 14:11:10 2025
Terminated at Wed Jan 22 03:59:49 2025
Results reported at Wed Jan 22 03:59:49 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 45:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_NGB_Robust Scaler_multimodal Rh_20250121"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250121.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250121.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type NGB                                        --radius 3                                        --vector count                                        --target "multimodal Rh"                                        --oligo_type "RRU Dimer"                                        --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   230987.47 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.99 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               11.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   49741 sec.
    Turnaround time :                            49721 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250121.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0017284488639914759), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 245), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0008240443961331027), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 937), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005817378228911874), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 788), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.762541856123049e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011124816869049732), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0029803839849484423), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 313), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.2668087843546808e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.044  0.061 -0.041]±[0.13  0.07  0.022]
[array([ 0.04392932,  0.0612162 , -0.04057358]), array([8.49573077e+00, 1.53231510e+02, 9.38188928e+04]), array([6.42858449e+00, 1.02928399e+02, 1.41216564e+04])]
Dimer
Filename: (ECFP3.count.512)_NGB_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/Dimer/(ECFP3.count.512)_NGB_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/Dimer/(ECFP3.count.512)_NGB_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/Dimer/(ECFP3.count.512)_NGB_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n01>
Subject: Job 296387: <ecfp_NGB_Robust Scaler_multimodal Rh_20250121> in cluster <Hazel> Done

Job <ecfp_NGB_Robust Scaler_multimodal Rh_20250121> was submitted from host <c203n13> by user <sdehgha2> in cluster <Hazel> at Tue Jan 21 14:11:08 2025
Job was executed on host(s) <8*c203n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Jan 21 14:11:10 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Jan 21 14:11:10 2025
Terminated at Wed Jan 22 05:16:23 2025
Results reported at Wed Jan 22 05:16:23 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 45:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_NGB_Robust Scaler_multimodal Rh_20250121"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250121.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250121.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type NGB                                        --radius 3                                        --vector count                                        --target "multimodal Rh"                                        --oligo_type "Dimer"                                        --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   253329.66 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.96 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               11.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   54339 sec.
    Turnaround time :                            54315 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250121.err> for stderr output of this job.

