


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05653704943317464), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2583348787798604), ('regressor__regressor__min_samples_split', 0.17165124983860222)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2478441762534787), ('regressor__regressor__min_samples_split', 0.27645265610167186)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.06336465629284219), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.23982661863005728), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.185365247654856), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.0678099018588246), ('regressor__regressor__min_samples_split', 0.7883985107902242)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.861903275886921)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05929529786428912), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.10581771373923654), ('regressor__regressor__min_samples_split', 0.975152352041839)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.185365247654856), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.0678099018588246), ('regressor__regressor__min_samples_split', 0.7883985107902242)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.435497721322115), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.34685161787782576), ('regressor__regressor__min_samples_split', 0.6799390713727985)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.06291498714759833), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.09868291224135163), ('regressor__regressor__min_samples_split', 0.4569065655808511)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.053412488819458634), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.28928100239220217), ('regressor__regressor__min_samples_split', 0.5939444760546818)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.27789178458165975), ('regressor__regressor__min_samples_split', 0.5954517058482728)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2028979089433643), ('regressor__regressor__min_samples_split', 0.3939194194690123)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.7874293370712214), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.7832449374594603), ('regressor__regressor__min_samples_split', 0.6959604091263834)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.23336643068632978), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.06984093794261065), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.7874293370712214), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.7832449374594603), ('regressor__regressor__min_samples_split', 0.6959604091263834)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05000000000000003), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.07577201042283185), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.25229001393764083), ('regressor__regressor__min_samples_split', 0.5683589643874855)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.06797951128404961), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2294581947768794), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.11005787516170515), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.08347431645179251), ('regressor__regressor__min_samples_split', 0.31716869801937436)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.08792411299300039), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.0738687175621914), ('regressor__regressor__min_samples_split', 0.2880703081896029)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129

------------------------------------------------------------
Sender: LSF System <lsfadmin@c012n01>
Subject: Job 199324: <poly_HSP_with_DT_on_Rg1 (nm)> in cluster <Hazel> Done

Job <poly_HSP_with_DT_on_Rg1 (nm)> was submitted from host <c202n04> by user <sdehgha2> in cluster <Hazel> at Tue Nov  5 15:36:25 2024
Job was executed on host(s) <4*c012n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Nov  5 15:48:59 2024
                            <4*c011n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Tue Nov  5 15:48:59 2024
Terminated at Tue Nov  5 15:56:25 2024
Results reported at Tue Nov  5 15:56:25 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "poly_HSP_with_DT_on_Rg1 (nm)"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                   --regressor_type "DT"                                   --numerical_feats "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH" "Ra"
                                  
conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7.56 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   445 sec.
    Turnaround time :                            1200 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c024n02>
Subject: Job 199590: <poly_HSP_with_DT_on_Rg1 (nm)> in cluster <Hazel> Done

Job <poly_HSP_with_DT_on_Rg1 (nm)> was submitted from host <c014n01> by user <sdehgha2> in cluster <Hazel> at Tue Nov  5 15:45:31 2024
Job was executed on host(s) <4*c024n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Nov  5 15:50:35 2024
                            <4*c026n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Tue Nov  5 15:50:35 2024
Terminated at Tue Nov  5 15:57:51 2024
Results reported at Tue Nov  5 15:57:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "poly_HSP_with_DT_on_Rg1 (nm)"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                   --regressor_type "DT"                                   --numerical_feats "Ra"
                                  
conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   8.64 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   439 sec.
    Turnaround time :                            740 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5542472734190033), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.8352487625519375), ('regressor__regressor__min_samples_split', 0.7851304478916721)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5542472734190033), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.8352487625519375), ('regressor__regressor__min_samples_split', 0.7851304478916721)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5542472734190033), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.8352487625519375), ('regressor__regressor__min_samples_split', 0.7851304478916721)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5542472734190033), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.8352487625519375), ('regressor__regressor__min_samples_split', 0.7851304478916721)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5542472734190033), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.8352487625519375), ('regressor__regressor__min_samples_split', 0.7851304478916721)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.185365247654856), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.0678099018588246), ('regressor__regressor__min_samples_split', 0.7883985107902242)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.07438513646904246), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.19640680924720816), ('regressor__regressor__min_samples_split', 0.31830414175859817)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.24951723860410158), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.055290933400532795), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.07380752825207519), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.42859741713646915)])


{'targets_shape': (255, 1), 'training_features_shape': (255, 6)}
Average scores:	 r: nan±nan	 r2: 0.01±0.21
scaler
Filename: (polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c019n04>
Subject: Job 192437: <poly_HSP_with_DT_on_Rg1 (nm)> in cluster <Hazel> Done

Job <poly_HSP_with_DT_on_Rg1 (nm)> was submitted from host <c040n03> by user <sdehgha2> in cluster <Hazel> at Tue Nov  5 13:04:17 2024
Job was executed on host(s) <4*c019n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Nov  5 13:29:36 2024
                            <4*c014n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Tue Nov  5 13:29:36 2024
Terminated at Tue Nov  5 16:07:32 2024
Results reported at Tue Nov  5 16:07:32 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "poly_HSP_with_DT_on_Rg1 (nm)"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                   --regressor_type "DT"                                   --numerical_feats "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"
                                  
conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1782.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.05 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   9485 sec.
    Turnaround time :                            10995 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.185365247654856), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.0678099018588246), ('regressor__regressor__min_samples_split', 0.7883985107902242)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.185365247654856), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.0678099018588246), ('regressor__regressor__min_samples_split', 0.7883985107902242)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.050775312213356044), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.06710014907750751), ('regressor__regressor__min_samples_split', 0.11925780001002682)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.185365247654856), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.0678099018588246), ('regressor__regressor__min_samples_split', 0.7883985107902242)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.435497721322115), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.34685161787782576), ('regressor__regressor__min_samples_split', 0.6799390713727985)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.435497721322115), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.34685161787782576), ('regressor__regressor__min_samples_split', 0.6799390713727985)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.435497721322115), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.34685161787782576), ('regressor__regressor__min_samples_split', 0.6799390713727985)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.435497721322115), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.34685161787782576), ('regressor__regressor__min_samples_split', 0.6799390713727985)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.7874293370712214), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.7832449374594603), ('regressor__regressor__min_samples_split', 0.6959604091263834)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.7874293370712214), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.7832449374594603), ('regressor__regressor__min_samples_split', 0.6959604091263834)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.7874293370712214), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.7832449374594603), ('regressor__regressor__min_samples_split', 0.6959604091263834)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.7874293370712214), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.7832449374594603), ('regressor__regressor__min_samples_split', 0.6959604091263834)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.7874293370712214), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.7832449374594603), ('regressor__regressor__min_samples_split', 0.6959604091263834)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.5699473181583913), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.4688246439037563), ('regressor__regressor__min_samples_split', 0.059996399033831825)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.25205931598743636), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.5332356148616714), ('regressor__regressor__min_samples_split', 0.1222776512236606)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.9467787774725889), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2841024627378567), ('regressor__regressor__min_samples_split', 0.055003235137064184)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.9467787774725889), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2841024627378567), ('regressor__regressor__min_samples_split', 0.055003235137064184)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.9467787774725889), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2841024627378567), ('regressor__regressor__min_samples_split', 0.055003235137064184)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.9467787774725889), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2841024627378567), ('regressor__regressor__min_samples_split', 0.055003235137064184)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.9467787774725889), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.2841024627378567), ('regressor__regressor__min_samples_split', 0.055003235137064184)])


{'targets_shape': (255, 1), 'training_features_shape': (255, 3)}
Average scores:	 r: nan±nan	 r2: -0.05±0.09
scaler
Filename: (polymer dP-polymer dD-polymer dH)_DT_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(polymer dP-polymer dD-polymer dH)_DT_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(polymer dP-polymer dD-polymer dH)_DT_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(polymer dP-polymer dD-polymer dH)_DT_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c019n03>
Subject: Job 192450: <poly_HSP_with_DT_on_Rg1 (nm)> in cluster <Hazel> Done

Job <poly_HSP_with_DT_on_Rg1 (nm)> was submitted from host <c032n02> by user <sdehgha2> in cluster <Hazel> at Tue Nov  5 13:04:26 2024
Job was executed on host(s) <4*c019n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Nov  5 15:10:02 2024
                            <4*c025n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Tue Nov  5 15:10:02 2024
Terminated at Tue Nov  5 17:28:10 2024
Results reported at Tue Nov  5 17:28:10 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "poly_HSP_with_DT_on_Rg1 (nm)"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                   --regressor_type "DT"                                   --numerical_feats "polymer dP" "polymer dD" "polymer dH" 
                                  
conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1336.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.00 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   8288 sec.
    Turnaround time :                            15824 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/poly_HSP_with_DT_on_Rg1 (nm).err> for stderr output of this job.

