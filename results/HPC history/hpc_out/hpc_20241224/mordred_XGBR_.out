yes



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13
yes



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0839595948176321), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0787749672705762), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 9806), ('regressor__regressor__n_estimators', 309), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 104), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 94), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09780980208091321), ('regressor__regressor__max_depth', 6366), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09780980208091321), ('regressor__regressor__max_depth', 6366), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 233), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09959821624674509), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 233), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09959821624674509), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09995933512582673), ('regressor__regressor__max_depth', 16), ('regressor__regressor__n_estimators', 425), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07045473403216711), ('regressor__regressor__max_depth', 2125), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 91), ('regressor__regressor__n_estimators', 1454), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09991069825165073), ('regressor__regressor__max_depth', 16), ('regressor__regressor__n_estimators', 787), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 110), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 91), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])


Average scores:	 r2: -0.02Â±0.03
structural
Filename: (Mordred)_XGBR_Standard_generalizability
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/informatics/MSE723_final/results/target_hole mobility/structural/(Mordred)_XGBR_Standard_generalizability_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/informatics/MSE723_final/results/target_hole mobility/structural/(Mordred)_XGBR_Standard_generalizability_predictions.csv
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n09>
Subject: Job 719978: <mordred_XGBR_> in cluster <Hazel> Done

Job <mordred_XGBR_> was submitted from host <c201n09> by user <sdehgha2> in cluster <Hazel> at Tue Dec 10 20:14:26 2024
Job was executed on host(s) <2*c201n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Dec 10 20:15:27 2024
                            <2*c201n04>
                            <2*c201n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/informatics/MSE723_final/code_/training/hpc> was used as the working directory.
Started at Tue Dec 10 20:15:27 2024
Terminated at Tue Dec 10 20:47:19 2024
Results reported at Tue Dec 10 20:47:19 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 10:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_XGBR_"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_XGBR_.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_XGBR_.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type XGBR 

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5197.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.89 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               46.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1939 sec.
    Turnaround time :                            1973 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_XGBR_.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0839595948176321), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0787749672705762), ('regressor__regressor__max_depth', 25), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 9806), ('regressor__regressor__n_estimators', 309), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 104), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 94), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09780980208091321), ('regressor__regressor__max_depth', 6366), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09780980208091321), ('regressor__regressor__max_depth', 6366), ('regressor__regressor__n_estimators', 111), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 233), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09959821624674509), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 233), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09959821624674509), ('regressor__regressor__max_depth', 4800), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09995933512582673), ('regressor__regressor__max_depth', 16), ('regressor__regressor__n_estimators', 425), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07045473403216711), ('regressor__regressor__max_depth', 2125), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 91), ('regressor__regressor__n_estimators', 1454), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09991069825165073), ('regressor__regressor__max_depth', 16), ('regressor__regressor__n_estimators', 787), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 110), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 91), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])


Average scores:	 r2: -0.02Â±0.03
structural
Filename: (ECFP)_XGBR_Standard_generalizability
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/informatics/MSE723_final/results/target_hole mobility/structural/(ECFP)_XGBR_Standard_generalizability_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/informatics/MSE723_final/results/target_hole mobility/structural/(ECFP)_XGBR_Standard_generalizability_predictions.csv
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n08>
Subject: Job 719979: <ecfp_XGBR_> in cluster <Hazel> Done

Job <ecfp_XGBR_> was submitted from host <c201n09> by user <sdehgha2> in cluster <Hazel> at Tue Dec 10 20:14:26 2024
Job was executed on host(s) <2*c201n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Dec 10 20:15:27 2024
                            <2*c201n14>
                            <2*c201n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/informatics/MSE723_final/code_/training/hpc> was used as the working directory.
Started at Tue Dec 10 20:15:27 2024
Terminated at Tue Dec 10 22:34:07 2024
Results reported at Tue Dec 10 22:34:07 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 10:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_XGBR_"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_XGBR_.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_XGBR_.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp              --regressor_type XGBR 

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   37080.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             2.99 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               44.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   8347 sec.
    Turnaround time :                            8381 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_XGBR_.err> for stderr output of this job.

