
------------------------------------------------------------
Sender: LSF System <lsfadmin@c012n04>
Subject: Job 930657: <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> in cluster <Hazel> Done

Job <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> was submitted from host <c012n04> by user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:48:28 2024
Job was executed on host(s) <2*c012n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:50:21 2024
                            <2*c003n03>
                            <2*c006n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec 23 15:50:21 2024
Terminated at Mon Dec 23 16:05:31 2024
Results reported at Mon Dec 23 16:05:31 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_rbf_Standard_Rg1 (nm)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_rbf_Standard_Rg1 (nm)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                     --regressor_type "sklearn-GPR"                                     --kernel "rbf"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   8.20 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   938 sec.
    Turnaround time :                            1023 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_rbf_Standard_Rg1 (nm)_final.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05007722908942513)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.052112475453649214)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.632478145304319)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.06558328224573029)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.06261834027026875)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.47481646870406946)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.06155428993031487)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.259806678617276)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05008115707428005)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.259806678617276)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.050836310576066274)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.050193115459282095)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 2.3642729195320245)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.06925447382325133)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.054883760332279145)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 2.3642729195320245)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.0500732310016149)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.6817495623055898)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05045394734006737)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.6817495623055898)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.11171115001172616)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.6841223214499335)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.6841223214499335)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.050050154529545504)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05039946993654243)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 2.8643589293022735)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05049641339071117)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05049641339071117)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.050427886548557344)])


Average scores:	 r: 0.33±0.16	 r2: 0.11±0.15
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.rbf_mean_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.rbf_mean_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.rbf_mean_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.rbf_mean_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n04>
Subject: Job 945150: <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> in cluster <Hazel> Done

Job <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> was submitted from host <c027n04> by user <sdehgha2> in cluster <Hazel> at Tue Dec 24 12:17:57 2024
Job was executed on host(s) <2*c202n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Dec 24 12:24:33 2024
                            <2*c202n14>
                            <2*c202n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Dec 24 12:24:33 2024
Terminated at Tue Dec 24 12:46:08 2024
Results reported at Tue Dec 24 12:46:08 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_rbf_Standard_Rg1 (nm)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_rbf_Standard_Rg1 (nm)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                     --regressor_type "sklearn-GPR"                                     --kernel "rbf"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2064.04 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.62 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               43.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1295 sec.
    Turnaround time :                            1691 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_rbf_Standard_Rg1 (nm)_final.err> for stderr output of this job.

