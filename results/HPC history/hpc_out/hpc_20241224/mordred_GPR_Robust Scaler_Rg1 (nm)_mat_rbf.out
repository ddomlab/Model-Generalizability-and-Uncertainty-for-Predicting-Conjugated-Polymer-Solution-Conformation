Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n04>
Subject: Job 627464: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:16 2024
Job was executed on host(s) <2*c207n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 12:21:51 2024
                            <2*c207n05>
                            <2*c207n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 12:21:51 2024
Terminated at Thu Dec  5 12:23:17 2024
Results reported at Thu Dec  5 12:23:17 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "matern"              --target "Rg1 (nm)"              --oligo_type "Monomer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   32.47 sec.
    Max Memory :                                 1 GB
    Average Memory :                             0.20 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               47.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   91 sec.
    Turnaround time :                            4381 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n04>
Subject: Job 627465: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:17 2024
Job was executed on host(s) <2*c207n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 12:23:52 2024
                            <2*c207n06>
                            <2*c207n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 12:23:52 2024
Terminated at Thu Dec  5 12:26:23 2024
Results reported at Thu Dec  5 12:26:23 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "rbf"              --target "Rg1 (nm)"              --oligo_type "Monomer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   33.06 sec.
    Max Memory :                                 1 GB
    Average Memory :                             0.14 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               47.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   153 sec.
    Turnaround time :                            4566 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c028n02>
Subject: Job 627468: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:21 2024
Job was executed on host(s) <2*c028n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 15:15:18 2024
                            <2*c030n04>
                            <2*c034n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 15:15:18 2024
Terminated at Thu Dec  5 15:16:14 2024
Results reported at Thu Dec  5 15:16:14 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "matern"              --target "Rg1 (nm)"              --oligo_type "Dimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   47.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.50 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               46.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   56 sec.
    Turnaround time :                            14753 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c030n04>
Subject: Job 627469: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:23 2024
Job was executed on host(s) <2*c030n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 15:16:19 2024
                            <2*c034n02>
                            <2*c030n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 15:16:19 2024
Terminated at Thu Dec  5 15:17:09 2024
Results reported at Thu Dec  5 15:17:09 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "rbf"              --target "Rg1 (nm)"              --oligo_type "Dimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   43.23 sec.
    Max Memory :                                 1 GB
    Average Memory :                             0.25 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               47.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   55 sec.
    Turnaround time :                            14806 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c038n02>
Subject: Job 627472: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:28 2024
Job was executed on host(s) <2*c038n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 15:54:27 2024
                            <2*c036n03>
                            <2*c040n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 15:54:27 2024
Terminated at Thu Dec  5 15:55:13 2024
Results reported at Thu Dec  5 15:55:13 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "matern"              --target "Rg1 (nm)"              --oligo_type "Trimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46.20 sec.
    Max Memory :                                 2 GB
    Average Memory :                             0.50 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               46.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   62 sec.
    Turnaround time :                            17085 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c038n02>
Subject: Job 627473: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:29 2024
Job was executed on host(s) <2*c038n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 15:55:27 2024
                            <2*c036n03>
                            <2*c040n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 15:55:27 2024
Terminated at Thu Dec  5 15:55:59 2024
Results reported at Thu Dec  5 15:55:59 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "rbf"              --target "Rg1 (nm)"              --oligo_type "Trimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   41.44 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   46 sec.
    Turnaround time :                            17130 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c037n03>
Subject: Job 627476: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:34 2024
Job was executed on host(s) <2*c037n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 16:20:04 2024
                            <2*c033n03>
                            <2*c029n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 16:20:04 2024
Terminated at Thu Dec  5 16:21:02 2024
Results reported at Thu Dec  5 16:21:02 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "matern"              --target "Rg1 (nm)"              --oligo_type "RRU Monomer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   52.00 sec.
    Max Memory :                                 1 GB
    Average Memory :                             0.25 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               47.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   79 sec.
    Turnaround time :                            18628 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c037n03>
Subject: Job 627477: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:36 2024
Job was executed on host(s) <2*c037n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 16:24:33 2024
                            <2*c033n03>
                            <2*c040n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 16:24:33 2024
Terminated at Thu Dec  5 16:24:56 2024
Results reported at Thu Dec  5 16:24:56 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "rbf"              --target "Rg1 (nm)"              --oligo_type "RRU Monomer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   44.00 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   24 sec.
    Turnaround time :                            18860 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c028n01>
Subject: Job 627480: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:43 2024
Job was executed on host(s) <2*c028n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 16:56:22 2024
                            <2*c031n01>
                            <2*c029n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 16:56:22 2024
Terminated at Thu Dec  5 16:57:11 2024
Results reported at Thu Dec  5 16:57:11 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "matern"              --target "Rg1 (nm)"              --oligo_type "RRU Dimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   45.21 sec.
    Max Memory :                                 1 GB
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               47.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   49 sec.
    Turnaround time :                            20788 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c028n01>
Subject: Job 627481: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:44 2024
Job was executed on host(s) <2*c028n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 17:22:46 2024
                            <2*c031n01>
                            <2*c037n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 17:22:46 2024
Terminated at Thu Dec  5 17:23:18 2024
Results reported at Thu Dec  5 17:23:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "rbf"              --target "Rg1 (nm)"              --oligo_type "RRU Dimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   42.06 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   33 sec.
    Turnaround time :                            22354 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c038n02>
Subject: Job 627485: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:47 2024
Job was executed on host(s) <2*c038n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 17:36:45 2024
                            <2*c031n03>
                            <2*c031n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 17:36:45 2024
Terminated at Thu Dec  5 17:37:13 2024
Results reported at Thu Dec  5 17:37:13 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "matern"              --target "Rg1 (nm)"              --oligo_type "RRU Trimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   39.51 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   42 sec.
    Turnaround time :                            23186 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c033n01>
Subject: Job 627486: <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> in cluster <Hazel> Exited

Job <mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat> was submitted from host <c008n01> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:10:48 2024
Job was executed on host(s) <2*c033n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 17:37:09 2024
                            <2*c031n04>
                            <2*c034n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 17:37:09 2024
Terminated at Thu Dec  5 17:39:21 2024
Results reported at Thu Dec  5 17:39:21 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
          
#BSUB -n 6
#BSUB -W 60:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "mordred_GPR_Robust Scaler_Rg1 (nm)_rbf_mat"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py mordred              --regressor_type GPR              --kernel "rbf"              --target "Rg1 (nm)"              --oligo_type "RRU Trimer"              --transform_type "Robust Scaler"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   50.29 sec.
    Max Memory :                                 2 GB
    Average Memory :                             0.29 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               46.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   154 sec.
    Turnaround time :                            23313 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/mordred_GPR_Robust Scaler_Rg1 (nm)_mat_rbf.err> for stderr output of this job.

