


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.059489933887546434), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.06553628958049235), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.1375030413061174), ('regressor__regressor__min_samples_split', 0.1129396345699698)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.9031724897447295)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.052348839286952636), ('regressor__regressor__min_samples_split', 0.06223045843752958)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05940641806197316), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.09355757152945471), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05115624658369856), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.10890988788456449)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.06405342752814466), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.07879328566142019), ('regressor__regressor__min_samples_split', 0.07362101236595202)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.25318574336429994)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.052990103702754004), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.055177538190085154), ('regressor__regressor__min_samples_split', 0.06918346692956812)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.10301694436705759), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.09623007431261679), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.5005390230323954)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.056860252060008575), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.813786222024051)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.07160934415893755), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.17224404544427513), ('regressor__regressor__min_samples_split', 0.18249897894699374)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.09446600273928113), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.9240541329784621)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.055398480378163126), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.12659514340951517), ('regressor__regressor__min_samples_split', 0.23287562958454033)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.08792411299300039), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.0738687175621914), ('regressor__regressor__min_samples_split', 0.2880703081896029)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05414819920095311), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.16473256254304497), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])


Average scores:	 r: 0.27±0.25	 r2: -0.02±0.21
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH-Ra)_DT_mean_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH-Ra)_DT_mean_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH-Ra)_DT_mean_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH-Ra)_DT_mean_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n13>
Subject: Job 821694: <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> in cluster <Hazel> Done

Job <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> was submitted from host <c004n04> by user <sdehgha2> in cluster <Hazel> at Fri Dec 20 17:00:57 2024
Job was executed on host(s) <2*c202n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec 20 17:01:00 2024
                            <2*c202n07>
                            <2*c202n09>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec 20 17:01:00 2024
Terminated at Fri Dec 20 17:45:15 2024
Results reported at Fri Dec 20 17:45:15 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rh (IW avg log)"                                     --regressor_type "DT"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH" "Ra"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2828.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.37 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               43.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   2659 sec.
    Turnaround time :                            2658 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c029n03>
Subject: Job 926890: <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> in cluster <Hazel> Exited

Job <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> was submitted from host <c011n03> by user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:02:41 2024
Job was executed on host(s) <2*c029n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:02:41 2024
                            <2*c029n04>
                            <2*c033n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec 23 15:02:41 2024
Terminated at Mon Dec 23 15:02:43 2024
Results reported at Mon Dec 23 15:02:43 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rh (IW avg log)"                                     --regressor_type "DT"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   0.49 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   15 sec.
    Turnaround time :                            2 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c029n03>
Subject: Job 926899: <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> in cluster <Hazel> Done

Job <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> was submitted from host <c011n03> by user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:03:39 2024
Job was executed on host(s) <2*c029n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:03:41 2024
                            <2*c029n04>
                            <2*c033n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec 23 15:03:41 2024
Terminated at Mon Dec 23 15:12:03 2024
Results reported at Mon Dec 23 15:12:03 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rh (IW avg log)"                                     --regressor_type "DT"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   9.10 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   527 sec.
    Turnaround time :                            504 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.10512653073867412)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.08995081027073579), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.08169899004241699), ('regressor__regressor__min_samples_split', 0.2506230853074368)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.99)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.40772526949279736)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.07428779723672277), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.07583445603239684)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.15366917211489084)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.06405342752814466), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.07879328566142019), ('regressor__regressor__min_samples_split', 0.07362101236595202)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.0930653659298137), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.1137229213008125), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.9004399641464816)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05715878227022597), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.14769445888131222), ('regressor__regressor__min_samples_split', 0.05220947556341599)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.9300457169759181)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.18248485741853931), ('regressor__regressor__min_samples_split', 0.08077970078003402)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.09067333243921569), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.17340198900753134)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'log2'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.8871402297797685)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.06517792248182651), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.05)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.08792411299300039), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.0738687175621914), ('regressor__regressor__min_samples_split', 0.2880703081896029)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.0634509718473509), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', None), ('regressor__regressor__min_samples_leaf', 0.14573702972821423), ('regressor__regressor__min_samples_split', 0.4150836468981632)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__ccp_alpha', 0.05), ('regressor__regressor__max_depth', None), ('regressor__regressor__max_features', 'sqrt'), ('regressor__regressor__min_samples_leaf', 0.05), ('regressor__regressor__min_samples_split', 0.16831076114485446)])


Average scores:	 r: 0.33±0.23	 r2: -0.01±0.23
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_mean_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_mean_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_mean_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_DT_mean_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c029n04>
Subject: Job 929322: <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> in cluster <Hazel> Done

Job <numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num> was submitted from host <c029n04> by user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:33:17 2024
Job was executed on host(s) <2*c029n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:34:13 2024
                            <2*c034n02>
                            <2*c033n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec 23 15:34:13 2024
Terminated at Mon Dec 23 19:43:03 2024
Results reported at Mon Dec 23 19:43:03 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_DT_polymer_size_feats_on_Rh (IW avg log)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rh (IW avg log)"                                     --regressor_type "DT"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2987.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             1.54 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               42.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   14956 sec.
    Turnaround time :                            14986 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_DT_Standard_Rh (IW avg log)_final.err> for stderr output of this job.

