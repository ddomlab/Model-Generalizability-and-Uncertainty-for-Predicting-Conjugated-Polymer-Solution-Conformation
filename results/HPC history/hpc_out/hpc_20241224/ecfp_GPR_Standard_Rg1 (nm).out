Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
Dimer
Filename: (ECFP3.binary.512)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.binary.512)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.binary.512)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.binary.512)_GPR_Standard_shape.json
Done Saving scores!


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69

------------------------------------------------------------
Sender: LSF System <lsfadmin@c036n03>
Subject: Job 598206: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:27 2024
Job was executed on host(s) <4*c036n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:13:06 2024
                            <4*c040n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:13:06 2024
Terminated at Mon Dec  2 16:55:42 2024
Results reported at Mon Dec  2 16:55:42 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 3                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   36162.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.57 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   60184 sec.
    Turnaround time :                            61755 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
RRU Dimer
Filename: (ECFP3.binary.512)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.binary.512)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.binary.512)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.binary.512)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c038n02>
Subject: Job 598213: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:33 2024
Job was executed on host(s) <4*c038n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:21:28 2024
                            <4*c027n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:21:28 2024
Terminated at Mon Dec  2 21:41:05 2024
Results reported at Mon Dec  2 21:41:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 3                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   38636.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.49 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   76778 sec.
    Turnaround time :                            78872 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
Dimer
Filename: (ECFP4.binary.1024)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.binary.1024)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.binary.1024)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.binary.1024)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c037n02>
Subject: Job 598221: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:41 2024
Job was executed on host(s) <4*c037n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:30:35 2024
                            <4*c037n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:30:35 2024
Terminated at Mon Dec  2 22:45:34 2024
Results reported at Mon Dec  2 22:45:34 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 4                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   45780.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.51 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   80099 sec.
    Turnaround time :                            82733 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Monomer
Filename: (ECFP4.binary.1024)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.binary.1024)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.binary.1024)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.binary.1024)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n06>
Subject: Job 598226: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:47 2024
Job was executed on host(s) <4*c202n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:43:45 2024
                            <4*c202n14>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:43:45 2024
Terminated at Tue Dec  3 00:53:18 2024
Results reported at Tue Dec  3 00:53:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 4                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   43734.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.44 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   86982 sec.
    Turnaround time :                            90391 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Dimer
Filename: (ECFP4.binary.1024)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.binary.1024)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.binary.1024)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.binary.1024)_GPR_Standard_shape.json
Done Saving scores!


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129

------------------------------------------------------------
Sender: LSF System <lsfadmin@c005n03>
Subject: Job 598230: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:49 2024
Job was executed on host(s) <4*c005n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:48:46 2024
                            <4*c006n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:48:46 2024
Terminated at Tue Dec  3 01:13:54 2024
Results reported at Tue Dec  3 01:13:54 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 4                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   39484.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.55 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   87908 sec.
    Turnaround time :                            91625 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
Trimer
Filename: (ECFP4.binary.1024)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.binary.1024)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.binary.1024)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.binary.1024)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n03>
Subject: Job 598224: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:43 2024
Job was executed on host(s) <4*c023n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:37:19 2024
                            <4*c023n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:37:19 2024
Terminated at Tue Dec  3 01:28:06 2024
Results reported at Tue Dec  3 01:28:06 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 4                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   40490.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.45 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   89468 sec.
    Turnaround time :                            92483 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Dimer
Filename: (ECFP5.binary.2048)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.binary.2048)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.binary.2048)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.binary.2048)_GPR_Standard_shape.json
Done Saving scores!


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890

------------------------------------------------------------
Sender: LSF System <lsfadmin@c021n03>
Subject: Job 598247: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:06 2024
Job was executed on host(s) <4*c021n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:21:30 2024
                            <4*c026n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:21:30 2024
Terminated at Tue Dec  3 03:54:48 2024
Results reported at Tue Dec  3 03:54:48 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 5                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   48550.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             1.58 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   95616 sec.
    Turnaround time :                            101262 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
Dimer
Filename: (ECFP5.binary.2048)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.binary.2048)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.binary.2048)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.binary.2048)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 598239: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:55 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:09:23 2024
                            <4*c200n08>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:09:23 2024
Terminated at Tue Dec  3 04:48:50 2024
Results reported at Tue Dec  3 04:48:50 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 5                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   60751.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.70 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   99587 sec.
    Turnaround time :                            104515 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
Monomer
Filename: (ECFP4.binary.1024)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.binary.1024)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.binary.1024)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.binary.1024)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c038n02>
Subject: Job 598217: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:38 2024
Job was executed on host(s) <4*c038n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:28:21 2024
                            <4*c039n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:28:21 2024
Terminated at Tue Dec  3 05:01:18 2024
Results reported at Tue Dec  3 05:01:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 4                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   45297.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.41 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   102790 sec.
    Turnaround time :                            105280 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
RRU Monomer
Filename: (ECFP3.binary.512)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.binary.512)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.binary.512)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.binary.512)_GPR_Standard_shape.json
Done Saving scores!


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n01>
Subject: Job 598210: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:32 2024
Job was executed on host(s) <4*c203n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:20:59 2024
                            <4*c203n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:20:59 2024
Terminated at Tue Dec  3 05:24:29 2024
Results reported at Tue Dec  3 05:24:29 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 3                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   34933.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.25 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   104608 sec.
    Turnaround time :                            106677 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Trimer
Filename: (ECFP4.binary.1024)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.binary.1024)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.binary.1024)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.binary.1024)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n03>
Subject: Job 598234: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:51 2024
Job was executed on host(s) <4*c202n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:58:31 2024
                            <4*c202n09>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:58:31 2024
Terminated at Tue Dec  3 11:13:45 2024
Results reported at Tue Dec  3 11:13:45 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 4                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   46823.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.28 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   123321 sec.
    Turnaround time :                            127614 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
Monomer
Filename: (ECFP5.binary.2048)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.binary.2048)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.binary.2048)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.binary.2048)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c004n04>
Subject: Job 598236: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:53 2024
Job was executed on host(s) <4*c004n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:02:34 2024
                            <4*c007n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:02:34 2024
Terminated at Tue Dec  3 11:59:39 2024
Results reported at Tue Dec  3 11:59:39 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 5                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   47558.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.30 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   125838 sec.
    Turnaround time :                            130366 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
Trimer
Filename: (ECFP3.binary.512)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.binary.512)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.binary.512)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.binary.512)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n01>
Subject: Job 598208: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:29 2024
Job was executed on host(s) <4*c200n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:16:09 2024
                            <4*c200n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:16:09 2024
Terminated at Tue Dec  3 14:50:22 2024
Results reported at Tue Dec  3 14:50:22 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 3                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   36979.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.16 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   138853 sec.
    Turnaround time :                            140633 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890
Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
RRU Trimer
Filename: (ECFP3.binary.512)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.binary.512)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.binary.512)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.binary.512)_GPR_Standard_shape.json
Done Saving scores!


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n12>
Subject: Job 598215: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:35 2024
Job was executed on host(s) <4*c203n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:24:11 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:24:11 2024
Terminated at Tue Dec  3 15:18:56 2024
Results reported at Tue Dec  3 15:18:56 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 3                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   36943.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.16 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   140101 sec.
    Turnaround time :                            142341 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.06±0.09
Monomer
Filename: (ECFP3.binary.512)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.binary.512)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.binary.512)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.binary.512)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c039n03>
Subject: Job 598204: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:25 2024
Job was executed on host(s) <4*c039n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 00:00:37 2024
                            <4*c038n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 00:00:37 2024
Terminated at Tue Dec  3 17:22:58 2024
Results reported at Tue Dec  3 17:22:58 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 3                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   35649.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.17 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   148962 sec.
    Turnaround time :                            149793 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
Trimer
Filename: (ECFP5.binary.2048)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.binary.2048)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.binary.2048)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.binary.2048)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c025n01>
Subject: Job 598241: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:57 2024
Job was executed on host(s) <4*c025n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:13:36 2024
                            <4*c015n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:13:36 2024
Terminated at Tue Dec  3 20:35:01 2024
Results reported at Tue Dec  3 20:35:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 5                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   46315.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.18 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   156091 sec.
    Turnaround time :                            161284 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
Dimer
Filename: (ECFP6.binary.4096)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.binary.4096)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.binary.4096)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.binary.4096)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n08>
Subject: Job 598255: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:16 2024
Job was executed on host(s) <4*c205n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:41:05 2024
                            <4*c205n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:41:05 2024
Terminated at Tue Dec  3 21:32:21 2024
Results reported at Tue Dec  3 21:32:21 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 6                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   89550.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.42 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   157899 sec.
    Turnaround time :                            164705 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])




Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Monomer
Filename: (ECFP6.binary.4096)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.binary.4096)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.binary.4096)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.binary.4096)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n02>
Subject: Job 598259: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:21 2024
Job was executed on host(s) <4*c201n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:52:55 2024
                            <4*c201n08>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:52:55 2024
Terminated at Tue Dec  3 22:07:05 2024
Results reported at Tue Dec  3 22:07:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 6                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   89241.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.47 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   159250 sec.
    Turnaround time :                            166784 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Trimer
Filename: (ECFP6.binary.4096)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.binary.4096)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.binary.4096)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.binary.4096)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c025n01>
Subject: Job 598265: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:27 2024
Job was executed on host(s) <4*c025n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 02:04:57 2024
                            <4*c024n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 02:04:57 2024
Terminated at Wed Dec  4 02:41:16 2024
Results reported at Wed Dec  4 02:41:16 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 6                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   67999.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.31 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   174979 sec.
    Turnaround time :                            183229 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Monomer
Filename: (ECFP5.binary.2048)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.binary.2048)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.binary.2048)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.binary.2048)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n01>
Subject: Job 598243: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:46:59 2024
Job was executed on host(s) <4*c200n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:21:19 2024
                            <4*c200n08>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:21:19 2024
Terminated at Wed Dec  4 03:32:51 2024
Results reported at Wed Dec  4 03:32:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 5                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   56294.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.21 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   180693 sec.
    Turnaround time :                            186352 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
Trimer
Filename: (ECFP6.binary.4096)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.binary.4096)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.binary.4096)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.binary.4096)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c025n01>
Subject: Job 598257: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:17 2024
Job was executed on host(s) <4*c025n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:43:18 2024
                            <4*c021n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:43:18 2024
Terminated at Wed Dec  4 04:10:53 2024
Results reported at Wed Dec  4 04:10:53 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 6                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   67566.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.29 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   181655 sec.
    Turnaround time :                            188616 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Dimer
Filename: (ECFP6.binary.4096)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.binary.4096)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.binary.4096)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.binary.4096)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c004n04>
Subject: Job 598262: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:25 2024
Job was executed on host(s) <4*c004n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 02:03:01 2024
                            <4*c003n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 02:03:01 2024
Terminated at Wed Dec  4 07:26:05 2024
Results reported at Wed Dec  4 07:26:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 6                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   69959.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             1.36 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   192184 sec.
    Turnaround time :                            200320 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
RRU Trimer
Filename: (ECFP5.binary.2048)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.binary.2048)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.binary.2048)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.binary.2048)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n12>
Subject: Job 598251: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:11 2024
Job was executed on host(s) <4*c203n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:24:00 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:24:00 2024
Terminated at Wed Dec  4 11:50:51 2024
Results reported at Wed Dec  4 11:50:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 5                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   59461.10 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.19 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   210412 sec.
    Turnaround time :                            216220 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])


Average scores:	 r: 0.37±0.18	 r2: 0.05±0.09
Monomer
Filename: (ECFP6.binary.4096)_GPR_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.binary.4096)_GPR_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.binary.4096)_GPR_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.binary.4096)_GPR_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n07>
Subject: Job 598253: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:13 2024
Job was executed on host(s) <4*c203n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec  2 01:26:01 2024
                            <4*c203n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec  2 01:26:01 2024
Terminated at Wed Dec  4 15:25:27 2024
Results reported at Wed Dec  4 15:25:27 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "tanimoto"                                        --radius 6                                        --vector binary                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   84495.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.33 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   223173 sec.
    Turnaround time :                            229094 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n04>
Subject: Job 619854: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:14 2024
Job was executed on host(s) <4*c207n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Dec  4 22:27:34 2024
                            <4*c207n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed Dec  4 22:27:34 2024
Terminated at Wed Dec  4 22:41:26 2024
Results reported at Wed Dec  4 22:41:26 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   95.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             0.60 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               30.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   840 sec.
    Turnaround time :                            17292 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n10>
Subject: Job 619856: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:14 2024
Job was executed on host(s) <4*c205n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Dec  4 22:40:23 2024
                            <4*c205n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed Dec  4 22:40:23 2024
Terminated at Wed Dec  4 23:01:21 2024
Results reported at Wed Dec  4 23:01:21 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   127.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             0.82 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   1258 sec.
    Turnaround time :                            18487 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c010n03>
Subject: Job 619860: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:16 2024
Job was executed on host(s) <4*c010n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 00:20:34 2024
                            <4*c012n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 00:20:34 2024
Terminated at Thu Dec  5 00:33:37 2024
Results reported at Thu Dec  5 00:33:37 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   113.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.18 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   797 sec.
    Turnaround time :                            24021 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c030n04>
Subject: Job 619863: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:16 2024
Job was executed on host(s) <4*c030n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 01:41:47 2024
                            <4*c031n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 01:41:47 2024
Terminated at Thu Dec  5 01:52:27 2024
Results reported at Thu Dec  5 01:52:27 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   140.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.58 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   655 sec.
    Turnaround time :                            28751 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c035n03>
Subject: Job 619872: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:19 2024
Job was executed on host(s) <4*c035n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:08:11 2024
                            <4*c037n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:08:11 2024
Terminated at Thu Dec  5 03:11:05 2024
Results reported at Thu Dec  5 03:11:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   143.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             0.75 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   184 sec.
    Turnaround time :                            33466 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n13>
Subject: Job 619875: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:20 2024
Job was executed on host(s) <4*c205n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:11:06 2024
                            <4*c205n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:11:06 2024
Terminated at Thu Dec  5 03:15:22 2024
Results reported at Thu Dec  5 03:15:22 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   462.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             3.09 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   258 sec.
    Turnaround time :                            33722 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n10>
Subject: Job 619882: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:24 2024
Job was executed on host(s) <4*c205n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:18:08 2024
                            <4*c205n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:18:08 2024
Terminated at Thu Dec  5 03:21:45 2024
Results reported at Thu Dec  5 03:21:45 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   202.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.00 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   225 sec.
    Turnaround time :                            34101 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c035n03>
Subject: Job 619883: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:24 2024
Job was executed on host(s) <4*c035n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:21:47 2024
                            <4*c037n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:21:47 2024
Terminated at Thu Dec  5 03:30:25 2024
Results reported at Thu Dec  5 03:30:25 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   415.00 sec.
    Max Memory :                                 8 GB
    Average Memory :                             4.30 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               24.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   528 sec.
    Turnaround time :                            34621 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n08>
Subject: Job 619890: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:26 2024
Job was executed on host(s) <4*c202n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:38:37 2024
                            <4*c202n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:38:37 2024
Terminated at Thu Dec  5 03:41:07 2024
Results reported at Thu Dec  5 03:41:07 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   193.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             2.71 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   159 sec.
    Turnaround time :                            35261 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c035n04>
Subject: Job 619892: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:27 2024
Job was executed on host(s) <4*c035n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:41:11 2024
                            <4*c035n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:41:11 2024
Terminated at Thu Dec  5 03:44:18 2024
Results reported at Thu Dec  5 03:44:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   130.48 sec.
    Max Memory :                                 5 GB
    Average Memory :                             2.89 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   192 sec.
    Turnaround time :                            35451 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c035n04>
Subject: Job 619900: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:30 2024
Job was executed on host(s) <4*c035n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:46:18 2024
                            <4*c035n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:46:18 2024
Terminated at Thu Dec  5 03:48:02 2024
Results reported at Thu Dec  5 03:48:02 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   143.16 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.33 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   130 sec.
    Turnaround time :                            35672 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n12>
Subject: Job 619901: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:31 2024
Job was executed on host(s) <4*c202n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:46:18 2024
                            <4*c202n08>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:46:18 2024
Terminated at Thu Dec  5 03:48:10 2024
Results reported at Thu Dec  5 03:48:10 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   163.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             1.50 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   112 sec.
    Turnaround time :                            35679 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n13>
Subject: Job 619905: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:33 2024
Job was executed on host(s) <4*c205n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:48:28 2024
                            <4*c205n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:48:28 2024
Terminated at Thu Dec  5 03:51:38 2024
Results reported at Thu Dec  5 03:51:38 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   180.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.22 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   190 sec.
    Turnaround time :                            35885 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n08>
Subject: Job 619904: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:33 2024
Job was executed on host(s) <4*c202n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:48:28 2024
                            <4*c202n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:48:28 2024
Terminated at Thu Dec  5 03:52:09 2024
Results reported at Thu Dec  5 03:52:09 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   297.24 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.20 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   239 sec.
    Turnaround time :                            35916 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n13>
Subject: Job 619908: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:35 2024
Job was executed on host(s) <4*c205n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:52:09 2024
                            <4*c205n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:52:09 2024
Terminated at Thu Dec  5 03:58:33 2024
Results reported at Thu Dec  5 03:58:33 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   299.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             2.07 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   412 sec.
    Turnaround time :                            36298 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619909: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:35 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 03:58:37 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 03:58:37 2024
Terminated at Thu Dec  5 04:03:16 2024
Results reported at Thu Dec  5 04:03:16 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   110.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             1.17 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   306 sec.
    Turnaround time :                            36581 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619912: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:37 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:06:32 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:06:32 2024
Terminated at Thu Dec  5 04:07:47 2024
Results reported at Thu Dec  5 04:07:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   184.17 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.00 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   75 sec.
    Turnaround time :                            36850 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619913: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:38 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:07:48 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:07:48 2024
Terminated at Thu Dec  5 04:12:36 2024
Results reported at Thu Dec  5 04:12:36 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   771.51 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.42 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   288 sec.
    Turnaround time :                            37138 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619916: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:41 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:15:36 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:15:36 2024
Terminated at Thu Dec  5 04:23:27 2024
Results reported at Thu Dec  5 04:23:27 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1517.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.72 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   471 sec.
    Turnaround time :                            37786 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619917: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:42 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:23:29 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:23:29 2024
Terminated at Thu Dec  5 04:26:29 2024
Results reported at Thu Dec  5 04:26:29 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   107.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             2.38 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   182 sec.
    Turnaround time :                            37967 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619920: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:43 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:31:30 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:31:30 2024
Terminated at Thu Dec  5 04:33:05 2024
Results reported at Thu Dec  5 04:33:05 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   194.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.33 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   96 sec.
    Turnaround time :                            38362 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619921: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:45 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:33:07 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:33:07 2024
Terminated at Thu Dec  5 04:35:36 2024
Results reported at Thu Dec  5 04:35:36 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   111.39 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.43 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   151 sec.
    Turnaround time :                            38511 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619924: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:47 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:39:23 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:39:23 2024
Terminated at Thu Dec  5 04:41:04 2024
Results reported at Thu Dec  5 04:41:04 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   199.24 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.50 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   101 sec.
    Turnaround time :                            38837 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619925: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:47 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:41:06 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:41:06 2024
Terminated at Thu Dec  5 04:42:38 2024
Results reported at Thu Dec  5 04:42:38 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   105.33 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.00 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               29.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   94 sec.
    Turnaround time :                            38931 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619928: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:49 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:45:06 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:45:06 2024
Terminated at Thu Dec  5 04:47:21 2024
Results reported at Thu Dec  5 04:47:21 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   241.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.00 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   135 sec.
    Turnaround time :                            39212 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619929: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:50 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:47:23 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:47:23 2024
Terminated at Thu Dec  5 04:48:47 2024
Results reported at Thu Dec  5 04:48:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   126.36 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.20 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   86 sec.
    Turnaround time :                            39297 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619932: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:51 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:58:15 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:58:15 2024
Terminated at Thu Dec  5 04:59:51 2024
Results reported at Thu Dec  5 04:59:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   142.22 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.33 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   96 sec.
    Turnaround time :                            39960 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619933: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:52 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 04:59:53 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 04:59:53 2024
Terminated at Thu Dec  5 05:03:44 2024
Results reported at Thu Dec  5 05:03:44 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   705.59 sec.
    Max Memory :                                 6 GB
    Average Memory :                             3.60 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   233 sec.
    Turnaround time :                            40192 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619936: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:53 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:12:44 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:12:44 2024
Terminated at Thu Dec  5 05:18:58 2024
Results reported at Thu Dec  5 05:18:58 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1004.35 sec.
    Max Memory :                                 6 GB
    Average Memory :                             4.93 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   374 sec.
    Turnaround time :                            41105 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619937: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:54 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:18:59 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:18:59 2024
Terminated at Thu Dec  5 05:20:44 2024
Results reported at Thu Dec  5 05:20:44 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   124.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             1.17 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   106 sec.
    Turnaround time :                            41210 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619941: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:55 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:23:41 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:23:41 2024
Terminated at Thu Dec  5 05:26:06 2024
Results reported at Thu Dec  5 05:26:06 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   130.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             1.86 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   171 sec.
    Turnaround time :                            41531 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 619940: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:55 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:23:41 2024
                            <4*c200n09>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:23:41 2024
Terminated at Thu Dec  5 05:26:18 2024
Results reported at Thu Dec  5 05:26:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   217.63 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.25 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   158 sec.
    Turnaround time :                            41543 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 619945: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:57 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:28:57 2024
                            <4*c200n09>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:28:57 2024
Terminated at Thu Dec  5 05:34:35 2024
Results reported at Thu Dec  5 05:34:35 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   174.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             1.57 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   338 sec.
    Turnaround time :                            42038 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c039n04>
Subject: Job 619944: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:57 2024
Job was executed on host(s) <4*c039n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:28:57 2024
                            <4*c029n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:28:57 2024
Terminated at Thu Dec  5 05:42:17 2024
Results reported at Thu Dec  5 05:42:17 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1818.27 sec.
    Max Memory :                                 9 GB
    Average Memory :                             5.52 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   806 sec.
    Turnaround time :                            42500 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619949: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:59 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:42:17 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:42:17 2024
Terminated at Thu Dec  5 05:45:46 2024
Results reported at Thu Dec  5 05:45:46 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   124.56 sec.
    Max Memory :                                 5 GB
    Average Memory :                             2.78 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   233 sec.
    Turnaround time :                            42707 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 619948: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:53:58 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:42:17 2024
                            <4*c200n09>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:42:17 2024
Terminated at Thu Dec  5 05:46:12 2024
Results reported at Thu Dec  5 05:46:12 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   235.45 sec.
    Max Memory :                                 5 GB
    Average Memory :                             1.80 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   247 sec.
    Turnaround time :                            42734 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619952: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:01 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:46:14 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:46:14 2024
Terminated at Thu Dec  5 05:48:51 2024
Results reported at Thu Dec  5 05:48:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   322.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             2.13 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   182 sec.
    Turnaround time :                            42890 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619956: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:02 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:48:53 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:48:53 2024
Terminated at Thu Dec  5 05:53:36 2024
Results reported at Thu Dec  5 05:53:36 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   309.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             3.58 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   285 sec.
    Turnaround time :                            43174 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c039n04>
Subject: Job 619953: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:01 2024
Job was executed on host(s) <4*c039n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 05:48:53 2024
                            <4*c039n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 05:48:53 2024
Terminated at Thu Dec  5 06:05:49 2024
Results reported at Thu Dec  5 06:05:49 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   3298.00 sec.
    Max Memory :                                 11 GB
    Average Memory :                             8.81 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               21.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   1027 sec.
    Turnaround time :                            43908 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 619961: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:07 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:05:51 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:05:51 2024
Terminated at Thu Dec  5 06:08:33 2024
Results reported at Thu Dec  5 06:08:33 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   166.51 sec.
    Max Memory :                                 6 GB
    Average Memory :                             3.63 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   172 sec.
    Turnaround time :                            44066 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n01>
Subject: Job 619960: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:06 2024
Job was executed on host(s) <4*c200n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:05:51 2024
                            <4*c200n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:05:51 2024
Terminated at Thu Dec  5 06:09:40 2024
Results reported at Thu Dec  5 06:09:40 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   567.47 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.20 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   257 sec.
    Turnaround time :                            44134 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c039n04>
Subject: Job 619957: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:03 2024
Job was executed on host(s) <4*c039n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:05:51 2024
                            <4*c039n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:05:51 2024
Terminated at Thu Dec  5 06:12:42 2024
Results reported at Thu Dec  5 06:12:42 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1168.00 sec.
    Max Memory :                                 10 GB
    Average Memory :                             7.44 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               22.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   413 sec.
    Turnaround time :                            44319 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n12>
Subject: Job 619966: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:09 2024
Job was executed on host(s) <4*c200n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:12:43 2024
                            <4*c200n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:12:43 2024
Terminated at Thu Dec  5 06:18:03 2024
Results reported at Thu Dec  5 06:18:03 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   170.32 sec.
    Max Memory :                                 6 GB
    Average Memory :                             3.23 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   331 sec.
    Turnaround time :                            44634 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n02>
Subject: Job 619964: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:08 2024
Job was executed on host(s) <4*c207n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:12:43 2024
                            <4*c207n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:12:43 2024
Terminated at Thu Dec  5 06:31:21 2024
Results reported at Thu Dec  5 06:31:21 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   3381.46 sec.
    Max Memory :                                 7 GB
    Average Memory :                             5.13 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               25.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   1146 sec.
    Turnaround time :                            45433 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n10>
Subject: Job 619969: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:11 2024
Job was executed on host(s) <4*c205n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:29:42 2024
                            <4*c205n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:29:42 2024
Terminated at Thu Dec  5 06:31:44 2024
Results reported at Thu Dec  5 06:31:44 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   316.42 sec.
    Max Memory :                                 5 GB
    Average Memory :                             3.50 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               27.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   141 sec.
    Turnaround time :                            45453 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.001), ('regressor__regressor__n_epoch', 100)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c030n04>
Subject: Job 619970: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:11 2024
Job was executed on host(s) <4*c030n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:30:44 2024
                            <4*c031n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:30:44 2024
Terminated at Thu Dec  5 06:37:01 2024
Results reported at Thu Dec  5 06:37:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1203.00 sec.
    Max Memory :                                 10 GB
    Average Memory :                             7.93 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               22.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   377 sec.
    Turnaround time :                            45770 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c031n03>
Subject: Job 619973: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:13 2024
Job was executed on host(s) <4*c031n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:37:02 2024
                            <4*c039n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:37:02 2024
Terminated at Thu Dec  5 06:39:04 2024
Results reported at Thu Dec  5 06:39:04 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   235.47 sec.
    Max Memory :                                 4 GB
    Average Memory :                             2.50 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               28.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   123 sec.
    Turnaround time :                            45891 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c031n03>
Subject: Job 619974: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Exited

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c024n04> by user <sdehgha2> in cluster <Hazel> at Wed Dec  4 17:54:13 2024
Job was executed on host(s) <4*c031n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 06:39:05 2024
                            <4*c039n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 06:39:05 2024
Terminated at Thu Dec  5 06:40:13 2024
Results reported at Thu Dec  5 06:40:13 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   168.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             1.80 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   69 sec.
    Turnaround time :                            45960 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Monomer
Filename: (ECFP3.count.512)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.count.512)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.count.512)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.count.512)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n14>
Subject: Job 627211: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:12 2024
Job was executed on host(s) <4*c202n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:24 2024
                            <4*c202n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 10:45:24 2024
Terminated at Thu Dec  5 11:52:12 2024
Results reported at Thu Dec  5 11:52:12 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   14093.39 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.00 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               25.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   4024 sec.
    Turnaround time :                            4020 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Dimer
Filename: (ECFP3.count.512)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.count.512)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.count.512)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.count.512)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c009n02>
Subject: Job 627219: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:13 2024
Job was executed on host(s) <4*c009n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:53:36 2024
                            <4*c005n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 10:53:36 2024
Terminated at Thu Dec  5 12:10:42 2024
Results reported at Thu Dec  5 12:10:42 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   10402.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             5.26 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   4647 sec.
    Turnaround time :                            5129 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Trimer
Filename: (ECFP3.count.512)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.count.512)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.count.512)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.count.512)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c014n01>
Subject: Job 627223: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:13 2024
Job was executed on host(s) <4*c014n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:53:36 2024
                            <4*c014n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 10:53:36 2024
Terminated at Thu Dec  5 12:15:04 2024
Results reported at Thu Dec  5 12:15:04 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   11884.24 sec.
    Max Memory :                                 9 GB
    Average Memory :                             5.68 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   4916 sec.
    Turnaround time :                            5391 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Trimer
Filename: (ECFP3.count.512)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.count.512)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.count.512)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP3.count.512)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c010n03>
Subject: Job 627222: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:13 2024
Job was executed on host(s) <4*c010n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:53:36 2024
                            <4*c006n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 10:53:36 2024
Terminated at Thu Dec  5 13:51:01 2024
Results reported at Thu Dec  5 13:51:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   35338.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             7.04 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   10645 sec.
    Turnaround time :                            11148 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP3.count.512)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.count.512)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.count.512)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.count.512)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n08>
Subject: Job 627227: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:13 2024
Job was executed on host(s) <4*c203n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 12:32:28 2024
                            <4*c203n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 12:32:28 2024
Terminated at Thu Dec  5 14:03:40 2024
Results reported at Thu Dec  5 14:03:40 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   14061.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             4.19 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   5478 sec.
    Turnaround time :                            11907 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP3.count.512)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.count.512)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.count.512)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.count.512)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n01>
Subject: Job 627231: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:14 2024
Job was executed on host(s) <4*c203n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 13:07:14 2024
                            <4*c203n07>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 13:07:14 2024
Terminated at Thu Dec  5 14:11:28 2024
Results reported at Thu Dec  5 14:11:28 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   14136.35 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.08 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   3876 sec.
    Turnaround time :                            12375 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Dimer
Filename: (ECFP3.count.512)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.count.512)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.count.512)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP3.count.512)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n12>
Subject: Job 627218: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:12 2024
Job was executed on host(s) <4*c200n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:52:36 2024
                            <4*c200n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 10:52:36 2024
Terminated at Thu Dec  5 14:45:19 2024
Results reported at Thu Dec  5 14:45:19 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   48462.19 sec.
    Max Memory :                                 6 GB
    Average Memory :                             4.96 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   13964 sec.
    Turnaround time :                            14407 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Monomer
Filename: (ECFP3.count.512)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.count.512)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.count.512)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP3.count.512)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n12>
Subject: Job 627210: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:12 2024
Job was executed on host(s) <4*c202n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:24 2024
                            <4*c202n08>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 10:45:24 2024
Terminated at Thu Dec  5 15:02:45 2024
Results reported at Thu Dec  5 15:02:45 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   54792.00 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.28 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               25.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   15460 sec.
    Turnaround time :                            15453 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP3.count.512)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.count.512)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.count.512)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP3.count.512)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 627226: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:13 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 11:52:35 2024
                            <4*c200n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 11:52:35 2024
Terminated at Thu Dec  5 15:23:48 2024
Results reported at Thu Dec  5 15:23:48 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   46109.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.51 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   12686 sec.
    Turnaround time :                            16715 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP3.count.512)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.count.512)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.count.512)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP3.count.512)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c037n02>
Subject: Job 627230: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:13 2024
Job was executed on host(s) <4*c037n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 12:44:24 2024
                            <4*c030n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 12:44:24 2024
Terminated at Thu Dec  5 15:46:47 2024
Results reported at Thu Dec  5 15:46:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   36241.04 sec.
    Max Memory :                                 9 GB
    Average Memory :                             7.55 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   10952 sec.
    Turnaround time :                            18094 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP3.count.512)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.count.512)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.count.512)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.count.512)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c029n03>
Subject: Job 627235: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:14 2024
Job was executed on host(s) <4*c029n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 16:48:13 2024
                            <4*c031n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 16:48:13 2024
Terminated at Thu Dec  5 17:59:57 2024
Results reported at Thu Dec  5 17:59:57 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   15536.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             7.88 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   4304 sec.
    Turnaround time :                            26083 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Dimer
Filename: (ECFP4.count.1024)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.count.1024)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.count.1024)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.count.1024)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n02>
Subject: Job 627243: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:14 2024
Job was executed on host(s) <4*c207n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:15:08 2024
                            <4*c207n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:15:08 2024
Terminated at Thu Dec  5 19:43:49 2024
Results reported at Thu Dec  5 19:43:49 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   19826.29 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.59 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   5342 sec.
    Turnaround time :                            32315 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP3.count.512)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.count.512)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.count.512)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP3.count.512)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c036n04>
Subject: Job 627234: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:14 2024
Job was executed on host(s) <4*c036n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 16:48:13 2024
                            <4*c033n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 16:48:13 2024
Terminated at Thu Dec  5 19:51:02 2024
Results reported at Thu Dec  5 19:51:02 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 3                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   39490.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             8.16 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   10969 sec.
    Turnaround time :                            32748 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Monomer
Filename: (ECFP4.count.1024)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.count.1024)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.count.1024)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.count.1024)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n07>
Subject: Job 627239: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:14 2024
Job was executed on host(s) <4*c205n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:15:08 2024
                            <4*c205n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:15:08 2024
Terminated at Thu Dec  5 20:41:32 2024
Results reported at Thu Dec  5 20:41:32 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22969.07 sec.
    Max Memory :                                 7 GB
    Average Memory :                             5.55 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               25.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   8785 sec.
    Turnaround time :                            35778 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Trimer
Filename: (ECFP4.count.1024)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.count.1024)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.count.1024)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.count.1024)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n12>
Subject: Job 627247: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:15 2024
Job was executed on host(s) <4*c201n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:17:09 2024
                            <4*c201n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:17:09 2024
Terminated at Thu Dec  5 20:54:48 2024
Results reported at Thu Dec  5 20:54:48 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22549.00 sec.
    Max Memory :                                 7 GB
    Average Memory :                             5.26 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               25.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   9487 sec.
    Turnaround time :                            36573 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP4.count.1024)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.count.1024)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.count.1024)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.count.1024)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n12>
Subject: Job 627255: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:16 2024
Job was executed on host(s) <4*c207n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:23:11 2024
                            <4*c207n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:23:11 2024
Terminated at Thu Dec  5 20:55:57 2024
Results reported at Thu Dec  5 20:55:57 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   23374.19 sec.
    Max Memory :                                 6 GB
    Average Memory :                             4.56 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   9180 sec.
    Turnaround time :                            36641 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP4.count.1024)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.count.1024)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.count.1024)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.count.1024)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n11>
Subject: Job 627251: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:15 2024
Job was executed on host(s) <4*c205n11>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:18:28 2024
                            <4*c205n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:18:28 2024
Terminated at Thu Dec  5 21:10:40 2024
Results reported at Thu Dec  5 21:10:40 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   24401.00 sec.
    Max Memory :                                 7 GB
    Average Memory :                             4.94 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               25.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   10348 sec.
    Turnaround time :                            37525 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP4.count.1024)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.count.1024)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.count.1024)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.count.1024)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n02>
Subject: Job 627259: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:16 2024
Job was executed on host(s) <4*c203n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 22:09:49 2024
                            <4*c203n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 22:09:49 2024
Terminated at Thu Dec  5 23:41:29 2024
Results reported at Thu Dec  5 23:41:29 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   20818.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.71 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   5515 sec.
    Turnaround time :                            46573 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Trimer
Filename: (ECFP4.count.1024)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.count.1024)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.count.1024)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP4.count.1024)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c038n03>
Subject: Job 627246: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:15 2024
Job was executed on host(s) <4*c038n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:15:10 2024
                            <4*c036n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:15:10 2024
Terminated at Fri Dec  6 00:21:49 2024
Results reported at Fri Dec  6 00:21:49 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   75435.00 sec.
    Max Memory :                                 10 GB
    Average Memory :                             8.11 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               22.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   22001 sec.
    Turnaround time :                            48994 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Monomer
Filename: (ECFP4.count.1024)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.count.1024)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.count.1024)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP4.count.1024)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c029n03>
Subject: Job 627238: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:14 2024
Job was executed on host(s) <4*c029n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 17:59:57 2024
                            <4*c031n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 17:59:57 2024
Terminated at Fri Dec  6 00:40:17 2024
Results reported at Fri Dec  6 00:40:17 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   95096.48 sec.
    Max Memory :                                 10 GB
    Average Memory :                             8.96 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               22.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   24020 sec.
    Turnaround time :                            50103 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Dimer
Filename: (ECFP5.count.2048)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.count.2048)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.count.2048)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.count.2048)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n07>
Subject: Job 627267: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:17 2024
Job was executed on host(s) <4*c203n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 22:47:19 2024
                            <4*c203n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 22:47:19 2024
Terminated at Fri Dec  6 01:06:38 2024
Results reported at Fri Dec  6 01:06:38 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   36591.00 sec.
    Max Memory :                                 8 GB
    Average Memory :                             6.58 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               24.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   8361 sec.
    Turnaround time :                            51681 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Monomer
Filename: (ECFP5.count.2048)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.count.2048)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.count.2048)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.count.2048)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n10>
Subject: Job 627263: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:16 2024
Job was executed on host(s) <4*c202n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 22:47:19 2024
                            <4*c202n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 22:47:19 2024
Terminated at Fri Dec  6 01:07:14 2024
Results reported at Fri Dec  6 01:07:14 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   35981.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             7.67 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   8409 sec.
    Turnaround time :                            51718 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP4.count.1024)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.count.1024)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.count.1024)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP4.count.1024)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n01>
Subject: Job 627258: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:16 2024
Job was executed on host(s) <4*c203n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:27:32 2024
                            <4*c203n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:27:32 2024
Terminated at Fri Dec  6 01:56:09 2024
Results reported at Fri Dec  6 01:56:09 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   94658.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.48 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   26938 sec.
    Turnaround time :                            54653 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP4.count.1024)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.count.1024)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.count.1024)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP4.count.1024)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 627254: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:15 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:23:09 2024
                            <4*c200n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:23:09 2024
Terminated at Fri Dec  6 01:57:46 2024
Results reported at Fri Dec  6 01:57:46 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   96368.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.44 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   27286 sec.
    Turnaround time :                            54751 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP4.count.1024)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.count.1024)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.count.1024)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP4.count.1024)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n03>
Subject: Job 627250: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:15 2024
Job was executed on host(s) <4*c201n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:18:28 2024
                            <4*c201n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:18:28 2024
Terminated at Fri Dec  6 02:04:22 2024
Results reported at Fri Dec  6 02:04:22 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   98040.19 sec.
    Max Memory :                                 8 GB
    Average Memory :                             6.39 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               24.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   27968 sec.
    Turnaround time :                            55147 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.19	 r2: 0.1±0.14
Dimer
Filename: (ECFP4.count.1024)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.count.1024)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.count.1024)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP4.count.1024)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n05>
Subject: Job 627242: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:14 2024
Job was executed on host(s) <4*c207n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 18:15:08 2024
                            <4*c207n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 18:15:08 2024
Terminated at Fri Dec  6 02:51:23 2024
Results reported at Fri Dec  6 02:51:23 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 4                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   113246.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.52 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               26.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   30975 sec.
    Turnaround time :                            57969 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Trimer
Filename: (ECFP5.count.2048)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.count.2048)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.count.2048)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.count.2048)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n07>
Subject: Job 627271: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:17 2024
Job was executed on host(s) <4*c203n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 01:31:50 2024
                            <4*c203n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 01:31:50 2024
Terminated at Fri Dec  6 03:37:09 2024
Results reported at Fri Dec  6 03:37:09 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   33162.00 sec.
    Max Memory :                                 8 GB
    Average Memory :                             6.68 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               24.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   7526 sec.
    Turnaround time :                            60712 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Dimer
Filename: (ECFP5.count.2048)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.count.2048)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.count.2048)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP5.count.2048)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n13>
Subject: Job 627266: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:16 2024
Job was executed on host(s) <4*c205n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 22:47:19 2024
                            <4*c205n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 22:47:19 2024
Terminated at Fri Dec  6 04:00:27 2024
Results reported at Fri Dec  6 04:00:27 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   66338.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             7.95 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   18790 sec.
    Turnaround time :                            62111 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP5.count.2048)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.count.2048)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.count.2048)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.count.2048)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n02>
Subject: Job 627275: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:17 2024
Job was executed on host(s) <4*c207n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 01:51:23 2024
                            <4*c207n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 01:51:23 2024
Terminated at Fri Dec  6 04:25:24 2024
Results reported at Fri Dec  6 04:25:24 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   35566.00 sec.
    Max Memory :                                 8 GB
    Average Memory :                             6.63 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               24.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   9249 sec.
    Turnaround time :                            63607 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Trimer
Filename: (ECFP5.count.2048)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.count.2048)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.count.2048)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP5.count.2048)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c031n01>
Subject: Job 627270: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:17 2024
Job was executed on host(s) <4*c031n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 00:40:17 2024
                            <4*c029n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 00:40:17 2024
Terminated at Fri Dec  6 05:51:09 2024
Results reported at Fri Dec  6 05:51:09 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   61128.00 sec.
    Max Memory :                                 11 GB
    Average Memory :                             10.29 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               21.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   18652 sec.
    Turnaround time :                            68752 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Monomer
Filename: (ECFP5.count.2048)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.count.2048)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.count.2048)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP5.count.2048)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c034n04>
Subject: Job 627262: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:16 2024
Job was executed on host(s) <4*c034n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Dec  5 22:09:56 2024
                            <4*c031n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Dec  5 22:09:56 2024
Terminated at Fri Dec  6 07:18:58 2024
Results reported at Fri Dec  6 07:18:58 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   129841.00 sec.
    Max Memory :                                 11 GB
    Average Memory :                             10.26 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               21.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   32943 sec.
    Turnaround time :                            74022 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP5.count.2048)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.count.2048)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.count.2048)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.count.2048)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n03>
Subject: Job 627283: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:18 2024
Job was executed on host(s) <4*c207n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 06:07:42 2024
                            <4*c207n11>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 06:07:42 2024
Terminated at Fri Dec  6 09:10:10 2024
Results reported at Fri Dec  6 09:10:10 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   41602.00 sec.
    Max Memory :                                 8 GB
    Average Memory :                             6.78 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               24.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   10969 sec.
    Turnaround time :                            80692 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Trimer
Filename: (ECFP6.count.4096)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c021n03>
Subject: Job 627295: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:20 2024
Job was executed on host(s) <4*c021n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 06:18:17 2024
                            <4*c016n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 06:18:17 2024
Terminated at Fri Dec  6 09:50:30 2024
Results reported at Fri Dec  6 09:50:30 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   52033.00 sec.
    Max Memory :                                 14 GB
    Average Memory :                             11.71 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               18.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   12760 sec.
    Turnaround time :                            83110 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Monomer
Filename: (ECFP6.count.4096)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.count.4096)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.count.4096)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.count.4096)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c017n04>
Subject: Job 627287: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:19 2024
Job was executed on host(s) <4*c017n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 06:18:17 2024
                            <4*c015n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 06:18:17 2024
Terminated at Fri Dec  6 09:55:43 2024
Results reported at Fri Dec  6 09:55:43 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   55801.00 sec.
    Max Memory :                                 14 GB
    Average Memory :                             11.70 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               18.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   13073 sec.
    Turnaround time :                            83424 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Dimer
Filename: (ECFP6.count.4096)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.count.4096)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.count.4096)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.count.4096)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c024n02>
Subject: Job 627291: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:19 2024
Job was executed on host(s) <4*c024n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 06:18:17 2024
                            <4*c016n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 06:18:17 2024
Terminated at Fri Dec  6 09:57:59 2024
Results reported at Fri Dec  6 09:57:59 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   56209.00 sec.
    Max Memory :                                 14 GB
    Average Memory :                             11.83 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               18.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   13209 sec.
    Turnaround time :                            83560 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP5.count.2048)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.count.2048)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.count.2048)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.count.2048)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n13>
Subject: Job 627279: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:18 2024
Job was executed on host(s) <4*c205n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 05:30:16 2024
                            <4*c205n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 05:30:16 2024
Terminated at Fri Dec  6 10:46:24 2024
Results reported at Fri Dec  6 10:46:24 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   65612.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             7.90 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   18988 sec.
    Turnaround time :                            86466 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP5.count.2048)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.count.2048)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.count.2048)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP5.count.2048)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n04>
Subject: Job 627274: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:17 2024
Job was executed on host(s) <4*c202n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 01:51:23 2024
                            <4*c202n12>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 01:51:23 2024
Terminated at Fri Dec  6 11:55:34 2024
Results reported at Fri Dec  6 11:55:34 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   132302.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             8.12 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   36261 sec.
    Turnaround time :                            90617 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP5.count.2048)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.count.2048)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.count.2048)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP5.count.2048)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n12>
Subject: Job 627282: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:18 2024
Job was executed on host(s) <4*c205n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 05:42:54 2024
                            <4*c205n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 05:42:54 2024
Terminated at Fri Dec  6 17:22:13 2024
Results reported at Fri Dec  6 17:22:13 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   165027.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             8.14 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   41986 sec.
    Turnaround time :                            110215 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Monomer
Filename: (ECFP6.count.4096)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.count.4096)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.count.4096)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(ECFP6.count.4096)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c014n04>
Subject: Job 627286: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:19 2024
Job was executed on host(s) <4*c014n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 06:18:17 2024
                            <4*c021n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 06:18:17 2024
Terminated at Fri Dec  6 17:46:00 2024
Results reported at Fri Dec  6 17:46:00 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   163540.00 sec.
    Max Memory :                                 15 GB
    Average Memory :                             12.46 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               17.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   41290 sec.
    Turnaround time :                            111641 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP5.count.2048)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.count.2048)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.count.2048)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP5.count.2048)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n06>
Subject: Job 627278: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:18 2024
Job was executed on host(s) <4*c205n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 05:30:16 2024
                            <4*c205n14>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 05:30:16 2024
Terminated at Fri Dec  6 18:08:02 2024
Results reported at Fri Dec  6 18:08:02 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 5                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   180786.00 sec.
    Max Memory :                                 9 GB
    Average Memory :                             8.07 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               23.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   45485 sec.
    Turnaround time :                            112964 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP6.count.4096)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c037n02>
Subject: Job 627299: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:20 2024
Job was executed on host(s) <4*c037n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 13:56:54 2024
                            <4*c034n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 13:56:54 2024
Terminated at Fri Dec  6 18:15:13 2024
Results reported at Fri Dec  6 18:15:13 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   64669.00 sec.
    Max Memory :                                 14 GB
    Average Memory :                             12.13 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               18.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   15501 sec.
    Turnaround time :                            113393 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6
RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Dimer
Filename: (ECFP6.count.4096)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.count.4096)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.count.4096)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(ECFP6.count.4096)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c014n02>
Subject: Job 627290: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:19 2024
Job was executed on host(s) <4*c014n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 06:18:17 2024
                            <4*c017n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 06:18:17 2024
Terminated at Fri Dec  6 19:41:39 2024
Results reported at Fri Dec  6 19:41:39 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   157778.00 sec.
    Max Memory :                                 14 GB
    Average Memory :                             12.40 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               18.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   48229 sec.
    Turnaround time :                            118580 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP6.count.4096)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.count.4096)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.count.4096)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.count.4096)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c025n02>
Subject: Job 627303: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:21 2024
Job was executed on host(s) <4*c025n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 18:51:06 2024
                            <4*c014n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 18:51:06 2024
Terminated at Fri Dec  6 22:48:12 2024
Results reported at Fri Dec  6 22:48:12 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   57473.00 sec.
    Max Memory :                                 14 GB
    Average Memory :                             11.26 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               18.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   14237 sec.
    Turnaround time :                            129771 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Monomer
Filename: (ECFP6.count.4096)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n08>
Subject: Job 627298: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:20 2024
Job was executed on host(s) <4*c207n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 07:56:06 2024
                            <4*c207n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 07:56:06 2024
Terminated at Fri Dec  6 23:07:55 2024
Results reported at Fri Dec  6 23:07:55 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Monomer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   216112.00 sec.
    Max Memory :                                 10 GB
    Average Memory :                             8.73 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               22.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   54711 sec.
    Turnaround time :                            130955 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
Trimer
Filename: (ECFP6.count.4096)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c025n04>
Subject: Job 627294: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:20 2024
Job was executed on host(s) <4*c025n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 06:18:17 2024
                            <4*c015n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 06:18:17 2024
Terminated at Fri Dec  6 23:35:32 2024
Results reported at Fri Dec  6 23:35:32 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   265043.00 sec.
    Max Memory :                                 13 GB
    Average Memory :                             11.58 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               19.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   62261 sec.
    Turnaround time :                            132612 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP6.count.4096)_GPR.rbf_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.count.4096)_GPR.rbf_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.count.4096)_GPR.rbf_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.count.4096)_GPR.rbf_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n09>
Subject: Job 627307: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:21 2024
Job was executed on host(s) <4*c202n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 18:51:06 2024
                            <4*c202n07>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 18:51:06 2024
Terminated at Fri Dec  6 23:39:45 2024
Results reported at Fri Dec  6 23:39:45 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "rbf"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   74265.00 sec.
    Max Memory :                                 11 GB
    Average Memory :                             9.27 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               21.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   17326 sec.
    Turnaround time :                            132864 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Dimer
Filename: (ECFP6.count.4096)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.count.4096)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.count.4096)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Dimer/(ECFP6.count.4096)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c014n03>
Subject: Job 627302: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:21 2024
Job was executed on host(s) <4*c014n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 18:51:06 2024
                            <4*c016n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 18:51:06 2024
Terminated at Sat Dec  7 04:30:48 2024
Results reported at Sat Dec  7 04:30:48 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Dimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   125788.00 sec.
    Max Memory :                                 14 GB
    Average Memory :                             12.24 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               18.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   34809 sec.
    Turnaround time :                            150327 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 200)])


Average scores:	 r: 0.4±0.2	 r2: 0.1±0.14
RRU Trimer
Filename: (ECFP6.count.4096)_GPR.matern_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.count.4096)_GPR.matern_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.count.4096)_GPR.matern_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Trimer/(ECFP6.count.4096)_GPR.matern_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c030n04>
Subject: Job 627306: <ecfp_GPR_Standard_Rg1 (nm)> in cluster <Hazel> Done

Job <ecfp_GPR_Standard_Rg1 (nm)> was submitted from host <c031n03> by user <sdehgha2> in cluster <Hazel> at Thu Dec  5 10:45:21 2024
Job was executed on host(s) <4*c030n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Dec  6 18:51:06 2024
                            <4*c029n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Dec  6 18:51:06 2024
Terminated at Sat Dec  7 06:11:43 2024
Results reported at Sat Dec  7 06:11:43 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 60:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_GPR_Standard_Rg1 (nm)"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type GPR                                        --kernel "matern"                                        --radius 6                                        --vector count                                        --target "Rg1 (nm)"                                        --oligo_type "RRU Trimer"                                        --transform_type "Standard"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147795.00 sec.
    Max Memory :                                 15 GB
    Average Memory :                             12.43 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               17.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   40841 sec.
    Turnaround time :                            156382 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_GPR_Standard_Rg1 (nm).err> for stderr output of this job.

