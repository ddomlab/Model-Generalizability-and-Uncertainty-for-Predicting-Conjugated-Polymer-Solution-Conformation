
------------------------------------------------------------
Sender: LSF System <lsfadmin@c019n01>
Subject: Job 930656: <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> in cluster <Hazel> Done

Job <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> was submitted from host <c012n04> by user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:48:26 2024
Job was executed on host(s) <2*c019n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Dec 23 15:50:13 2024
                            <2*c024n01>
                            <2*c021n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Dec 23 15:50:13 2024
Terminated at Mon Dec 23 16:26:01 2024
Results reported at Mon Dec 23 16:26:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_matern_Robust Scaler_Rg1 (nm)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_matern_Robust Scaler_Rg1 (nm)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                     --regressor_type "sklearn-GPR"                                     --kernel "matern"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   9.34 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   2152 sec.
    Turnaround time :                            2255 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_matern_Robust Scaler_Rg1 (nm)_final.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.6832336590922726), ('regressor__regressor__kernel__nu', 0.5402865431865436)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 2.8901068695064462), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.7475816215020324), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5628904421902737), ('regressor__regressor__kernel__nu', 0.8616766017927835)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.8041710150637449), ('regressor__regressor__kernel__nu', 0.8376778281633874)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.47895502329543493), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.13998983232734674), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.7721710395078827), ('regressor__regressor__kernel__nu', 0.6997489796403377)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.4629087881661064), ('regressor__regressor__kernel__nu', 0.9012453239808753)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5397753951422793), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.698964715328817), ('regressor__regressor__kernel__nu', 0.500059357156269)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.7139826514099632), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.13107317921775535), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.9879667043911087), ('regressor__regressor__kernel__nu', 0.5637641622951831)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.6921508460950642), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.48674867158081986), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5417423601314098), ('regressor__regressor__kernel__nu', 1.412811621159239)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.7259606810536707), ('regressor__regressor__kernel__nu', 1.0375527729206708)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.8722292345636544), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.872449229892688), ('regressor__regressor__kernel__nu', 0.8046041416420902)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5356561660311149), ('regressor__regressor__kernel__nu', 1.0630285670085171)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.41152503298599946), ('regressor__regressor__kernel__nu', 2.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.43712476984248805), ('regressor__regressor__kernel__nu', 1.178696302103142)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5939762925622366), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.7362027042704496), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.05), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5137356711273862), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.6024652069087073), ('regressor__regressor__kernel__nu', 0.6505798442135196)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5904617356625705), ('regressor__regressor__kernel__nu', 1.4807445587768626)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.540804432758558), ('regressor__regressor__kernel__nu', 0.5043833334574357)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.8144557882009487), ('regressor__regressor__kernel__nu', 0.5)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.7529877925116372), ('regressor__regressor__kernel__nu', 0.8036993515469231)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 1.4840676843062062), ('regressor__regressor__kernel__nu', 0.9681845898062439)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.5669080384416909), ('regressor__regressor__kernel__nu', 0.9769082997504533)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR sklearn-GPR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__kernel__length_scale', 0.42612498534912646), ('regressor__regressor__kernel__nu', 0.5)])


Average scores:	 r: 0.73±0.3	 r2: 0.57±0.4
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.matern_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.matern_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.matern_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_sklearn-GPR.matern_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n02>
Subject: Job 945149: <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> in cluster <Hazel> Done

Job <numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num> was submitted from host <c027n04> by user <sdehgha2> in cluster <Hazel> at Tue Dec 24 12:17:56 2024
Job was executed on host(s) <2*c202n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue Dec 24 12:24:09 2024
                            <2*c202n08>
                            <2*c202n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue Dec 24 12:24:09 2024
Terminated at Tue Dec 24 13:08:44 2024
Results reported at Tue Dec 24 13:08:44 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[ptile=2]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_sklearn-GPR_polymer_size_feats_on_Rg1 (nm)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_matern_Robust Scaler_Rg1 (nm)_final.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_matern_Robust Scaler_Rg1 (nm)_final.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                     --regressor_type "sklearn-GPR"                                     --kernel "matern"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4928.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.79 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               43.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   2677 sec.
    Turnaround time :                            3048 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_sklearn-GPR_matern_Robust Scaler_Rg1 (nm)_final.err> for stderr output of this job.

