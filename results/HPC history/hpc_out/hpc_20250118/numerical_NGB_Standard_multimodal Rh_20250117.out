


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009442196097706777), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0008091299196126802), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.078475162813721), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 847), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00036941418309087464), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0008926837108471101), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 216), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.029038808134485134), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 365), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01047290862965006), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 95), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.000911537574325068), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017286976261198052), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 134), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001011131249482285), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 605), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.044000951064149e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010960611953416195), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 548), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004898735221235543), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 59), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0034179188581025238), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 76), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00022396716056509891), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02343883654024424), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 144), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003247687718478422), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 337), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 1e-06), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09947032432259396), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 225), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009303608593215), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007015951810991966), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0038369042274637604), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 102), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0007234745838623838), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016558764095623622), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008579032169407558), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012653658127746268), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 91), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.07673626644896725), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 84), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.033603648652436036), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 114), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0008990925044417325), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013336568278656586), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00017234829757199624), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 101), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005637369156630971), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 72), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0010386609007325153), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0005168669312602745), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0003254712403577001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 933), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001996893918823779), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1065), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0017010417137749382), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 754), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005506736215942974), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 200), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002517030682973351), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1387), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.165  0.201 -2.066]±[0.118 0.12  5.855]
[array([ 0.16499041,  0.20138665, -2.06625745]), array([7.94589705e+00, 1.40971997e+02, 9.79533329e+04]), array([5.65231967e+00, 9.51440024e+01, 1.74422830e+04])]
{6: {'fit_time': array([51.46654677, 52.63546133, 51.58388376, 52.19749737, 51.40308762]), 'score_time': array([1.38054633, 1.46979594, 1.40887284, 1.5103929 , 1.4741056 ]), 'test_r2': [array([-0.07212875,  0.35113669, -1.21068307]), array([ 0.16874768,  0.05583175, -0.01656059]), array([0.16804344, 0.23098855, 0.52134537]), array([ 0.27377977,  0.14652106, -1.94106666]), array([ 0.16613941,  0.24498017, -3.63671376])], 'test_rmse': [array([6.70692252e+00, 1.14798203e+02, 2.55277789e+04]), array([7.97901495e+00, 1.32831523e+02, 3.36861383e+05]), array([8.04815650e+00, 1.62449791e+02, 1.66297064e+04]), array([8.21470248e+00, 1.54180445e+02, 2.21850669e+04]), array([8.75675135e+00, 1.40137392e+02, 4.22192669e+04])], 'test_mae': [array([4.98803116e+00, 8.36113605e+01, 8.59392746e+03]), array([6.00757806e+00, 9.10685226e+01, 5.48672017e+04]), array([5.56019307e+00, 1.08337188e+02, 5.60386893e+03]), array([5.80239376e+00, 9.80317602e+01, 7.94009473e+03]), array([6.42060726e+00, 9.81685020e+01, 1.04075748e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.0008091299196126802, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'fit_time': array([3.49395895, 3.42289543, 3.5811007 , 3.44900298, 3.37819147]), 'score_time': array([0.11803603, 0.11747813, 0.11151552, 0.11837149, 0.11876082]), 'test_r2': [array([  0.25490917,   0.22515966, -30.58652854]), array([0.27209514, 0.33613825, 0.55120709]), array([0.13316884, 0.17700003, 0.04917569]), array([-0.06132114,  0.25245256,  0.00482068]), array([0.22943456, 0.17621576, 0.71319357])], 'test_rmse': [array([8.47274847e+00, 1.59649571e+02, 4.92647454e+04]), array([7.62999045e+00, 1.31685225e+02, 1.85269210e+04]), array([8.84559747e+00, 1.36555801e+02, 9.12708647e+04]), array([6.63694630e+00, 1.33826526e+02, 3.21514931e+05]), array([7.67843396e+00, 1.31305389e+02, 7.92212708e+03])], 'test_mae': [array([5.73765974e+00, 9.90189515e+01, 1.37904156e+04]), array([5.44949987e+00, 8.95409524e+01, 6.97626551e+03]), array([6.28180409e+00, 9.28433037e+01, 1.37064143e+04]), array([4.89445911e+00, 8.69711664e+01, 4.46277774e+04]), array([   5.39628267,   96.95961071, 4543.88572135])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 134, 'regressor__estimator__learning_rate': 0.017286976261198052, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'fit_time': array([3.66417551, 3.73098087, 3.61741519, 3.62276483, 3.61088848]), 'score_time': array([0.12418032, 0.12297702, 0.12582541, 0.12394404, 0.12134194]), 'test_r2': [array([0.27590652, 0.07198248, 0.55774664]), array([0.16143102, 0.28713285, 0.33938856]), array([ 0.18443713,  0.10145138, -0.01268837]), array([ 0.16651386,  0.35837406, -2.44712418]), array([ 0.10371166,  0.26593147, -7.82304831])], 'test_rmse': [array([7.67160451e+00, 1.49656392e+02, 1.55973391e+04]), array([7.96788938e+00, 1.40850319e+02, 4.86751256e+04]), array([5.85257781e+00, 1.54782067e+02, 3.31981790e+05]), array([9.31163220e+00, 1.41270984e+02, 2.56149952e+04]), array([8.49229187e+00, 1.15069390e+02, 5.78668485e+04])], 'test_mae': [array([5.56268277e+00, 1.06495933e+02, 5.81708089e+03]), array([5.31083636e+00, 8.79574064e+01, 9.25695072e+03]), array([4.39675421e+00, 1.08379311e+02, 4.88979550e+04]), array([6.22606612e+00, 8.88484343e+01, 8.90892883e+03]), array([6.06152514e+00, 7.46590222e+01, 1.29375426e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 144, 'regressor__estimator__learning_rate': 0.02343883654024424, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'fit_time': array([2.5751543 , 2.67549777, 2.56976342, 2.58371592, 2.67689085]), 'score_time': array([0.09275937, 0.09652948, 0.09299803, 0.09257531, 0.08970404]), 'test_r2': [array([ 0.00845616,  0.21588736, -0.00068904]), array([0.11401891, 0.01736725, 0.01992676]), array([-0.04670424,  0.19968755,  0.42252433]), array([0.04226057, 0.00287776, 0.28233724]), array([ 0.12305848,  0.07851905, -2.13271522])], 'test_rmse': [array([7.85234323e+00, 1.45722874e+02, 3.22165537e+05]), array([8.01095422e+00, 1.53024739e+02, 9.26032287e+04]), array([1.03972312e+01, 1.32262896e+02, 2.37941865e+04]), array([9.17482688e+00, 1.55192551e+02, 1.09505742e+04]), array([7.35069349e+00, 1.67808946e+02, 2.07793564e+04])], 'test_mae': [array([6.18305056e+00, 1.06679089e+02, 4.53905003e+04]), array([6.14328298e+00, 1.09820746e+02, 1.87610013e+04]), array([7.29663551e+00, 9.35080654e+01, 1.28683302e+04]), array([6.78704066e+00, 1.06197533e+02, 9.10047011e+03]), array([6.05808136e+00, 1.05312861e+02, 1.28674254e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 102, 'regressor__estimator__learning_rate': 0.0038369042274637604, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'fit_time': array([2.86097097, 2.94641471, 2.83737135, 2.85159755, 2.86493134]), 'score_time': array([0.10169864, 0.10188031, 0.10227346, 0.10018635, 0.10301852]), 'test_r2': [array([  0.13789989,   0.1630718 , -17.0982209 ]), array([0.35405055, 0.44444007, 0.1097166 ]), array([ 0.45863469,  0.29103507, -0.67909089]), array([0.07422234, 0.26343365, 0.00345348]), array([ 0.14162888, -0.0003215 ,  0.15346042])], 'test_rmse': [array([8.20143647e+00, 1.52327219e+02, 6.72522705e+04]), array([7.90813818e+00, 9.27642281e+01, 9.15344465e+04]), array([6.61602471e+00, 1.41950190e+02, 9.65004365e+03]), array([8.01935300e+00, 1.69681022e+02, 3.21435720e+05]), array([7.45171888e+00, 1.30031670e+02, 2.10482378e+04])], 'test_mae': [array([5.75542795e+00, 9.19674681e+01, 1.36890451e+04]), array([5.18820783e+00, 7.12207858e+01, 1.46049013e+04]), array([   4.71161728,  100.63753801, 4633.03567014]), array([5.24338295e+00, 1.08711439e+02, 4.22366613e+04]), array([5.35390737e+00, 8.98908065e+01, 7.75246860e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 114, 'regressor__estimator__learning_rate': 0.033603648652436036, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'fit_time': array([1.25590372, 1.27027583, 1.24199963, 1.25966692, 1.2379818 ]), 'score_time': array([0.05755615, 0.05661201, 0.05651641, 0.05563378, 0.05623341]), 'test_r2': [array([-2.44819321e-03,  2.31575841e-01, -4.13754569e+00]), array([ 0.30640575, -0.05393536,  0.00111158]), array([ 0.2789731 ,  0.46772639, -3.11462938]), array([ 0.02876462,  0.25487123, -1.1739916 ]), array([0.25817345, 0.06308413, 0.00094773])], 'test_rmse': [array([7.52348532e+00, 1.64540843e+02, 7.24673278e+04]), array([7.49065793e+00, 1.38150406e+02, 9.32931958e+04]), array([7.72340334e+00, 9.62934213e+01, 1.88472576e+04]), array([7.99827680e+00, 1.61651639e+02, 1.86173358e+04]), array([8.92890529e+00, 1.39046213e+02, 3.23782732e+05])], 'test_mae': [array([5.34121096e+00, 9.89758314e+01, 1.60161200e+04]), array([5.01643620e+00, 9.54280601e+01, 1.43488870e+04]), array([5.17442746e+00, 6.77187008e+01, 6.10412067e+03]), array([5.39476071e+00, 1.09291799e+02, 6.15930991e+03]), array([5.99057468e+00, 8.94783108e+01, 4.43227548e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'fit_time': array([26.84986115, 26.52516413, 26.23526978, 26.53458643, 26.41029644]), 'score_time': array([0.75123262, 0.75111961, 0.77044916, 0.75308514, 0.71522212]), 'test_r2': [array([0.14198094, 0.25697911, 0.34432231]), array([0.22787189, 0.17536668, 0.05192942]), array([ 0.22270876,  0.28585517, -0.03177128]), array([ 0.26499692,  0.18778932, -0.77632108]), array([0.21484256, 0.22192536, 0.37377018])], 'test_rmse': [array([8.22913341e+00, 1.12220627e+02, 2.00210827e+04]), array([7.03602775e+00, 1.51763985e+02, 9.05115762e+04]), array([7.93675289e+00, 1.32471855e+02, 3.23073178e+05]), array([8.05427122e+00, 1.76805341e+02, 2.92230012e+04]), array([7.93750218e+00, 1.21260217e+02, 4.56574736e+04])], 'test_mae': [array([5.65376203e+00, 8.36321554e+01, 6.81614494e+03]), array([5.00158475e+00, 9.26481264e+01, 1.24712828e+04]), array([5.70173155e+00, 9.39213061e+01, 4.61343088e+04]), array([5.79774693e+00, 1.10667277e+02, 1.11674900e+04]), array([5.94194528e+00, 9.34407625e+01, 8.15976390e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1065, 'regressor__estimator__learning_rate': 0.001996893918823779, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 'r2_avg': array([ 0.16499041,  0.20138665, -2.06625745]), 'r2_stdev': array([0.11823333, 0.12036643, 5.85535962]), 'rmse_avg': array([7.94589705e+00, 1.40971997e+02, 9.79533329e+04]), 'rmse_stdev': array([8.30924126e-01, 1.93958186e+01, 1.16847340e+05]), 'mae_avg': array([5.65231967e+00, 9.51440024e+01, 1.74422830e+04]), 'mae_stdev': array([5.84519995e-01, 1.07732309e+01, 1.50725621e+04]), 'r2_avg_aggregate': -0.5666267990456132, 'r2_stdev_aggregate': 2.0313197931257934, 'rmse_avg_aggregate': 32700.750263167927, 'rmse_stdev_aggregate': 38955.85545178272, 'mae_avg_aggregate': 5847.69312059852, 'mae_stdev_aggregate': 5027.973269663121}
scaler
Filename: (PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c039n03>
Subject: Job 269011: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250117> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250117> was submitted from host <c039n02> by user <sdehgha2> in cluster <Hazel> at Fri Jan 17 14:31:43 2025
Job was executed on host(s) <6*c039n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Jan 17 14:31:44 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Jan 17 14:31:44 2025
Terminated at Fri Jan 17 23:11:13 2025
Results reported at Fri Jan 17 23:11:13 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250117"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250117.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250117.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Standard"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   143741.44 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.92 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   31176 sec.
    Turnaround time :                            31170 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Standard_multimodal Rh_20250117.err> for stderr output of this job.

