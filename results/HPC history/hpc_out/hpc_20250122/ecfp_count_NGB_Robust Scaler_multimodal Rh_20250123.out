RRU Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
Dimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00010535598452447336), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002469311618599412), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 158), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00021392322660626232), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 88), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006532284527031156), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 186), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0003901486774729039), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 60), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00013214690759674475), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 421), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002432517560853716), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 59), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001117972787615783), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 88), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00027040626397159523), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1035), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00018538894022839894), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 959), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005869314416009408), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 205), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00035068000919765574), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 160), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00015788853056890797), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 225), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00010253943538922507), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 770), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0009867153281822158), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 72), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002893557554015805), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 126), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00035528917239074676), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 285), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002551713462563931), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 95), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0028362705805410654), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005328537023251016), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 85), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 850), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000992523606386908), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1045), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00011888291445928685), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 221), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00047521446855364706), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 139), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00025691183464218015), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 587), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006210206527393419), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 140), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 964), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001521415558776506), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 82), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.014  0.037 -1.1  ]±[0.08  0.044 2.106]
[array([ 0.01380352,  0.03720389, -1.09998783]), array([8.65773782e+00, 1.55283293e+02, 9.72286425e+04]), array([6.64029300e+00, 1.06608071e+02, 2.48101418e+04])]
RRU Dimer
Filename: (ECFP3.count.512)_NGB_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/RRU Dimer/(ECFP3.count.512)_NGB_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/RRU Dimer/(ECFP3.count.512)_NGB_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/RRU Dimer/(ECFP3.count.512)_NGB_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n10>
Subject: Job 315456: <ecfp_NGB_Robust Scaler_multimodal Rh_20250123> in cluster <Hazel> Done

Job <ecfp_NGB_Robust Scaler_multimodal Rh_20250123> was submitted from host <c207n04> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:12:31 2025
Job was executed on host(s) <8*c200n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:12:31 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:12:31 2025
Terminated at Thu Jan 23 22:17:08 2025
Results reported at Thu Jan 23 22:17:08 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 45:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_NGB_Robust Scaler_multimodal Rh_20250123"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type NGB                                        --radius 3                                        --vector count                                        --target "multimodal Rh"                                        --oligo_type "RRU Dimer"                                        --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   131865.62 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.97 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               13.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   29091 sec.
    Turnaround time :                            29077 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00021042267617073172), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1645), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00015925734764885537), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 119), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006642412608664187), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 171), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002788445634324515), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 86), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00041776773505758797), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 133), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00023994975263002004), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 58), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00022906713922110495), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 402), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0004994917754851539), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 578), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00018538894022839894), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 959), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000598009039492094), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 206), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0004717562000452668), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 122), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007553177195416015), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 236), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00011096847532952636), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 307), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002494819336351938), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 295), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001593419900171358), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 465), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000600038328678436), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002488852936522439), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 402), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00018222809869248085), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 122), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000720789840484911), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 244), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00038169942447151137), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1226), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002297794001054199), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 396), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00042292510702669186), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 133), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1025), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00038868732579439247), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012799359356372385), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00025860581760785834), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 573), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005753440267510997), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 145), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0004889377245685946), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 198), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001547176559720609), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00010940470748802792), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 62), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.012  0.032 -1.087]±[0.08  0.04  2.148]
[array([ 0.01226301,  0.03204986, -1.08682836]), array([8.66555033e+00, 1.55702035e+02, 9.71117321e+04]), array([6.64287528e+00, 1.07019674e+02, 2.48462298e+04])]
Dimer
Filename: (ECFP3.count.512)_NGB_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/Dimer/(ECFP3.count.512)_NGB_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/Dimer/(ECFP3.count.512)_NGB_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/Dimer/(ECFP3.count.512)_NGB_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n06>
Subject: Job 315455: <ecfp_NGB_Robust Scaler_multimodal Rh_20250123> in cluster <Hazel> Done

Job <ecfp_NGB_Robust Scaler_multimodal Rh_20250123> was submitted from host <c207n04> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:12:30 2025
Job was executed on host(s) <8*c207n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:12:31 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:12:31 2025
Terminated at Thu Jan 23 22:23:53 2025
Results reported at Thu Jan 23 22:23:53 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 45:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "ecfp_NGB_Robust Scaler_multimodal Rh_20250123"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type NGB                                        --radius 3                                        --vector count                                        --target "multimodal Rh"                                        --oligo_type "Dimer"                                        --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   135921.45 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.98 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               13.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   29492 sec.
    Turnaround time :                            29483 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/ecfp_count_NGB_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.

