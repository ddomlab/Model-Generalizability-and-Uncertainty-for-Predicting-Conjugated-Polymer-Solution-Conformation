Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
Trimer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6
RRU Monomer



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0189234498606264), ('regressor__regressor__max_depth', 148), ('regressor__regressor__n_estimators', 175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010804169830392006), ('regressor__regressor__max_depth', 7567), ('regressor__regressor__n_estimators', 446), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07422302068868875), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 177), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014854104037707164), ('regressor__regressor__max_depth', 41), ('regressor__regressor__n_estimators', 271), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09569986034231306), ('regressor__regressor__max_depth', 18), ('regressor__regressor__n_estimators', 370), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02242271846582641), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 142), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0839595948176321), ('regressor__regressor__max_depth', 269), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.033112567422777774), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 99), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011761924187901089), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01201901828722398), ('regressor__regressor__max_depth', 23), ('regressor__regressor__n_estimators', 315), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017145838038053692), ('regressor__regressor__max_depth', 2119), ('regressor__regressor__n_estimators', 188), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 62), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04815291395222262), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 89), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016110490523015774), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005897097501653908), ('regressor__regressor__max_depth', 3758), ('regressor__regressor__n_estimators', 396), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0032212014536504184), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1260), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006049493322952197), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 436), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0529200829684634), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007289411153286276), ('regressor__regressor__max_depth', 6601), ('regressor__regressor__n_estimators', 327), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006154225770764847), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 505), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0036357707108794104), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 986), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09953116419879474), ('regressor__regressor__max_depth', 3215), ('regressor__regressor__n_estimators', 1178), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06744666851288009), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06582554107335588), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00823729557309238), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 210), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01984569483315648), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 219), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005767843184416537), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 548), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0026910540949914344), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001609320845543168), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04240388937444825), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 91), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08091703337929072), ('regressor__regressor__max_depth', 502), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.042343711227612726), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 90), ('regressor__regressor__n_jobs', -2)])


{'targets_shape': (255, 1), 'training_features_shape': (255, 4096)}
Average scores:	 r: 0.41±0.18	 r2: 0.16±0.18
RRU Monomer
Filename: (ECFP6.binary.4096)_XGBR_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.binary.4096)_XGBR_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.binary.4096)_XGBR_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.binary.4096)_XGBR_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c028n03>
Subject: Job 505123: <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> in cluster <Hazel> Done

Job <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> was submitted from host <c014n03> by user <sdehgha2> in cluster <Hazel> at Mon Nov 18 15:31:51 2024
Job was executed on host(s) <4*c028n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Nov 18 17:54:50 2024
                            <4*c037n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Mon Nov 18 17:54:50 2024
Terminated at Mon Nov 18 22:46:35 2024
Results reported at Mon Nov 18 22:46:35 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius_tructure_only_XGBR_with_Robust Scaler" 
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type XGBR --radius 6 --vector binary --target "Rg1 (nm)" --oligo_type "RRU Monomer" --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   78921.02 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.46 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               59.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   17533 sec.
    Turnaround time :                            26084 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006093928272100474), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 550), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006134097351633705), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 646), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014854104037707164), ('regressor__regressor__max_depth', 41), ('regressor__regressor__n_estimators', 271), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006466702530841413), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 558), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.033804698460762984), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 97), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09939643527172846), ('regressor__regressor__max_depth', 1720), ('regressor__regressor__n_estimators', 1171), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016474225531962297), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1537), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 480), ('regressor__regressor__n_estimators', 609), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006337573557896935), ('regressor__regressor__max_depth', 2888), ('regressor__regressor__n_estimators', 605), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007440115291250096), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 403), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07099519963654069), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003729467246056076), ('regressor__regressor__max_depth', 8049), ('regressor__regressor__n_estimators', 1171), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016423209051802691), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04223558234583116), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 93), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003069702334335469), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 854), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0021110816240119865), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0031607772143844573), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 843), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004659943804653297), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 516), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008655339316522183), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 267), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0041934419791592945), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 724), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006969004427069357), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 467), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05292783188772537), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005271816057149271), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 649), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014968784237522877), ('regressor__regressor__max_depth', 24), ('regressor__regressor__n_estimators', 1964), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008206622017916141), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 208), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012782929690378447), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 339), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03851874374258007), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 84), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005128865287193734), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 785), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01904502388873411), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 209), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012901000463871331), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 235), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0033781461661283145), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 1083), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08091703337929072), ('regressor__regressor__max_depth', 502), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007916993358944083), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 379), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08091703337929072), ('regressor__regressor__max_depth', 502), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])


{'targets_shape': (255, 1), 'training_features_shape': (255, 4096)}
Average scores:	 r: 0.41±0.18	 r2: 0.16±0.18
Trimer
Filename: (ECFP6.binary.4096)_XGBR_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.binary.4096)_XGBR_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.binary.4096)_XGBR_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.binary.4096)_XGBR_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c036n02>
Subject: Job 505121: <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> in cluster <Hazel> Done

Job <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> was submitted from host <c014n03> by user <sdehgha2> in cluster <Hazel> at Mon Nov 18 15:31:51 2024
Job was executed on host(s) <4*c036n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Nov 18 17:54:50 2024
                            <4*c029n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Mon Nov 18 17:54:50 2024
Terminated at Mon Nov 18 23:31:47 2024
Results reported at Mon Nov 18 23:31:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius_tructure_only_XGBR_with_Robust Scaler" 
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type XGBR --radius 6 --vector binary --target "Rg1 (nm)" --oligo_type "Trimer" --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   90726.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.45 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               59.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   20218 sec.
    Turnaround time :                            28796 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001619169561817938), ('regressor__regressor__max_depth', 7255), ('regressor__regressor__n_estimators', 1960), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014854104037707164), ('regressor__regressor__max_depth', 41), ('regressor__regressor__n_estimators', 271), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0017606968699029136), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1995), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014854104037707164), ('regressor__regressor__max_depth', 41), ('regressor__regressor__n_estimators', 271), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0032196491798995616), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 958), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05104318389255769), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001846956919978804), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 1507), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06075290851755219), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 175), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006337573557896935), ('regressor__regressor__max_depth', 2888), ('regressor__regressor__n_estimators', 605), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004839743714049425), ('regressor__regressor__max_depth', 13), ('regressor__regressor__n_estimators', 596), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08146216961026964), ('regressor__regressor__max_depth', 1264), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00405121853587081), ('regressor__regressor__max_depth', 5884), ('regressor__regressor__n_estimators', 1065), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00167170717859632), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007268086680280647), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 474), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005710266319602412), ('regressor__regressor__max_depth', 3108), ('regressor__regressor__n_estimators', 437), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022403954278211015), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008774252766275196), ('regressor__regressor__max_depth', 15), ('regressor__regressor__n_estimators', 298), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002366062897335481), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 987), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008706769082583625), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 264), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.002411141592683735), ('regressor__regressor__max_depth', 19), ('regressor__regressor__n_estimators', 1210), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0070784012379412455), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 463), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0521873163587536), ('regressor__regressor__max_depth', 549), ('regressor__regressor__n_estimators', 220), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0014958526662070416), ('regressor__regressor__max_depth', 14), ('regressor__regressor__n_estimators', 1992), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007017236252555322), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 473), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008199947372267145), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 206), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01276010707184459), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 338), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04277824164360002), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 86), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003712532999505482), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1087), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.004449619857720839), ('regressor__regressor__max_depth', 6021), ('regressor__regressor__n_estimators', 1167), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001615123676175348), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0048601200792011984), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 754), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03953280965138618), ('regressor__regressor__max_depth', 9295), ('regressor__regressor__n_estimators', 95), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08091703337929072), ('regressor__regressor__max_depth', 502), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.044065215791128244), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 90), ('regressor__regressor__n_jobs', -2)])


{'targets_shape': (255, 1), 'training_features_shape': (255, 4096)}
Average scores:	 r: 0.41±0.18	 r2: 0.16±0.18
Trimer
Filename: (ECFP6.count.4096)_XGBR_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_XGBR_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_XGBR_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(ECFP6.count.4096)_XGBR_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n14>
Subject: Job 505125: <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> in cluster <Hazel> Done

Job <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> was submitted from host <c014n03> by user <sdehgha2> in cluster <Hazel> at Mon Nov 18 15:31:51 2024
Job was executed on host(s) <4*c201n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Nov 18 18:23:07 2024
                            <4*c201n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Mon Nov 18 18:23:07 2024
Terminated at Tue Nov 19 01:08:01 2024
Results reported at Tue Nov 19 01:08:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius_tructure_only_XGBR_with_Robust Scaler" 
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type XGBR --radius 6 --vector count --target "Rg1 (nm)" --oligo_type "Trimer" --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   110140.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.81 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               60.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   24315 sec.
    Turnaround time :                            34570 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03156015064131554), ('regressor__regressor__max_depth', 8213), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0020936631210808185), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014854104037707164), ('regressor__regressor__max_depth', 41), ('regressor__regressor__n_estimators', 271), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09959869312789155), ('regressor__regressor__max_depth', 9706), ('regressor__regressor__n_estimators', 1601), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03681134238329736), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 94), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04944628876331641), ('regressor__regressor__max_depth', 2287), ('regressor__regressor__n_estimators', 1119), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05824360186662927), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007425120207112921), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.013134888805013158), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 290), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0015877493850297263), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1891), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 21), ('regressor__regressor__n_estimators', 331), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003525067806843797), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 1050), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07380640698590911), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008242510718383377), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 287), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.018026080659232276), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 239), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003183502568962313), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 871), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008414668198219375), ('regressor__regressor__max_depth', 12), ('regressor__regressor__n_estimators', 273), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.005289450825713432), ('regressor__regressor__max_depth', 9957), ('regressor__regressor__n_estimators', 457), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006905051054458788), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 476), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0032584592573431685), ('regressor__regressor__max_depth', 8904), ('regressor__regressor__n_estimators', 1308), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 648), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06365993855394), ('regressor__regressor__max_depth', 26), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0023449130640862117), ('regressor__regressor__max_depth', 9078), ('regressor__regressor__n_estimators', 1399), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00823208945024992), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 208), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.012916671602116223), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 344), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0016557743608840386), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 915), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025115189785599495), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 117), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03649312253732427), ('regressor__regressor__max_depth', 10000), ('regressor__regressor__n_estimators', 124), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09783915800640382), ('regressor__regressor__max_depth', 8412), ('regressor__regressor__n_estimators', 818), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04207980685357569), ('regressor__regressor__max_depth', 10), ('regressor__regressor__n_estimators', 90), ('regressor__regressor__n_jobs', -2)])


{'targets_shape': (255, 1), 'training_features_shape': (255, 4096)}
Average scores:	 r: 0.41±0.18	 r2: 0.16±0.18
RRU Monomer
Filename: (ECFP6.count.4096)_XGBR_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_XGBR_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_XGBR_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/RRU Monomer/(ECFP6.count.4096)_XGBR_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n06>
Subject: Job 505127: <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> in cluster <Hazel> Done

Job <ecfp_radius_tructure_only_XGBR_with_Robust Scaler> was submitted from host <c014n03> by user <sdehgha2> in cluster <Hazel> at Mon Nov 18 15:31:51 2024
Job was executed on host(s) <4*c202n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Nov 18 18:25:57 2024
                            <4*c202n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training> was used as the working directory.
Started at Mon Nov 18 18:25:57 2024
Terminated at Tue Nov 19 01:09:21 2024
Results reported at Tue Nov 19 01:09:21 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "ecfp_radius_tructure_only_XGBR_with_Robust Scaler" 
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_only.py ecfp --regressor_type XGBR --radius 6 --vector count --target "Rg1 (nm)" --oligo_type "RRU Monomer" --transform_type "Robust Scaler"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   110808.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.65 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               60.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   24180 sec.
    Turnaround time :                            34650 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/structure_only_ecfp_XGBR_with_Robust Scaler.err> for stderr output of this job.

