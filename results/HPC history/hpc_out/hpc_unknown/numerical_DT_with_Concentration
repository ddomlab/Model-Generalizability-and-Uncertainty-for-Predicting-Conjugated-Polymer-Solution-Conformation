/home/sdehgha2/.lsbatch/1727885319.742559.shell: line 17: syntax error near unexpected token `('
/home/sdehgha2/.lsbatch/1727885319.742559.shell: line 17: `python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --columns_to_impute Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --imputer "mean"'

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n01>
Subject: Job 742559: <finger_numerical_maccs> in cluster <Hazel> Exited

Job <finger_numerical_maccs> was submitted from host <c011n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:08:39 2024
Job was executed on host(s) <4*c023n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:08:40 2024
                            <4*c022n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:08:40 2024
Terminated at Wed Oct  2 12:08:42 2024
Results reported at Wed Oct  2 12:08:42 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
    



#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K).err


source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --columns_to_impute Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   0.73 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              1
    Max Threads :                                1
    Run time :                                   4 sec.
    Turnaround time :                            3 sec.

The output (if any) is above this job summary.

/home/sdehgha2/.lsbatch/1727885319.742557.shell: line 17: syntax error near unexpected token `('
/home/sdehgha2/.lsbatch/1727885319.742557.shell: line 17: `python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"'

------------------------------------------------------------
Sender: LSF System <lsfadmin@c009n02>
Subject: Job 742557: <finger_numerical_maccs> in cluster <Hazel> Exited

Job <finger_numerical_maccs> was submitted from host <c011n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:08:39 2024
Job was executed on host(s) <4*c009n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:08:40 2024
                            <4*c011n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:08:40 2024
Terminated at Wed Oct  2 12:08:42 2024
Results reported at Wed Oct  2 12:08:42 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
    



#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).err


source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   0.71 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   18 sec.
    Turnaround time :                            3 sec.

The output (if any) is above this job summary.

/home/sdehgha2/.lsbatch/1727885443.742594.shell: line 17: syntax error near unexpected token `('
/home/sdehgha2/.lsbatch/1727885443.742594.shell: line 17: `python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"'

------------------------------------------------------------
Sender: LSF System <lsfadmin@c012n01>
Subject: Job 742594: <finger_numerical_maccs> in cluster <Hazel> Exited

Job <finger_numerical_maccs> was submitted from host <c011n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:10:43 2024
Job was executed on host(s) <4*c012n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:10:44 2024
                            <4*c011n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:10:44 2024
Terminated at Wed Oct  2 12:10:45 2024
Results reported at Wed Oct  2 12:10:45 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
    



#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).err


source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   0.64 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   30 sec.
    Turnaround time :                            2 sec.

The output (if any) is above this job summary.

/home/sdehgha2/.lsbatch/1727885443.742596.shell: line 17: syntax error near unexpected token `('
/home/sdehgha2/.lsbatch/1727885443.742596.shell: line 17: `python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --columns_to_impute Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --imputer "mean"'

------------------------------------------------------------
Sender: LSF System <lsfadmin@c022n02>
Subject: Job 742596: <finger_numerical_maccs> in cluster <Hazel> Exited

Job <finger_numerical_maccs> was submitted from host <c011n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:10:43 2024
Job was executed on host(s) <4*c022n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:10:44 2024
                            <4*c014n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:10:44 2024
Terminated at Wed Oct  2 12:10:45 2024
Results reported at Wed Oct  2 12:10:45 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
    



#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K).err


source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --columns_to_impute Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   0.65 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   3 sec.
    Turnaround time :                            2 sec.

The output (if any) is above this job summary.

/home/sdehgha2/.lsbatch/1727885819.742678.shell: line 17: syntax error near unexpected token `('
/home/sdehgha2/.lsbatch/1727885819.742678.shell: line 17: `python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --columns_to_impute Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --imputer "mean"'
/home/sdehgha2/.lsbatch/1727885819.742676.shell: line 17: syntax error near unexpected token `('
/home/sdehgha2/.lsbatch/1727885819.742676.shell: line 17: `python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"'

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n01>
Subject: Job 742678: <finger_numerical_maccs> in cluster <Hazel> Exited

Job <finger_numerical_maccs> was submitted from host <c010n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:16:59 2024
Job was executed on host(s) <4*c023n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:17:00 2024
                            <4*c015n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:17:00 2024
Terminated at Wed Oct  2 12:17:01 2024
Results reported at Wed Oct  2 12:17:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
    



#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K).err


source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --columns_to_impute Concentration (mg/ml) Temperature SANS/SLS/DLS/SEC (K)                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   0.64 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   6 sec.
    Turnaround time :                            2 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c009n03>
Subject: Job 742676: <finger_numerical_maccs> in cluster <Hazel> Exited

Job <finger_numerical_maccs> was submitted from host <c010n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:16:59 2024
Job was executed on host(s) <4*c009n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:17:00 2024
                            <4*c011n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:17:00 2024
Terminated at Wed Oct  2 12:17:01 2024
Results reported at Wed Oct  2 12:17:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
    



#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).err


source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   0.67 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   16 sec.
    Turnaround time :                            2 sec.

The output (if any) is above this job summary.

/home/sdehgha2/.lsbatch/1727886086.742742.shell: line 17: syntax error near unexpected token `('
/home/sdehgha2/.lsbatch/1727886086.742742.shell: line 17: `python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"'

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n12>
Subject: Job 742742: <finger_numerical_maccs> in cluster <Hazel> Exited

Job <finger_numerical_maccs> was submitted from host <c201n01> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:21:26 2024
Job was executed on host(s) <4*c202n12>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:21:26 2024
                            <4*c202n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:21:26 2024
Terminated at Wed Oct  2 12:21:51 2024
Results reported at Wed Oct  2 12:21:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
    



#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).err


source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type DT                                   --numerical_feats Concentration (mg/ml)                                   --columns_to_impute Concentration (mg/ml)                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   1.32 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   47 sec.
    Turnaround time :                            25 sec.

The output (if any) is above this job summary.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numeric.py", line 318, in <module>
    main_numerical_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numeric.py", line 42, in main_numerical_only
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c009n03>
Subject: Job 742854: <finger_numerical_maccs> in cluster <Hazel> Done

Job <finger_numerical_maccs> was submitted from host <c004n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:30:48 2024
Job was executed on host(s) <4*c009n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:30:50 2024
                            <4*c011n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:30:50 2024
Terminated at Wed Oct  2 12:31:32 2024
Results reported at Wed Oct  2 12:31:32 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Lp (nm)"                                   --regressor_type "DT"                                   --numerical_feats "Concentration (mg/ml)"                                   --columns_to_impute "Concentration (mg/ml)"                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   19.12 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   54 sec.
    Turnaround time :                            44 sec.

The output (if any) is above this job summary.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR DT 	SEED: 6
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numeric.py", line 318, in <module>
    main_numerical_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numeric.py", line 42, in main_numerical_only
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c010n02>
Subject: Job 742944: <finger_numerical_maccs> in cluster <Hazel> Done

Job <finger_numerical_maccs> was submitted from host <c004n03> by user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:38:02 2024
Job was executed on host(s) <4*c010n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct  2 12:38:03 2024
                            <4*c012n01>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct  2 12:38:03 2024
Terminated at Wed Oct  2 12:38:32 2024
Results reported at Wed Oct  2 12:38:32 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
##BSUB -x
#BSUB -R "rusage[mem=32GB]"
#BSUB -J finger_numerical_maccs
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_DT_with_Concentration (mg/ml).err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numeric.py --target_features "Rg1 (nm)"                                   --regressor_type "DT"                                   --numerical_feats "Concentration (mg/ml)"                                   --columns_to_impute "Concentration (mg/ml)"                                   --imputer "mean"

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22.00 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   35 sec.
    Turnaround time :                            30 sec.

The output (if any) is above this job summary.

