


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__lr', 0.01), ('regressor__regressor__n_epoch', 1000)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR GPR 	SEED: 13

------------------------------------------------------------
Sender: LSF System <lsfadmin@c009n02>
Subject: Job 598174: <numerical_GPR_polymer_size_feats_on_Rg1 (nm)_all_num> in cluster <Hazel> Done

Job <numerical_GPR_polymer_size_feats_on_Rg1 (nm)_all_num> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:44:29 2024
Job was executed on host(s) <4*c009n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:47:30 2024
                            <4*c005n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Dec  1 23:47:30 2024
Terminated at Mon Dec  2 07:58:02 2024
Results reported at Mon Dec  2 07:58:02 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "numerical_GPR_polymer_size_feats_on_Rg1 (nm)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_GPR_polymer_on_Rg1 (nm)_all_num.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_GPR_polymer_on_Rg1 (nm)_all_num.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                     --regressor_type "GPR"                                     --kernel "matern"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' "Concentration (mg/ml)" "Temperature SANS/SLS/DLS/SEC (K)" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)'                                     --special_impute 'Mw (g/mol)'                                     --imputer mean

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7862.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             1.17 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   29434 sec.
    Turnaround time :                            29613 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_GPR_polymer_on_Rg1 (nm)_all_num.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c006n01>
Subject: Job 598175: <numerical_GPR_polymer_size_feats_on_Rg1 (nm)_all_num> in cluster <Hazel> Exited

Job <numerical_GPR_polymer_size_feats_on_Rg1 (nm)_all_num> was submitted from host <c009n02> by user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:44:31 2024
Job was executed on host(s) <4*c006n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Dec  1 23:49:14 2024
                            <4*c007n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Dec  1 23:49:14 2024
Terminated at Mon Dec  2 09:10:37 2024
Results reported at Mon Dec  2 09:10:37 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 8
#BSUB -W 30:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "numerical_GPR_polymer_size_feats_on_Rg1 (nm)_all_num"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_GPR_polymer_on_Rg1 (nm)_all_num.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_GPR_polymer_on_Rg1 (nm)_all_num.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "Rg1 (nm)"                                     --regressor_type "GPR"                                     --kernel "rbf"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' "Concentration (mg/ml)" "Temperature SANS/SLS/DLS/SEC (K)" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)'                                     --special_impute 'Mw (g/mol)'                                     --imputer mean

conda deactivate


------------------------------------------------------------

Exited with exit code 255.

Resource usage summary:

    CPU time :                                   2600.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.16 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   33676 sec.
    Turnaround time :                            33966 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_out/numerical_GPR_polymer_on_Rg1 (nm)_all_num.err> for stderr output of this job.

