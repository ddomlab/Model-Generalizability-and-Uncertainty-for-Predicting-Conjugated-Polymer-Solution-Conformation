
------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n09>
Subject: Job 257318: <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> in cluster <Hazel> Exited

Job <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Sun Mar  9 18:02:06 2025
Job was executed on host(s) <8*c200n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Mar  9 18:02:50 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Mar  9 18:02:50 2025
Terminated at Sun Mar  9 18:02:56 2025
Results reported at Sun Mar  9 18:02:56 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_numerical.py --target_features "Rg1 (nm)"                                       --representation "ECFP"                                       --regressor_type "NGB"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   3.94 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   7 sec.
    Turnaround time :                            50 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n11>
Subject: Job 257351: <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> in cluster <Hazel> Exited

Job <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Sun Mar  9 18:06:01 2025
Job was executed on host(s) <8*c203n11>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Mar  9 18:06:02 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Mar  9 18:06:02 2025
Terminated at Sun Mar  9 18:06:20 2025
Results reported at Sun Mar  9 18:06:20 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_numerical.py --target_features "Rg1 (nm)"                                       --representation "ECFP"                                       --regressor_type "NGB"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   4.41 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   31 sec.
    Turnaround time :                            19 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



-------------------------------------------------- 
OOD TEST ON 0



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07407306106367079), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 620), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 214), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00036941418309087464), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 911), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.051189437324308466), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.018194616005535746), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1050), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06598855972529777), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 730), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04312347715488935), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 876), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 304), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.029656141659616986), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 575), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06801638198576461), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 272), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04379701944657008), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 135), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.051543083312963485), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 498), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 483), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09929937012679989), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 660), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.3773705063380456e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08659699002524876), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.3639967264708466e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.045179986354770565), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1191), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09800152160747899), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 375), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0005808096323031351), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 766), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01220626722409574), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1245), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 921), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03924810175905992), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 667), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.038417919375682466), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 619), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00012318138841164986), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06208867307724955), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.053813722395485326), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1181), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 625), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 376), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05817798417385077), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 678), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.024469962177301022), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 758), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03465866052254702), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 728), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04780643508967529), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 684), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09807145550374481), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 549), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.000282120029648694), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057206280671183427), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1283), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OOD TEST ON 1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06393324221810032), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1458), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.048525289631100324), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 367), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00036941418309087464), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.042019560856149184), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1222), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 512), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1693), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05482079400687474), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 599), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1200), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.1200688201979395e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09952119490392267), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 263), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.4527928915110374e-05), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04975448208472006), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 445), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 345), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06366649620635999), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 207), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07201136003480699), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09939793013929618), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.3527825731996607e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07588091510568834), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 875), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.054799652329885665), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1413), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05161295269762692), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 830), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06775004010930251), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 134), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09875022798145708), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 347), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.0745548745256106e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.71006616411378e-05), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.049079665005445174), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 283), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006289852848290557), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07082184964054937), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 199), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08403246169680247), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04092365930455628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04310560709705524), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06415761321641986), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 99), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05444843374870956), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 507), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05515465446602002), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 939), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0009655390167721185), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017868168686542264), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1100), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.2965512316454423e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OOD TEST ON 2



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0003655837528604233), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1242), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00014735619928666035), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003998641429356242), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 150), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00022972049157031182), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00534601256928602), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 79), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0001219162429898735), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 990), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1470), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00035510667217010554), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 533), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06991692945397764), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.541254600438871e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.1200688201979395e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00044301274441413077), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 622), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006880089723278436), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 242), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027364528220782454), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 454), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.7081473573792404e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000980838502525219), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 338), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.390574606467376e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0022698208519179924), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 52), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0012430235023264452), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 153), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09929030480089016), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 298), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 8.227329791434283e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017167766764998687), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1966), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.9072914017861594e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007975167020468502), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 579), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.0907142673513772e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05210766700567591), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 324), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 236), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1967), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.3135839998299566e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07012340914857662), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 880), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1033), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001174392133586356), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07294769962876341), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03989103262191513), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00015435397464148287), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00021014528979117312), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1327), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 52), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0003909630552170634), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025110050741759458), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 849), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.2881294633636083e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 139), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.451969177228877e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OOD TEST ON 3



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04364904473578981), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 366), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.0078916184764762e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 8.739287996435623e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09998602757147512), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 436), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.1420862479577863e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.009675147139043312), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1252), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05123708242777729), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 340), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.022353209247119192), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0002971116484955541), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1393), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.1432039979022032e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03246050588530025), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08668971386402068), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 390), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 7.794717768414431e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 234), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07604763467370271), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 103), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0008215792871338929), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 378), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00015429157700576246), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 752), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1030), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.984936292466444e-05), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06558047617862564), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 277), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.303084049229246e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1235), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 916), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 390), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.087712265801031), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 228), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.3855114203776812e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0024956551422054183), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 138), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.787105590525745e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07783512673072839), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 142), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0009828359486258864), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05549099965113532), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04103038112516125), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 574), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06774949934992477), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 342), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015787007901963624), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1315), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 256), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 230), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])


{'CO_0': {6: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 77.50831926532663, 'test_rmse': 158.52555941196263, 'test_r2': -0.3042239709735983, 'test_pearson_r': array([-0.0793604]), 'test_pearson_p_value': array([0.34956133]), 'test_spearman_r': 0.02266806020347096, 'test_spearman_p_value': 0.7896181075179639, 'test_kendall_r': -0.021875763378966767, 'test_kendall_p_value': 0.7038096006675639, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 911, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 13: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 80.86220581182846, 'test_rmse': 160.72627963682953, 'test_r2': -0.3406869234653227, 'test_pearson_r': array([-0.05288493]), 'test_pearson_p_value': array([0.53340295]), 'test_spearman_r': -0.045384875876414814, 'test_spearman_p_value': 0.5930691005935479, 'test_kendall_r': -0.05775217472922013, 'test_kendall_p_value': 0.3157644997235586, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 730, 'regressor__learning_rate': 0.06598855972529777, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 42: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 71.24073959039386, 'test_rmse': 156.3494244108037, 'test_r2': -0.2686626748434331, 'test_pearson_r': array([-0.06697956]), 'test_pearson_p_value': array([0.43002715]), 'test_spearman_r': -0.11964951213611517, 'test_spearman_p_value': 0.157598610316695, 'test_kendall_r': -0.10040712571674712, 'test_kendall_p_value': 0.08087981295418027, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.04379701944657008, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 69: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 79.16336102641266, 'test_rmse': 158.67599464745138, 'test_r2': -0.30670047173478654, 'test_pearson_r': array([-0.04811179]), 'test_pearson_p_value': array([0.57102766]), 'test_spearman_r': -0.004355139962153166, 'test_spearman_p_value': 0.9591228673210719, 'test_kendall_r': -0.03586202916122569, 'test_kendall_p_value': 0.5333042992696574, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1191, 'regressor__learning_rate': 0.045179986354770565, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 420: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 74.51591702484077, 'test_rmse': 158.292873507475, 'test_r2': -0.3003980666398667, 'test_pearson_r': array([-0.06720887]), 'test_pearson_p_value': array([0.42844639]), 'test_spearman_r': -0.10430994644339661, 'test_spearman_p_value': 0.21834256259949025, 'test_kendall_r': -0.10559373853505631, 'test_kendall_p_value': 0.06626865951748644, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 667, 'regressor__learning_rate': 0.03924810175905992, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 1234567890: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 78.949483082301, 'test_rmse': 158.76098929569363, 'test_r2': -0.30810071242619874, 'test_pearson_r': array([-0.08460452]), 'test_pearson_p_value': array([0.31853645]), 'test_spearman_r': -0.012935990452096298, 'test_spearman_p_value': 0.878993390211205, 'test_kendall_r': -0.050627373526142466, 'test_kendall_p_value': 0.3788862478680316, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 376, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 473129: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 74.07281493773685, 'test_rmse': 155.52921300936987, 'test_r2': -0.2553867428419456, 'test_pearson_r': array([-0.03627441]), 'test_pearson_p_value': array([0.66934941]), 'test_spearman_r': -0.02465654279237179, 'test_spearman_p_value': 0.7716493631925612, 'test_kendall_r': -0.030088885280242884, 'test_kendall_p_value': 0.6009818126353237, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1283, 'regressor__learning_rate': 0.057206280671183427, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}}, 'CO_1': {6: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 85.01299628907839, 'test_rmse': 173.25066957122033, 'test_r2': -56.26504102424475, 'test_pearson_r': array([-0.27099073]), 'test_pearson_p_value': array([0.26178198]), 'test_spearman_r': 0.049252437694764964, 'test_spearman_p_value': 0.8412989020963321, 'test_kendall_r': 0.03571491842465247, 'test_kendall_p_value': 0.8331350939013934, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 512, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 13: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 142.0152674822743, 'test_rmse': 211.57603673659986, 'test_r2': -84.4029137314983, 'test_pearson_r': array([-0.13969476]), 'test_pearson_p_value': array([0.56841619]), 'test_spearman_r': 0.130167156764736, 'test_spearman_p_value': 0.595325206107569, 'test_kendall_r': 0.09523978246573993, 'test_kendall_p_value': 0.5742388103830554, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 263, 'regressor__learning_rate': 0.09952119490392267, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 42: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 57.29767933197676, 'test_rmse': 106.13121456816629, 'test_r2': -20.489484689977715, 'test_pearson_r': array([-0.18384008]), 'test_pearson_p_value': array([0.45121264]), 'test_spearman_r': 0.01934917195151481, 'test_spearman_p_value': 0.9373332015162439, 'test_kendall_r': 0.0, 'test_kendall_p_value': 1.0, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.07201136003480699, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 69: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 89.32874694156898, 'test_rmse': 180.51326126985936, 'test_r2': -61.16672053971645, 'test_pearson_r': array([-0.21088277]), 'test_pearson_p_value': array([0.38615124]), 'test_spearman_r': 0.30079167306445753, 'test_spearman_p_value': 0.21081167013397828, 'test_kendall_r': 0.26190940178078476, 'test_kendall_p_value': 0.12234519674227803, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.05161295269762692, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 420: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 70.73932779678222, 'test_rmse': 141.0226976005072, 'test_r2': -36.94178586639792, 'test_pearson_r': array([-0.19683397]), 'test_pearson_p_value': array([0.41927497]), 'test_spearman_r': 0.276165454217075, 'test_spearman_p_value': 0.25242192993637497, 'test_kendall_r': 0.2142895105479148, 'test_kendall_p_value': 0.20619610437027291, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1123, 'regressor__learning_rate': 0.05913781436124809, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 1234567890: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 81.87807469895719, 'test_rmse': 164.94284870847324, 'test_r2': -50.90470350946312, 'test_pearson_r': array([-0.21247921]), 'test_pearson_p_value': array([0.38248172]), 'test_spearman_r': 0.16534746940385386, 'test_spearman_p_value': 0.49873399895718007, 'test_kendall_r': 0.1071447552739574, 'test_kendall_p_value': 0.5273559970445866, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 199, 'regressor__learning_rate': 0.07082184964054937, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 473129: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 57.156423851426936, 'test_rmse': 109.10143994709905, 'test_r2': -21.709140528976352, 'test_pearson_r': array([-0.2219838]), 'test_pearson_p_value': array([0.36104022]), 'test_spearman_r': 0.024626218847382482, 'test_spearman_p_value': 0.9202884827911385, 'test_kendall_r': 0.023809945616434982, 'test_kendall_p_value': 0.8883005471633357, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 99, 'regressor__learning_rate': 0.06415761321641986, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}}, 'CO_2': {6: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 109.33328298253099, 'test_rmse': 138.51537827433265, 'test_r2': -1.7788973272461375, 'test_pearson_r': array([-0.42038248]), 'test_pearson_p_value': array([0.0001922]), 'test_spearman_r': -0.5852717510997106, 'test_spearman_p_value': 4.335131118498439e-08, 'test_kendall_r': -0.430216034216246, 'test_kendall_p_value': 6.313419455812028e-08, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1470, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 13: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 125.43962619685347, 'test_rmse': 161.64614360358743, 'test_r2': -2.7844886970896763, 'test_pearson_r': array([-0.41624003]), 'test_pearson_p_value': array([0.00022553]), 'test_spearman_r': -0.5738078866578796, 'test_spearman_p_value': 9.074236389595918e-08, 'test_kendall_r': -0.4287312506641623, 'test_kendall_p_value': 7.005923619450774e-08, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 533, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 42: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 129.8018893946842, 'test_rmse': 175.11839826176526, 'test_r2': -3.4416063856548273, 'test_pearson_r': array([-0.36623286]), 'test_pearson_p_value': array([0.00133153]), 'test_spearman_r': -0.4807951635774533, 'test_spearman_p_value': 1.4523689991592389e-05, 'test_kendall_r': -0.35545862204073825, 'test_kendall_p_value': 8.089233366523678e-06, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 50, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 69: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 106.79640544234718, 'test_rmse': 131.42529376793837, 'test_r2': -1.5016953953813714, 'test_pearson_r': array([-0.45360529]), 'test_pearson_p_value': array([4.93260705e-05]), 'test_spearman_r': -0.4906022302569501, 'test_spearman_p_value': 9.103538923973811e-06, 'test_kendall_r': -0.35344421188869934, 'test_kendall_p_value': 8.848452298478057e-06, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 298, 'regressor__learning_rate': 0.09929030480089016, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 420: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 138.23866040535597, 'test_rmse': 198.18808447724408, 'test_r2': -4.688943186045376, 'test_pearson_r': array([-0.34153793]), 'test_pearson_p_value': array([0.00290034]), 'test_spearman_r': -0.489384078752922, 'test_spearman_p_value': 9.6549304820237e-06, 'test_kendall_r': -0.3663703414766478, 'test_kendall_p_value': 4.087737150662692e-06, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 236, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 1234567890: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 139.96172886369118, 'test_rmse': 203.09240158575494, 'test_r2': -4.973981408262583, 'test_pearson_r': array([-0.34646178]), 'test_pearson_p_value': array([0.00249549]), 'test_spearman_r': -0.4389673148149003, 'test_spearman_p_value': 9.138281344309622e-05, 'test_kendall_r': -0.3124081884265463, 'test_kendall_p_value': 8.649040392545987e-05, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.07294769962876341, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 473129: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 122.80235339547562, 'test_rmse': 162.43210965250873, 'test_r2': -2.8213805265259677, 'test_pearson_r': array([-0.38074773]), 'test_pearson_p_value': array([0.00081822]), 'test_spearman_r': -0.5008627543891224, 'test_spearman_p_value': 5.497577533187544e-06, 'test_kendall_r': -0.3596888154922712, 'test_kendall_p_value': 6.101104809101003e-06, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 139, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}}, 'CO_3': {6: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 101.70773954081162, 'test_rmse': 137.5555161406904, 'test_r2': -0.9089607116431051, 'test_pearson_r': array([-0.1735694]), 'test_pearson_p_value': array([0.40668475]), 'test_spearman_r': -0.14238970073240528, 'test_spearman_p_value': 0.49715571597011277, 'test_kendall_r': -0.11462756546520023, 'test_kendall_p_value': 0.43611528846024006, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 13: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 97.78307406885149, 'test_rmse': 129.38435552569476, 'test_r2': -0.6889022040970902, 'test_pearson_r': array([-0.02445372]), 'test_pearson_p_value': array([0.90763203]), 'test_spearman_r': 0.00737023395919364, 'test_spearman_p_value': 0.9721077479047441, 'test_kendall_r': 0.013869505459353088, 'test_kendall_p_value': 0.9248149093516425, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 340, 'regressor__learning_rate': 0.05123708242777729, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 42: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 98.38856570230764, 'test_rmse': 133.57739230609502, 'test_r2': -0.800142521233081, 'test_pearson_r': array([-0.10632578]), 'test_pearson_p_value': array([0.61296238]), 'test_spearman_r': 0.055858615269678114, 'test_spearman_p_value': 0.7908544909747198, 'test_kendall_r': 0.02080425818902963, 'test_kendall_p_value': 0.8874310115826572, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 234, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 69: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 100.23283402501589, 'test_rmse': 135.15520138572344, 'test_r2': -0.8429200570256623, 'test_pearson_r': array([-0.21896306]), 'test_pearson_p_value': array([0.29298594]), 'test_spearman_r': -0.19593133207047592, 'test_spearman_p_value': 0.3479137718609834, 'test_kendall_r': -0.14241606618403665, 'test_kendall_p_value': 0.33326287939324817, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 404, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 420: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 102.38905100912129, 'test_rmse': 137.50514632346105, 'test_r2': -0.9075629284048041, 'test_pearson_r': array([-0.10545755]), 'test_pearson_p_value': array([0.61588182]), 'test_spearman_r': -0.12919828431577918, 'test_spearman_p_value': 0.538219586958272, 'test_kendall_r': -0.0798919395666547, 'test_kendall_p_value': 0.5872819727857694, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1235, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 1234567890: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 92.94320915015196, 'test_rmse': 128.0412483365747, 'test_r2': -0.6540200430743945, 'test_pearson_r': array([0.0329893]), 'test_pearson_p_value': array([0.87560419]), 'test_spearman_r': 0.04210436520872374, 'test_spearman_p_value': 0.8416118906493633, 'test_kendall_r': 0.006959564088827693, 'test_kendall_p_value': 0.9623449435096092, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 142, 'regressor__learning_rate': 0.07783512673072839, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}, 473129: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 101.55140274914855, 'test_rmse': 136.13954615914662, 'test_r2': -0.8698620422682943, 'test_pearson_r': array([-0.05047554]), 'test_pearson_p_value': array([0.81063313]), 'test_spearman_r': -0.040738197757227666, 'test_spearman_p_value': 0.8466906489583118, 'test_kendall_r': -0.017367812949272764, 'test_kendall_p_value': 0.9060712748932757, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 256, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler': None}}}, 'overall data shape': {'targets_shape': (259, 1), 'training_features_shape': (259, 522)}}
Trimer_scaler
Filename: (ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_transformerOFF
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/OOD_target_Rg/KM4 Mordred_Polysize cluster/Trimer_scaler/(ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_transformerOFF_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/OOD_target_Rg/KM4 Mordred_Polysize cluster/Trimer_scaler/(ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_transformerOFF_predictions.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/OOD_target_Rg/KM4 Mordred_Polysize cluster/Trimer_scaler/(ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_transformerOFF_ClusterTruth.json
Done Saving scores!
---------------------------------------- 
Plotted Comparitive Cluster Scores!
____________________ 
Plotted Parity Plots!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c012n02>
Subject: Job 257406: <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> in cluster <Hazel> Done

Job <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> was submitted from host <c012n03> by user <sdehgha2> in cluster <Hazel> at Sun Mar  9 18:11:14 2025
Job was executed on host(s) <8*c012n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Mar  9 18:11:23 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Mar  9 18:11:23 2025
Terminated at Mon Mar 10 16:46:23 2025
Results reported at Mon Mar 10 16:46:23 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "Rg1 (nm)"                                       --representation "ECFP"                                       --regressor_type "NGB"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   350209.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.57 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   1 GB
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   81302 sec.
    Turnaround time :                            81309 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00036941418309087464), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 316), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1119), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.052908665990050265), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1194), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06126150127153131), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1959), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.363427597027551e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1209), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03351981370914465), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 217), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.029079677077541725), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028323216179065244), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.2288862090463194e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.390574606467376e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.1604097204816164e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006832058533615792), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.260279806861773e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025787719904410488), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07163314216256438), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 332), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09607254673790876), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1920), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 5.421989610128517e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 256), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0983840891517748), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 548), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.1421744372188176e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 288), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06843847000580877), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 149), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05728103520605716), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 350), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.0430007920741113e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1330), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0214495401720318), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 618), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 909), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.051906418706481605), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 522), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07898675028522285), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 701), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00029935036179329474), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025855199373628818), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07318214029709554), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 520), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 8.369967223525454e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030512507137345428), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.4484432186195195e-05), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OOD TEST ON 1



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 90), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00036941418309087464), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05178197751133478), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1190), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 639), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1688), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04213366833835316), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 404), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.1200688201979395e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1846), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0593195999418197), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07675445830417607), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 119), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09843537539052484), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1938), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0007684702587014306), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09900625117806384), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 393), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0004834646256321465), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05933587604904638), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 161), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 83), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08881611114737507), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1975), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.018134590832078e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03203795307253567), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 577), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05295944823500707), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 217), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0664622176026821), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 363), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 470), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01715794630883375), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1177), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.71006616411378e-05), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0399244331335335), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 184), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001415335644030793), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 813), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017562357519796172), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.060838165758801695), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 285), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.049185184701328315), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1002), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.8049957050703987e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09786906595339098), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1889), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0004572076274244886), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07482247929537425), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04359103918287353), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09912330751117687), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1966), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0008338522389231092), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04405678652062143), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 370), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OOD TEST ON 2



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01012476110519668), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 65), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.0414995756495762e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0032561508094648473), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 127), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006185201161032772), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 648), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1179), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08531573518620951), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 880), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 8.964960570318946e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 105), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035636033502860764), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04582592894797557), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 364), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0008620012710881534), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0026369013489041045), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 99), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0023207243291627493), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 58), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.958577693114751e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.390574606467376e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0023147156062120894), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 134), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.058351393766863886), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 137), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00015465701473048776), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0021906405541874847), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 56), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.716490783703775e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009519780329023408), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 213), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 70), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.9375931707724944e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06964501677278215), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04463082315623304), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 452), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 123), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02016759164419643), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 445), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.71006616411378e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05538002356513517), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 240), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017887878537152756), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019470391791502176), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 513), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.029637408325312104), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 188), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0008598203961711375), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05321773251934609), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 836), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 409), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.003946857119127379), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 73), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00020988703443180552), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1331), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 5.206337826605882e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001359572189681686), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1324), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OOD TEST ON 3



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 206), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00045806605549997536), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 480), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 139), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01353810387493122), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 97), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.034769668589043685), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1119), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.861376425553951e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06991692945397764), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.541254600438871e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03847696980019872), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00038777377648138554), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1081), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 729), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07627491460747814), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09948480499615982), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 359), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00091174515709598), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 456), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.390574606467376e-05), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1505), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1782), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05115472758336016), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1231), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08219309243751466), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 228), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 701), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.057533542677667984), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 160), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 124), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 380), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00014102146068458983), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05168402976721137), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 703), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0626403921003465), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1292), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.009934917469264995), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 589), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007673625167098906), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07105364240237387), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1215), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.315348274965384e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07240149455038915), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1505), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0008321863828806477), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0509505091510787), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1260), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])


{'CO_0': {6: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 89.01447700667201, 'test_rmse': 165.54173330894594, 'test_r2': -0.4222259075614998, 'test_pearson_r': array([-0.07188025]), 'test_pearson_p_value': array([0.39697883]), 'test_spearman_r': -0.061020124529818635, 'test_spearman_p_value': 0.47226776392610503, 'test_kendall_r': -0.09357226360975468, 'test_kendall_p_value': 0.10393804528404642, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 84.25983155283603, 'test_rmse': 160.5855775109811, 'test_r2': -0.33834063718721796, 'test_pearson_r': array([-0.07821765]), 'test_pearson_p_value': array([0.3565657]), 'test_spearman_r': -0.11196916778511007, 'test_spearman_p_value': 0.1862061804441197, 'test_kendall_r': -0.1130761290152226, 'test_kendall_p_value': 0.04939346942506421, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1209, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 80.54229883280881, 'test_rmse': 159.34404219984876, 'test_r2': -0.3177264072943238, 'test_pearson_r': array([-0.08326135]), 'test_pearson_p_value': array([0.32630754]), 'test_spearman_r': -0.0678794411676343, 'test_spearman_p_value': 0.42384302050363887, 'test_kendall_r': -0.1019629989313308, 'test_kendall_p_value': 0.07633029640956199, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 79.18510414586012, 'test_rmse': 160.44354841214962, 'test_r2': -0.33597430692938524, 'test_pearson_r': array([-0.0708041]), 'test_pearson_p_value': array([0.404103]), 'test_spearman_r': -0.07936094015482859, 'test_spearman_p_value': 0.34955804356814, 'test_kendall_r': -0.07972662564841518, 'test_kendall_p_value': 0.16600268548406472, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 332, 'regressor__learning_rate': 0.07163314216256438, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 85.58958523281508, 'test_rmse': 162.30302914597428, 'test_r2': -0.36712063959308816, 'test_pearson_r': array([-0.05026052]), 'test_pearson_p_value': array([0.55393614]), 'test_spearman_r': -0.0905086854230576, 'test_spearman_p_value': 0.28581081314992457, 'test_kendall_r': -0.09393918203560697, 'test_kendall_p_value': 0.10243890343075716, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 548, 'regressor__learning_rate': 0.0983840891517748, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 78.38391287552452, 'test_rmse': 159.87226570081074, 'test_r2': -0.3264773809959802, 'test_pearson_r': array([-0.10466815]), 'test_pearson_p_value': array([0.21675689]), 'test_spearman_r': -0.2156357505190283, 'test_spearman_p_value': 0.010227959892864246, 'test_kendall_r': -0.1882548087964605, 'test_kendall_p_value': 0.001068918668545187, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 909, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'test_mad': 59.97695622453599, 'test_ystd': 138.81078345008424, 'test_mae': 75.23426373292811, 'test_rmse': 157.51328100441853, 'test_r2': -0.28762068599950785, 'test_pearson_r': array([-0.06030904]), 'test_pearson_p_value': array([0.47745457]), 'test_spearman_r': -0.07210967561672356, 'test_spearman_p_value': 0.39546975177818033, 'test_kendall_r': -0.07114368596414804, 'test_kendall_p_value': 0.21611865650469209, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.030512507137345428, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}}, 'CO_1': {6: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 80.82503099185531, 'test_rmse': 179.68997551889504, 'test_r2': -60.6009531093763, 'test_pearson_r': array([-0.30021419]), 'test_pearson_p_value': array([0.21173223]), 'test_spearman_r': -0.005277046895867676, 'test_spearman_p_value': 0.9828942458380594, 'test_kendall_r': -0.023809945616434982, 'test_kendall_p_value': 0.8883005471633357, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 69.17908299088603, 'test_rmse': 112.24086398784354, 'test_r2': -23.034867642670587, 'test_pearson_r': array([-0.16296887]), 'test_pearson_p_value': array([0.50501636]), 'test_spearman_r': 0.0439753907988973, 'test_spearman_p_value': 0.8581287406879723, 'test_kendall_r': 0.03571491842465247, 'test_kendall_p_value': 0.8331350939013934, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1846, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 63.548464050872134, 'test_rmse': 141.37484192401809, 'test_r2': -37.13150945611649, 'test_pearson_r': array([-0.17279911]), 'test_pearson_p_value': array([0.47930023]), 'test_spearman_r': 0.32893592317575177, 'test_spearman_p_value': 0.16910490750506915, 'test_kendall_r': 0.28571934739721977, 'test_kendall_p_value': 0.09189998010732182, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.05933587604904638, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 67.48987624645677, 'test_rmse': 147.22408850339988, 'test_r2': -40.35209159258719, 'test_pearson_r': array([-0.24349253]), 'test_pearson_p_value': array([0.31512353]), 'test_spearman_r': 0.1284081411327801, 'test_spearman_p_value': 0.600350311382782, 'test_kendall_r': 0.09523978246573993, 'test_kendall_p_value': 0.5742388103830554, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.05295944823500707, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 71.67978011076377, 'test_rmse': 142.9784471792597, 'test_r2': -38.0014617941471, 'test_pearson_r': array([-0.22158819]), 'test_pearson_p_value': array([0.36191876]), 'test_spearman_r': 0.12664912550082422, 'test_spearman_p_value': 0.60539275735294, 'test_kendall_r': 0.07142983684930494, 'test_kendall_p_value': 0.6734886902336497, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1123, 'regressor__learning_rate': 0.05913781436124809, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 70.44052310443115, 'test_rmse': 129.44114290401512, 'test_r2': -30.96571407769979, 'test_pearson_r': array([-0.15100196]), 'test_pearson_p_value': array([0.53718695]), 'test_spearman_r': 0.19349171951514813, 'test_spearman_p_value': 0.4273721305986067, 'test_kendall_r': 0.19047956493147986, 'test_kendall_p_value': 0.26116596186988394, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.017562357519796172, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'test_mad': 17.112243767313018, 'test_ystd': 22.894445721077116, 'test_mae': 67.67274276806546, 'test_rmse': 149.8512513964636, 'test_r2': -41.84108692643467, 'test_pearson_r': array([-0.20800549]), 'test_pearson_p_value': array([0.39281394]), 'test_spearman_r': 0.1706245162997215, 'test_spearman_p_value': 0.4849323918293915, 'test_kendall_r': 0.13095470089039238, 'test_kendall_p_value': 0.43981704152643053, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.07482247929537425, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}}, 'CO_2': {6: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 131.36406086164814, 'test_rmse': 177.29636863125526, 'test_r2': -3.5527750995293754, 'test_pearson_r': array([-0.38085701]), 'test_pearson_p_value': array([0.00081516]), 'test_spearman_r': -0.5890291420147339, 'test_spearman_p_value': 3.381719691293357e-08, 'test_kendall_r': -0.43994354052010604, 'test_kendall_p_value': 3.337289985668062e-08, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 880, 'regressor__learning_rate': 0.08531573518620951, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 123.88515319249257, 'test_rmse': 164.22210941012642, 'test_r2': -2.906067723852033, 'test_pearson_r': array([-0.38214574]), 'test_pearson_p_value': array([0.0007798]), 'test_spearman_r': -0.5138417842571099, 'test_spearman_p_value': 2.8362867901851694e-06, 'test_kendall_r': -0.38075908815363846, 'test_kendall_p_value': 1.713706022134104e-06, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 105, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 148.13748591804713, 'test_rmse': 211.7009924516002, 'test_r2': -5.491159852576029, 'test_pearson_r': array([-0.35977666]), 'test_pearson_p_value': array([0.00164186]), 'test_spearman_r': -0.540135400970123, 'test_spearman_p_value': 6.804621697636203e-07, 'test_kendall_r': -0.3933841235555451, 'test_kendall_p_value': 7.853793612317969e-07, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 50, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 84.98271446599033, 'test_rmse': 110.51831129461601, 'test_r2': -0.7690699152675786, 'test_pearson_r': array([-0.48933407]), 'test_pearson_p_value': array([9.6782185e-06]), 'test_spearman_r': -0.5172791887142845, 'test_spearman_p_value': 2.3693484843024048e-06, 'test_kendall_r': -0.3688440931636113, 'test_kendall_p_value': 3.6414287571205307e-06, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 70, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 118.16708778619471, 'test_rmse': 156.52178490658304, 'test_r2': -2.5483471312045185, 'test_pearson_r': array([-0.37028431]), 'test_pearson_p_value': array([0.00116492]), 'test_spearman_r': -0.47233516727323666, 'test_spearman_p_value': 2.1485548029972763e-05, 'test_kendall_r': -0.3387196499734768, 'test_kendall_p_value': 2.071546046500918e-05, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 123, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 141.52609134440962, 'test_rmse': 202.1966829414992, 'test_r2': -4.921402321623826, 'test_pearson_r': array([-0.35983246]), 'test_pearson_p_value': array([0.00163892]), 'test_spearman_r': -0.5521242981012379, 'test_spearman_p_value': 3.4060289454659527e-07, 'test_kendall_r': -0.4049747138308234, 'test_kendall_p_value': 3.5375335984623113e-07, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 409, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'test_mad': 73.12898100803508, 'test_ystd': 83.09248394512653, 'test_mae': 126.45057920023206, 'test_rmse': 164.47162109079164, 'test_r2': -2.917946147713381, 'test_pearson_r': array([-0.41708306]), 'test_pearson_p_value': array([0.00021835]), 'test_spearman_r': -0.5497100734190434, 'test_spearman_p_value': 3.9238814310102617e-07, 'test_kendall_r': -0.4020051467266561, 'test_kendall_p_value': 4.3049102155309926e-07, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1324, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}}, 'CO_3': {6: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 102.02672741982924, 'test_rmse': 136.38844934049973, 'test_r2': -0.8767056094996788, 'test_pearson_r': array([-0.10908153]), 'test_pearson_p_value': array([0.60373421]), 'test_spearman_r': -0.07137489728903315, 'test_spearman_p_value': 0.7345821196813165, 'test_kendall_r': -0.04160851637805926, 'test_kendall_p_value': 0.7770915416837916, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 2000, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 13: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 96.37660015156571, 'test_rmse': 132.43679053922088, 'test_r2': -0.7695313602851506, 'test_pearson_r': array([-0.32767481]), 'test_pearson_p_value': array([0.10982018]), 'test_spearman_r': -0.22076223356059566, 'test_spearman_p_value': 0.28893814619585445, 'test_kendall_r': -0.17020456690287308, 'test_kendall_p_value': 0.2475358721968277, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 97, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 42: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 100.62923204993086, 'test_rmse': 138.71809365498441, 'test_r2': -0.9413649851966226, 'test_pearson_r': array([-0.23587971]), 'test_pearson_p_value': array([0.25632233]), 'test_spearman_r': -0.26538025967565454, 'test_spearman_p_value': 0.19980582431198043, 'test_kendall_r': -0.17715169208258216, 'test_kendall_p_value': 0.2287622253810846, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 359, 'regressor__learning_rate': 0.09948480499615982, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 69: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 101.5975179449936, 'test_rmse': 136.88874262476563, 'test_r2': -0.8904989363747073, 'test_pearson_r': array([-0.18948969]), 'test_pearson_p_value': array([0.36430089]), 'test_spearman_r': -0.1730065445158086, 'test_spearman_p_value': 0.4082316054965005, 'test_kendall_r': -0.1109560436748247, 'test_kendall_p_value': 0.4502709489546475, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1505, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 420: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 101.99802765598419, 'test_rmse': 137.33064872839094, 'test_r2': -0.9027245067878957, 'test_pearson_r': array([-0.15567053]), 'test_pearson_p_value': array([0.4574503]), 'test_spearman_r': -0.16101287684999505, 'test_spearman_p_value': 0.44196131443726194, 'test_kendall_r': -0.12157469064490933, 'test_kendall_p_value': 0.40882221866694324, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 701, 'regressor__learning_rate': 0.1, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 1234567890: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 94.26594376016448, 'test_rmse': 130.5593756112295, 'test_r2': -0.719717447850093, 'test_pearson_r': array([-0.23451784]), 'test_pearson_p_value': array([0.25915841]), 'test_spearman_r': -0.08147639551445533, 'test_spearman_p_value': 0.6986301262133261, 'test_kendall_r': -0.08683906474636381, 'test_kendall_p_value': 0.5552059518212993, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 703, 'regressor__learning_rate': 0.05168402976721137, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}, 473129: {'test_mad': 79.886624, 'test_ystd': 99.55876844075563, 'test_mae': 95.75369641917443, 'test_rmse': 129.001714260976, 'test_r2': -0.6789274575786552, 'test_pearson_r': array([-0.2166851]), 'test_pearson_p_value': array([0.2981616]), 'test_spearman_r': -0.01784721044602355, 'test_spearman_p_value': 0.9325205986701994, 'test_kendall_r': -0.010420687769563657, 'test_kendall_p_value': 0.9435591117232794, 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__natural_gradient': True, 'regressor__n_estimators': 1505, 'regressor__learning_rate': 0.07240149455038915, 'regressor__minibatch_frac': 1, 'regressor__col_sample': 1.0, 'regressor__verbose': False, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__with_mean': True, 'transformer__y scaler__with_std': True}}}, 'overall data shape': {'targets_shape': (259, 1), 'training_features_shape': (259, 522)}}
Trimer_scaler
Filename: (ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/OOD_target_Rg/KM4 Mordred_Polysize cluster/Trimer_scaler/(ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/OOD_target_Rg/KM4 Mordred_Polysize cluster/Trimer_scaler/(ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard_predictions.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/OOD_target_Rg/KM4 Mordred_Polysize cluster/Trimer_scaler/(ECFP3.count.512-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard_ClusterTruth.json
Done Saving scores!
------------------------------ 
Plotted Comparitive Cluster Scores!
______________________________ 
Plotted Parity Plots!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n05>
Subject: Job 265159: <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> in cluster <Hazel> Done

Job <NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309> was submitted from host <c205n14> by user <sdehgha2> in cluster <Hazel> at Mon Mar 10 00:17:27 2025
Job was executed on host(s) <6*c207n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Mon Mar 10 02:19:10 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Mon Mar 10 02:19:10 2025
Terminated at Tue Mar 11 02:30:16 2025
Results reported at Tue Mar 11 02:30:16 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_Rg1 (nm)_ECFP_Trimer_KM4 Mordred_Polysize cluster_20250309"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "Rg1 (nm)"                                       --representation "ECFP"                                       --regressor_type "NGB"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "KM4 Mordred_Polysize cluster" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   377455.62 sec.
    Max Memory :                                 2 GB
    Average Memory :                             2.00 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               14.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   87067 sec.
    Turnaround time :                            94369 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_202503_09/NGB_Rg1 (nm)_ECFP_Trimer_3_count_KM4 Mordred_Polysize cluster_20250309.err> for stderr output of this job.

