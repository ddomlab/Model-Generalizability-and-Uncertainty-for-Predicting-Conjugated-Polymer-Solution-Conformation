


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0109802460567415), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0020969837758933103), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 772), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.07963094943084924), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0022895860702434453), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 78), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.041134905523477525), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1233), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00043629267730113463), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009023186237044664), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 260), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0001011131249482285), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 605), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.044000951064149e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01999330482772195), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 324), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005836900750660192), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0021940322949769095), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 123), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011063918953152977), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 128), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0007556955860872822), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 337), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005552562237787177), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 2.5570903415064906e-06), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 910), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09899856540492477), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 161), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.3527825731996607e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008316337705920126), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00033713294727274784), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1257), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 5.022178456876271e-05), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1755), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.000330742351953116), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0010779712089545603), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 422), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.622871358263901e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012169984718251356), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 92), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03275686356117121), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 114), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004428245510743486), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 782), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012765093209015229), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007151706460876171), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00019894435086182535), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0010529154795411912), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0305452733593647e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0058838019757050984), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02874987427269309), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 87), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00013635839226139857), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.023526654301758338), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.3341595298297248e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004376919582167503), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 255), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00021597548253582513), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1616), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.162  0.2   -1.827]Â±[0.118 0.117 5.57 ]
[array([ 0.16191535,  0.20007001, -1.82728798]), array([7.96193294e+00, 1.41129515e+02, 9.73842071e+04]), array([5.70297662e+00, 9.54803189e+01, 1.75168093e+04])]
{6: {'fit_time': array([18.93450451, 18.94783711, 18.89892697, 18.91619658, 18.95479631]), 'score_time': array([0.56428361, 0.55845571, 0.52987409, 0.56879663, 0.55756092]), 'test_r2': [array([-0.07032963,  0.34798067, -1.20238432]), array([ 0.16904386,  0.05522129, -0.01647937]), array([0.16936163, 0.22336958, 0.52184132]), array([ 0.2745933 ,  0.14656815, -1.90065666]), array([ 0.16753961,  0.24611325, -3.50054142])], 'test_rmse': [array([6.70129278e+00, 1.15077049e+02, 2.54798191e+04]), array([7.97759334e+00, 1.32874457e+02, 3.36847925e+05]), array([8.04177803e+00, 1.63252542e+02, 1.66210889e+04]), array([8.21010000e+00, 1.54176191e+02, 2.20321293e+04]), array([8.74939620e+00, 1.40032199e+02, 4.15946933e+04])], 'test_mae': [array([4.98503136e+00, 8.35366309e+01, 8.58485966e+03]), array([6.00633273e+00, 9.11024270e+01, 5.48520501e+04]), array([5.55229010e+00, 1.07779969e+02, 5.61702886e+03]), array([5.79571734e+00, 9.80020464e+01, 7.91417478e+03]), array([6.40132998e+00, 9.80725935e+01, 1.03291701e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 772, 'regressor__estimator__learning_rate': 0.0020969837758933103, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([5.97443342, 5.96777463, 6.01317358, 5.9797461 , 5.87218451]), 'score_time': array([0.18684363, 0.19534111, 0.18893456, 0.19211745, 0.18823457]), 'test_r2': [array([  0.25143895,   0.22594137, -31.19761503]), array([0.27588798, 0.3349762 , 0.56646501]), array([0.12702965, 0.18676487, 0.0514097 ]), array([-0.05778153,  0.24632801,  0.00439076]), array([0.22530434, 0.17863789, 0.7216144 ])], 'test_rmse': [array([8.49245623e+00, 1.59569018e+02, 4.97390109e+04]), array([7.61008599e+00, 1.31800428e+02, 1.82092615e+04]), array([8.87686595e+00, 1.35743271e+02, 9.11635789e+04]), array([6.62586961e+00, 1.34373618e+02, 3.21584370e+05]), array([7.69898462e+00, 1.31112212e+02, 7.80496116e+03])], 'test_mae': [array([5.74762107e+00, 9.83833958e+01, 1.35132442e+04]), array([5.43986947e+00, 8.96469270e+01, 6.76157072e+03]), array([6.31112862e+00, 9.19721707e+01, 1.37800896e+04]), array([4.87738654e+00, 8.71733627e+01, 4.46064914e+04]), array([   5.42131209,   96.75710785, 4513.56835399])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 260, 'regressor__estimator__learning_rate': 0.009023186237044664, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([3.01817536, 3.06110954, 2.99845624, 3.01777911, 3.03324866]), 'score_time': array([0.10238075, 0.10550547, 0.10425806, 0.10527182, 0.10298586]), 'test_r2': [array([0.21989928, 0.04170616, 0.25229896]), array([0.1418746 , 0.25085213, 0.313652  ]), array([ 0.17759555,  0.1207445 , -0.01202532]), array([ 0.13109172,  0.30537822, -2.67593909]), array([ 0.07128129,  0.2625993 , -0.63182972])], 'test_rmse': [array([7.96277101e+00, 1.52078048e+02, 2.02805130e+04]), array([8.06026421e+00, 1.44390064e+02, 4.96142262e+04]), array([5.87707456e+00, 1.53111355e+02, 3.31873091e+05]), array([9.50743994e+00, 1.46989465e+02, 2.64514795e+04]), array([8.64456480e+00, 1.15330263e+02, 2.48861618e+04])], 'test_mae': [array([6.04358494e+00, 1.08994338e+02, 8.37409613e+03]), array([5.78749584e+00, 9.09474026e+01, 9.68208144e+03]), array([4.75912440e+00, 1.10514077e+02, 4.95844453e+04]), array([6.61568857e+00, 9.51281906e+01, 9.68702088e+03]), array([6.42913692e+00, 7.85050292e+01, 8.79944304e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 128, 'regressor__estimator__learning_rate': 0.011063918953152977, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([30.54633236, 30.03639174, 29.6937964 , 30.17622852, 30.65348172]), 'score_time': array([0.90634918, 0.87657857, 0.85445142, 0.87148857, 0.88233352]), 'test_r2': [array([ 2.01669494e-02,  2.21239322e-01, -1.26997207e-05]), array([0.12060344, 0.01688047, 0.0204272 ]), array([-0.04871701,  0.20652626,  0.4302799 ]), array([0.04287266, 0.00323464, 0.31684655]), array([ 0.1255223 ,  0.08071541, -2.28323694])], 'test_rmse': [array([7.80583482e+00, 1.45224706e+02, 3.22056647e+05]), array([7.98113038e+00, 1.53062636e+02, 9.25795836e+04]), array([1.04072231e+01, 1.31696586e+02, 2.36338669e+04]), array([9.17189459e+00, 1.55164776e+02, 1.06840477e+04]), array([7.34036011e+00, 1.67608840e+02, 2.12727064e+04])], 'test_mae': [array([6.14938270e+00, 1.06212506e+02, 4.52473356e+04]), array([6.10651657e+00, 1.09603305e+02, 1.85225762e+04]), array([7.29035901e+00, 9.32075038e+01, 1.24803431e+04]), array([6.77512483e+00, 1.06013773e+02, 8.75183798e+03]), array([6.04896785e+00, 1.04974437e+02, 1.25276048e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1257, 'regressor__estimator__learning_rate': 0.00033713294727274784, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([19.03785443, 19.01037669, 18.99965191, 18.97113657, 19.32507467]), 'score_time': array([0.56848288, 0.56183076, 0.55916643, 0.58248615, 0.53865862]), 'test_r2': [array([  0.12497858,   0.16041088, -12.79191915]), array([0.34929809, 0.42773127, 0.11576063]), array([ 0.46852834,  0.29390362, -0.59828056]), array([0.0860859 , 0.26125519, 0.00329419]), array([ 0.11686408,  0.00369844, -2.24157109])], 'test_rmse': [array([8.26267021e+00, 1.52569181e+02, 5.87085508e+04]), array([7.93717623e+00, 9.41488643e+01, 9.12232091e+04]), array([6.55529080e+00, 1.41662725e+02, 9.41496445e+03]), array([7.96780452e+00, 1.69931760e+02, 3.21461409e+05]), array([7.55844904e+00, 1.29770131e+02, 4.11879222e+04])], 'test_mae': [array([5.84002257e+00, 9.36024921e+01, 1.30227649e+04]), array([5.26286610e+00, 7.38625348e+01, 1.48679056e+04]), array([   4.65628483,  100.39422908, 4648.89688208]), array([5.31676765e+00, 1.08490276e+02, 4.24250342e+04]), array([5.51321923e+00, 9.08726116e+01, 1.30735523e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 782, 'regressor__estimator__learning_rate': 0.004428245510743486, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([1.1844275 , 1.18811131, 1.15482187, 1.17005134, 1.16532969]), 'score_time': array([0.05328536, 0.05147409, 0.04883671, 0.05140686, 0.0526216 ]), 'test_r2': [array([-2.30742272e-03,  2.36456231e-01, -4.11982507e+00]), array([ 0.30640575, -0.05354022,  0.00085835]), array([ 0.27933196,  0.46222691, -3.11462938]), array([ 0.03939942,  0.25512734, -1.21667519]), array([0.25982124, 0.06549521, 0.00098663])], 'test_rmse': [array([7.52295705e+00, 1.64017497e+02, 7.23422413e+04]), array([7.49065793e+00, 1.38124505e+02, 9.33050202e+04]), array([7.72148106e+00, 9.67895983e+01, 1.88472576e+04]), array([7.95436664e+00, 1.61623855e+02, 1.87992113e+04]), array([8.91898307e+00, 1.38867185e+02, 3.23776430e+05])], 'test_mae': [array([5.34121096e+00, 9.85762883e+01, 1.55589014e+04]), array([5.01643620e+00, 9.54021158e+01, 1.45689596e+04]), array([5.17028750e+00, 6.81611681e+01, 6.10412067e+03]), array([5.37455307e+00, 1.09201441e+02, 6.31672025e+03]), array([5.96648938e+00, 8.95717895e+01, 4.43227548e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([2.29112053, 2.3797183 , 2.21280026, 2.35639858, 2.27990246]), 'score_time': array([0.08948684, 0.0929234 , 0.08393669, 0.09284067, 0.08650208]), 'test_r2': [array([0.14511282, 0.27052538, 0.39673977]), array([0.2402985 , 0.20783857, 0.05107603]), array([ 0.22463205,  0.30196827, -0.02544688]), array([ 0.27396487,  0.18059749, -0.56689575]), array([0.22034422, 0.2269779 , 0.3729429 ])], 'test_rmse': [array([8.21410099e+00, 1.11192954e+02, 1.92041329e+04]), array([6.97917927e+00, 1.48745943e+02, 9.05523036e+04]), array([7.92692765e+00, 1.30968861e+02, 3.22081493e+05]), array([8.00498435e+00, 1.77586390e+02, 2.74463206e+04]), array([7.90964396e+00, 1.20865866e+02, 4.56876214e+04])], 'test_mae': [array([5.53779332e+00, 8.25059410e+01, 6.70577517e+03]), array([4.87961764e+00, 9.02089320e+01, 1.23917840e+04]), array([5.65574134e+00, 9.26449703e+01, 4.58583492e+04]), array([5.69505799e+00, 1.10368540e+02, 1.07176060e+04]), array([5.83443300e+00, 9.14206386e+01, 8.37616706e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 87, 'regressor__estimator__learning_rate': 0.02874987427269309, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([ 0.16191535,  0.20007001, -1.82728798]), 'r2_stdev': array([0.11795141, 0.11741876, 5.57002526]), 'rmse_avg': array([7.96193294e+00, 1.41129515e+02, 9.73842071e+04]), 'rmse_stdev': array([8.46773017e-01, 1.93820453e+01, 1.16929318e+05]), 'mae_avg': array([5.70297662e+00, 9.54803189e+01, 1.75168093e+04]), 'mae_stdev': array([5.88829807e-01, 1.04154383e+01, 1.50345878e+04]), 'r2_avg_aggregate': -0.48843420755485134, 'r2_stdev_aggregate': 1.9351318078097854, 'rmse_avg_aggregate': 32511.099517958635, 'rmse_stdev_aggregate': 38983.18217876816, 'mae_avg_aggregate': 5872.664186124953, 'mae_stdev_aggregate': 5015.197345857078}
scaler
Filename: (PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c035n03>
Subject: Job 269010: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250117> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250117> was submitted from host <c039n02> by user <sdehgha2> in cluster <Hazel> at Fri Jan 17 14:31:43 2025
Job was executed on host(s) <6*c035n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri Jan 17 14:31:43 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri Jan 17 14:31:43 2025
Terminated at Fri Jan 17 23:51:37 2025
Results reported at Fri Jan 17 23:51:37 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 40:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250117"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250117.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250117.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   155229.17 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.73 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   33598 sec.
    Turnaround time :                            33594 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250117.err> for stderr output of this job.

