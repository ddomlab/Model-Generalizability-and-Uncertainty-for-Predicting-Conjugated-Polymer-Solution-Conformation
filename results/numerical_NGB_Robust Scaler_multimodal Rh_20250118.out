


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006293285132606745), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0019299371422440176), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0006945210416982247), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006337228717085522), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007730546794225013), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009311314933113139), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007051857921767076), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00024601821037749654), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1066), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003230273564236901), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011795190257167065), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0008327518720539275), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 651), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0838499106941783), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 72), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01537948446580078), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 153), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00039118639884156683), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005770558888648424), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 439), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00012445436422126515), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01537948446580078), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 153), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00039118639884156683), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05081673009521831), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.4373782983422386e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011081935097528759), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 345), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007965804475801358), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 284), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0001607339300888757), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016197054027412608), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007988774334633427), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 198), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 8.325050638370811e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007912979913366548), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 331), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 9.924240724304398e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007999931041466244), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 143), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00011140257518337417), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 74), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017178860709572523), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 188), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00021115781335286985), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.021929209354836807), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 108), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00032153647571461097), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016777818834616674), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 184), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00020155244384548312), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015615447853643903), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 137), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0002965123485508191), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003171247995408755), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 762), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004371484582007536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.809955146978886e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04288736349697456), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.078017589319869e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0035621679223858), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 814), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012109604118873837), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 414), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.7140680574906867e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0024725594645105945), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.447026197540174e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04233217598827874), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 96), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00012543547548899276), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01311522872313837), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 110), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00865318187303269), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 478), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [-0.916 -0.322 -1.888]Â±[1.615 0.34  7.779]
[array([-0.91553991, -0.32206655, -1.88773109]), array([1.15945493e+01, 1.80910961e+02, 1.00179650e+05]), array([6.54491524e+00, 1.02140730e+02, 1.47180986e+04])]
{6: {'fit_time': array([54.78688788, 54.06029844, 53.97609329, 53.9999845 , 54.28683877]), 'score_time': array([1.89600182, 1.87803888, 1.94176459, 2.05519748, 1.92200875]), 'test_r2': [array([-0.50686357, -0.25371544, -0.0329713 ]), array([-0.24200134, -0.37502321, -0.02609173]), array([ -0.34547029,  -0.02229031, -18.01238506]), array([-0.45926598, -0.23842456, -0.05995348]), array([-0.900135  , -0.30527679, -0.0599864 ])], 'test_rmse': [array([7.95127520e+00, 1.59572471e+02, 1.74499390e+04]), array([9.75312695e+00, 1.60299242e+02, 3.38436883e+05]), array([1.02348891e+01, 1.87300905e+02, 1.04807352e+05]), array([1.16446086e+01, 1.85723846e+02, 1.33183895e+04]), array([1.32186932e+01, 1.84257918e+02, 2.01862520e+04])], 'test_mae': [array([   4.61174304,   95.5499382 , 3900.52362629]), array([5.45438454e+00, 9.33063771e+01, 5.37359309e+04]), array([5.83270630e+00, 1.10825806e+02, 1.28821515e+04]), array([   6.76509913,   97.50864006, 3375.9444261 ]), array([   9.01495538,  108.94324941, 4786.06324214])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.0019299371422440176, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([2.08790874, 2.04775047, 2.07094908, 2.09589911, 2.06004596]), 'score_time': array([0.09729576, 0.09787893, 0.10035968, 0.09472108, 0.09791231]), 'test_r2': [array([-0.40202904, -0.47718237,  0.18978411]), array([-0.47292973, -0.06273302,  0.59622731]), array([-0.56092637, -0.27322894, -0.0213    ]), array([-0.30602125,  0.00541562, -0.02007912]), array([-8.56351044, -0.34709863, -4.67302092])], 'test_rmse': [array([  11.62246404,  220.43406088, 7890.15747214]), array([1.08536972e+01, 1.66613549e+02, 1.75731141e+04]), array([1.18700110e+01, 1.69849196e+02, 9.45929335e+04]), array([7.36241032e+00, 1.54363153e+02, 3.25512298e+05]), array([2.70505786e+01, 1.67909593e+02, 3.52334001e+04])], 'test_mae': [array([   6.94007879,  130.00472513, 1930.51883327]), array([   6.48359085,  103.31457348, 4005.61474307]), array([7.41701021e+00, 7.91085946e+01, 1.38014446e+04]), array([4.22899684e+00, 8.75889186e+01, 4.58389541e+04]), array([   8.45967942,  103.4778156 , 6419.3253683 ])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 72, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([9.22348595, 9.28470707, 9.35314584, 9.73490047, 9.26596904]), 'score_time': array([0.33457375, 0.33369064, 0.35011792, 0.36813736, 0.39032507]), 'test_r2': [array([-0.49895559, -0.35859273,  0.06567017]), array([-0.68068993, -0.21282336, -0.0298694 ]), array([-0.16533339, -0.22744795, -0.02149962]), array([-0.53008716, -0.06148876, -0.03480857]), array([-0.53236584, -0.34227758,  0.09276319])], 'test_rmse': [array([1.10378191e+01, 1.81076389e+02, 2.26707062e+04]), array([1.12802233e+01, 1.83718255e+02, 6.07750202e+04]), array([6.99589961e+00, 1.80905342e+02, 3.33422924e+05]), array([1.26163785e+01, 1.81706186e+02, 1.40344638e+04]), array([1.11040720e+01, 1.55601104e+02, 1.85558492e+04])], 'test_mae': [array([   6.78564657,  104.72992457, 4283.95041085]), array([7.22062016e+00, 9.67696639e+01, 1.02798810e+04]), array([3.77324045e+00, 1.00359818e+02, 4.82207711e+04]), array([   7.56958348,   95.35856445, 2988.35036066]), array([   6.58272048,   98.98566527, 3565.04917537])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 345, 'regressor__estimator__learning_rate': 0.011081935097528759, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([9.05353546, 9.17244291, 9.15101814, 9.25187445, 9.19657588]), 'score_time': array([0.32169175, 0.36440492, 0.32462955, 0.33524346, 0.36086273]), 'test_r2': [array([-0.37686829, -0.30576652, -0.01930764]), array([-0.40920939, -0.46233623, -0.02159464]), array([-0.74569869, -0.26207974,  0.02676369]), array([-0.51171337, -0.53271224, -0.03100433]), array([-0.60475156, -0.18469494, -0.03523351])], 'test_rmse': [array([9.25314811e+00, 1.88049102e+02, 3.25148795e+05]), array([1.01032195e+01, 1.86676499e+02, 9.45444778e+04]), array([1.34273513e+01, 1.66093117e+02, 3.08896626e+04]), array([1.15268043e+01, 1.92409709e+02, 1.31252303e+04]), array([9.94367452e+00, 1.90272137e+02, 1.19451276e+04])], 'test_mae': [array([5.18518533e+00, 1.11589649e+02, 4.48148926e+04]), array([5.80548050e+00, 1.11242403e+02, 1.37957938e+04]), array([   8.71744073,   97.38004695, 6098.91607426]), array([   6.77511776,  114.85821868, 2621.79462035]), array([   6.26906104,   91.85416073, 2236.12909512])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 331, 'regressor__estimator__learning_rate': 0.007912979913366548, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([2.08945632, 2.21015215, 2.12577844, 2.10525274, 2.16806817]), 'score_time': array([0.10044909, 0.09480453, 0.10160613, 0.09720182, 0.09539318]), 'test_r2': [array([-0.80519398, -0.33810715, -0.05087552]), array([-0.10164828, -0.06539175, -0.02668939]), array([-1.39834151, -0.00820391, -0.07484746]), array([-0.95198239, -0.04580518, -0.0172328 ]), array([-6.01453352, -1.09229355, -0.03204784])], 'test_rmse': [array([1.18678764e+01, 1.92610012e+02, 1.62055825e+04]), array([1.03275299e+01, 1.28460540e+02, 9.82969312e+04]), array([  13.92539172,  169.27693569, 7720.85851394]), array([1.16445827e+01, 2.02186768e+02, 3.24754762e+05]), array([2.13018985e+01, 1.88057495e+02, 2.32403157e+04])], 'test_mae': [array([   7.71763453,   97.55602885, 3640.48466526]), array([5.27077481e+00, 8.72746667e+01, 1.63168236e+04]), array([   7.84472753,   95.97098016, 2157.19524341]), array([6.75787153e+00, 1.06184837e+02, 4.22379485e+04]), array([   7.10451324,  107.42599372, 5728.17600575])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 74, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([21.00592327, 21.04639316, 21.16496158, 21.69938922, 21.38044739]), 'score_time': array([0.71889162, 0.75231981, 0.74634123, 0.75712609, 0.72786069]), 'test_r2': [array([-0.62896925, -0.23970171, -0.04632025]), array([-0.52844076, -0.37317462, -0.0165087 ]), array([-0.4102906 , -0.38604213,  0.03467433]), array([-0.61111955, -0.29378867, -0.03485422]), array([-0.52141728, -0.28876178, -0.02009511])], 'test_rmse': [array([9.59057293e+00, 2.08993035e+02, 3.27036867e+04]), array([1.11196605e+01, 1.57691418e+02, 9.41124391e+04]), array([  10.80158   ,  155.38796081, 9128.92696871]), array([1.03014431e+01, 2.13008098e+02, 1.28448249e+04]), array([1.27870747e+01, 1.63077930e+02, 3.27174850e+05])], 'test_mae': [array([6.25641664e+00, 1.17782285e+02, 7.47025934e+03]), array([6.74623583e+00, 8.87787887e+01, 1.19994368e+04]), array([   5.92485198,  101.10006226, 2023.83574851]), array([   6.48442167,  121.64315604, 2445.61019176]), array([7.47105450e+00, 8.54108864e+01, 4.61926443e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 762, 'regressor__estimator__learning_rate': 0.003171247995408755, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([12.8449955 , 12.76745367, 12.94727349, 13.01432538, 12.87244225]), 'score_time': array([0.44549775, 0.45948768, 0.47555184, 0.47120786, 0.4873414 ]), 'test_r2': [array([ -0.44751753,  -0.32003042, -43.54344108]), array([-0.44297661, -0.23865462, -0.01397642]), array([-0.42236071, -0.16917646, -0.01565517]), array([-0.40001241, -1.95127143, -0.06860581]), array([-0.54426632, -0.16214814, -0.01621562])], 'test_rmse': [array([1.06885194e+01, 1.49576769e+02, 1.65019109e+05]), array([9.61861426e+00, 1.86000193e+02, 9.36047140e+04]), array([1.07363299e+01, 1.69500312e+02, 3.20540071e+05]), array([1.11159763e+01, 3.37027711e+02, 2.26658937e+04]), array([1.11318304e+01, 1.48196674e+02, 5.81618132e+04])], 'test_mae': [array([6.75131118e+00, 9.47044206e+01, 2.01464494e+04]), array([5.46097200e+00, 1.04691599e+02, 1.09752249e+04]), array([6.17572400e+00, 9.00829304e+01, 3.97189652e+04]), array([   6.22675622,  156.785233  , 6071.89475941]), array([6.98642680e+00, 8.67769458e+01, 8.42650357e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 478, 'regressor__estimator__learning_rate': 0.00865318187303269, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([-0.91553991, -0.32206655, -1.88773109]), 'r2_stdev': array([1.61473169, 0.3398882 , 7.77915224]), 'rmse_avg': array([1.15945493e+01, 1.80910961e+02, 1.00179650e+05]), 'rmse_stdev': array([3.50686038e+00, 3.30911323e+01, 1.19447162e+05]), 'mae_avg': array([6.54491524e+00, 1.02140730e+02, 1.47180986e+04]), 'mae_stdev': array([1.14757519e+00, 1.43244160e+01, 1.62560030e+04]), 'r2_avg_aggregate': -1.041779185061115, 'r2_stdev_aggregate': 3.2445907142485217, 'rmse_avg_aggregate': 33457.38521218248, 'rmse_stdev_aggregate': 39827.91991453622, 'mae_avg_aggregate': 4942.261423847927, 'mae_stdev_aggregate': 5423.825013072696}
scaler
Filename: (PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n11>
Subject: Job 275243: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250118> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250118> was submitted from host <c028n01> by user <sdehgha2> in cluster <Hazel> at Sat Jan 18 17:11:05 2025
Job was executed on host(s) <6*c202n11>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sat Jan 18 17:11:05 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sat Jan 18 17:11:05 2025
Terminated at Sun Jan 19 01:37:04 2025
Results reported at Sun Jan 19 01:37:04 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250118"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250118.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250118.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   135855.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.80 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   30365 sec.
    Turnaround time :                            30359 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250118.err> for stderr output of this job.

