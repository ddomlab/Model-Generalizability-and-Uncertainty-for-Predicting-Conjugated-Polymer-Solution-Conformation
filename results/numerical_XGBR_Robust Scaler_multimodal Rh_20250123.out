
------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n07>
Subject: Job 315465: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c037n01> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:13:27 2025
Job was executed on host(s) <6*c200n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:13:29 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:13:29 2025
Terminated at Thu Jan 23 14:13:35 2025
Results reported at Thu Jan 23 14:13:35 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' "concentration" "temperature" "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "concentration" "temperature"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4.25 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   14 sec.
    Turnaround time :                            8 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n03>
Subject: Job 315472: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c037n01> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:14:42 2025
Job was executed on host(s) <6*c200n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:14:43 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:14:43 2025
Terminated at Thu Jan 23 14:14:50 2025
Results reported at Thu Jan 23 14:14:50 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' "concentration" "temperature" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "concentration" "temperature"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4.19 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   9 sec.
    Turnaround time :                            8 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n10>
Subject: Job 315481: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c200n03> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:16:15 2025
Job was executed on host(s) <6*c200n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:16:16 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:16:16 2025
Terminated at Thu Jan 23 14:16:23 2025
Results reported at Thu Jan 23 14:16:23 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' "concentration" "temperature"                                     --columns_to_impute "PDI" "concentration" "temperature"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4.81 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   19 sec.
    Turnaround time :                            8 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002580106893630506), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 381), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008276743289927412), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014257041503689349), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 119), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03168869946382142), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010386752223198053), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004793792994072043), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 225), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01806242693514321), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.018310558599648405), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003844316875035001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 203), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003434574718834613), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 189), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008220913353979597), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009856207929534361), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 89), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014313136340626248), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 62), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03962995209800703), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0015277309410115193), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 454), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 380), ('regressor__regressor__estimator__n_estimators', 204), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02896928158918152), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 84), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00451904536210184), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 70), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.023819609799180484), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0142682559263522), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 72), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01717331228663675), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016068358109623915), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 66), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002523240329816278), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 229), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01247946945752369), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 90), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004193341728834456), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 164), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019001394051387475), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 113), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02142467468373836), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03297550808151503), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 74), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0165615021341916), ('regressor__regressor__estimator__max_depth', 1294), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012113123258497427), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017302177520157582), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 123), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02374941781850542), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02376294290573879), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016439649367825035), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.027173751784028557), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [0.056 0.02  0.184]±[0.109 0.103 0.366]
[array([0.05563705, 0.02017541, 0.18405956]), array([8.45490389e+00, 1.56184291e+02, 8.71586247e+04]), array([6.30091863e+00, 1.05618683e+02, 1.69230504e+04])]
scaler
Filename: (concentration-temperature)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(concentration-temperature)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(concentration-temperature)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(concentration-temperature)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c012n03>
Subject: Job 315527: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c202n06> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:32:08 2025
Job was executed on host(s) <6*c012n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:35:01 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:35:01 2025
Terminated at Thu Jan 23 15:04:13 2025
Results reported at Thu Jan 23 15:04:13 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)"                                     --columns_to_impute "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4443.07 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.10 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   1756 sec.
    Turnaround time :                            1925 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012706802474126927), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 98), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 550), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012184269350370566), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 75), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013350348255474352), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 102), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011946564446124685), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 91), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0026679563844527396), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 60), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007653748652334875), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0025056505901214993), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 109), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011867450821009464), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 104), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0014234877840353178), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004694441979466593), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0015738768093244769), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012749684138682168), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 136), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 84), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0026387166211330393), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012367577216822628), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 91), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 217), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0017911422735800442), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 76), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004898514714346864), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 138), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00756804042471949), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0070382698276372935), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002541409188909871), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 113), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003234754415548537), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0017592651253041489), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 163), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011253308477431636), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011517399618439603), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001980128733684795), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [ 0.029  0.101 -0.929]±[0.075 0.073 1.572]
[array([ 0.02910476,  0.10069118, -0.92921653]), array([8.59264380e+00, 1.50014999e+02, 9.61852002e+04]), array([6.51143189e+00, 1.03420263e+02, 2.44428348e+04])]
scaler
Filename: (polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c003n02>
Subject: Job 315534: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c013n04> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:37:23 2025
Job was executed on host(s) <6*c003n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:37:25 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:37:25 2025
Terminated at Thu Jan 23 15:06:04 2025
Results reported at Thu Jan 23 15:06:04 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH" 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3559.00 sec.
    Max Memory :                                 5 GB
    Average Memory :                             4.47 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               11.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   1729 sec.
    Turnaround time :                            1721 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01279761025495901), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 78), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002571980301255375), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 325), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02124837674448969), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020796270853499495), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 85), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010313642735228197), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0034366532454480686), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 364), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007058515933380566), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 129), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02078643979248797), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006430320336334554), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 126), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0021185956111061588), ('regressor__regressor__estimator__max_depth', 11), ('regressor__regressor__estimator__n_estimators', 328), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005963494946045504), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 75), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014718788418995743), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006403660075204093), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 120), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.033817978340255926), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009105866545879159), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 83), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 190), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03764539421290884), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004078152302168805), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 86), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001763173426040344), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 725), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006989610308924164), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 110), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007713027823241479), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 131), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017407801006554362), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 82), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001403610324317572), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 445), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0057028510080954645), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 238), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013274725723493397), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04126926031004745), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014375420703315994), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03176743888995586), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006504968559531981), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 130), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0022232759927460744), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 257), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02547431251318529), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020722960364473558), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02608523582827256), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011518579955227353), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.026632163922572182), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [0.159 0.101 0.189]±[0.079 0.093 0.314]
[array([0.15869357, 0.10061618, 0.18892973]), array([8.00902304e+00, 1.49766862e+02, 8.85198599e+04]), array([5.60803330e+00, 9.75325322e+01, 1.75862244e+04])]
scaler
Filename: (PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c003n04>
Subject: Job 315511: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c006n04> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:28:39 2025
Job was executed on host(s) <6*c003n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:28:40 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:28:40 2025
Terminated at Thu Jan 23 15:07:49 2025
Results reported at Thu Jan 23 15:07:49 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats  'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6555.52 sec.
    Max Memory :                                 10 GB
    Average Memory :                             9.41 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               6.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   2352 sec.
    Turnaround time :                            2350 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01279761025495901), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 78), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002571980301255375), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 325), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02124837674448969), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020796270853499495), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 85), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010313642735228197), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0034366532454480686), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 364), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007058515933380566), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 129), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02078643979248797), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006430320336334554), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 126), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0021185956111061588), ('regressor__regressor__estimator__max_depth', 11), ('regressor__regressor__estimator__n_estimators', 328), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005963494946045504), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 75), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014718788418995743), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006403660075204093), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 120), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.033817978340255926), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009105866545879159), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 83), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 190), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03764539421290884), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004078152302168805), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 86), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001763173426040344), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 725), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006989610308924164), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 110), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007713027823241479), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 131), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017407801006554362), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 82), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001403610324317572), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 445), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0057028510080954645), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 238), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013274725723493397), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04126926031004745), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014375420703315994), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03176743888995586), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006504968559531981), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 130), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0022232759927460744), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 257), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02547431251318529), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020722960364473558), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02608523582827256), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011518579955227353), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.026632163922572182), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [0.159 0.101 0.189]±[0.079 0.093 0.314]
[array([0.15869357, 0.10061618, 0.18892973]), array([8.00902304e+00, 1.49766862e+02, 8.85198599e+04]), array([5.60803330e+00, 9.75325322e+01, 1.75862244e+04])]
scaler
Filename: (PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c007n04>
Subject: Job 315515: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c007n04> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:29:18 2025
Job was executed on host(s) <6*c007n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:30:17 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:30:17 2025
Terminated at Thu Jan 23 15:09:05 2025
Results reported at Thu Jan 23 15:09:05 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats  'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6522.22 sec.
    Max Memory :                                 10 GB
    Average Memory :                             9.49 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               6.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   2351 sec.
    Turnaround time :                            2387 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0015127454335927104), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 606), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01575511497336293), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016443217970830336), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 113), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.041793220280629706), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01769818000813142), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 91), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00485809541835891), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 74), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 35), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004896661458256314), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 202), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009767876571281931), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007767433318949824), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 87), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014495550529786667), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01697810361496088), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005511041398295211), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 132), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03874653730691624), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00917148266117474), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004095839483284779), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 68), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013295378357161526), ('regressor__regressor__estimator__max_depth', 23), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 404), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01930051282055277), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 81), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01728463523480272), ('regressor__regressor__estimator__max_depth', 26), ('regressor__regressor__estimator__n_estimators', 51), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009683577351655766), ('regressor__regressor__estimator__max_depth', 16), ('regressor__regressor__estimator__n_estimators', 97), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013293832389114149), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 95), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003287869762409934), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 134), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014751682040555129), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 75), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0025534291649726764), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02810643633902221), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013598608651962179), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019056582945491247), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013954695043446552), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 62), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013730416901686528), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006898781429737519), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 374), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008740560028487542), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 103), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011534052617755572), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 147), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01223058048344878), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012156797411110101), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 1205), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [0.137 0.237 0.058]±[0.096 0.107 0.344]
[array([0.13653855, 0.23683804, 0.05772712]), array([8.10711431e+00, 1.37799751e+02, 8.87083187e+04]), array([5.52608578e+00, 8.92906546e+01, 1.76408341e+04])]
scaler
Filename: (PDI-Mw-concentration-temperature-Ra)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-Ra)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-Ra)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-Ra)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n04>
Subject: Job 315504: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c202n11> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:23:42 2025
Job was executed on host(s) <6*c023n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:28:28 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:28:28 2025
Terminated at Thu Jan 23 15:12:14 2025
Results reported at Thu Jan 23 15:12:14 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats  'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)" "Ra"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7808.00 sec.
    Max Memory :                                 11 GB
    Average Memory :                             10.30 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               5.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   2626 sec.
    Turnaround time :                            2912 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013153118866374228), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012339241251701977), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 193), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013857940808585294), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 349), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0029520225599482673), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 79), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01242150861468852), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004568518519416382), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 85), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004709259316138182), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001277078135341464), ('regressor__regressor__estimator__max_depth', 11), ('regressor__regressor__estimator__n_estimators', 99), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007880065141125313), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0014481450640132618), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0035097421599713267), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003211108440081694), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 81), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002479858846586536), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 89), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00111844213519507), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013832102351323693), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 266), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 1109), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 177), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0019719363035948824), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 59), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003499995422112493), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 67), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 150), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0030355471242929895), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0028855731235207997), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 62), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003144778192226898), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 66), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 167), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [ 0.021  0.041 -0.885]±[0.082 0.044 1.705]
[array([ 0.02140212,  0.04069137, -0.88475936]), array([8.62211315e+00, 1.55021065e+02, 9.64360430e+04]), array([6.58354545e+00, 1.06065574e+02, 2.49423303e+04])]
scaler
Filename: (polymer dP-polymer dD-polymer dH)_XGBR_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(polymer dP-polymer dD-polymer dH)_XGBR_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(polymer dP-polymer dD-polymer dH)_XGBR_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(polymer dP-polymer dD-polymer dH)_XGBR_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n04>
Subject: Job 315549: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c040n02> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:40:52 2025
Job was executed on host(s) <6*c023n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:49:54 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:49:54 2025
Terminated at Thu Jan 23 15:14:04 2025
Results reported at Thu Jan 23 15:14:04 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats "polymer dP" "polymer dD" "polymer dH" 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2556.58 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.76 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   1461 sec.
    Turnaround time :                            1992 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0018616987677922783), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 89), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0038811577623623678), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 245), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0024937044243035374), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 66), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011115849110619456), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 123), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003134822978096909), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 69), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00114357926164308), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 610), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004865919753443869), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 123), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001247473523743299), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 220), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00636405384434675), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 96), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0049428428130263175), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0014203565866659983), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 68), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013959208121110643), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016388145422940382), ('regressor__regressor__estimator__max_depth', 764), ('regressor__regressor__estimator__n_estimators', 107), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013310061623156677), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 86), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001230606444663539), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0025811738213609484), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 115), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009504546321775676), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 108), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 182), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0010865815841622647), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 219), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001844998430390193), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 579), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 140), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016617887169395888), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [ 0.027  0.097 -0.887]±[0.084 0.094 1.363]
[array([ 0.0269636 ,  0.09740631, -0.88718759]), array([8.59807763e+00, 1.50078178e+02, 9.70293139e+04]), array([6.59757156e+00, 1.04142877e+02, 2.57068155e+04])]
scaler
Filename: (solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(solvent dP-solvent dD-solvent dH)_XGBR_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n06>
Subject: Job 315540: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c007n03> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:38:14 2025
Job was executed on host(s) <6*c202n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:40:29 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:40:29 2025
Terminated at Thu Jan 23 15:15:44 2025
Results reported at Thu Jan 23 15:15:44 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats "solvent dP" "solvent dD" "solvent dH" 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4448.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.93 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               13.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   2130 sec.
    Turnaround time :                            2250 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014999903805735022), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 64), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020462064681478632), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014882761896936849), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 99), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02751415246041816), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0100959691437111), ('regressor__regressor__estimator__max_depth', 1786), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008838557914332426), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 186), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.022251422010843267), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02106063330337058), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012901203123972018), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 60), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0023564492007914937), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 281), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006244344992693491), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012450373951521057), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 71), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00860908230601596), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 102), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0670159622519988), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0058030518548600404), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 128), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01728463523480272), ('regressor__regressor__estimator__max_depth', 26), ('regressor__regressor__estimator__n_estimators', 51), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011257401930327253), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 166), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004947477886233022), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 70), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010777855194844447), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 125), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00914165401530612), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 85), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012424736479014755), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01550798332033686), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 72), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008395663316598268), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017898869892582582), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 65), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006989382172061524), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 140), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04150828530410831), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012447866048621123), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.028491301535847988), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005324761928638362), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 170), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007245707936007642), ('regressor__regressor__estimator__max_depth', 13), ('regressor__regressor__estimator__n_estimators', 110), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009607737453851132), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 229), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02156588044314265), ('regressor__regressor__estimator__max_depth', 273), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02910163438066593), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01813680040053438), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004675854502341978), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 284), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [0.167 0.134 0.232]±[0.099 0.076 0.259]
[array([0.16659077, 0.13418455, 0.23195041]), array([7.95412269e+00, 1.47092107e+02, 8.81595889e+04]), array([5.45357100e+00, 9.57237134e+01, 1.70812810e+04])]
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n08>
Subject: Job 315493: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c200n03> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:22:04 2025
Job was executed on host(s) <6*c201n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:22:06 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:22:06 2025
Terminated at Thu Jan 23 15:26:05 2025
Results reported at Thu Jan 23 15:26:05 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats  'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)" "polymer dP" "polymer dD" "polymer dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   11682.20 sec.
    Max Memory :                                 8 GB
    Average Memory :                             7.13 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               8.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   3862 sec.
    Turnaround time :                            3841 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0030725417010005495), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 329), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004328981068855746), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 208), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.024204132363740385), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.021556152360549995), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 68), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010279947291041201), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016904702244379607), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 70), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00614907632094264), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 170), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005923239485778082), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 157), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009929325431477929), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 79), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008493312317899182), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 83), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008947193217425785), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014320710464064385), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015509589362597357), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 60), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.049507142744761756), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005528923699188505), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 124), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003185818961724396), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 63), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.034313737940192074), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 376), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02690936771711479), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011606959294616559), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017854297439700885), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 65), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0029158590804288192), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 491), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0111617925577823), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006319810004364159), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 248), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013239742040189796), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010294738803903304), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 236), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014554054260561663), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03258454646633873), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 69), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015937441877700402), ('regressor__regressor__estimator__max_depth', 8492), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008020175372965626), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 89), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01479917060215358), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 138), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011659620576268879), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 76), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03350720449889265), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 942), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02421117353835108), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [0.167 0.179 0.196]±[0.11  0.147 0.231]
[array([0.16666822, 0.17886171, 0.19621256]), array([7.94656891e+00, 1.42318669e+02, 8.89404497e+04]), array([5.40213225e+00, 9.08511075e+01, 1.68248366e+04])]
scaler
Filename: (PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 315499: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c200n03> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:23:05 2025
Job was executed on host(s) <6*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:23:08 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:23:08 2025
Terminated at Thu Jan 23 15:29:08 2025
Results reported at Thu Jan 23 15:29:08 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats  'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   12530.00 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.80 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   3961 sec.
    Turnaround time :                            3963 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004456504849303432), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 229), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019566313085669442), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01417028878629448), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 103), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017795903125775475), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 88), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002225007471952157), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 227), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01598479307347958), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 86), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016989101797257637), ('regressor__regressor__estimator__max_depth', 27), ('regressor__regressor__estimator__n_estimators', 638), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019076434871098585), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00137665264016601), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 575), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016251675122572473), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 417), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005251598543036882), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 90), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.018510140554818005), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007523586617123296), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 119), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.029979399414103856), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 111), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0054653909087564985), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 129), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01100044897566884), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 78), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0017237382527131929), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 1049), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0021948745166386766), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 165), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002298234274591331), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 722), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011977501100604929), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 59), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013813546270820827), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 82), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014735333069688718), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 83), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00910604795755366), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 66), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02600213008156839), ('regressor__regressor__estimator__max_depth', 4087), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.018296972467243357), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005198322319192034), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 377), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013460233357012663), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03519852232816391), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008055989872343933), ('regressor__regressor__estimator__max_depth', 10000), ('regressor__regressor__estimator__n_estimators', 100), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008975260148248601), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 93), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010800919133887938), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 89), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02509828733055815), ('regressor__regressor__estimator__max_depth', 7279), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01795483289851227), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__n_jobs', -2)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR XGBR 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014096351321131077), ('regressor__regressor__estimator__max_depth', 10), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__n_jobs', -2)])


Average scores:	 r2: [0.17  0.229 0.216]±[0.103 0.144 0.234]
[array([0.16971909, 0.22915989, 0.21577713]), array([7.93317593e+00, 1.38415349e+02, 8.83139142e+04]), array([5.31883680e+00, 8.83615811e+01, 1.68464808e+04])]
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh_without_log/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_XGBR_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n07>
Subject: Job 315488: <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> in cluster <Hazel> Done

Job <numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123> was submitted from host <c201n08> by user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:21:07 2025
Job was executed on host(s) <6*c200n07>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Jan 23 14:21:09 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Thu Jan 23 14:21:09 2025
Terminated at Thu Jan 23 15:30:01 2025
Results reported at Thu Jan 23 15:30:01 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_XGBR_polymer_size_feats_on_multimodal Rh_all_num_20250123"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "XGBR"                                     --transform_type "Robust Scaler"                                     --numerical_feats  'PDI' 'Mn (g/mol)' 'Mw (g/mol)' 'Concentration (mg/ml)' "Temperature SANS/SLS/DLS/SEC (K)" "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   13630.00 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.69 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   4145 sec.
    Turnaround time :                            4134 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_XGBR_Robust Scaler_multimodal Rh_20250123.err> for stderr output of this job.

