


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000715461859009483), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.95600404171375e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013372073781603789), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1742), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01906928224632264), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003867039354795831), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09961375755781819), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 51), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 6.93931898160618e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 65), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 6.157046193067231e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0014452448282553623), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011603023130236645), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04790254252588556), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013842518563014347), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006660465574584089), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 595), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006727950782144144), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.4060483185760889e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004337849541275851), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 434), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003505505307671411), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0008177249259814372), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013987889965600901), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 149), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004222558754825821), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 802), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0018237436441454107), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007342382186833189), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 8.180146991642523e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03179092896978174), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 119), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.7639717335282795e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006485835828921119), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1446), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 9.590941089616503e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016007635647352233), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09903786448590741), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 53), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00013793676501291783), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04203028148024148), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 394), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00024601821037749654), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1066), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003230273564236901), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002483748247384979), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 6.787009560433051e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004041630266908765), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 578), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017096739363377054), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 298), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003026476724919837), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014053710934837864), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 400), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09212856002948844), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1980), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00042950047384347474), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015033910775653218), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 119), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0006258553995376559), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00013795286266611313), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015339717791355864), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 60), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02483675969428454), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007552816994455245), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 987), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02106200663607589), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006485835828921119), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1446), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 9.590941089616503e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005585484609773744), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.1704955008231316e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013330897520445692), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 934), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02007382016828937), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01798750428188598), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 72), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01415928266967789), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 96), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002346503921361817), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 314), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01209856332770352), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.6149221877156604e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005134197255719341), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.8903734192686476e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0009989428701931982), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 930), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007692313895714623), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 708), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003596061608144687), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1545), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.7857060967962304e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014125559280662347), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010354779668361845), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 77), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.087372333375777e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00925381053434835), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 75), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.2848406393279076e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007819669100828965), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 979), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000327762700250794), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011646755478628085), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 271), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005269235146499754), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011436013545115715), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 459), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004510553639066416), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 134), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.6898650943989912e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011123751388255745), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010321199736881512), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009547113486784584), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003396167634984825), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 151), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.3224761411461314e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01247190356888307), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 61), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0037834131646103408), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 168), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 6.731935198661853e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004274980655872327), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 138), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011663302916903057), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 381), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.06459156914147546), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 289), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.1200688201979395e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04291474498856304), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 55), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.6509885154302366e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0067838161564016865), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 850), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.448408466574206e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.049485633681557506), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1045), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.7081412411366642e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04371559584072467), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0006327506000288692), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008069616464378069), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1694), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0007394474838060241), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006161949683196696), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 545), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0024722026377098274), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 218), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0046525693479235455), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 214), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0016851543868330301), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.3600284191329175e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011977866618483964), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 176), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00037748749186632206), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 286), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0005448619243365788), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01688889062191561), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 118), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 182), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.589626673548189e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.026525868306465018), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1993), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.3071772414133182e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0067779282578173715), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 332), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.2227583650170396e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016755323392696392), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 121), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014234152948073663), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 90), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04375530079867314), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 101), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019286073872708292), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.8434051395077224e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0041403437000295355), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 720), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00016456367256344735), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0035175066340793694), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1162), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009645567711087399), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.031477812582098426), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 105), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014112509227526783), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000751622410481295), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00012822156221844547), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.06448938160816309), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.5171190171874643e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0030290049898141435), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.5529065157933965e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015517395710174934), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 138), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00019766645921853574), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04229053210264924), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 176), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0313264607903887e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015032161523605383), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 276), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01463008235149531), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 151), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.4586543184536019e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009948719998234101), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 349), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0005147024286785698), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0009998336669569227), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1622), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.1426469526091455e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009487068235697211), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 271), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008431043726167101), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 350), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.053738972646628975), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005426464657414754), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 607), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00908495352712158), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 528), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 8.808075324063603e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05452357844783955), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 70), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.3976010396075515e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.037348477523895536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1251), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.2402517678636831e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01768482336593542), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 221), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0002697318190779397), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.018191192015881034), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 200), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00023357166457748475), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09850625636414022), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1860), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.8561609171202838e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.08987499816056037), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 58), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0005526360287827956), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00796095823171769), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 131), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00011322023842738378), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002065032531244614), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1530), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.029946488133866425), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 79), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008013892843685984), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 215), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00013287860133417393), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.023884596362997734), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 112), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001513880496223792), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1251), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.8205272531510063e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04089245067090473), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 130), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0029036218288856774), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.025798773581076732), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 117), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0041403437000295355), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 720), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00016456367256344735), ('regressor__regressor__estimator__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0038449116375544657), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 855), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003472861493163591), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00028794356635454885), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0844625375837638e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0004030063391642811), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1539), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.016986533720633797), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009330366566142557), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01537283378693197), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0004952661432635167), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00349105351875894), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 269), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0044758888836009866), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 246), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03824587086612331), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 98), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.2025772219026267e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 71), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.6320441494441582e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01843595531141922), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 219), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006898765256133213), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04435231613101386), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015172757578667683), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 239), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00024563361097640384), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004817527117835808), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 978), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.2365050786181201e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01537948446580078), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 153), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00039118639884156683), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04052355679065018), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009999819009829905), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03877135751508885), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.009158603827515686), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 230), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.018048901916532224), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 217), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008001590222287382), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 138), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00011848597049477576), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013360082329246495), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00455237362959374), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 380), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 8.924784366952673e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020236923873442097), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 220), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007987918907945273), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 131), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0001133870114177078), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006351660777015773), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 490), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0004475792442808878), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04202692339304819), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 107), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.017360626675741772), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 187), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00029183090219667834), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.040257787722792475), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 190), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00023292968341944467), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000738956318650451), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1929), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002874949342515079), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 837), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04814854243967334), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 82), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.4103076091788285e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004371484582007536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.809955146978886e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0018763633465915162), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 97), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006096224728039288), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 279), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006909552890670951), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 161), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006112568751229778), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 435), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.9418344284513412e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004371484582007536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.809955146978886e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.06054700484420163), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004371484582007536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.809955146978886e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03305874038486581), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 70), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00017562561026029263), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004371484582007536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.809955146978886e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019798182039464263), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 96), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006058841238225416), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 179), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00014862745018686505), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00017722924769465046), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019013554513331286), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 168), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.6980259507827906e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003652035830931817), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 193), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0027393210711311386), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 282), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0030541542931408145), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 185), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0035599147034782817), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 234), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0046630708726582435), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 84), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00020840878226940476), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00016708063701075204), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0011614049153393638), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 564), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 8.686049218998303e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00033589530634831673), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0038456078486820344), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 309), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0003869041869408276), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010887603738421918), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0004967526801400341), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005244771174717171), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 872), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0030945413461472126), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 116), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014262592604169169), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006254594997060118), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1961), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.2176217970346398e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0031243917304687144), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 915), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03093076485835818), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003052879872188729), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 149), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01280679751746647), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 95), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000328537566500212), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001470937975532662), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 628), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0020980683249668996), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 247), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003796690792953479), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 90), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.07532594802897e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007009205273585441), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 143), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00017610764413284813), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002083773021972487), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 398), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011979166764731552), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0006609322114866453), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002391255315608959), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 145), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004728701865055429), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 391), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0022895082011893278), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 308), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0020163536122688717), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 276), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005419013848555591), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 981), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001039637335713716), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 756), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.3503015063380083e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012414309664625629), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.811430853815046e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0013028548764589445), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 575), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0008637432549576499), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012418386369066366), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.3377558256188576e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.028  0.146 -0.04 ][0.123 0.119 0.021]
[array([ 0.02834983,  0.14622175, -0.03971518]), array([8.57187564e+00, 1.45781555e+02, 9.38132608e+04]), array([6.52061291e+00, 1.01032033e+02, 1.41017364e+04])]
{6: {'fit_time': array([7.76336074, 7.96606708, 7.78322363, 7.71365166, 7.63603091]), 'score_time': array([0.27718115, 0.29531693, 0.29760027, 0.28195643, 0.26623225]), 'test_r2': [array([-0.30771   ,  0.16723834, -0.05800551]), array([ 0.06515406, -0.01869264, -0.02611748]), array([ 0.10876193,  0.27079459, -0.02780209]), array([-0.00625001,  0.08972497, -0.07478914]), array([ 0.03370664,  0.22396793, -0.06088786])], 'test_rmse': [array([7.40722508e+00, 1.30052541e+02, 1.76601241e+04]), array([8.46160733e+00, 1.37974249e+02, 3.38441129e+05]), array([8.32996069e+00, 1.58189516e+02, 2.43684664e+04]), array([9.66964687e+00, 1.59227914e+02, 1.34112711e+04]), array([9.42650691e+00, 1.42074025e+02, 2.01948339e+04])], 'test_mae': [array([   5.75268776,   94.7620483 , 4137.47518328]), array([6.68132824e+00, 9.39591248e+01, 5.39909189e+04]), array([   6.20287589,  103.01764129, 4008.51658868]), array([   6.87605733,  108.4057866 , 3541.53737916]), array([   7.36949909,  101.55003364, 4840.11996679])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 282, 'regressor__estimator__learning_rate': 0.0027393210711311386, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([8.43882298, 8.50259233, 8.43100834, 8.56549978, 8.33680081]), 'score_time': array([0.292449  , 0.33379388, 0.29221725, 0.31527281, 0.29327512]), 'test_r2': [array([ 0.16014024,  0.17249196, -0.07077516]), array([ 0.17040035,  0.28036069, -0.04759505]), array([-0.12501526, -0.03587573, -0.02067646]), array([-0.27979718,  0.2450027 , -0.02029886]), array([ 0.12565031,  0.15790575, -0.02670779])], 'test_rmse': [array([8.99545411e+00, 1.64986251e+02, 9.07056705e+03]), array([8.14556036e+00, 1.37105749e+02, 2.83059005e+04]), array([1.00771824e+01, 1.53201872e+02, 9.45640527e+04]), array([7.28811927e+00, 1.34491713e+02, 3.25547357e+05]), array([8.17919327e+00, 1.32756613e+02, 1.49889355e+04])], 'test_mae': [array([   6.45652535,  105.93695915, 2461.78991534]), array([   6.56307808,   95.11017828, 6029.55982174]), array([7.79009378e+00, 1.03831220e+02, 1.34518269e+04]), array([5.80789022e+00, 9.08536027e+01, 4.59047667e+04]), array([   5.75628634,  101.79363217, 2486.71515978])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 309, 'regressor__estimator__learning_rate': 0.0038456078486820344, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([52.30241275, 52.60789442, 53.40483546, 53.28939438, 53.02664375]), 'score_time': array([1.72516251, 1.91064692, 1.8993237 , 1.93003464, 1.85494399]), 'test_r2': [array([ 0.10792386,  0.22785153, -0.03733791]), array([ 0.09714195,  0.121336  , -0.0307129 ]), array([-0.12183432,  0.06616744, -0.02151161]), array([ 0.07496935,  0.11683915, -0.05029013]), array([-0.17267001,  0.22983478, -0.03823563])], 'test_rmse': [array([8.51510190e+00, 1.36510981e+02, 2.38877402e+04]), array([8.26767956e+00, 1.56374146e+02, 6.07999038e+04]), array([6.86408786e+00, 1.57791773e+02, 3.33424880e+05]), array([9.80967650e+00, 1.65741749e+02, 1.41390574e+04]), array([9.71379530e+00, 1.17864620e+02, 1.98503637e+04])], 'test_mae': [array([   6.3978477 ,   96.18027862, 4572.54573625]), array([6.22927722e+00, 1.00423795e+02, 1.04905379e+04]), array([5.68323358e+00, 1.15466733e+02, 4.83351042e+04]), array([   7.21610453,  108.97007218, 3109.31705602]), array([   7.55011497,   82.90307279, 3818.28428908])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1961, 'regressor__estimator__learning_rate': 0.0006254594997060118, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([2.68502951, 2.69588089, 2.72894359, 2.63989305, 2.62687016]), 'score_time': array([0.09964323, 0.09801912, 0.10257745, 0.10467267, 0.09717512]), 'test_r2': [array([-0.01882732,  0.25927685, -0.01952078]), array([ 0.15105953,  0.02473092, -0.02271547]), array([ 0.14927212,  0.44275766, -0.04199501]), array([-0.08453054, -0.03715498, -0.03783518]), array([-0.10477239,  0.09669771, -0.03740073])], 'test_rmse': [array([7.95964328e+00, 1.41633654e+02, 3.25182789e+05]), array([7.84170756e+00, 1.52450290e+02, 9.45963276e+04]), array([9.37348402e+00, 1.10364727e+02, 3.19622125e+04]), array([9.76326521e+00, 1.58277251e+02, 1.31686387e+04]), array([8.25048354e+00, 1.66145462e+02, 1.19576244e+04])], 'test_mae': [array([6.00126621e+00, 1.04358617e+02, 4.49854762e+04]), array([5.91703284e+00, 1.04995446e+02, 1.40506407e+04]), array([   6.69782945,   85.03996009, 6409.18673271]), array([   7.28459209,  108.04079149, 2562.38308692]), array([   6.66303208,  102.38209963, 2294.4748965 ])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 95, 'regressor__estimator__learning_rate': 0.01280679751746647, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([16.93451548, 17.05602193, 16.98963547, 16.94392276, 16.38385797]), 'score_time': array([0.58456707, 0.58194637, 0.57737041, 0.59527588, 0.56780457]), 'test_r2': [array([ 0.04419848,  0.01022579, -0.04231243]), array([ 0.17169626,  0.30351089, -0.02893775]), array([ 0.11135149,  0.28514887, -0.0990891 ]), array([ 0.01874755,  0.1919042 , -0.01729965]), array([-0.05659323, -0.08952768, -0.06932399])], 'test_rmse': [array([8.63564808e+00, 1.65653829e+02, 1.61394216e+04]), array([8.95508668e+00, 1.03865722e+02, 9.84045030e+04]), array([   8.47650685,  142.53824445, 7807.4394812 ]), array([8.25612691e+00, 1.77729189e+02, 3.24765432e+05]), array([8.26747376e+00, 1.35705820e+02, 2.36562970e+04])], 'test_mae': [array([   6.4409068 ,  104.60577637, 3256.29483084]), array([6.67049712e+00, 8.72533877e+01, 1.64968389e+04]), array([   6.34948953,  103.10344198, 2368.36728215]), array([6.42189037e+00, 1.15700253e+02, 4.23478161e+04]), array([   6.57271204,   94.10576002, 6026.32863416])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 628, 'regressor__estimator__learning_rate': 0.001470937975532662, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([8.28128147, 8.30641937, 8.30737615, 8.62439895, 8.28004813]), 'score_time': array([0.29871511, 0.28918815, 0.34182644, 0.30589747, 0.30504179]), 'test_r2': [array([ 0.03344965,  0.12402422, -0.05642038]), array([ 0.10682923,  0.02110658, -0.01677967]), array([ 0.16567424,  0.29901392, -0.05710629]), array([-0.06428245,  0.19055533, -0.03841705]), array([ 0.09286848, -0.03073853, -0.02072995])], 'test_rmse': [array([7.38754857e+00, 1.75678762e+02, 3.28611520e+04]), array([8.50030432e+00, 1.33141326e+02, 9.41249824e+04]), array([8.30808263e+00, 1.10505489e+02, 9.55305183e+03]), array([8.37264416e+00, 1.68483753e+02, 1.28669172e+04]), array([9.87375072e+00, 1.45842172e+02, 3.27276641e+05])], 'test_mae': [array([5.83484731e+00, 1.13358844e+02, 7.59434776e+03]), array([6.12661545e+00, 1.04049756e+02, 1.20903788e+04]), array([   6.60906247,   87.42938316, 2224.22846432]), array([   6.47515542,  110.92288777, 2478.16687277]), array([7.36793950e+00, 1.00151120e+02, 4.66384319e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 308, 'regressor__estimator__learning_rate': 0.0022895082011893278, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([20.34841514, 20.21055007, 20.69398546, 20.57189465, 20.35268641]), 'score_time': array([0.68534899, 0.7150712 , 0.72956419, 0.71247435, 0.72175622]), 'test_r2': [array([-0.04126076,  0.18379901, -0.03901869]), array([ 0.07017203,  0.08669049, -0.01419391]), array([ 0.05010241,  0.07405823, -0.01571654]), array([ 0.14561508,  0.17379522, -0.08206258]), array([ 0.12090219,  0.19293894, -0.02141259])], 'test_rmse': [array([9.06536693e+00, 1.17617173e+02, 2.52031042e+04]), array([7.72118866e+00, 1.59715576e+02, 9.36147526e+04]), array([8.77383303e+00, 1.50842009e+02, 3.20549754e+05]), array([8.68377287e+00, 1.78321983e+02, 2.28081610e+04]), array([8.39893234e+00, 1.23498280e+02, 5.83103447e+04])], 'test_mae': [array([   6.84619684,   90.47363835, 4887.70425578]), array([5.76109384e+00, 1.01662387e+02, 1.10748744e+04]), array([6.71837366e+00, 1.03448504e+02, 3.98722565e+04]), array([   6.65742271,  111.98161243, 6282.53069577]), array([6.47259620e+00, 9.98933115e+01, 8.44103077e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 756, 'regressor__estimator__learning_rate': 0.001039637335713716, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([ 0.02834983,  0.14622175, -0.03971518]), 'r2_stdev': array([0.12284848, 0.11872054, 0.02095661]), 'rmse_avg': array([8.57187564e+00, 1.45781555e+02, 9.38132608e+04]), 'rmse_stdev': array([7.80628197e-01, 1.96588840e+01, 1.20180010e+05]), 'mae_avg': array([6.52061291e+00, 1.01032033e+02, 1.41017364e+04]), 'mae_stdev': array([5.35967781e-01, 8.33258072e+00, 1.64591073e+04]), 'r2_avg_aggregate': 0.044952130813311765, 'r2_stdev_aggregate': 0.08750854356118977, 'rmse_avg_aggregate': 31322.538082842657, 'rmse_stdev_aggregate': 40066.8165051253, 'mae_avg_aggregate': 4736.42967628098, 'mae_stdev_aggregate': 5489.325280255266}
scaler
Filename: (solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n10>
Subject: Job 288790: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c202n11> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:22:15 2025
Job was executed on host(s) <6*c205n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:22:16 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:22:16 2025
Terminated at Mon Jan 20 08:21:38 2025
Results reported at Mon Jan 20 08:21:38 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats "solvent dP" "solvent dD" "solvent dH"                                


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   148397.25 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.78 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   32362 sec.
    Turnaround time :                            32363 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007858550054645806), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00011374302244968057), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.07272128001758887), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 439), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 8.338976779782157e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [  0.128   0.098 -20.303][  0.136   0.137 118.341]
[array([  0.12790158,   0.09830047, -20.30269507]), array([8.10649917e+00, 1.49348633e+02, 1.10137094e+05]), array([5.45039345e+00, 9.72157525e+01, 1.58697138e+04])]
{6: {'fit_time': array([1.22782421, 1.2644639 , 1.23035049, 1.2336154 , 1.26145291]), 'score_time': array([0.05345154, 0.06065512, 0.05674648, 0.05679774, 0.05862832]), 'test_r2': [array([0.07693376, 0.24010094, 0.04267242]), array([ 0.28822867, -0.09426672, -0.02609818]), array([ 0.14126857,  0.15787876, -0.57031143]), array([ 0.30430225,  0.11739127, -0.07721945]), array([ 0.13006696, -0.00893961, -0.02123932])], 'test_rmse': [array([6.22323575e+00, 1.24232847e+02, 1.67988701e+04]), array([7.38334377e+00, 1.43000663e+02, 3.38437947e+05]), array([8.17663791e+00, 1.69996533e+02, 3.01207891e+04]), array([8.04022060e+00, 1.56789509e+02, 1.34264253e+04]), array([8.94415270e+00, 1.61997174e+02, 1.98138700e+04])], 'test_mae': [array([   4.41652263,   82.25975269, 3851.85415062]), array([5.26513142e+00, 9.72320160e+01, 5.38349216e+04]), array([5.46203698e+00, 1.09084001e+02, 5.82163345e+03]), array([   5.40127844,   93.84966689, 3548.65296399]), array([   6.14517404,  103.29494637, 4732.3531275 ])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 51, 'regressor__estimator__learning_rate': 0.09961375755781819, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([14.22796226, 13.01872206, 11.6104176 , 11.42984009, 11.86797476]), 'score_time': array([0.28180456, 0.2887516 , 0.29742646, 0.29177904, 0.28850794]), 'test_r2': [array([0.26554589, 0.20683526, 0.2128519 ]), array([0.22078132, 0.15775221, 0.01132115]), array([ 0.14174865, -0.07688411, -0.02110491]), array([-0.22795341,  0.04458546, -0.01514363]), array([ 0.21519087, -0.02808449, -0.82442989])], 'test_rmse': [array([   8.41205375,  161.52633694, 7777.02543792]), array([7.89434972e+00, 1.48326301e+02, 2.74984287e+04]), array([8.80171219e+00, 1.56204928e+02, 9.45838982e+04]), array([7.13897466e+00, 1.51292969e+02, 3.24723874e+05]), array([7.74907587e+00, 1.46686524e+02, 1.99807116e+04])], 'test_mae': [array([   5.65501759,  105.03123101, 2059.9498223 ]), array([5.20755939e+00, 9.50209626e+01, 5.79924359e+03]), array([5.77995847e+00, 9.78723788e+01, 1.36602180e+04]), array([4.75047231e+00, 9.65709395e+01, 4.44531290e+04]), array([   5.17762174,  102.55447687, 3851.0433695 ])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 394, 'regressor__estimator__learning_rate': 0.04203028148024148, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([85.51945829, 85.41612864, 84.64066339, 86.9919281 , 86.01780486]), 'score_time': array([1.41280723, 1.34424067, 1.3904171 , 1.34015822, 1.40741777]), 'test_r2': [array([ 0.24977714, -0.17086982,  0.05903035]), array([ 0.0211643 ,  0.15984168, -0.00472762]), array([-0.28978925,  0.04886826, -0.02138553]), array([0.19633563, 0.39790099, 0.15629305]), array([ 0.15864624, -0.00485141,  0.21417512])], 'test_rmse': [array([7.80879525e+00, 1.68101461e+02, 2.27511183e+04]), array([8.60852607e+00, 1.52909371e+02, 6.00285989e+04]), array([7.36000061e+00, 1.59246607e+02, 3.33404304e+05]), array([9.14353180e+00, 1.36850368e+02, 1.26724804e+04]), array([8.22792565e+00, 1.34630182e+02, 1.72696442e+04])], 'test_mae': [array([   5.29471868,  117.53109951, 4296.21852726]), array([5.07884082e+00, 9.54705653e+01, 1.01867275e+04]), array([4.38056049e+00, 1.06513789e+02, 4.83920642e+04]), array([   5.83570041,   84.83862454, 2628.77022659]), array([   5.50455334,   84.01951304, 3345.57786313])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1980, 'regressor__estimator__learning_rate': 0.09212856002948844, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([1.17977452, 1.24852753, 1.18972158, 1.1783092 , 1.18097711]), 'score_time': array([0.05278063, 0.0604012 , 0.05331564, 0.05311751, 0.05342984]), 'test_r2': [array([ 0.19050143,  0.14053288, -0.02035326]), array([ 0.19215342, -0.0422267 , -0.02035833]), array([0.00589786, 0.34429308, 0.13004642]), array([0.09412351, 0.09730142, 0.0294005 ]), array([ 0.06545231,  0.14600416, -0.03707809])], 'test_rmse': [array([7.09498298e+00, 1.52564375e+02, 3.25315524e+05]), array([7.64956027e+00, 1.57596702e+02, 9.44872525e+04]), array([1.01326074e+01, 1.19719012e+02, 2.92046533e+04]), array([8.92295470e+00, 1.47661763e+02, 1.27349346e+04]), array([7.58828672e+00, 1.61547338e+02, 1.19557648e+04])], 'test_mae': [array([5.06092218e+00, 1.04133291e+02, 4.59546100e+04]), array([5.12466883e+00, 1.07159773e+02, 1.36588300e+04]), array([   6.73118365,   78.19367364, 5792.23863271]), array([   6.00800187,   91.20021566, 2540.15839498]), array([   5.540609  ,   92.81439955, 2284.53475027])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([77.65793705, 80.39991665, 80.4147861 , 80.72625828, 76.26497412]), 'score_time': array([1.20995021, 1.32746601, 1.33612466, 1.25060749, 1.2897954 ]), 'test_r2': [array([0.09919895, 0.06398932, 0.72647155]), array([ 0.38522277,  0.2265192 , -0.01756825]), array([ 0.1697871 ,  0.24130104, -0.07618254]), array([-0.03021005,  0.14761164, -0.01710746]), array([-1.08740121e-01, -2.50069158e-01, -7.10341659e+02])], 'test_rmse': [array([   8.38350287,  161.09194136, 8267.80564082]), array([7.71496336e+00, 1.09456069e+02, 9.78593209e+04]), array([   8.19306964,  146.84472352, 7725.65208635]), array([8.45958139e+00, 1.82534974e+02, 3.24734753e+05]), array([8.46903243e+00, 1.45360484e+02, 6.10142434e+05])], 'test_mae': [array([   5.65582376,   94.96479143, 2063.06048134]), array([4.94466325e+00, 7.61562982e+01, 1.60807966e+04]), array([   4.94392767,   96.26169522, 2146.56955034]), array([5.14724364e+00, 1.12399642e+02, 4.23248509e+04]), array([5.39143548e+00, 9.81051039e+01, 7.17827857e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1860, 'regressor__estimator__learning_rate': 0.09850625636414022, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([9.27021146, 9.29104233, 9.22156763, 9.38098907, 9.42895865]), 'score_time': array([0.29063201, 0.28859234, 0.29477739, 0.28484511, 0.2828815 ]), 'test_r2': [array([ 0.15497506,  0.16562677, -0.05083658]), array([ 0.15066559, -0.09999755, -0.01664818]), array([ 0.12951263,  0.23583552, -0.03713377]), array([ 0.03847873,  0.19901814, -0.03484605]), array([ 0.1473283 ,  0.12108445, -0.02063168])], 'test_rmse': [array([6.90753149e+00, 1.71456278e+02, 3.27741916e+04]), array([8.28908485e+00, 1.41137049e+02, 9.41188960e+04]), array([8.48621864e+00, 1.15377886e+02, 9.46237583e+03]), array([7.95817765e+00, 1.67600683e+02, 1.28447741e+04]), array([9.57277729e+00, 1.34673591e+02, 3.27260885e+05])], 'test_mae': [array([5.43182395e+00, 1.06240507e+02, 7.54131740e+03]), array([5.89227786e+00, 1.02236959e+02, 1.20245615e+04]), array([   6.41470897,   87.01115502, 2156.46947351]), array([   5.85572291,  109.77016646, 2429.76810546]), array([7.08610879e+00, 9.71580323e+01, 4.65669186e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 375, 'regressor__estimator__learning_rate': 0.004371484582007536, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([15.99744773, 15.71432376, 16.42212582, 15.93965077, 17.38760066]), 'score_time': array([0.29811263, 0.3125248 , 0.32232618, 0.31826878, 0.29344058]), 'test_r2': [array([0.11098681, 0.0557926 , 0.03759848]), array([ 0.15679831,  0.16255057, -0.01408466]), array([ 0.18819262,  0.19230666, -0.01554745]), array([0.29432371, 0.09813799, 0.06430788]), array([0.14965881, 0.04764588, 0.02319935])], 'test_rmse': [array([8.37644493e+00, 1.26504472e+02, 2.42560738e+04]), array([7.35272962e+00, 1.52938765e+02, 9.36097102e+04]), array([8.11105733e+00, 1.40881420e+02, 3.20523071e+05]), array([7.89195197e+00, 1.86307819e+02, 2.12095067e+04]), array([8.26041924e+00, 1.34155025e+02, 5.70227261e+04])], 'test_mae': [array([   5.45086243,   86.97572468, 4988.73065284]), array([4.78997360e+00, 8.71006414e+01, 1.10185280e+04]), array([5.36390091e+00, 9.68808433e+01, 3.97336266e+04]), array([5.15222538e+00, 1.12148936e+02, 5.70402481e+03]), array([5.42254004e+00, 9.44955264e+01, 8.18524422e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 439, 'regressor__estimator__learning_rate': 0.07272128001758887, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([  0.12790158,   0.09830047, -20.30269507]), 'r2_stdev': array([  0.13609634,   0.13664371, 118.34091117]), 'rmse_avg': array([8.10649917e+00, 1.49348633e+02, 1.10137094e+05]), 'rmse_stdev': array([7.50578781e-01, 1.75482042e+01, 1.47310509e+05]), 'mae_avg': array([5.45039345e+00, 9.72157525e+01, 1.58697138e+04]), 'mae_stdev': array([5.65338178e-01, 9.83966685e+00, 1.89925278e+04]), 'r2_avg_aggregate': -6.692164338916787, 'r2_stdev_aggregate': 39.537883739318566, 'rmse_avg_aggregate': 36764.84971595393, 'rmse_stdev_aggregate': 49109.60253227212, 'mae_avg_aggregate': 5324.126636392026, 'mae_stdev_aggregate': 6334.3109358530955}
scaler
Filename: (PDI-Mw-concentration-temperature)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c019n04>
Subject: Job 288752: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c023n02> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:11:47 2025
Job was executed on host(s) <6*c019n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:11:49 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:11:49 2025
Terminated at Mon Jan 20 08:36:32 2025
Results reported at Mon Jan 20 08:36:32 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)'                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   155904.02 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.86 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   33885 sec.
    Turnaround time :                            33885 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 78), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.000537738023194021), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004371484582007536), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 375), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.809955146978886e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.035697999644851354), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 82), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.0385144285520227e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003794737933710587), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 849), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.5871897255499115e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002325060766919232), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 3.689755554499981e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00252423662704871), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0003015057972949545), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.059242083203619574), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 54), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.016830535471718e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.032748046897963026), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 95), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.007323743647980129), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1967), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0006449103072973438), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.164  0.26  -0.183][0.109 0.146 0.693]
[array([ 0.16443757,  0.25998401, -0.18324912]), array([7.95823910e+00, 1.35491263e+02, 9.47457895e+04]), array([5.52146465e+00, 8.87924043e+01, 1.41660131e+04])]
{6: {'fit_time': array([30.56729722, 30.30290461, 30.95343876, 29.93382382, 30.22698236]), 'score_time': array([1.110291  , 1.11058736, 1.13527513, 1.07225394, 1.05221057]), 'test_r2': [array([ 0.09536661,  0.39410994, -0.0236946 ]), array([ 0.19179863,  0.04656008, -0.02609728]), array([ 0.17585435,  0.47293177, -0.02640796]), array([ 0.25184767,  0.12285354, -0.06317317]), array([ 0.14965227,  0.19212059, -0.02843051])], 'test_rmse': [array([6.16078603e+00, 1.10931631e+02, 1.73714068e+04]), array([7.86760657e+00, 1.33482128e+02, 3.38437799e+05]), array([8.01028694e+00, 1.34488817e+02, 2.43519338e+04]), array([8.33782322e+00, 1.56303588e+02, 1.33386019e+04]), array([8.84289709e+00, 1.44959981e+02, 1.98835086e+04])], 'test_mae': [array([   4.29815977,   78.03606628, 3948.67305066]), array([5.71391933e+00, 8.84099782e+01, 5.38112603e+04]), array([   5.41333405,   91.00776424, 4040.58222235]), array([   5.84581959,   94.4953143 , 3392.87976288]), array([   6.12558696,   95.96111672, 4670.77559915])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1162, 'regressor__estimator__learning_rate': 0.0035175066340793694, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([51.63410854, 51.38063836, 51.74473834, 52.15029454, 51.03937912]), 'score_time': array([1.90878487, 1.87118387, 1.95021009, 1.88204288, 1.8927362 ]), 'test_r2': [array([ 0.29958135,  0.2416054 , -0.02873511]), array([0.13572641, 0.31128273, 0.45053957]), array([ 0.08767226,  0.15767381, -0.02054155]), array([-0.16339485,  0.32781417, -0.0192721 ]), array([ 0.2672386 ,  0.2387699 , -2.36963999])], 'test_rmse': [array([8.21482957e+00, 1.57946229e+02, 8.89072290e+03]), array([8.31404376e+00, 1.34127772e+02, 2.04997454e+04]), array([9.07476434e+00, 1.38149843e+02, 9.45578028e+04]), array([6.94877844e+00, 1.26901718e+02, 3.25383512e+05]), array([7.48771286e+00, 1.26221631e+02, 2.71543314e+04])], 'test_mae': [array([   5.26399867,   97.24654719, 2226.84314874]), array([   5.78313868,   91.83705162, 4681.58007716]), array([6.11049901e+00, 9.14054082e+01, 1.33819541e+04]), array([5.08405408e+00, 7.55265329e+01, 4.55209419e+04]), array([   5.21011744,   90.20769237, 4740.45475733])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.0030290049898141435, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([7.39135313, 7.42166114, 7.20295382, 7.39224792, 7.28046846]), 'score_time': array([0.27520585, 0.26909661, 0.30836558, 0.29110146, 0.29923105]), 'test_r2': [array([ 0.20314705,  0.18424128, -0.02672532]), array([ 0.17363233,  0.20621309, -0.01887704]), array([ 0.12019099,  0.18883222, -0.02146333]), array([ 0.1350035 ,  0.44678449, -0.04683473]), array([ 0.09231677,  0.36709257, -0.03157135])], 'test_rmse': [array([8.04781494e+00, 1.40313043e+02, 2.37652331e+04]), array([7.90970994e+00, 1.48629666e+02, 6.04498076e+04]), array([6.07872753e+00, 1.47063601e+02, 3.33417002e+05]), array([9.48601482e+00, 1.31177451e+02, 1.41157798e+04]), array([8.54610438e+00, 1.06846821e+02, 1.97865528e+04])], 'test_mae': [array([   6.03746169,   97.94988447, 4317.0987215 ]), array([5.36929642e+00, 9.56208510e+01, 1.02491349e+04]), array([5.11993671e+00, 1.03538836e+02, 4.82786314e+04]), array([   6.40090609,   84.96501507, 3074.40556118]), array([   6.20327057,   71.2045864 , 3755.50173169])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 271, 'regressor__estimator__learning_rate': 0.009487068235697211, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([9.33112001, 9.45362377, 9.29593062, 9.55562234, 9.37320971]), 'score_time': array([0.35333419, 0.36446762, 0.33728433, 0.35451746, 0.35693359]), 'test_r2': [array([ 0.19408274,  0.39053504, -0.01947314]), array([ 0.25192386,  0.15214848, -0.02216598]), array([-0.01560416,  0.52774262, -0.03659913]), array([ 0.11309868,  0.17436623, -0.01923645]), array([ 0.10112856,  0.1908142 , -0.03557148])], 'test_rmse': [array([7.07927107e+00, 1.28473297e+02, 3.25175191e+05]), array([7.36113741e+00, 1.42143148e+02, 9.45709116e+04]), array([1.02416032e+01, 1.01600914e+02, 3.18793483e+04]), array([8.82900666e+00, 1.41218110e+02, 1.30501097e+04]), array([7.44203637e+00, 1.57251956e+02, 1.19470773e+04])], 'test_mae': [array([5.28216249e+00, 8.58402176e+01, 4.49165358e+04]), array([5.20203980e+00, 9.57867150e+01, 1.39007418e+04]), array([   6.85766347,   74.01508849, 6296.97042904]), array([   6.13055198,   93.62672884, 2587.08876287]), array([   5.75445399,   95.85066873, 2252.32990743])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 350, 'regressor__estimator__learning_rate': 0.008431043726167101, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([6.12781954, 5.91310549, 5.92617631, 6.00039887, 5.87694001]), 'score_time': array([0.24118137, 0.23077917, 0.22371411, 0.22907162, 0.22263265]), 'test_r2': [array([ 0.06065773,  0.08445965, -0.03659958]), array([ 0.34787259,  0.50346514, -0.02856676]), array([ 0.4039503 ,  0.41790827, -0.08245093]), array([ 0.04706739,  0.27347435, -0.01726301]), array([ 0.13525372,  0.19397333, -3.44520883])], 'test_rmse': [array([8.56097069e+00, 1.59320682e+02, 1.60951313e+04]), array([7.94586550e+00, 8.76980525e+01, 9.83867616e+04]), array([6.94213641e+00, 1.28623201e+02, 7.74811904e+03]), array([8.13611498e+00, 1.68520528e+02, 3.24759583e+05]), array([7.47933982e+00, 1.16722356e+02, 4.82323245e+04])], 'test_mae': [array([   5.97175309,   97.6533637 , 3132.06362748]), array([5.45488201e+00, 6.63462659e+01, 1.63600655e+04]), array([   4.98392172,   89.89528855, 2236.58339913]), array([5.38941348e+00, 1.05334514e+02, 4.22386171e+04]), array([5.47731011e+00, 8.27234690e+01, 9.17590927e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 221, 'regressor__estimator__learning_rate': 0.01768482336593542, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([87.36501455, 89.17967725, 86.57158613, 90.28139067, 84.49081063]), 'score_time': array([1.65231204, 1.71575546, 1.79637718, 1.74613094, 1.78892422]), 'test_r2': [array([0.11664783, 0.03615408, 0.03968191]), array([ 0.26297796, -0.18987398, -0.01617055]), array([ 0.15571994,  0.39015764, -0.01747427]), array([-0.02356788,  0.42166013, -0.03930862]), array([ 0.24423387,  0.28065365, -0.02011849])], 'test_rmse': [array([7.06244454e+00, 1.84279497e+02, 3.13308338e+04]), array([7.72160289e+00, 1.46789726e+02, 9.40967844e+04]), array([8.35749735e+00, 1.03071345e+02, 9.37226421e+03]), array([8.21093299e+00, 1.42415090e+02, 1.28724397e+04]), array([9.01240590e+00, 1.21836633e+02, 3.27178600e+05])], 'test_mae': [array([5.07795997e+00, 1.08144232e+02, 7.11294447e+03]), array([5.08734784e+00, 8.88211464e+01, 1.20013617e+04]), array([   5.11388869,   75.720136  , 1941.02820277]), array([   5.35688066,   93.16082524, 2486.93484447]), array([6.01684547e+00, 7.59712639e+01, 4.65809039e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([55.992033  , 49.77183461, 59.71765494, 58.45571184, 50.13921857]), 'score_time': array([1.83716702, 1.72653031, 1.58784556, 1.79260087, 1.75724435]), 'test_r2': [array([0.17685459, 0.29581277, 0.24047723]), array([ 0.24026476,  0.29422937, -0.01392927]), array([ 0.21399739,  0.24786036, -0.01563421]), array([ 0.29793353,  0.20595571, -0.07088655]), array([ 0.21518746,  0.30905777, -0.45629668])], 'test_rmse': [array([8.06016469e+00, 1.09248693e+02, 2.15482872e+04]), array([6.97933424e+00, 1.40400958e+02, 9.36025380e+04]), array([7.98110396e+00, 1.35950156e+02, 3.20536763e+05]), array([7.87174084e+00, 1.74816893e+02, 2.26900689e+04]), array([7.93575859e+00, 1.14269041e+02, 6.96257578e+04])], 'test_mae': [array([   5.36739544,   76.98939096, 4414.85801985]), array([4.68596072e+00, 8.32163686e+01, 1.09456164e+04]), array([5.33222694e+00, 9.61753077e+01, 3.97161381e+04]), array([5.23797147e+00, 9.81912385e+01, 6.07079340e+03]), array([5.49113442e+00, 7.68592784e+01, 1.13522566e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1967, 'regressor__estimator__learning_rate': 0.007323743647980129, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([ 0.16443757,  0.25998401, -0.18324912]), 'r2_stdev': array([0.10858636, 0.14607327, 0.69311105]), 'rmse_avg': array([7.95823910e+00, 1.35491263e+02, 9.47457895e+04]), 'rmse_stdev': array([8.49624196e-01, 2.10894920e+01, 1.19776429e+05]), 'mae_avg': array([5.52146465e+00, 8.87924043e+01, 1.41660131e+04]), 'mae_stdev': array([5.07725123e-01, 1.00993195e+01, 1.63755462e+04]), 'r2_avg_aggregate': 0.08039081806935626, 'r2_stdev_aggregate': 0.31592356040856967, 'rmse_avg_aggregate': 31629.746346035157, 'rmse_stdev_aggregate': 39932.789532805014, 'mae_avg_aggregate': 4753.44232258075, 'mae_stdev_aggregate': 5462.0510893244145}
scaler
Filename: (PDI-Mw-concentration-temperature-Ra)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-Ra)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-Ra)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-Ra)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n03>
Subject: Job 288778: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c201n03> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:18:21 2025
Job was executed on host(s) <6*c202n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:18:22 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:18:22 2025
Terminated at Mon Jan 20 08:41:34 2025
Results reported at Mon Jan 20 08:41:34 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' 'Ra'                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   152560.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.88 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   33819 sec.
    Turnaround time :                            33793 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002045862406468061), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 659), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0030843712025130795), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 801), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03303835204601734), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.3008124755323866e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.026078313064159985), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 87), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.056409978380655645), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003035319172530649), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 551), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.045621200417375295), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03137790953242362), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 52), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.036641281774035674), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 51), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.171098453134644e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03552884796045094), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005332840402870948), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 367), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001334767379546833), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02545640331644895), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 73), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001255483882948892), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.011931986442969335), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 146), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03304702501141781), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 94), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0027125724485380994), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 780), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.020088525525795264), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 76), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0014349289954744314), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1671), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005648391848469002), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 293), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02211011085004017), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 70), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03408350883575477), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05525498615220733), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04156950367323965), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03477455941172548), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03345129542128174), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010366200554298759), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 165), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009141728406590112), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008686210971214175), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 312), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05792305355198513), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.7840249981176745e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019564266370332303), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 102), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006823613312164333), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04557174197777909), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 69), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04415685038382257), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0001615202392523496), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010285657349317788), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 251), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.12   0.158 -0.039][0.133 0.092 0.02 ]
[array([ 0.11988235,  0.15804333, -0.03907943]), array([8.14608337e+00, 1.45009873e+02, 9.38088420e+04]), array([5.69076476e+00, 9.48955019e+01, 1.40722264e+04])]
{6: {'fit_time': array([1.51294756, 1.56182671, 1.52232003, 1.49969625, 1.47250605]), 'score_time': array([0.06967854, 0.07158518, 0.0714972 , 0.07411242, 0.06999373]), 'test_r2': [array([-0.17135377,  0.2894948 , -0.05607786]), array([ 0.17637514,  0.02470813, -0.0261088 ]), array([ 0.13168971,  0.23579228, -0.02746298]), array([ 0.27959091,  0.14369246, -0.07214004]), array([ 0.07393045,  0.07446464, -0.05868108])], 'test_rmse': [array([7.01041712e+00, 1.20127410e+02, 1.76440287e+04]), array([7.94232340e+00, 1.35003105e+02, 3.38439699e+05]), array([8.22211527e+00, 1.61941615e+02, 2.43644460e+04]), array([8.18176984e+00, 1.54435726e+02, 1.33947331e+04]), array([9.22822330e+00, 1.55156995e+02, 2.01738190e+04])], 'test_mae': [array([   4.77892362,   83.94397228, 4081.90907919]), array([5.52956599e+00, 9.04333336e+01, 5.38877244e+04]), array([   5.55029573,  102.10756168, 3986.57658219]), array([   5.61543022,   88.93033195, 3521.04125835]), array([   6.48561893,  104.57131564, 4722.72208579])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.056409978380655645, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([1.51700449, 1.38319516, 1.51440477, 1.55748248, 1.49218845]), 'score_time': array([0.07809329, 0.06876469, 0.07130003, 0.0763011 , 0.06834602]), 'test_r2': [array([ 0.27320507,  0.15039809, -0.07234343]), array([ 0.10276658,  0.18432394, -0.04763505]), array([ 0.08565166,  0.1674746 , -0.0206746 ]), array([-0.35458531,  0.23091358, -0.02029832]), array([ 0.2492057 ,  0.01065463, -0.02700691])], 'test_rmse': [array([8.36807665e+00, 1.67174250e+02, 9.07720704e+03]), array([8.47109217e+00, 1.45967808e+02, 2.83064409e+04]), array([9.08480802e+00, 1.37343779e+02, 9.45639665e+04]), array([7.49804558e+00, 1.35740797e+02, 3.25547272e+05]), array([7.57928736e+00, 1.43896349e+02, 1.49911188e+04])], 'test_mae': [array([   5.70491098,  106.54853706, 2461.45302532]), array([   6.01259123,   95.97525339, 6001.74250927]), array([6.54496571e+00, 9.02024587e+01, 1.34505322e+04]), array([5.31697115e+00, 8.48866980e+01, 4.58854234e+04]), array([   5.12394739,  100.35694544, 2480.87627507])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.045621200417375295, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([10.09233904, 10.30171585, 10.21808982, 10.23236537, 10.15983748]), 'score_time': array([0.35847759, 0.38679504, 0.38581228, 0.39875436, 0.35793471]), 'test_r2': [array([ 0.09171132,  0.03398337, -0.03863717]), array([ 0.19829396,  0.14095839, -0.03075764]), array([-0.01565209,  0.15579254, -0.02151339]), array([ 0.2111367 ,  0.26957372, -0.0505972 ]), array([ 0.02308473,  0.20086533, -0.03823931])], 'test_rmse': [array([8.59212998e+00, 1.52689609e+02, 2.39026952e+04]), array([7.79078962e+00, 1.54618208e+02, 6.08012232e+04]), array([6.53116952e+00, 1.50028733e+02, 3.33425172e+05]), array([9.05894241e+00, 1.50730176e+02, 1.41411241e+04]), array([8.86603591e+00, 1.20060872e+02, 1.98503988e+04])], 'test_mae': [array([   6.26478953,  104.96946704, 4610.35838643]), array([5.29065069e+00, 9.85565881e+01, 1.05001897e+04]), array([4.93075966e+00, 1.01437011e+02, 4.83527024e+04]), array([   6.27408801,   93.32464192, 3114.76853114]), array([   6.07611545,   77.96166619, 3808.80108695])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 367, 'regressor__estimator__learning_rate': 0.005332840402870948, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([46.10347605, 45.89582705, 46.06111741, 48.63513231, 46.00362682]), 'score_time': array([1.56596971, 1.51055408, 1.53354788, 1.65121102, 1.57000113]), 'test_r2': [array([ 0.09313208,  0.26370663, -0.01951931]), array([ 0.22167728, -0.02959683, -0.02272847]), array([ 0.17717856,  0.3581063 , -0.04210779]), array([ 0.01099318,  0.12453739, -0.03798962]), array([ 0.15248031,  0.12488881, -0.03741426])], 'test_rmse': [array([7.50957456e+00, 1.41209510e+02, 3.25182553e+05]), array([7.50847742e+00, 1.56638900e+02, 9.45969286e+04]), array([9.21846285e+00, 1.18451290e+02, 3.19639422e+04]), array([9.32338969e+00, 1.45417097e+02, 1.31696185e+04]), array([7.22633177e+00, 1.63532301e+02, 1.19577024e+04])], 'test_mae': [array([5.31226947e+00, 9.71592681e+01, 4.49461601e+04]), array([5.24198705e+00, 1.05252970e+02, 1.40474513e+04]), array([6.34918060e+00, 7.91675257e+01, 6.41187661e+03]), array([   6.28337115,   92.03461318, 2552.14707004]), array([   5.55020526,   97.49786631, 2284.26117619])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1671, 'regressor__estimator__learning_rate': 0.0014349289954744314, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([1.5174067 , 1.52557087, 1.5421772 , 1.45466733, 1.40029955]), 'score_time': array([0.06804252, 0.07208943, 0.07194257, 0.07127738, 0.06917119]), 'test_r2': [array([ 0.21561686,  0.13206674, -0.04165154]), array([ 0.26415543,  0.25284173, -0.02891406]), array([ 0.21247236,  0.25900295, -0.09569535]), array([ 0.02909373,  0.07082445, -0.01729766]), array([ 0.10713596,  0.09559544, -0.06878641])], 'test_rmse': [array([7.82303369e+00, 1.55123137e+02, 1.61343041e+04]), array([8.44049712e+00, 1.07577484e+02, 9.84033703e+04]), array([   7.97966779,  145.12152749, 7795.37630023]), array([8.21248587e+00, 1.90579516e+02, 3.24765114e+05]), array([7.59996477e+00, 1.23640488e+02, 2.36503499e+04])], 'test_mae': [array([   5.43320708,   91.53826277, 3233.16040759]), array([5.73429488e+00, 8.10558502e+01, 1.64677924e+04]), array([   5.71680804,   99.85890734, 2340.22063457]), array([5.72778329e+00, 1.18877403e+02, 4.23178983e+04]), array([5.40535973e+00, 8.53668940e+01, 6.00453639e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.04156950367323965, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([1.50399208, 1.52415681, 1.50000167, 1.378021  , 1.37934065]), 'score_time': array([0.0737648 , 0.06871247, 0.06792259, 0.06742525, 0.06696749]), 'test_r2': [array([ 0.20840792,  0.1193197 , -0.05552518]), array([ 0.15786757,  0.01934895, -0.01673864]), array([ 0.2265972 ,  0.30503302, -0.04889739]), array([-0.05715914,  0.17230781, -0.03566219]), array([ 0.10125048,  0.12868233, -0.0207237 ])], 'test_rmse': [array([6.68557598e+00, 1.76149880e+02, 3.28472259e+04]), array([8.25386614e+00, 1.33260803e+02, 9.41230832e+04]), array([7.99900285e+00, 1.10030031e+02, 9.51588770e+03]), array([8.34457779e+00, 1.70372255e+02, 1.28498382e+04]), array([9.82802759e+00, 1.34090227e+02, 3.27275637e+05])], 'test_mae': [array([4.98302649e+00, 1.08160299e+02, 7.53040379e+03]), array([5.31823029e+00, 9.38101040e+01, 1.20200970e+04]), array([   5.56436571,   80.65983315, 2150.5845314 ]), array([   5.56125868,  109.11464077, 2425.03682173]), array([7.05250430e+00, 8.75922684e+01, 4.65984906e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.05792305355198513, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([6.90397811, 7.00930691, 6.97744322, 6.98059726, 6.94451332]), 'score_time': array([0.24183559, 0.2743752 , 0.3290062 , 0.2721262 , 0.28242111]), 'test_r2': [array([ 0.02157413,  0.04569512, -0.0379842 ]), array([-0.00455671,  0.18282808, -0.01415551]), array([ 0.2500402 ,  0.22760898, -0.01571482]), array([ 0.26728855,  0.12857762, -0.0807892 ]), array([ 0.18558567,  0.23705081, -0.02131079])], 'test_rmse': [array([8.78758621e+00, 1.27179101e+02, 2.51905546e+04]), array([8.02546290e+00, 1.51075834e+02, 9.36129800e+04]), array([7.79596650e+00, 1.37768230e+02, 3.20549483e+05]), array([8.04170538e+00, 1.83136701e+02, 2.27947367e+04]), array([8.08403501e+00, 1.20075809e+02, 5.83074388e+04])], 'test_mae': [array([   6.03610602,   91.25388375, 4836.12435167]), array([5.38988337e+00, 9.01719023e+01, 1.10467641e+04]), array([5.38672711e+00, 9.25192776e+01, 3.98575355e+04]), array([5.83993534e+00, 1.10569250e+02, 6.22209132e+03]), array([5.79063847e+00, 8.54757643e+01, 8.36846952e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 251, 'regressor__estimator__learning_rate': 0.010285657349317788, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([ 0.11988235,  0.15804333, -0.03907943]), 'r2_stdev': array([0.13312998, 0.09176077, 0.02026348]), 'rmse_avg': array([8.14608337e+00, 1.45009873e+02, 9.38088420e+04]), 'rmse_stdev': array([7.34547089e-01, 1.96242454e+01, 1.20182522e+05]), 'mae_avg': array([5.69076476e+00, 9.48955019e+01, 1.40722264e+04]), 'mae_stdev': array([4.93590336e-01, 9.76287053e+00, 1.64566234e+04]), 'r2_avg_aggregate': 0.0796154197339599, 'r2_stdev_aggregate': 0.08171807556698725, 'rmse_avg_aggregate': 31320.66597453099, 'rmse_stdev_aggregate': 40067.62705568183, 'mae_avg_aggregate': 4724.270877912053, 'mae_stdev_aggregate': 5488.959951529701}
scaler
Filename: (PDI-Mw)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n13>
Subject: Job 288767: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c023n02> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:15:14 2025
Job was executed on host(s) <6*c201n13>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:15:16 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:15:16 2025
Terminated at Mon Jan 20 08:45:28 2025
Results reported at Mon Jan 20 08:45:28 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)'                                     --columns_to_impute "PDI"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   158131.39 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.82 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   34213 sec.
    Turnaround time :                            34214 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003794737933710587), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 849), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.5871897255499115e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05889790947231506), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0374514253812812e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.3666274938040117e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019013554513331286), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 168), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.6980259507827906e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.03703415180979626), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 96), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006490488434582707), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 723), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.822546871774115e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [  0.19    0.218 -75.604][1.10000e-01 1.38000e-01 4.28277e+02]
[array([  0.19001426,   0.21791391, -75.60428217]), array([7.83260087e+00, 1.39239447e+02, 1.33877357e+05]), array([5.35901298e+00, 9.17851479e+01, 1.83369439e+04])]
{6: {'fit_time': array([6.26957774, 6.49659348, 6.24181938, 6.24283528, 6.23434591]), 'score_time': array([0.23938799, 0.2427814 , 0.22594404, 0.23538446, 0.23649883]), 'test_r2': [array([-0.04241572,  0.32742527, -0.02747984]), array([ 0.20997389,  0.01683971, -0.02609169]), array([  0.19627614,   0.34131195, -73.98005388]), array([ 0.30222199,  0.17231551, -0.06448331]), array([ 0.20090439,  0.23395315, -0.05764089])], 'test_rmse': [array([6.61333153e+00, 1.16876919e+02, 1.74034938e+04]), array([7.77863809e+00, 1.35546597e+02, 3.38436876e+05]), array([7.91041955e+00, 1.50346266e+02, 2.08135578e+05]), array([8.05223246e+00, 1.51832694e+02, 1.33468180e+04]), array([8.57226656e+00, 1.41157032e+02, 2.01639058e+04])], 'test_mae': [array([   4.5570278 ,   80.15727984, 3876.43916925]), array([5.44958360e+00, 9.27873488e+01, 5.37482980e+04]), array([5.27133438e+00, 1.01384466e+02, 2.41769906e+04]), array([   5.31784131,   89.43693793, 3439.53117738]), array([   5.93750109,   95.25487024, 4717.24125413])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 219, 'regressor__estimator__learning_rate': 0.01843595531141922, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([25.43134546, 25.66154361, 26.00551629, 25.71145654, 25.76856112]), 'score_time': array([0.90567112, 0.91110682, 0.97149229, 0.90235639, 0.92559314]), 'test_r2': [array([0.29256846, 0.23619209, 0.04963396]), array([0.29546486, 0.35186258, 0.12718041]), array([ 0.10471479,  0.20089977, -0.02081052]), array([-0.01257142,  0.24159524, -0.01990036]), array([0.23629287, 0.20881793, 0.00089088])], 'test_rmse': [array([8.25585228e+00, 1.58508925e+02, 8.54536756e+03]), array([7.50650911e+00, 1.30116321e+02, 2.58370247e+04]), array([8.98960522e+00, 1.34558418e+02, 9.45702628e+04]), array([6.48272694e+00, 1.34794866e+02, 3.25483776e+05]), array([7.64418719e+00, 1.28680882e+02, 1.47861063e+04])], 'test_mae': [array([   5.35623576,   95.79441471, 2050.1483542 ]), array([5.16599570e+00, 8.68008576e+01, 5.60061025e+03]), array([6.07176955e+00, 8.94965684e+01, 1.34518001e+04]), array([4.48902155e+00, 8.62214235e+01, 4.58039609e+04]), array([   5.266271  ,   91.88557137, 2493.66707877])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 978, 'regressor__estimator__learning_rate': 0.004817527117835808, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([6.11757016, 6.34364009, 6.06816673, 6.36638141, 6.01028585]), 'score_time': array([0.31297493, 0.243469  , 0.22831345, 0.22635889, 0.22616625]), 'test_r2': [array([0.28009001, 0.06677503, 0.0444498 ]), array([ 0.17847181,  0.29276328, -0.0299225 ]), array([ 0.24508828,  0.09835824, -0.02149904]), array([ 0.17687342,  0.37253818, -0.03300173]), array([0.0700378 , 0.26658376, 0.08610014])], 'test_rmse': [array([7.64941083e+00, 1.50075693e+02, 2.29267078e+04]), array([7.88651502e+00, 1.40292978e+02, 6.07765872e+04]), array([5.63075405e+00, 1.55048247e+02, 3.33422830e+05]), array([9.25358326e+00, 1.39702978e+02, 1.40222058e+04]), array([8.65035015e+00, 1.15018253e+02, 1.86238647e+04])], 'test_mae': [array([   5.49771748,  107.34478719, 4228.57441558]), array([5.19894296e+00, 8.73161573e+01, 1.02745633e+04]), array([4.17205578e+00, 1.08491385e+02, 4.81898154e+04]), array([   6.15635441,   87.32176335, 2935.88480418]), array([   6.06979261,   75.03417806, 3563.64483424])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 217, 'regressor__estimator__learning_rate': 0.018048901916532224, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([6.50602341, 6.36178041, 6.18737316, 6.39363146, 6.22513342]), 'score_time': array([0.24085236, 0.23161745, 0.23210216, 0.22717094, 0.22954869]), 'test_r2': [array([ 0.25292128,  0.28527772, -0.01865329]), array([ 0.28417865,  0.11465207, -0.01962018]), array([0.09514758, 0.48636244, 0.05404916]), array([ 0.08887706,  0.11101013, -0.02533907]), array([ 0.18192691,  0.1587085 , -0.03428502])], 'test_rmse': [array([6.81595158e+00, 1.39125635e+02, 3.25044414e+05]), array([7.20069384e+00, 1.45252299e+02, 9.44530691e+04]), array([9.66706384e+00, 1.05958702e+02, 3.04535761e+04]), array([8.94875637e+00, 1.46536251e+02, 1.30891198e+04]), array([7.09968450e+00, 1.60341219e+02, 1.19396542e+04])], 'test_mae': [array([4.82809965e+00, 9.41468994e+01, 4.44169169e+04]), array([4.70401066e+00, 9.68992198e+01, 1.36092182e+04]), array([   6.24394348,   76.09754625, 6029.02474179]), array([   5.89303793,   93.64706737, 2597.36477352]), array([   5.22201094,   92.20999675, 2225.00416505])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 220, 'regressor__estimator__learning_rate': 0.020236923873442097, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([5.54065061, 5.77118182, 5.53726673, 5.69155836, 5.43563199]), 'score_time': array([0.2032032 , 0.21686888, 0.20344138, 0.20873284, 0.2056694 ]), 'test_r2': [array([ 0.09844631,  0.17670903, -0.01096343]), array([ 0.37444254,  0.4392974 , -0.02621902]), array([ 0.48466756,  0.33507071, -0.07742302]), array([ 0.05574514,  0.27287337, -0.01722702]), array([ 0.03895716, -0.23349949, -0.03458507])], 'test_rmse': [array([8.38700447e+00, 1.51081083e+02, 1.58948609e+04]), array([7.78231108e+00, 9.31925860e+01, 9.82744116e+04]), array([6.45499110e+00, 1.37471076e+02, 7.73010337e+03]), array([8.09898502e+00, 1.68590213e+02, 3.24753838e+05]), array([7.88479284e+00, 1.44393893e+02, 2.32688656e+04])], 'test_mae': [array([   5.75011755,   90.57280289, 3186.04021925]), array([4.92349966e+00, 6.95755902e+01, 1.63251958e+04]), array([   4.35539085,   95.58558564, 2191.10352985]), array([5.15810020e+00, 1.05721411e+02, 4.21676612e+04]), array([5.41457348e+00, 9.65425958e+01, 5.70840867e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 190, 'regressor__estimator__learning_rate': 0.040257787722792475, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([23.17682767, 22.87833452, 22.6743443 , 24.40914583, 22.92926288]), 'score_time': array([0.81758571, 0.80782771, 0.78310513, 0.92820382, 0.77720118]), 'test_r2': [array([ 0.08950781,  0.22860297, -0.04742154]), array([ 0.24894772,  0.01349432, -0.01650154]), array([0.24970562, 0.41846523, 0.03900398]), array([ 0.08187634,  0.23952019, -0.03497335]), array([ 0.22389978,  0.02955177, -0.02009499])], 'test_rmse': [array([7.17011666e+00, 1.64858822e+02, 3.27208930e+04]), array([7.79475214e+00, 1.33658004e+02, 9.41121077e+04]), array([7.87859592e+00, 1.00650745e+02, 9.10843158e+03]), array([7.77651066e+00, 1.63308311e+02, 1.28455642e+04]), array([9.13284179e+00, 1.41512581e+02, 3.27174831e+05])], 'test_mae': [array([5.25791845e+00, 1.01544571e+02, 7.47417451e+03]), array([5.42973395e+00, 9.59948269e+01, 1.19952129e+04]), array([   5.77238659,   76.84046469, 2040.3416186 ]), array([   5.44146411,  108.32126725, 2448.24947113]), array([6.39382389e+00, 9.35679714e+01, 4.61900795e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 837, 'regressor__estimator__learning_rate': 0.002874949342515079, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([1.51038861, 1.5442605 , 1.50643301, 1.65616989, 1.51340127]), 'score_time': array([0.07791638, 0.07404256, 0.07215095, 0.13756824, 0.07623911]), 'test_r2': [array([ 1.25553573e-01,  3.22123537e-01, -2.57183634e+03]), array([ 0.20583596,  0.20243731, -0.01398203]), array([ 0.19511869,  0.25982956, -0.01567913]), array([ 0.32418125,  0.18553565, -0.00894311]), array([ 0.21657044,  0.15273279, -0.01205019])], 'test_rmse': [array([8.30753614e+00, 1.07188318e+02, 1.25414698e+06]), array([7.13572280e+00, 1.49252185e+02, 9.36049731e+04]), array([8.07638279e+00, 1.34864093e+02, 3.20543851e+05]), array([7.72319124e+00, 1.77050465e+02, 2.20240620e+04]), array([7.92876341e+00, 1.26537110e+02, 5.80424894e+04])], 'test_mae': [array([5.53216889e+00, 7.36517430e+01, 1.39424536e+05]), array([4.97235557e+00, 8.70056110e+01, 1.09544398e+04]), array([5.41000194e+00, 9.28139776e+01, 3.97342216e+04]), array([5.31302714e+00, 1.06624968e+02, 5.92939780e+03]), array([5.57234432e+00, 9.03880513e+01, 8.59527452e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([  0.19001426,   0.21791391, -75.60428217]), 'r2_stdev': array([1.09598525e-01, 1.38136937e-01, 4.28277447e+02]), 'rmse_avg': array([7.83260087e+00, 1.39239447e+02, 1.33877357e+05]), 'rmse_stdev': array([8.44067905e-01, 1.90151412e+01, 2.26808591e+05]), 'mae_avg': array([5.35901298e+00, 9.17851479e+01, 1.83369439e+04]), 'mae_stdev': array([5.23330397e-01, 9.79804521e+00, 2.64199683e+04]), 'r2_avg_aggregate': -25.065451334918517, 'r2_stdev_aggregate': 142.8417274664874, 'rmse_avg_aggregate': 44674.809731320005, 'rmse_stdev_aggregate': 75609.48353792985, 'mae_avg_aggregate': 6144.696011029551, 'mae_stdev_aggregate': 8810.096559679301}
scaler
Filename: (PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n05>
Subject: Job 288737: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c039n03> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:03:13 2025
Job was executed on host(s) <6*c201n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:03:15 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:03:15 2025
Terminated at Mon Jan 20 08:51:19 2025
Results reported at Mon Jan 20 08:51:19 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   160746.28 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.89 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   35301 sec.
    Turnaround time :                            35286 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.014915130199323869), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006266082423567262), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 560), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0008674883526748464), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.012380447064726493), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 121), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0005777979925246829), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1863), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009291164052998842), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09899856540492477), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 161), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.3527825731996607e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0004779147729407262), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0029747411089792552), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 365), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0036924453874579138), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 344), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0466146096711547e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005385814711958247), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 141), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02540264952182542), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0008482557860846624), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 714), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09660461721523969), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 57), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.88427454268843e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0020356184235582326), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 209), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00778381142992043), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 378), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.001179364890736555), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 894), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006936569576784391), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 126), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0009905067455584198), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 833), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0015406186568812403), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1011), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.021266789181958522), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 51), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00013337568127875737), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0050222557402816665), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 256), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00024014464659768343), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019951756261388155), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.058  0.182 -0.041][0.139 0.11  0.023]
[array([ 0.05835182,  0.18206455, -0.04149116]), array([8.42523739e+00, 1.42807112e+02, 9.38239703e+04]), array([6.22876371e+00, 9.77658434e+01, 1.41117408e+04])]
{6: {'fit_time': array([1.51926613, 1.51297903, 1.71224713, 1.50995278, 1.50321031]), 'score_time': array([0.06074929, 0.05791306, 0.07021141, 0.05913138, 0.06002927]), 'test_r2': [array([-0.26157493,  0.27244843, -0.05778006]), array([ 0.09722017, -0.02215912, -0.02611623]), array([ 0.09737938,  0.36030154, -0.0277588 ]), array([ 0.13428796,  0.08695227, -0.07440319]), array([ 0.05866756,  0.11430686, -0.06074104])], 'test_rmse': [array([7.27539109e+00, 1.21559911e+02, 1.76582424e+04]), array([8.31522044e+00, 1.38208804e+02, 3.38440923e+05]), array([8.38298548e+00, 1.48163220e+02, 2.43679532e+04]), array([8.96900766e+00, 1.59470234e+02, 1.34088629e+04]), array([9.30395941e+00, 1.51780679e+02, 2.01934364e+04])], 'test_mae': [array([   5.46426053,   93.44336157, 4131.76988065]), array([6.25970892e+00, 9.43569901e+01, 5.39825073e+04]), array([   5.89193871,   97.69677766, 4006.16957944]), array([   6.53209347,  101.49705468, 3538.73826238]), array([   6.93796195,  103.20627031, 4835.53898902])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.02483675969428454, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([24.74691558, 25.12173843, 24.74816084, 25.29121113, 25.01661777]), 'score_time': array([0.85558128, 0.86041594, 0.89293528, 0.88021398, 0.92791867]), 'test_r2': [array([ 0.22562533,  0.22926951, -0.08023496]), array([ 0.16529732,  0.25930159, -0.04820437]), array([-0.00580948,  0.1593782 , -0.02068917]), array([-0.2989873 ,  0.25946813, -0.02029969]), array([ 0.19013858,  0.14468817, -0.02845156])], 'test_rmse': [array([8.63764347e+00, 1.59225607e+02, 9.11054606e+03]), array([8.17057439e+00, 1.39097374e+02, 2.83141311e+04]), array([9.52835166e+00, 1.38010004e+02, 9.45646416e+04]), array([7.34255736e+00, 1.33197079e+02, 3.25547489e+05]), array([7.87178542e+00, 1.33794436e+02, 1.50016588e+04])], 'test_mae': [array([   6.07912337,  105.24510391, 2516.53931878]), array([   6.31304612,   98.20112838, 6072.00663315]), array([7.14950258e+00, 9.47547535e+01, 1.34612367e+04]), array([5.73978952e+00, 8.90745373e+01, 4.59154653e+04]), array([   5.6855028 ,   99.50216968, 2508.962051  ])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 934, 'regressor__estimator__learning_rate': 0.0013330897520445692, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([1.43682575, 1.45190167, 1.75739098, 1.63089156, 1.64846778]), 'score_time': array([0.0568893 , 0.05626392, 0.06376648, 0.06184149, 0.06015873]), 'test_r2': [array([ 0.09407464,  0.07532359, -0.03937896]), array([ 0.11577112,  0.15756843, -0.03084852]), array([-0.1231028 ,  0.19062746, -0.0215162 ]), array([ 0.10355498,  0.2625006 , -0.05130965]), array([-0.03136954,  0.24319331, -0.03871208])], 'test_rmse': [array([8.58094457e+00, 1.49386747e+02, 2.39112292e+04]), array([8.18193915e+00, 1.53116098e+02, 6.08039037e+04]), array([6.86796744e+00, 1.46900774e+02, 3.33425630e+05]), array([9.65691600e+00, 1.51458220e+02, 1.41459181e+04]), array([9.10978629e+00, 1.16837966e+02, 1.98549178e+04])], 'test_mae': [array([   6.33616227,  100.38058026, 4654.96158128]), array([6.16903557e+00, 1.00564189e+02, 1.05182659e+04]), array([5.53658687e+00, 1.06082063e+02, 4.83889894e+04]), array([   7.05051674,  102.10140771, 3125.75674564]), array([   6.94196799,   83.60163843, 3833.57497793])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.014915130199323869, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([5.12322664, 6.39754915, 6.3706193 , 6.72223425, 5.13084459]), 'score_time': array([0.16329002, 0.17106032, 0.15772176, 0.22983289, 0.16958356]), 'test_r2': [array([-0.05755339,  0.14844159, -0.01951268]), array([ 0.21343595,  0.06008455, -0.02253537]), array([ 0.13056442,  0.49663275, -0.04145981]), array([-0.12124551,  0.0232863 , -0.08660723]), array([-0.15533277,  0.10002813, -0.03566037])], 'test_rmse': [array([8.10950724e+00, 1.51860813e+02, 3.25181496e+05]), array([7.54812477e+00, 1.49661613e+02, 9.45879977e+04]), array([9.47598610e+00, 1.04894017e+02, 3.19540030e+04]), array([9.92714929e+00, 1.53596143e+02, 1.34745101e+04]), array([8.43716500e+00, 1.65838896e+02, 1.19475900e+04])], 'test_mae': [array([5.77328265e+00, 1.05380870e+02, 4.49400520e+04]), array([5.31441233e+00, 9.44925356e+01, 1.38514428e+04]), array([   6.70228388,   77.41084255, 6356.57645343]), array([   6.79813645,   98.07204373, 2937.06423587]), array([   6.18826294,   98.21959777, 2262.00342583])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 161, 'regressor__estimator__learning_rate': 0.09899856540492477, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([1.42417717, 1.50513244, 1.77326655, 1.80599117, 1.38294315]), 'score_time': array([0.05838847, 0.05939722, 0.10507131, 0.0607152 , 0.05840468]), 'test_r2': [array([ 0.06385009,  0.11624328, -0.04224696]), array([ 0.22951684,  0.28311191, -0.02894259]), array([ 0.22276957,  0.36882765, -0.10107426]), array([ 0.04366305,  0.06448381, -0.01729958]), array([ 0.06628922,  0.13314773, -0.06919574])], 'test_rmse': [array([8.54641105e+00, 1.56530791e+02, 1.61389147e+04]), array([8.63687349e+00, 1.05375770e+02, 9.84047349e+04]), array([   7.92732761,  133.93607923, 7814.48715206]), array([8.15063510e+00, 1.91228663e+02, 3.24765420e+05]), array([7.77186235e+00, 1.21046402e+02, 2.36548783e+04])], 'test_mae': [array([   6.29625259,  100.54535949, 3254.98768693]), array([6.16780005e+00, 8.46288551e+01, 1.65004723e+04]), array([   5.79564615,   93.56659081, 2377.61191423]), array([6.08452906e+00, 1.22318809e+02, 4.23475584e+04]), array([6.02078096e+00, 8.88173920e+01, 6.02128819e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.02540264952182542, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([23.93095827, 24.17413592, 23.6419301 , 24.16646981, 23.6522913 ]), 'score_time': array([0.89682937, 0.82650495, 0.80265331, 0.84114623, 0.84427905]), 'test_r2': [array([ 0.09006693,  0.09128308, -0.05634711]), array([ 0.1700357 ,  0.05365811, -0.01677716]), array([ 0.16480281,  0.37374599, -0.05658811]), array([-0.1520186 ,  0.23836834, -0.03825142]), array([ 0.14323497,  0.13178464, -0.02072933])], 'test_rmse': [array([7.16791478e+00, 1.78931795e+02, 3.28600124e+04]), array([8.19401831e+00, 1.30908910e+02, 9.41248660e+04]), array([8.31242026e+00, 1.04449030e+02, 9.55071017e+03]), array([8.71091805e+00, 1.63431941e+02, 1.28658909e+04]), array([9.59572728e+00, 1.33851302e+02, 3.27276541e+05])], 'test_mae': [array([5.62967240e+00, 1.13867852e+02, 7.58954967e+03]), array([5.72139371e+00, 9.74459188e+01, 1.20879340e+04]), array([   6.53827082,   83.3436469 , 2221.0402602 ]), array([   6.46436736,  111.03665696, 2476.13779666]), array([7.07875149e+00, 9.18040996e+01, 4.66347320e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 894, 'regressor__estimator__learning_rate': 0.001179364890736555, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([1.4866631 , 1.49889803, 1.51111627, 1.44686532, 1.48480225]), 'score_time': array([0.05464029, 0.06162953, 0.06220841, 0.05592918, 0.06233907]), 'test_r2': [array([-0.12607938,  0.1372287 , -0.03911845]), array([ 0.07870844,  0.19685667, -0.01419261]), array([ 0.19682327,  0.25962478, -0.01571633]), array([ 0.20235628,  0.1661727 , -0.0820768 ]), array([ 0.07725295,  0.13607942, -0.02141407])], 'test_rmse': [array([9.42736101e+00, 1.20926093e+02, 2.52043142e+04]), array([7.68566424e+00, 1.49773442e+02, 9.36146925e+04]), array([8.06782615e+00, 1.34882749e+02, 3.20549721e+05]), array([8.39046723e+00, 1.79142689e+02, 2.28083109e+04]), array([8.60491958e+00, 1.27774627e+02, 5.83103868e+04])], 'test_mae': [array([   6.8274981 ,   89.74248078, 4892.37541871]), array([5.58716424e+00, 9.71568071e+01, 1.10744000e+04]), array([6.09729748e+00, 9.72946191e+01, 3.98706708e+04]), array([   6.44198822,  112.29272475, 6282.96847365]), array([6.39174168e+00, 9.46587929e+01, 8.44157980e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.019951756261388155, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([ 0.05835182,  0.18206455, -0.04149116]), 'r2_stdev': array([0.13893109, 0.1100622 , 0.02286738]), 'rmse_avg': array([8.42523739e+00, 1.42807112e+02, 9.38239703e+04]), 'rmse_stdev': array([7.47437611e-01, 2.03640652e+01, 1.20172689e+05]), 'mae_avg': array([6.22876371e+00, 9.77658434e+01, 1.41117408e+04]), 'mae_stdev': array([4.95306810e-01, 9.02330917e+00, 1.64496292e+04]), 'r2_avg_aggregate': 0.06630840464343078, 'r2_stdev_aggregate': 0.09062022358569466, 'rmse_avg_aggregate': 31325.06756573165, 'rmse_stdev_aggregate': 40064.60008462114, 'mae_avg_aggregate': 4738.578472638038, 'mae_stdev_aggregate': 5486.382617337596}
scaler
Filename: (polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n06>
Subject: Job 288785: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c201n10> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:21:24 2025
Job was executed on host(s) <6*c201n06>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:21:24 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:21:24 2025
Terminated at Mon Jan 20 08:59:02 2025
Results reported at Mon Jan 20 08:59:02 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   152389.06 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.75 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   34679 sec.
    Turnaround time :                            34658 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010833148036662217), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0023645301224487036), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 294), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008349627423529925), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 87), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0042935068486233685), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 148), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0006520272203712914), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 779), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.000796722940610063), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1099), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00033491369392795784), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 2000), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.008843335352811978), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 117), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004952957888556596), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 167), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.003972618483802132), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 163), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00035964349568493693), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1938), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.390918243557952e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0020387277348597865), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 352), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0006123794816738515), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0012264638395077304), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 638), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00876748789063011), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.006151031161668558), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 71), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0009034943317393439), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.013010391217743826), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0007374481740254744), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 463), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.0005193187251642418), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0015329912780176103), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 354), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.002379714152529786), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 444), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.048  0.068 -0.041][0.122 0.072 0.022]
[array([ 0.04778292,  0.06752526, -0.04057391]), array([8.48220580e+00, 1.52732811e+02, 9.38188954e+04]), array([6.44725429e+00, 1.02158757e+02, 1.41217101e+04])]
{6: {'fit_time': array([2.19341707, 2.22598004, 2.26107001, 2.23276019, 2.20240331]), 'score_time': array([0.08019066, 0.08538508, 0.08674693, 0.08205032, 0.08159256]), 'test_r2': [array([-0.20489736,  0.1086811 , -0.05822495]), array([ 0.03294515, -0.12878569, -0.02611814]), array([ 0.0328328 ,  0.12974572, -0.02783677]), array([ 0.18284973,  0.07158433, -0.07501854]), array([ 0.03452299,  0.03659767, -0.06112797])], 'test_rmse': [array([7.11008588e+00, 1.34547317e+02, 1.76619554e+04]), array([8.60613981e+00, 1.45238650e+02, 3.38441238e+05]), array([8.67754487e+00, 1.72812773e+02, 2.43688775e+04]), array([8.71382092e+00, 1.60806694e+02, 1.34127023e+04]), array([9.42252421e+00, 1.58299192e+02, 2.01971191e+04])], 'test_mae': [array([   5.47546091,   96.79280679, 4142.89986643]), array([6.53180242e+00, 1.00297141e+02, 5.39952680e+04]), array([   6.38707513,  107.19122962, 4010.35817287]), array([   6.69390401,  103.19052226, 3543.17666923]), array([   7.16461439,  106.22926125, 4847.58746228])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 77, 'regressor__estimator__learning_rate': 0.010354779668361845, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([55.4434154 , 53.33020067, 54.44873881, 54.01128554, 51.48811603]), 'score_time': array([1.96361637, 1.89099431, 1.84950542, 1.81861973, 1.73738503]), 'test_r2': [array([ 0.19435884,  0.07034277, -0.08354123]), array([ 0.09597414,  0.06202147, -0.04831239]), array([ 0.03017907,  0.20000043, -0.02069531]), array([-0.32025195,  0.03754627, -0.02030007]), array([ 0.14951909, -0.00449993, -0.02888596])], 'test_rmse': [array([8.81029659e+00, 1.74873125e+02, 9.12447768e+03]), array([8.50309660e+00, 1.56528952e+02, 2.83155900e+04]), array([9.35633346e+00, 1.34634115e+02, 9.45649259e+04]), array([7.40241288e+00, 1.51849286e+02, 3.25547551e+05]), array([8.06677929e+00, 1.44994246e+02, 1.50048267e+04])], 'test_mae': [array([   6.3513598 ,  110.97894161, 2533.62259148]), array([   6.63387032,  103.8360685 , 6078.68524499]), array([7.09440570e+00, 8.98850381e+01, 1.34653619e+04]), array([5.86098250e+00, 9.96383081e+01, 4.59197271e+04]), array([   6.0157052 ,  103.65648534, 2514.15043446])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.0005269235146499754, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([3.74628544, 3.74273324, 4.3930428 , 4.43863916, 3.81927919]), 'score_time': array([0.13511348, 0.13477683, 0.13791895, 0.14550686, 0.14421368]), 'test_r2': [array([ 0.01056292, -0.02876381, -0.03941125]), array([ 0.12366965,  0.12292125, -0.03085698]), array([-0.22742098,  0.08116755, -0.02151636]), array([ 0.12915689,  0.11695489, -0.05134985]), array([-0.00487639,  0.04316329, -0.03873773])], 'test_rmse': [array([8.96773940e+00, 1.57570539e+02, 2.39116007e+04]), array([8.14531390e+00, 1.56233021e+02, 6.08041529e+04]), array([7.17984791e+00, 1.56519342e+02, 3.33425656e+05]), array([9.51801932e+00, 1.65730888e+02, 1.41461886e+04]), array([8.99202198e+00, 1.31374302e+02, 1.98551629e+04])], 'test_mae': [array([   6.78432439,  101.42420024, 4656.1311946 ]), array([6.13010187e+00, 1.05085049e+02, 1.05198795e+04]), array([5.87124296e+00, 1.09457257e+02, 4.83905668e+04]), array([   7.07111804,  107.76058634, 3126.33511755]), array([   6.81056575,   90.95505212, 3834.31451914])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 138, 'regressor__estimator__learning_rate': 0.004274980655872327, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([2.59872293, 2.73761249, 2.4935348 , 2.39067936, 2.61716604]), 'score_time': array([0.1139338 , 0.12215638, 0.09306645, 0.09898853, 0.11468315]), 'test_r2': [array([-0.03033845,  0.10379933, -0.01952413]), array([ 0.18934396,  0.00485769, -0.02284035]), array([ 0.04879761,  0.13575678, -0.04258462]), array([-0.07177269,  0.06716386, -0.04042158]), array([ 0.07942743,  0.0780909 , -0.03877489])], 'test_rmse': [array([8.00448266e+00, 1.55790557e+02, 3.25183322e+05]), array([7.66285018e+00, 1.53995711e+02, 9.46021027e+04]), array([9.9115637e+00, 1.3744414e+02, 3.1971254e+04]), array([9.70567035e+00, 1.50106449e+02, 1.31850374e+04]), array([7.53133579e+00, 1.67847926e+02, 1.19655414e+04])], 'test_mae': [array([6.30472072e+00, 1.07944260e+02, 4.50002898e+04]), array([5.99609454e+00, 1.03617689e+02, 1.41367067e+04]), array([   7.09459704,   90.98300983, 6461.4574996 ]), array([   7.16621477,  101.40531704, 2598.88415586]), array([   6.19904554,  107.31863001, 2311.78388131])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 87, 'regressor__estimator__learning_rate': 0.008349627423529925, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([3.20592523, 3.26958776, 3.80250049, 3.81526542, 3.17181206]), 'score_time': array([0.12528658, 0.11759043, 0.1805439 , 0.16163516, 0.11526608]), 'test_r2': [array([ 0.085265  ,  0.16296909, -0.0425482 ]), array([ 0.14707618,  0.14163887, -0.02895066]), array([ 0.1225915 ,  0.15600306, -0.10246529]), array([ 0.04632291, -0.1511389 , -0.01730071]), array([ 0.09597971,  0.06451111, -0.06994657])], 'test_rmse': [array([8.44809374e+00, 1.52336566e+02, 1.61412469e+04]), array([9.08720034e+00, 1.15305520e+02, 9.84051208e+04]), array([   8.42272899,  154.87953468, 7819.42175252]), array([8.13929253e+00, 2.12124680e+02, 3.24765601e+05]), array([7.64729780e+00, 1.25747297e+02, 2.36631825e+04])], 'test_mae': [array([   6.33619359,  102.05511335, 3260.84112435]), array([6.68730974e+00, 8.62966908e+01, 1.65062990e+04]), array([   6.26608795,  101.87120955, 2383.86012059]), array([6.27582736e+00, 1.30332514e+02, 4.23523843e+04]), array([5.91827030e+00, 8.91823830e+01, 6.05027881e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 117, 'regressor__estimator__learning_rate': 0.008843335352811978, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([17.18021703, 17.10939574, 17.3273592 , 17.1896472 , 16.97777319]), 'score_time': array([0.57280827, 0.58068085, 0.6071279 , 0.62022686, 0.60757685]), 'test_r2': [array([ 0.0689988 ,  0.01857171, -0.0564768 ]), array([ 0.04738459,  0.01868121, -0.0167816 ]), array([ 0.16489761,  0.11768385, -0.05739542]), array([-0.09741597,  0.06911555, -0.03858183]), array([ 0.1250397 ,  0.12543487, -0.02073029])], 'test_rmse': [array([7.25042108e+00, 1.85952704e+02, 3.28620295e+04]), array([8.77861545e+00, 1.33306165e+02, 9.41250715e+04]), array([8.31194848e+00, 1.23977041e+02, 9.55435819e+03]), array([8.50197496e+00, 1.80680936e+02, 1.28679380e+04]), array([9.69708507e+00, 1.34339876e+02, 3.27276694e+05])], 'test_mae': [array([5.75051295e+00, 1.15171578e+02, 7.59800388e+03]), array([6.24729726e+00, 9.80649809e+01, 1.20922791e+04]), array([   6.66733276,   91.65832029, 2225.98191356]), array([   6.39963779,  116.45943315, 2480.16346483]), array([7.44260972e+00, 9.19787218e+01, 4.66403963e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 638, 'regressor__estimator__learning_rate': 0.0012264638395077304, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([11.87747049, 11.84986854, 12.26116323, 11.70493031, 11.86741853]), 'score_time': array([0.41086578, 0.40816784, 0.42837334, 0.40415621, 0.43041015]), 'test_r2': [array([-0.09016112,  0.00165218, -0.03924597]), array([-0.01736883,  0.09767031, -0.01419866]), array([ 0.21746864,  0.09080031, -0.01571678]), array([ 0.19626826,  0.07537574, -0.08224411]), array([ 0.08547291,  0.06606934, -0.02142485])], 'test_rmse': [array([9.27579154e+00, 1.30080775e+02, 2.52058607e+04]), array([8.07647916e+00, 1.58752621e+02, 9.36149715e+04]), array([7.96346085e+00, 1.49472091e+02, 3.20549792e+05]), array([8.42242649e+00, 1.88644295e+02, 2.28100742e+04]), array([8.56650691e+00, 1.32851062e+02, 5.83106947e+04])], 'test_mae': [array([   6.87603886,   94.63014842, 4898.24040085]), array([5.96163221e+00, 9.98032814e+01, 1.10766851e+04]), array([6.14469224e+00, 1.01065829e+02, 3.98741080e+04]), array([   6.61356429,  115.97811845, 6288.05875177]), array([6.42968702e+00, 9.33613162e+01, 8.44508544e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 444, 'regressor__estimator__learning_rate': 0.002379714152529786, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([ 0.04778292,  0.06752526, -0.04057391]), 'r2_stdev': array([0.12215668, 0.0719296 , 0.02189316]), 'rmse_avg': array([8.48220580e+00, 1.52732811e+02, 9.38188954e+04]), 'rmse_stdev': array([7.40205391e-01, 2.01902363e+01, 1.20176692e+05]), 'mae_avg': array([6.44725429e+00, 1.02158757e+02, 1.41217101e+04]), 'mae_stdev': array([4.57634991e-01, 9.05879774e+00, 1.64566906e+04]), 'r2_avg_aggregate': 0.02491142545342835, 'r2_stdev_aggregate': 0.07199314545381293, 'rmse_avg_aggregate': 31326.703470317032, 'rmse_stdev_aggregate': 40065.87406249044, 'mae_avg_aggregate': 4743.438690629583, 'mae_stdev_aggregate': 5488.735681183304}
scaler
Filename: (polymer dP-polymer dD-polymer dH)_NGB_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(polymer dP-polymer dD-polymer dH)_NGB_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(polymer dP-polymer dD-polymer dH)_NGB_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(polymer dP-polymer dD-polymer dH)_NGB_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n10>
Subject: Job 288795: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c023n02> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:23:15 2025
Job was executed on host(s) <6*c201n10>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:23:16 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:23:16 2025
Terminated at Mon Jan 20 09:02:03 2025
Results reported at Mon Jan 20 09:02:03 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats "polymer dP" "polymer dD" "polymer dH"                                


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   153393.14 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.75 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   34743 sec.
    Turnaround time :                            34728 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.01480138218389328), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 507), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 9.08331155930982e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.010400123029701334), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 124), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.04387691012296149), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 60), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.740424862595285e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.00313407794920592), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1008), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.3271115597778825e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.1), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1633), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0052865877799675234), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 343), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.001), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.019013554513331286), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 168), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.6980259507827906e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05444800396226463), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 169), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.015410931076297422), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 150), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.969799118250895e-05), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.02408798419267564), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 511), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 0.00010335580926562485), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [ 0.178  0.281 -4.273][ 0.118  0.118 21.357]
[array([ 0.17847202,  0.28054992, -4.27323855]), array([7.88187037e+00, 1.33696391e+02, 1.02924139e+05]), array([5.22245156e+00, 8.76356720e+01, 1.49719263e+04])]
{6: {'fit_time': array([55.24765873, 54.69090176, 55.08460927, 55.26144147, 53.74320245]), 'score_time': array([1.863096  , 1.8855629 , 1.98359728, 1.98485231, 1.81585097]), 'test_r2': [array([-0.00892656,  0.48685552, -0.00371579]), array([ 0.23730196,  0.00332663, -0.02609619]), array([  0.19057198,   0.43153032, -11.38000232]), array([ 0.26763828,  0.16910461, -0.06296518]), array([ 0.18272929,  0.23535251, -0.05460971])], 'test_rmse': [array([6.50623277e+00, 1.02088850e+02, 1.72010581e+04]), array([7.64291731e+00, 1.36474930e+02, 3.38437619e+05]), array([7.93844071e+00, 1.39671053e+02, 8.45734043e+04]), array([8.24936431e+00, 1.52126918e+02, 1.33372972e+04]), array([8.66920474e+00, 1.41028045e+02, 2.01349904e+04])], 'test_mae': [array([   4.41577873,   75.30141003, 4039.644071  ]), array([5.34825513e+00, 8.93645928e+01, 5.37782827e+04]), array([5.06877930e+00, 9.69645906e+01, 1.04880632e+04]), array([   5.41304965,   85.45988344, 3417.7191861 ]), array([   5.86114358,   91.41580709, 4641.516167  ])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 2000, 'regressor__estimator__learning_rate': 0.0018237436441454107, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([45.44808602, 50.34124255, 44.02078724, 47.07723618, 46.18691993]), 'score_time': array([1.03846169, 1.0601759 , 0.97819805, 1.04246783, 0.97658849]), 'test_r2': [array([0.31990336, 0.34726586, 0.17396928]), array([0.25153573, 0.32927771, 0.61273286]), array([-0.00101431,  0.20647786, -0.0224836 ]), array([ 0.01232945,  0.23020779, -0.01835062]), array([  0.2380827 ,   0.23946234, -11.86941409])], 'test_rmse': [array([   8.09477943,  146.53109967, 7966.79041859]), array([7.73699333e+00, 1.32363912e+02, 1.72101867e+04]), array([9.50561143e+00, 1.34087956e+02, 9.46477300e+04]), array([6.40252006e+00, 1.35803068e+02, 3.25236396e+05]), array([7.63522442e+00, 1.26164210e+02, 5.30672704e+04])], 'test_mae': [array([   4.91442284,   90.98262869, 2163.24241525]), array([   5.10488702,   88.83550203, 3784.47596536]), array([6.10239194e+00, 8.03763718e+01, 1.41286079e+04]), array([4.04982697e+00, 8.28121004e+01, 4.51214610e+04]), array([4.86504625e+00, 8.63084708e+01, 7.70329148e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1045, 'regressor__estimator__learning_rate': 0.049485633681557506, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([1.74310088, 1.6425252 , 1.57110357, 1.82429338, 1.82451773]), 'score_time': array([0.07382584, 0.10083222, 0.07461929, 0.10491252, 0.1027534 ]), 'test_r2': [array([0.27257404, 0.16562996, 0.61997366]), array([ 0.12009479,  0.33112264, -0.02996979]), array([ 0.13208453,  0.21161343, -0.0215015 ]), array([ 0.20477351,  0.50447689, -0.03758524]), array([0.12603587, 0.26746484, 0.27218407])], 'test_rmse': [array([7.68923766e+00, 1.41904619e+02, 1.44584518e+04]), array([8.16191077e+00, 1.36435311e+02, 6.07779822e+04]), array([6.03750062e+00, 1.44983794e+02, 3.33423232e+05]), array([9.09540502e+00, 1.24149212e+02, 1.40532802e+04]), array([8.38586451e+00, 1.14949145e+02, 1.66200100e+04])], 'test_mae': [array([   5.17514758,   95.70594335, 3356.81802156]), array([5.10376655e+00, 8.49036901e+01, 1.03098996e+04]), array([4.21632328e+00, 9.89898683e+01, 4.82185437e+04]), array([   5.91202401,   79.276508  , 3005.36097197]), array([   5.14748286,   75.03168509, 3259.56011752])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([6.37688971, 6.60540032, 7.00779486, 7.20583439, 6.40661216]), 'score_time': array([0.22904539, 0.22400427, 0.30214977, 0.40644813, 0.22022629]), 'test_r2': [array([ 0.17667023,  0.33304325, -0.01948145]), array([ 0.30806466,  0.14249789, -0.02141798]), array([ 0.04408993,  0.49333373, -0.03179399]), array([0.06619991, 0.24546662, 0.31912219]), array([ 0.16053403,  0.27333223, -0.03705165])], 'test_rmse': [array([7.15533915e+00, 1.34396307e+02, 3.25176516e+05]), array([7.07953577e+00, 1.42949825e+02, 9.45363024e+04]), array([9.93606053e+00, 1.05237189e+02, 3.18053743e+04]), array([9.05943576e+00, 1.35000662e+02, 1.06662382e+04]), array([7.19191497e+00, 1.49018394e+02, 1.19556124e+04])], 'test_mae': [array([5.11403434e+00, 9.38688621e+01, 4.49392457e+04]), array([4.99687040e+00, 9.50240320e+01, 1.40004501e+04]), array([   6.60897071,   76.50618966, 6397.06666295]), array([   6.28356509,   91.83155427, 2288.63553202]), array([   5.43304457,   93.68803717, 2282.57316478])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 215, 'regressor__estimator__learning_rate': 0.008013892843685984, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([3.5764873 , 3.53645349, 3.67775917, 3.80372548, 3.89890075]), 'score_time': array([0.14066505, 0.13829708, 0.16535735, 0.18158984, 0.17220259]), 'test_r2': [array([ 0.20635906,  0.1885586 , -0.03724023]), array([ 0.37878373,  0.4136239 , -0.02808587]), array([ 0.43388347,  0.40657855, -0.08423828]), array([ 0.10398864,  0.23462915, -0.01718081]), array([ 0.14037672,  0.2733924 , -0.05450892])], 'test_rmse': [array([7.86906453e+00, 1.49989893e+02, 1.61001042e+04]), array([7.75526054e+00, 9.53022619e+01, 9.83637594e+04]), array([6.76557677e+00, 1.29868917e+02, 7.75451329e+03]), array([7.88937755e+00, 1.72967016e+02, 3.24746462e+05]), array([7.45715207e+00, 1.10822848e+02, 2.34918509e+04])], 'test_mae': [array([   5.45224553,   92.69569988, 3105.15993078]), array([5.05124369e+00, 7.19731037e+01, 1.64120608e+04]), array([   4.65148664,   90.82881394, 2261.6848934 ]), array([5.21915839e+00, 1.10781982e+02, 4.22576088e+04]), array([5.22470437e+00, 8.23360542e+01, 5.88216248e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 117, 'regressor__estimator__learning_rate': 0.025798773581076732, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([13.57121849, 14.10377026, 13.5946281 , 14.09180403, 13.8040936 ]), 'score_time': array([0.49816394, 0.52330732, 0.49640083, 0.56096745, 0.49604177]), 'test_r2': [array([-0.08973308,  0.15105384,  0.1349135 ]), array([ 0.33529639,  0.01968678, -0.01654566]), array([ 0.30834637,  0.40105309, -0.01063533]), array([ 0.0659341 ,  0.35370571, -0.0364636 ]), array([ 0.27516854,  0.33720946, -0.01989329])], 'test_rmse': [array([7.84419130e+00, 1.72947101e+02, 2.97367954e+04]), array([7.33299256e+00, 1.33237846e+02, 9.41141504e+04]), array([7.56444921e+00, 1.02146459e+02, 9.34071334e+03]), array([7.84373553e+00, 1.50549600e+02, 1.28548090e+04]), array([8.82603304e+00, 1.16949136e+02, 3.27142483e+05])], 'test_mae': [array([5.32929621e+00, 1.02957144e+02, 6.62422808e+03]), array([4.62288109e+00, 8.64456109e+01, 1.19862932e+04]), array([   4.78562116,   75.0941839 , 2056.18599208]), array([   5.05413842,   96.83092236, 2441.21511355]), array([5.74977529e+00, 7.96638492e+01, 4.63476433e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 507, 'regressor__estimator__learning_rate': 0.01480138218389328, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([15.54114747, 14.61049414, 13.73275876, 14.23691607, 15.0989635 ]), 'score_time': array([0.49565983, 0.53992152, 0.50059652, 0.51610398, 0.54962969]), 'test_r2': [array([ 3.06088471e-02,  2.71586796e-01, -1.27799184e+02]), array([ 0.17322983,  0.37951408, -0.01393926]), array([ 0.09933486,  0.30828889, -0.01548279]), array([0.26338773, 0.19111139, 0.06733876]), array([0.22028194, 0.24241204, 0.00625403])], 'test_rmse': [array([8.74692014e+00, 1.11112030e+02, 2.80607266e+05]), array([7.28073565e+00, 1.31644964e+02, 9.36029989e+04]), array([8.54343754e+00, 1.30374557e+02, 3.20512868e+05]), array([8.06308325e+00, 1.76443390e+02, 2.11751280e+04]), array([7.90995983e+00, 1.19653180e+02, 5.75152082e+04])], 'test_mae': [array([5.69643043e+00, 7.59536928e+01, 3.28233955e+04]), array([4.80352319e+00, 7.67547276e+01, 1.09844156e+04]), array([5.41876056e+00, 9.17003732e+01, 3.96747843e+04]), array([5.35592558e+00, 9.93243684e+01, 5.78809930e+03]), array([5.23580326e+00, 8.12602682e+01, 8.04802723e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 511, 'regressor__estimator__learning_rate': 0.02408798419267564, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([ 0.17847202,  0.28054992, -4.27323855]), 'r2_stdev': array([ 0.11792319,  0.11767092, 21.35744598]), 'rmse_avg': array([7.88187037e+00, 1.33696391e+02, 1.02924139e+05]), 'rmse_stdev': array([8.36279882e-01, 1.92066046e+01, 1.22849439e+05]), 'mae_avg': array([5.22245156e+00, 8.76356720e+01, 1.49719263e+04]), 'mae_stdev': array([5.32334005e-01, 9.08452045e+00, 1.65355236e+04]), 'r2_avg_aggregate': -1.2714055369431196, 'r2_stdev_aggregate': 7.197680033406123, 'rmse_avg_aggregate': 34355.238968802754, 'rmse_stdev_aggregate': 40956.49412636521, 'mae_avg_aggregate': 5021.594823242661, 'mae_stdev_aggregate': 5515.046816474941}
scaler
Filename: (PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(PDI-Mw-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n08>
Subject: Job 288774: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c201n06> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:17:27 2025
Job was executed on host(s) <6*c201n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:17:27 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:17:27 2025
Terminated at Mon Jan 20 09:29:18 2025
Results reported at Mon Jan 20 09:29:18 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Mn (g/mol)' 'PDI' 'Mw (g/mol)' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" "solvent dP" "solvent dD" "solvent dH"                                     --columns_to_impute "PDI" "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --special_impute 'Mw (g/mol)'                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   161038.00 sec.
    Max Memory :                                 6 GB
    Average Memory :                             5.83 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               10.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   36718 sec.
    Turnaround time :                            36711 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.



Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.005536362672887622), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 50), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.2689012219902284e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.05889790947231506), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 56), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 1.0374514253812812e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.004363509602571013), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 274), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 4.111487137162257e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0002968009741481782), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 1988), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 5.0128041534186204e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.0058066966011342805), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 113), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 2.5056685756955856e-06), ('regressor__regressor__estimator__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__estimator__learning_rate', 0.09655060089124314), ('regressor__regressor__estimator__minibatch_frac', 1), ('regressor__regressor__estimator__n_estimators', 58), ('regressor__regressor__estimator__natural_gradient', True), ('regressor__regressor__estimator__tol', 7.787803997468569e-06), ('regressor__regressor__estimator__verbose', False)])


Average scores:	 r2: [0.006 0.017 0.058][0.216 0.144 0.163]
[array([0.00616913, 0.01701842, 0.05772504]), array([8.63502900e+00, 1.56067502e+02, 9.27006253e+04]), array([6.43209196e+00, 1.07695496e+02, 1.38679006e+04])]
{6: {'fit_time': array([3.4323132 , 3.41141582, 3.47300768, 3.45069027, 3.43831921]), 'score_time': array([0.11343789, 0.12775207, 0.1243    , 0.11196327, 0.12079978]), 'test_r2': [array([-0.06368157,  0.23583865,  0.07717676]), array([ 0.08020409, -0.08334529, -0.02566678]), array([0.01418542, 0.19582153, 0.00430594]), array([ 0.09231293,  0.02440009, -0.06776861]), array([ 0.0730066 , -0.07523609, -0.01456577])], 'test_rmse': [array([6.68044875e+00, 1.24580771e+02, 1.64933565e+04]), array([8.39321952e+00, 1.42285257e+02, 3.38366795e+05]), array([8.76079881e+00, 1.66122698e+02, 2.39848169e+04]), array([9.18387030e+00, 1.64842338e+02, 1.33673981e+04]), array([9.23282525e+00, 1.67234844e+02, 1.97490244e+04])], 'test_mae': [array([   5.28335415,   90.03410651, 3801.00731403]), array([6.34375211e+00, 1.00312508e+02, 5.38229172e+04]), array([   6.56554196,  109.04459297, 3964.46981676]), array([   6.79124854,  110.77271398, 3462.57659213]), array([   6.98116523,  122.56799747, 4628.77251039])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 119, 'regressor__estimator__learning_rate': 0.03179092896978174, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 13: {'fit_time': array([1.47366452, 1.50389457, 1.46883345, 1.48078585, 1.48496079]), 'score_time': array([0.06336308, 0.06243968, 0.05981183, 0.07467532, 0.06118727]), 'test_r2': [array([0.08505932, 0.06744295, 0.30522406]), array([0.10334761, 0.05814012, 0.18068627]), array([ 0.17978471, -0.12357612, -0.0067684 ]), array([-0.31591736, -0.0053726 , -0.01828124]), array([-0.02414927, -0.20426438,  0.39114965])], 'test_rmse': [array([   9.3889316 ,  175.14564702, 7306.47124509]), array([8.46834884e+00, 1.56852475e+02, 2.50325662e+04]), array([8.60446444e+00, 1.59555396e+02, 9.39175629e+04]), array([7.39025125e+00, 1.55198081e+02, 3.25225317e+05]), array([8.85216540e+00, 1.58758407e+02, 1.15425733e+04])], 'test_mae': [array([   7.01035886,  116.46958929, 2285.66795401]), array([   6.40056551,  106.39155652, 5423.71314256]), array([6.23737519e+00, 1.09932668e+02, 1.36664642e+04]), array([5.83343989e+00, 1.06853299e+02, 4.55929941e+04]), array([   6.39652102,  117.74536192, 2001.98789631])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 50, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 42: {'fit_time': array([88.05628204, 91.24858236, 88.34849191, 83.65583444, 83.2356379 ]), 'score_time': array([1.62577152, 1.62210774, 1.71186137, 1.63031983, 1.55164504]), 'test_r2': [array([ 0.21263577, -0.39066306,  0.01947052]), array([0.12402993, 0.11046072, 0.00833912]), array([-1.10088598, -0.00113555, -0.02140637]), array([-0.08475486,  0.29699982,  0.18570611]), array([-0.04840467, -0.09005735,  0.73038682])], 'test_rmse': [array([7.99975575e+00, 1.83201127e+02, 2.32244410e+04]), array([8.14363937e+00, 1.57338896e+02, 5.96369778e+04]), array([9.39333293e+00, 1.63379022e+02, 3.33407706e+05]), array([1.06228837e+01, 1.47873288e+02, 1.24496288e+04]), array([9.18471135e+00, 1.40222008e+02, 1.01155863e+04])], 'test_mae': [array([   6.02904829,  128.66898744, 5411.27153746]), array([5.94341867e+00, 1.06665641e+02, 9.90896590e+03]), array([6.24701406e+00, 1.18078941e+02, 4.82570847e+04]), array([   7.32817929,   92.61528238, 2759.77441612]), array([   6.60507685,   92.00543545, 2199.06723851])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 1993, 'regressor__estimator__learning_rate': 0.026525868306465018, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 69: {'fit_time': array([1.6122148 , 1.61392212, 1.60091543, 1.60577059, 1.61200166]), 'score_time': array([0.06352973, 0.06424117, 0.06042409, 0.0606842 , 0.06272197]), 'test_r2': [array([-0.0161269 ,  0.12795428, -0.01949104]), array([ 0.11844059,  0.01466817, -0.0221173 ]), array([-0.10102456,  0.22016866, -0.03647277]), array([ 0.0623771 ,  0.03253162, -0.03733444]), array([-0.05325363,  0.09455027, -0.0385123 ])], 'test_rmse': [array([7.94908770e+00, 1.53676736e+02, 3.25178045e+05]), array([7.99093901e+00, 1.53234757e+02, 9.45686594e+04]), array([1.06636090e+01, 1.30559531e+02, 3.18774052e+04]), array([9.07796069e+00, 1.52867464e+02, 1.31654615e+04]), array([8.05581490e+00, 1.66342836e+02, 1.19640290e+04])], 'test_mae': [array([6.41655784e+00, 1.12273600e+02, 4.49874460e+04]), array([6.32363342e+00, 1.13194297e+02, 1.41081436e+04]), array([   7.59041443,   91.14854411, 6436.14085547]), array([   6.85221202,  103.49126488, 2592.82619824]), array([   6.40488109,  109.56414026, 2305.83571029])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 56, 'regressor__estimator__learning_rate': 0.016986533720633797, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 420: {'fit_time': array([2.8084352 , 2.75444555, 2.99925327, 2.9323082 , 3.06205583]), 'score_time': array([0.08987832, 0.09677124, 0.09529066, 0.08795643, 0.08998036]), 'test_r2': [array([ 0.00639747, -0.02978886,  0.08532485]), array([ 0.1941058 ,  0.10494089, -0.00944348]), array([-0.01034166,  0.09139455, -0.08931691]), array([-0.09492191,  0.09091973, -0.01705667]), array([ 0.02980577, -0.36575674,  0.3463246 ])], 'test_rmse': [array([8.80475791e+00, 1.68969184e+02, 1.51189785e+04]), array([8.83311730e+00, 1.17744583e+02, 9.74678589e+04]), array([   9.03828514,  160.69829488, 7772.65334026]), array([8.72122631e+00, 1.88507420e+02, 3.24726645e+05]), array([7.92224479e+00, 1.51937864e+02, 1.84958025e+04])], 'test_mae': [array([   6.67774808,  110.97649296, 3055.23630671]), array([6.26050411e+00, 8.59199138e+01, 1.59019501e+04]), array([   6.23905078,  109.76778058, 2283.76078716]), array([6.31577408e+00, 1.22280141e+02, 4.22843666e+04]), array([   5.9940539 ,  103.88621794, 4719.67840395])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 97, 'regressor__estimator__learning_rate': 0.1, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 1234567890: {'fit_time': array([8.08990216, 8.28142786, 8.22502041, 8.02039576, 8.50426459]), 'score_time': array([0.24185371, 0.25428963, 0.24079585, 0.22820783, 0.23188472]), 'test_r2': [array([ 0.04172135,  0.06956329, -0.04891027]), array([ 0.05468781, -0.11513358, -0.01333691]), array([-0.00949612,  0.12131367, -0.02754647]), array([ 0.03282806,  0.07860401, -0.03884811]), array([ 0.10476882,  0.01336759, -0.02044723])], 'test_rmse': [array([7.35586948e+00, 1.81057546e+02, 3.27441383e+04]), array([8.74490011e+00, 1.42104759e+02, 9.39654960e+04]), array([9.13871865e+00, 1.23721759e+02, 9.41853902e+03]), array([7.98152775e+00, 1.79757742e+02, 1.28695875e+04]), array([9.80877179e+00, 1.42687706e+02, 3.27231312e+05])], 'test_mae': [array([5.76937878e+00, 1.17634537e+02, 7.50995824e+03]), array([6.45199803e+00, 1.06840585e+02, 1.20264651e+04]), array([   7.21113837,   91.97046536, 2103.63087725]), array([   6.07102915,  123.64993157, 2519.07753832]), array([7.34797396e+00, 1.00671335e+02, 4.65467174e+04])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 279, 'regressor__estimator__learning_rate': 0.006096224728039288, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 473129: {'fit_time': array([1.55390334, 1.69133115, 1.61450791, 1.59064627, 1.6450808 ]), 'score_time': array([0.05820417, 0.0625515 , 0.07150745, 0.06268859, 0.06463552]), 'test_r2': [array([0.07375115, 0.08337255, 0.05354926]), array([ 0.1863945 , -0.05057898, -0.01133469]), array([ 0.05722098,  0.08780889, -0.01558173]), array([ 0.17259789, -0.01770402,  0.18392568]), array([ 0.03921448, -0.0720049 ,  0.04901428])], 'test_rmse': [array([8.55006619e+00, 1.24643205e+02, 2.40542247e+04]), array([7.22253740e+00, 1.71298135e+02, 9.34826997e+04]), array([8.74089549e+00, 1.49717783e+02, 3.20528481e+05]), array([8.54554926e+00, 1.97911840e+02, 1.98074669e+04]), array([8.78048906e+00, 1.42333162e+02, 5.62641811e+04])], 'test_mae': [array([   6.40505536,   91.43431569, 4587.41776283]), array([5.38191544e+00, 1.06888946e+02, 1.10432206e+04]), array([6.51422282e+00, 1.08097174e+02, 3.97844958e+04]), array([   6.31630302,  124.73960956, 5407.02430247]), array([6.58331430e+00, 1.06754378e+02, 7.98639366e+03])], 'best_params': {'check_inverse': True, 'func': None, 'inverse_func': None, 'regressor__estimator__natural_gradient': True, 'regressor__estimator__n_estimators': 58, 'regressor__estimator__learning_rate': 0.09655060089124314, 'regressor__estimator__minibatch_frac': 1, 'regressor__estimator__col_sample': 1.0, 'regressor__estimator__verbose': False, 'regressor__n_jobs': None, 'transformer__memory': None, 'transformer__verbose': False, 'transformer__log transform__accept_sparse': False, 'transformer__log transform__check_inverse': True, 'transformer__log transform__feature_names_out': None, 'transformer__log transform__inv_kw_args': None, 'transformer__log transform__kw_args': None, 'transformer__log transform__validate': False, 'transformer__y scaler__copy': True, 'transformer__y scaler__unit_variance': False, 'transformer__y scaler__with_centering': True, 'transformer__y scaler__with_scaling': True}}, 'r2_avg': array([0.00616913, 0.01701842, 0.05772504]), 'r2_stdev': array([0.21557315, 0.14366306, 0.16285304]), 'rmse_avg': array([8.63502900e+00, 1.56067502e+02, 9.27006253e+04]), 'rmse_stdev': array([8.32355755e-01, 1.87387633e+01, 1.20771768e+05]), 'mae_avg': array([6.43209196e+00, 1.07695496e+02, 1.38679006e+04]), 'mae_stdev': array([5.01505679e-01, 1.07923126e+01, 1.65213338e+04]), 'r2_avg_aggregate': 0.026970863425584024, 'r2_stdev_aggregate': 0.17402975087394182, 'rmse_avg_aggregate': 30955.109285965664, 'rmse_stdev_aggregate': 40263.779582348725, 'mae_avg_aggregate': 4660.676056692638, 'mae_stdev_aggregate': 5510.875861268123}
scaler
Filename: (concentration-temperature)_NGB_mean_Robust Scaler
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(concentration-temperature)_NGB_mean_Robust Scaler_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(concentration-temperature)_NGB_mean_Robust Scaler_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_multimodal Rh/scaler/(concentration-temperature)_NGB_mean_Robust Scaler_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c031n04>
Subject: Job 288762: <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> in cluster <Hazel> Done

Job <numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119> was submitted from host <c023n02> by user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:13:47 2025
Job was executed on host(s) <6*c031n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Sun Jan 19 23:13:49 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Sun Jan 19 23:13:49 2025
Terminated at Mon Jan 20 09:40:20 2025
Results reported at Mon Jan 20 09:40:20 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 25:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "numerical_NGB_polymer_size_feats_on_multimodal Rh_all_num_20250119"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "multimodal Rh"                                     --regressor_type "NGB"                                     --transform_type "Robust Scaler"                                     --numerical_feats 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)'                                     --columns_to_impute "Temperature SANS/SLS/DLS/SEC (K)" "Concentration (mg/ml)"                                     --imputer mean


conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   172812.42 sec.
    Max Memory :                                 7 GB
    Average Memory :                             6.85 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               9.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   37596 sec.
    Turnaround time :                            37593 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/numerical_NGB_Robust Scaler_multimodal Rh_20250119.err> for stderr output of this job.

