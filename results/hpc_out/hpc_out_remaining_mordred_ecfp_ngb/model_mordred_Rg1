


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
usage: train_structure_only.py mordred [-h] [--regressor_type REGRESSOR_TYPE]
                                       [--target TARGET]
                                       [--oligo_type {Monomer,Dimer,Trimer,RRU Monomer,RRU Dimer,RRU Trimer}]
train_structure_only.py mordred: error: argument --oligo_type: invalid choice: 'RRU' (choose from 'Monomer', 'Dimer', 'Trimer', 'RRU Monomer', 'RRU Dimer', 'RRU Trimer')

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n04>
Subject: Job 824513: <RRU_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <RRU_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:40 2024
Job was executed on host(s) <4*c202n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:58:44 2024
                            <4*c202n14>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:58:44 2024
Terminated at Wed Oct 16 11:00:49 2024
Results reported at Wed Oct 16 11:00:49 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "RRU_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type RRU

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   4.42 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   152 sec.
    Turnaround time :                            17529 sec.

The output (if any) is above this job summary.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
usage: train_structure_only.py mordred [-h] [--regressor_type REGRESSOR_TYPE]
                                       [--target TARGET]
                                       [--oligo_type {Monomer,Dimer,Trimer,RRU Monomer,RRU Dimer,RRU Trimer}]
train_structure_only.py mordred: error: argument --oligo_type: invalid choice: 'RRU' (choose from 'Monomer', 'Dimer', 'Trimer', 'RRU Monomer', 'RRU Dimer', 'RRU Trimer')

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n02>
Subject: Job 824511: <RRU_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <RRU_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:39 2024
Job was executed on host(s) <4*c202n02>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:57:45 2024
                            <4*c202n03>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:57:45 2024
Terminated at Wed Oct 16 11:00:58 2024
Results reported at Wed Oct 16 11:00:58 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "RRU_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type RRU

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   4.39 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   196 sec.
    Turnaround time :                            17539 sec.

The output (if any) is above this job summary.

usage: train_structure_only.py mordred [-h] [--regressor_type REGRESSOR_TYPE]
                                       [--target TARGET]
                                       [--oligo_type {Monomer,Dimer,Trimer,RRU Monomer,RRU Dimer,RRU Trimer}]
train_structure_only.py mordred: error: argument --oligo_type: invalid choice: 'RRU' (choose from 'Monomer', 'Dimer', 'Trimer', 'RRU Monomer', 'RRU Dimer', 'RRU Trimer')

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n09>
Subject: Job 824509: <RRU_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <RRU_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:38 2024
Job was executed on host(s) <4*c202n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:57:43 2024
                            <4*c202n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:57:43 2024
Terminated at Wed Oct 16 11:01:17 2024
Results reported at Wed Oct 16 11:01:17 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "RRU_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type RRU

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   4.44 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   239 sec.
    Turnaround time :                            17559 sec.

The output (if any) is above this job summary.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:16: RuntimeWarning: invalid value encountered in divide
  D[:, 0] = (self.loc - Y) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:17: RuntimeWarning: invalid value encountered in divide
  D[:, 1] = 1 - ((self.loc - Y) ** 2) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: divide by zero encountered in divide
  FI[:, 0, 0] = 1 / self.var
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 250, in fit
    return self.partial_fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 385, in partial_fit
    proj_grad = self.fit_base(X_batch, grads, weight_batch)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in fit_base
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in <listcomp>
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 1377, in fit
    super()._fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 252, in _fit
    X, y = self._validate_data(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 648, in _validate_data
    y = check_array(y, input_name="y", **check_y_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input y contains NaN.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 270, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 267, in main
    perform_model_mordred(args.regressor_type, args.target, args.oligo_type)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 210, in perform_model_mordred
    main_Mordred_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 141, in main_Mordred_only
    scores, predictions, data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
ValueError: Input y contains NaN.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n14>
Subject: Job 824506: <Monomer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <Monomer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:35 2024
Job was executed on host(s) <4*c207n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:52:47 2024
                            <4*c207n07>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:52:47 2024
Terminated at Wed Oct 16 11:06:23 2024
Results reported at Wed Oct 16 11:06:23 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Monomer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Monomer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Monomer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Monomer

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1667.60 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.24 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   837 sec.
    Turnaround time :                            17868 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:71: RuntimeWarning: overflow encountered in square
  self.var = self.scale**2
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:16: RuntimeWarning: invalid value encountered in divide
  D[:, 0] = (self.loc - Y) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:17: RuntimeWarning: invalid value encountered in divide
  D[:, 1] = 1 - ((self.loc - Y) ** 2) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: divide by zero encountered in divide
  FI[:, 0, 0] = 1 / self.var
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 250, in fit
    return self.partial_fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 385, in partial_fit
    proj_grad = self.fit_base(X_batch, grads, weight_batch)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in fit_base
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in <listcomp>
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 1377, in fit
    super()._fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 252, in _fit
    X, y = self._validate_data(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 648, in _validate_data
    y = check_array(y, input_name="y", **check_y_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input y contains NaN.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 270, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 267, in main
    perform_model_mordred(args.regressor_type, args.target, args.oligo_type)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 210, in perform_model_mordred
    main_Mordred_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 141, in main_Mordred_only
    scores, predictions, data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
ValueError: Input y contains NaN.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 824514: <Trimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <Trimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:41 2024
Job was executed on host(s) <4*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:59:05 2024
                            <4*c203n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:59:05 2024
Terminated at Wed Oct 16 11:07:47 2024
Results reported at Wed Oct 16 11:07:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Trimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Trimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Trimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Trimer

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   864.31 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.20 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   522 sec.
    Turnaround time :                            17946 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:71: RuntimeWarning: overflow encountered in square
  self.var = self.scale**2
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:70: RuntimeWarning: overflow encountered in exp
  self.scale = np.exp(params[1])
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:71: RuntimeWarning: overflow encountered in square
  self.var = self.scale**2
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:365: RuntimeWarning: overflow encountered in square
  return -x**2 / 2.0 - _norm_pdf_logC
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:16: RuntimeWarning: invalid value encountered in divide
  D[:, 0] = (self.loc - Y) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:17: RuntimeWarning: invalid value encountered in divide
  D[:, 1] = 1 - ((self.loc - Y) ** 2) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: divide by zero encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 250, in fit
    return self.partial_fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 385, in partial_fit
    proj_grad = self.fit_base(X_batch, grads, weight_batch)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in fit_base
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in <listcomp>
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 1377, in fit
    super()._fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 252, in _fit
    X, y = self._validate_data(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 648, in _validate_data
    y = check_array(y, input_name="y", **check_y_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input y contains NaN.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 270, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 267, in main
    perform_model_mordred(args.regressor_type, args.target, args.oligo_type)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 210, in perform_model_mordred
    main_Mordred_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 141, in main_Mordred_only
    scores, predictions, data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
ValueError: Input y contains NaN.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n14>
Subject: Job 824507: <Dimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <Dimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:36 2024
Job was executed on host(s) <4*c200n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:52:51 2024
                            <4*c200n02>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:52:51 2024
Terminated at Wed Oct 16 11:08:56 2024
Results reported at Wed Oct 16 11:08:56 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Dimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Dimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Dimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Dimer

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   2310.05 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.47 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   965 sec.
    Turnaround time :                            18020 sec.

The output (if any) is above this job summary.




OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:71: RuntimeWarning: overflow encountered in square
  self.var = self.scale**2
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:16: RuntimeWarning: invalid value encountered in divide
  D[:, 0] = (self.loc - Y) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:17: RuntimeWarning: invalid value encountered in divide
  D[:, 1] = 1 - ((self.loc - Y) ** 2) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: divide by zero encountered in divide
  FI[:, 0, 0] = 1 / self.var
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 250, in fit
    return self.partial_fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 385, in partial_fit
    proj_grad = self.fit_base(X_batch, grads, weight_batch)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in fit_base
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in <listcomp>
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 1377, in fit
    super()._fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 252, in _fit
    X, y = self._validate_data(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 648, in _validate_data
    y = check_array(y, input_name="y", **check_y_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input y contains NaN.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 270, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 267, in main
    perform_model_mordred(args.regressor_type, args.target, args.oligo_type)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 210, in perform_model_mordred
    main_Mordred_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 141, in main_Mordred_only
    scores, predictions, data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
ValueError: Input y contains NaN.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n04>
Subject: Job 824510: <Monomer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <Monomer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:38 2024
Job was executed on host(s) <4*c202n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:57:43 2024
                            <4*c202n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:57:43 2024
Terminated at Wed Oct 16 11:10:22 2024
Results reported at Wed Oct 16 11:10:22 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Monomer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Monomer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Monomer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Monomer

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1138.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.22 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   784 sec.
    Turnaround time :                            18104 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:71: RuntimeWarning: overflow encountered in square
  self.var = self.scale**2
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:70: RuntimeWarning: overflow encountered in exp
  self.scale = np.exp(params[1])
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:16: RuntimeWarning: invalid value encountered in divide
  D[:, 0] = (self.loc - Y) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:17: RuntimeWarning: invalid value encountered in divide
  D[:, 1] = 1 - ((self.loc - Y) ** 2) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: divide by zero encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 250, in fit
    return self.partial_fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 385, in partial_fit
    proj_grad = self.fit_base(X_batch, grads, weight_batch)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in fit_base
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in <listcomp>
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 1377, in fit
    super()._fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 252, in _fit
    X, y = self._validate_data(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 648, in _validate_data
    y = check_array(y, input_name="y", **check_y_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input y contains NaN.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 270, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 267, in main
    perform_model_mordred(args.regressor_type, args.target, args.oligo_type)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 210, in perform_model_mordred
    main_Mordred_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 141, in main_Mordred_only
    scores, predictions, data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
ValueError: Input y contains NaN.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n05>
Subject: Job 824508: <Trimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <Trimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:38 2024
Job was executed on host(s) <4*c202n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:57:43 2024
                            <4*c202n14>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:57:43 2024
Terminated at Wed Oct 16 11:11:48 2024
Results reported at Wed Oct 16 11:11:48 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Trimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Trimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Trimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Trimer

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1864.18 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.23 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   846 sec.
    Turnaround time :                            18190 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:16: RuntimeWarning: invalid value encountered in divide
  D[:, 0] = (self.loc - Y) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:17: RuntimeWarning: invalid value encountered in divide
  D[:, 1] = 1 - ((self.loc - Y) ** 2) / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: divide by zero encountered in divide
  FI[:, 0, 0] = 1 / self.var
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/distns/normal.py:22: RuntimeWarning: overflow encountered in divide
  FI[:, 0, 0] = 1 / self.var
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 463, in _process_worker
    r = call_item()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in __call__
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 598, in <listcomp>
    return [func(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 136, in __call__
    return self.function(*args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/compose/_target.py", line 288, in fit
    self.regressor_.fit(X, y_trans, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 250, in fit
    return self.partial_fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 385, in partial_fit
    proj_grad = self.fit_base(X_batch, grads, weight_batch)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in fit_base
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/ngboost/ngboost.py", line 166, in <listcomp>
    models = [clone(self.Base).fit(X, g) for g in grads.T]
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 1377, in fit
    super()._fit(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 252, in _fit
    X, y = self._validate_data(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 648, in _validate_data
    y = check_array(y, input_name="y", **check_y_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input y contains NaN.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 270, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 267, in main
    perform_model_mordred(args.regressor_type, args.target, args.oligo_type)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 210, in perform_model_mordred
    main_Mordred_only(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_only.py", line 141, in main_Mordred_only
    scores, predictions, data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1754, in _retrieve
    self._raise_error_fast()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1789, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 745, in get_result
    return self._return_or_raise()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 763, in _return_or_raise
    raise self._result
ValueError: Input y contains NaN.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c202n09>
Subject: Job 824512: <Dimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <Dimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c025n04> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 06:08:40 2024
Job was executed on host(s) <4*c202n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 10:58:44 2024
                            <4*c202n06>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 10:58:44 2024
Terminated at Wed Oct 16 11:14:14 2024
Results reported at Wed Oct 16 11:14:14 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Dimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Dimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Dimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Dimer

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1100.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.15 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   957 sec.
    Turnaround time :                            18334 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.012066314142156895, 1, 155, True, 4.7255952107197764e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0002346547155263777, 1, 150, True, 5.375910750209258e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.00011051110374171373, 1, 878, True, 0.00023035926320551762, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0034472980656429127, 1, 239, True, 6.334432601004258e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.03615444215817928, 1, 1108, True, 2.1985491486977563e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0014043559229705738, 1, 95, True, 4.4882220559517476e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.009591866001509308, 1, 290, True, 0.0002487907936370736, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.004383563747774247, 1, 366, True, 3.71459228288051e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.004219671323801641, 1, 1673, True, 1.0625517653736443e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.002278168866500747, 1, 232, True, 0.0003136992731718017, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0284172866447641, 1, 192, True, 2.056198663712488e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.00048068261178315307, 1, 798, True, 3.0495478221931123e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.001893747751828535, 1, 202, True, 2.9065307024893834e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00047738766343247206, 1, 614, True, 6.8999963250564455e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.013242996266325172, 1, 104, True, 4.798352417310213e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0003296569238620194, 1, 127, True, 9.522516945680815e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0002346547155263777, 1, 150, True, 5.375910750209258e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.00875903570823002, 1, 926, True, 3.526674715099216e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.027540760343946778, 1, 587, True, 2.7627453628385667e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00011051110374171373, 1, 878, True, 0.00023035926320551762, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.06610392791400534, 1, 462, True, 7.826801972460072e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.03000244660585327, 1, 426, True, 0.00013160408885153297, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.005243640592251073, 1, 357, True, 1.541108759949908e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.07406915811517857, 1, 98, True, 0.000350648841926105, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.013713648897731476, 1, 96, True, 8.767617716411702e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.045373413739326254, 1, 436, True, 2.9282581415271997e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.001186795380217221, 1, 1197, True, 8.876318054021814e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0023997910064361525, 1, 152, True, 3.822729909902378e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.022151823410285133, 1, 706, True, 1.1779032555102984e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.000123339686169303, 1, 386, True, 6.319607910747145e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.011666872969820097, 1, 765, True, 2.0815870879318976e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.003702040333418697, 1, 196, True, 0.00012758318151892645, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.017865846766430802, 1, 411, True, 2.5966383733877323e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0004546182701495419, 1, 420, True, 3.5241226136475516e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0022221614237953285, 1, 348, True, 0.00040261724114884484, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.051132990355973906, 1, 444, True, 2.572578830100912e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.00035108814573770966, 1, 92, True, 5.178566368255941e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.00015540232499270995, 1, 68, True, 2.250491521285756e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0008536714600266263, 1, 1007, True, 0.0003862157613264864, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.001565360406230398, 1, 138, True, 0.0005340531932464406, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0016667636449710559, 1, 538, True, 4.994029470894879e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.02611771848088472, 1, 1231, True, 3.5713241738094106e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0006309734369999129, 1, 232, True, 3.0210021352648518e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0001710123577095909, 1, 853, True, 2.0286955790567503e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.025417398691464282, 1, 1358, True, 1.1834329115877803e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0012929245851185786, 1, 108, True, 0.0009111911212590682, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.08603836609287525, 1, 99, True, 0.00010434300958697912, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0007803768000389418, 1, 663, True, 1.8962270538309703e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.03559274519818588, 1, 954, True, 8.105813565041927e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.03072972758912493, 1, 1429, True, 1.928608206438564e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.011015154453209924, 1, 692, True, 4.2443589952143866e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.00017218142713814968, 1, 499, True, 0.0009811565599764321, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.004733933203541537, 1, 1212, True, 0.00017439426632726514, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.038717223652965656, 1, 1334, True, 5.528274697107728e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0004971198569375435, 1, 1418, True, 8.24634810875749e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.008283419842830465, 1, 77, True, 3.61509626399564e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.024553820388737633, 1, 125, True, 0.0002981835659086422, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0054995380774535705, 1, 898, True, 8.795381756938975e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.011050680386837982, 1, 1147, True, 2.6412040697129213e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00023272606144644634, 1, 958, True, 7.198427151137317e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0003903212492015867, 1, 201, True, 6.09545631802649e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0013876609565881138, 1, 713, True, 0.0004788177243870536, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0011362870225116335, 1, 221, True, 1.9430018018449314e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0009985918803840246, 1, 66, True, 0.00027339843152224475, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0014991531901114357, 1, 112, True, 0.00021281608375521425, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.002636789267868834, 1, 399, True, 6.99539517445214e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.007906193886901879, 1, 77, True, 3.281892788673504e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0006261588339370762, 1, 1715, True, 1.108824887276637e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.000105199834168051, 1, 571, True, 1.8667165427611215e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.07209540905894918, 1, 563, True, 4.183198804437312e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.013082099264896377, 1, 543, True, 0.0001420219045677668, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0015908610057508157, 1, 441, True, 4.945719487854239e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00026458106412725804, 1, 996, True, 0.00015705795526603985, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.018908450050049864, 1, 65, True, 1.0143101908782946e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0003554257473796965, 1, 57, True, 1.2494615981436778e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.009591866001509308, 1, 290, True, 0.0002487907936370736, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.004383563747774247, 1, 366, True, 3.71459228288051e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.00044782253482358365, 1, 1435, True, 1.4968078841923233e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.001301568495166768, 1, 59, True, 0.00012534668451817232, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.024553820388737633, 1, 125, True, 0.0002981835659086422, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.00758082042266208, 1, 65, True, 2.8920487561678257e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0054995380774535705, 1, 898, True, 8.795381756938975e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.011050680386837982, 1, 1147, True, 2.6412040697129213e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.00023272606144644634, 1, 958, True, 7.198427151137317e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.01784974622589027, 1, 322, True, 0.00016189451351274512, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.04088393058343165, 1, 302, True, 0.0002957622857323286, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0005135378835922466, 1, 65, True, 1.0664867854963207e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0771607557119841, 1, 507, True, 0.00044127331692587, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0011725490883857043, 1, 84, True, 1.2342966757651529e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0005823215600482014, 1, 1275, True, 0.0004858892196511903, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00011919000254347699, 1, 261, True, 0.0007134229134846048, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0030062010673117044, 1, 1260, True, 0.00016141579545618414, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.05462582025068383, 1, 394, True, 0.00016660718633650594, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0004703948352193837, 1, 88, True, 0.0008335430737684432, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.005642382960447129, 1, 278, True, 2.0003300546342006e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0055218801409236806, 1, 220, True, 1.0918358091635648e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0008649202629067524, 1, 193, True, 0.0006044297881809244, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00019239951745127426, 1, 57, True, 4.6310558069161516e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.010252388012499248, 1, 474, True, 0.00065743940328587, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0005439736904921165, 1, 268, True, 0.0006508288297695006, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0006443458113260074, 1, 207, True, 1.8872647179084173e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00014875351706710713, 1, 296, True, 0.00016121224971581128, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.07627839611797058, 1, 112, True, 5.500570170836495e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0005675474097420118, 1, 330, True, 0.00026185243100107004, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.002278168866500747, 1, 232, True, 0.0003136992731718017, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0284172866447641, 1, 192, True, 2.056198663712488e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0004033666960746797, 1, 52, True, 3.791641629014269e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0011108776683087756, 1, 116, True, 2.915719268191902e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.007624587531566631, 1, 145, True, 2.0815418607965626e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.015489933242494704, 1, 1451, True, 1.197353859420998e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.07841587679810368, 1, 208, True, 0.000437571671461839, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.04332626688393504, 1, 1352, True, 2.683203632227366e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.00045390495978977124, 1, 754, True, 0.0004028150262569263, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0163390233698763, 1, 67, True, 0.00041276386798446964, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.006742555860114095, 1, 377, True, 3.756954932192281e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0025348720181462506, 1, 533, True, 0.0008227390506190273, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0034065274075423565, 1, 167, True, 2.7202458188702774e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0015728076274530633, 1, 71, True, 4.980803999721616e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0022324193664694757, 1, 902, True, 7.64346045450857e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.042645287180253455, 1, 1145, True, 3.144118441071239e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.02124872119728732, 1, 276, True, 5.71668683979222e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 1e-06, False] before, using random point [0.0015980646094125182, 1, 1938, True, 0.00013045710163246332, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00014594209105447373, 1, 97, True, 0.00010858619420586525, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.026627701781420945, 1, 861, True, 4.727235549031084e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00373253891845766, 1, 1609, True, 2.368681039622259e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00012144804496155966, 1, 1998, True, 0.0004692508656116422, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0008434458007049109, 1, 160, True, 8.61405822207194e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0004630420326253605, 1, 154, True, 0.0005556823496023869, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0008164068606089233, 1, 204, True, 0.00012551256886288243, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0036995303376640126, 1, 244, True, 5.516047322333215e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00024676799262813464, 1, 89, True, 1.9047430570243545e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0008162911462762215, 1, 759, True, 1.588427280518983e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.06610392791400534, 1, 462, True, 7.826801972460072e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.03000244660585327, 1, 426, True, 0.00013160408885153297, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.005243640592251073, 1, 357, True, 1.541108759949908e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.07406915811517857, 1, 98, True, 0.000350648841926105, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.013713648897731476, 1, 96, True, 8.767617716411702e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.045373413739326254, 1, 436, True, 2.9282581415271997e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.001186795380217221, 1, 1197, True, 8.876318054021814e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0023997910064361525, 1, 152, True, 3.822729909902378e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.022151823410285133, 1, 706, True, 1.1779032555102984e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.000123339686169303, 1, 386, True, 6.319607910747145e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.0023168891853805724, 1, 616, True, 3.417652540921954e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00019204019211973623, 1, 421, True, 0.00018628569440321856, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.00010649302664302677, 1, 371, True, 5.840646065800784e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.003702040333418697, 1, 196, True, 0.00012758318151892645, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 2000, True, 0.001, False] before, using random point [0.017865846766430802, 1, 411, True, 2.5966383733877323e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.07406915811517857, 1, 98, True, 0.000350648841926105, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.045373413739326254, 1, 436, True, 2.9282581415271997e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.001186795380217221, 1, 1197, True, 8.876318054021814e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0023997910064361525, 1, 152, True, 3.822729909902378e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.022151823410285133, 1, 706, True, 1.1779032555102984e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.0023168891853805724, 1, 616, True, 3.417652540921954e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 0.001, False] before, using random point [0.008283419842830465, 1, 77, True, 3.61509626399564e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.001301568495166768, 1, 59, True, 0.00012534668451817232, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00011277192640934277, 1, 1380, True, 7.492888118666533e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.024553820388737633, 1, 125, True, 0.0002981835659086422, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00758082042266208, 1, 65, True, 2.8920487561678257e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0054995380774535705, 1, 898, True, 8.795381756938975e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.011050680386837982, 1, 1147, True, 2.6412040697129213e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00023272606144644634, 1, 958, True, 7.198427151137317e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.04088393058343165, 1, 302, True, 0.0002957622857323286, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.03814674629126179, 1, 104, True, 0.0006902641573957533, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0005823215600482014, 1, 1275, True, 0.0004858892196511903, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00011919000254347699, 1, 261, True, 0.0007134229134846048, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.00013895115319535306, 1, 1093, True, 2.216761378508989e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0010711650114563448, 1, 1281, True, 0.0004025345279185702, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.03335344536966711, 1, 795, True, 4.794420547076302e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.012967957352574161, 1, 613, True, 1.683716165747327e-06, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.1, 1, 50, True, 1e-06, False] before, using random point [0.0010056368080265201, 1, 378, True, 2.209208314088516e-05, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 124), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03748857110204243), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1229), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00036941418309087464), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.008644070186378677), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0006993167901911248), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05396510243581508), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 154), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09911703527493196), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 527), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00029195127012925635), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.040634830685173415), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 347), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0986732304215235), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1264), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.1570305449188742e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.1200688201979395e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0366008510131366), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 136), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.2537292989688585e-05), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.390574606467376e-05), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 160), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.027364528220782454), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 454), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.7081473573792404e-05), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025041499136197735), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0005147024286785698), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06605247295256951), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 645), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04206080643587124), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 166), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025405816743855503), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01076014174173652), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 616), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04988680570849131), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.061606254788150336), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 317), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.4544014455967227e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.006396050329783065), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06335440839644148), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0003155796515858672), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 189), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.007063902603304091), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1146), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07808956240500073), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 228), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 601), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030434865087846628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05909859893798998), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03218924479305508), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 291), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.016949553821188748), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1219), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])


Average scores:	 r: 0.950.04	 r2: 0.890.09
Monomer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration)_NGB_mean
Saved results to:
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration)_NGB_mean_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration)_NGB_mean_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer_scaler/(Mordred-Mw-PDI-temperature-concentration)_NGB_mean_predictions.csv



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 871), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015025518430925413), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 83), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00020859830172963438), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01773555482460957), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 170), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 801), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0006950234576141619), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.045373413739326254), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 436), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.9282581415271997e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.1200688201979395e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.060250882592134736), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1130), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.1072157649866174e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 121), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0029663217247257465), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09519991703670388), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1980), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00042950047384347474), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03575399697039866), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.025041499136197735), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 349), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0005147024286785698), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 700), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00984745084657205), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 358), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 81), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07261796069734805), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 265), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.010862179930096387), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03790361246808865), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 357), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 81), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03770052924189587), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 220), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00026582794314867315), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 340), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.011636770146365267), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05107437620082176), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 909), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.009147477358411895), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05893955044000349), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 516), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 107), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06884752872535625), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 953), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.422445525466379e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01385147998028513), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07224981083968625), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 192), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 926), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])


Average scores:	 r: 0.950.04	 r2: 0.90.08
Dimer_scaler
Filename: (Mordred-Mw-PDI-temperature-concentration)_NGB_mean
Saved results to:
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration)_NGB_mean_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration)_NGB_mean_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer_scaler/(Mordred-Mw-PDI-temperature-concentration)_NGB_mean_predictions.csv



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 630), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08850625325083689), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1063), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 168), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05791565245235398), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 74), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 5.5886990215650815e-05), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0626487601422041), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03389938429048122), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1010), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 963), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0999596423433713), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 193), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0008483982002480671), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0495286993925504), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 274), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04671151639535687), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 569), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05443754630181812), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1361), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.041699092345251196), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 756), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04980606394034698), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 829), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.028079123287410163), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 840), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017142118749961282), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09996307036083676), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 55), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0005675312501099172), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03168947686601995), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 347), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05379952136143293), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 251), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 170), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 811), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 50), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890
Traceback (most recent call last):
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1650, in _get_outputs
    yield from self._retrieve()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1762, in _retrieve
    time.sleep(0.01)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 276, in <module>
    main()
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 273, in main
    perform_model_mordred_numerical(args.regressor_type, args.target)
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 82, in perform_model_mordred_numerical
    main_mordred_numerical(dataset=w_data,
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/train_structure_numerical.py", line 51, in main_mordred_numerical
    scores, predictions,data_shapes  = train_regressor(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 97, in train_regressor
    scores, predictions, data_shape = _prepare_data(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 167, in _prepare_data
    score,predication= run(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 206, in run
    best_estimator, regressor_params = _optimize_hyperparams(
  File "/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/training_utils.py", line 271, in _optimize_hyperparams
    bayes.fit(X_train, y_train)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 542, in fit
    super().fit(X=X, y=y, groups=groups, **fit_params)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 1019, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 599, in _run_search
    optim_result, score_name = self._step(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/searchcv.py", line 453, in _step
    all_results = evaluate_candidates(params_dict)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 965, in evaluate_candidates
    out = parallel(
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 74, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 2007, in __call__
    return output if self.return_generator else list(output)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1703, in _get_outputs
    self._abort()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/parallel.py", line 1614, in _abort
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/executor.py", line 75, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 1297, in shutdown
    self._executor_manager_thread_wakeup.wakeup()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 132, in wakeup
    self._writer.send_bytes(b"")
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/connection.py", line 183, in send_bytes
    self._check_closed()
  File "/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/multiprocessing/connection.py", line 134, in _check_closed
    def _check_closed(self):
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 824697: <mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <mordred_NGB_structure_only> was submitted from host <c201n08> by user <sdehgha2> in cluster <Hazel> at Wed Oct 16 09:33:48 2024
Job was executed on host(s) <4*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Oct 16 11:07:49 2024
                            <4*c203n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Wed Oct 16 11:07:49 2024
Terminated at Thu Oct 17 11:52:41 2024
Results reported at Thu Oct 17 11:52:41 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 90:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "mordred_NGB_structure_only"  # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)"

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   403573.00 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.99 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   89094 sec.
    Turnaround time :                            94733 sec.

The output (if any) is above this job summary.

Pipeline(steps=[('scaling features',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('structural_scaling',
                                                  StandardScaler(),
                                                  ['Monomer Mordred ABC',
                                                   'Monomer Mordred ABCGG',
                                                   'Monomer Mordred nAcid',
                                                   'Monomer Mordred nBase',
                                                   'Monomer Mordred nAromAtom',
                                                   'Monomer Mordred nAromBond',
                                                   'Monomer Mordred nAtom',
                                                   'Monomer Mordred nHeavyAtom',
                                                   'Monomer Mordred nHetero',
                                                   'Monomer...
                                                   'Monomer Mordred nBr',
                                                   'Monomer Mordred nX',
                                                   'Monomer Mordred ATS0dv',
                                                   'Monomer Mordred ATS1dv',
                                                   'Monomer Mordred ATS2dv',
                                                   'Monomer Mordred ATS3dv',
                                                   'Monomer Mordred ATS4dv',
                                                   'Monomer Mordred ATS5dv',
                                                   'Monomer Mordred ATS6dv',
                                                   'Monomer Mordred ATS7dv',
                                                   'Monomer Mordred ATS8dv',
                                                   'Monomer Mordred ATS0d',
                                                   'Monomer Mordred ATS1d',
                                                   'Monomer Mordred ATS2d', ...])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
Pipeline(steps=[('scaling features',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('structural_scaling',
                                                  StandardScaler(),
                                                  ['Dimer Mordred ABC',
                                                   'Dimer Mordred ABCGG',
                                                   'Dimer Mordred nAcid',
                                                   'Dimer Mordred nBase',
                                                   'Dimer Mordred nAromAtom',
                                                   'Dimer Mordred nAromBond',
                                                   'Dimer Mordred nAtom',
                                                   'Dimer Mordred nHeavyAtom',
                                                   'Dimer Mordred nHetero',
                                                   'Dimer Mordred nH',
                                                   'Dimer Mor...
                                                   'Dimer Mordred nF',
                                                   'Dimer Mordred nCl',
                                                   'Dimer Mordred nBr',
                                                   'Dimer Mordred nX',
                                                   'Dimer Mordred ATS0dv',
                                                   'Dimer Mordred ATS1dv',
                                                   'Dimer Mordred ATS2dv',
                                                   'Dimer Mordred ATS3dv',
                                                   'Dimer Mordred ATS4dv',
                                                   'Dimer Mordred ATS5dv',
                                                   'Dimer Mordred ATS6dv',
                                                   'Dimer Mordred ATS7dv',
                                                   'Dimer Mordred ATS8dv',
                                                   'Dimer Mordred ATS0d',
                                                   'Dimer Mordred ATS1d',
                                                   'Dimer Mordred ATS2d', ...])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
Pipeline(steps=[('scaling features',
                 ColumnTransformer(remainder='passthrough',
                                   transformers=[('structural_scaling',
                                                  StandardScaler(),
                                                  ['Trimer Mordred ABC',
                                                   'Trimer Mordred ABCGG',
                                                   'Trimer Mordred nAcid',
                                                   'Trimer Mordred nBase',
                                                   'Trimer Mordred nAromAtom',
                                                   'Trimer Mordred nAromBond',
                                                   'Trimer Mordred nAtom',
                                                   'Trimer Mordred nHeavyAtom',
                                                   'Trimer Mordred nHetero',
                                                   'Trimer Mordred nH'...
                                                   'Trimer Mordred nCl',
                                                   'Trimer Mordred nBr',
                                                   'Trimer Mordred nX',
                                                   'Trimer Mordred ATS0dv',
                                                   'Trimer Mordred ATS1dv',
                                                   'Trimer Mordred ATS2dv',
                                                   'Trimer Mordred ATS3dv',
                                                   'Trimer Mordred ATS4dv',
                                                   'Trimer Mordred ATS5dv',
                                                   'Trimer Mordred ATS6dv',
                                                   'Trimer Mordred ATS7dv',
                                                   'Trimer Mordred ATS8dv',
                                                   'Trimer Mordred ATS0d',
                                                   'Trimer Mordred ATS1d',
                                                   'Trimer Mordred ATS2d', ...])],
                                   verbose_feature_names_out=False))])



OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6
usage: train_structure_only.py mordred [-h] [--regressor_type REGRESSOR_TYPE]
                                       [--target TARGET]
                                       [--oligo_type {Monomer,Dimer,Trimer,RRU Monomer,RRU Dimer,RRU Trimer}]
train_structure_only.py mordred: error: argument --oligo_type: invalid choice: 'RRU' (choose from 'Monomer', 'Dimer', 'Trimer', 'RRU Monomer', 'RRU Dimer', 'RRU Trimer')
usage: train_structure_only.py mordred [-h] [--regressor_type REGRESSOR_TYPE]
                                       [--target TARGET]
                                       [--oligo_type {Monomer,Dimer,Trimer,RRU Monomer,RRU Dimer,RRU Trimer}]
train_structure_only.py mordred: error: argument --oligo_type: invalid choice: 'RRU' (choose from 'Monomer', 'Dimer', 'Trimer', 'RRU Monomer', 'RRU Dimer', 'RRU Trimer')

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 829791: <RRU Dimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <RRU Dimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c024n02> by user <sdehgha2> in cluster <Hazel> at Thu Oct 17 12:03:45 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 17 15:59:30 2024
                            <4*c200n07>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 17 15:59:30 2024
Terminated at Thu Oct 17 15:59:34 2024
Results reported at Thu Oct 17 15:59:34 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "RRU Dimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU Dimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU Dimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type RRU Dimer

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   1.94 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   27 sec.
    Turnaround time :                            14149 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n14>
Subject: Job 829790: <RRU Monomer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <RRU Monomer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c024n02> by user <sdehgha2> in cluster <Hazel> at Thu Oct 17 12:03:45 2024
Job was executed on host(s) <4*c200n14>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 17 15:59:30 2024
                            <4*c200n13>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 17 15:59:30 2024
Terminated at Thu Oct 17 15:59:34 2024
Results reported at Thu Oct 17 15:59:34 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "RRU Monomer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU Monomer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU Monomer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type RRU Monomer

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   2.13 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   27 sec.
    Turnaround time :                            14149 sec.

The output (if any) is above this job summary.

usage: train_structure_only.py mordred [-h] [--regressor_type REGRESSOR_TYPE]
                                       [--target TARGET]
                                       [--oligo_type {Monomer,Dimer,Trimer,RRU Monomer,RRU Dimer,RRU Trimer}]
train_structure_only.py mordred: error: argument --oligo_type: invalid choice: 'RRU' (choose from 'Monomer', 'Dimer', 'Trimer', 'RRU Monomer', 'RRU Dimer', 'RRU Trimer')

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n09>
Subject: Job 829792: <RRU Trimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <RRU Trimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c024n02> by user <sdehgha2> in cluster <Hazel> at Thu Oct 17 12:03:45 2024
Job was executed on host(s) <4*c200n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 17 15:59:30 2024
                            <4*c200n04>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 17 15:59:30 2024
Terminated at Thu Oct 17 15:59:34 2024
Results reported at Thu Oct 17 15:59:34 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "RRU Trimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU Trimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_RRU Trimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type RRU Trimer

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   2.00 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   23 sec.
    Turnaround time :                            14149 sec.

The output (if any) is above this job summary.

usage: train_structure_numerical.py mordred [-h]
                                            [--regressor_type REGRESSOR_TYPE]
                                            [--target TARGET]
                                            [--oligo_type {Monomer,Dimer,Trimer,RRU Monomer,RRU Dimer,RRU Trimer}]
train_structure_numerical.py mordred: error: argument --oligo_type: invalid choice: 'RRU' (choose from 'Monomer', 'Dimer', 'Trimer', 'RRU Monomer', 'RRU Dimer', 'RRU Trimer')

------------------------------------------------------------
Sender: LSF System <lsfadmin@c200n05>
Subject: Job 833530: <mordred_NGB_structure_only> in cluster <Hazel> Exited

Job <mordred_NGB_structure_only> was submitted from host <c200n14> by user <sdehgha2> in cluster <Hazel> at Thu Oct 17 16:00:49 2024
Job was executed on host(s) <4*c200n05>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 17 16:02:50 2024
                            <4*c200n07>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 17 16:02:50 2024
Terminated at Thu Oct 17 16:03:01 2024
Results reported at Thu Oct 17 16:03:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 72:01
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "mordred_NGB_structure_only"  # Job name
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_numerical.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type RRU Trimer

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   2.40 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                6
    Run time :                                   35 sec.
    Turnaround time :                            132 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0007609062721976293, 1, 73, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.000856034943163054, 1, 81, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.000856034943163054, 1, 81, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0007609062721976293, 1, 73, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [4.299960238589645e-05, 1, 185, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [3.8195942265904995e-06, 1, 872, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0007609062721976293, 1, 73, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [1.0618598209803557e-05, 1, 987, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [4.299960238589645e-05, 1, 185, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [8.766116906680014e-06, 1, 139, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [3.8195942265904995e-06, 1, 872, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0001642070794211, 1, 1971, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [1.0618598209803557e-05, 1, 987, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [8.766116906680014e-06, 1, 139, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0001642070794211, 1, 1971, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0007609062721976293, 1, 73, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.000856034943163054, 1, 81, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [3.8195942265904995e-06, 1, 872, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [1.0618598209803557e-05, 1, 987, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0007609062721976293, 1, 73, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.000856034943163054, 1, 81, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [4.299960238589645e-05, 1, 185, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [3.8195942265904995e-06, 1, 872, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [1.0618598209803557e-05, 1, 987, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0001642070794211, 1, 1971, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0007609062721976293, 1, 73, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.000856034943163054, 1, 81, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [4.299960238589645e-05, 1, 185, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [3.8195942265904995e-06, 1, 872, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [1.0618598209803557e-05, 1, 987, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0001642070794211, 1, 1971, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0007609062721976293, 1, 73, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.000856034943163054, 1, 81, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [4.299960238589645e-05, 1, 185, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [3.8195942265904995e-06, 1, 872, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [1.0618598209803557e-05, 1, 987, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 1, 2000, True, False] before, using random point [0.0001642070794211, 1, 1971, True, False]
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006186731578681482), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1725), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1231), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008539381379525299), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1237), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0007321767848144419), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1691), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0004883491477285188), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1058), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1430), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0005448887853292174), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1468), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0005373395866118658), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006387947955524358), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1596), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1345), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1498), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1406), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008670692367770716), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1203), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 986), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1288), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 792), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1626), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1117), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0005281886962142089), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1359), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009530254515804563), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1947), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000857362134522251), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1766), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 935), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1743), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000862753776893207), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1468), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00038579658369031076), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000588625277274479), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 933), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008345614042302678), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Average scores:	 r: 0.420.19	 r2: 0.160.18
Dimer
Filename: (Mordred)_NGB
Saved results to:
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(Mordred)_NGB_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(Mordred)_NGB_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Dimer/(Mordred)_NGB_predictions.csv

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n09>
Subject: Job 829788: <Dimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Done

Job <Dimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c024n02> by user <sdehgha2> in cluster <Hazel> at Thu Oct 17 12:03:45 2024
Job was executed on host(s) <4*c205n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 17 15:49:08 2024
                            <4*c205n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 17 15:49:08 2024
Terminated at Fri Oct 18 01:58:55 2024
Results reported at Fri Oct 18 01:58:55 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Dimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Dimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Dimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Dimer

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   167748.20 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.98 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   36604 sec.
    Turnaround time :                            50110 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 920), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1304), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0005252783892396268), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008926429392178787), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1497), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0005586700715580491), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009035308082430365), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1164), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006212819139009042), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008266048878215101), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1502), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00063567030728999), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1532), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1154), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000755495193213128), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009032291629808546), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1723), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1101), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 945), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0007062665528469075), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0005385002750653572), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1323), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000841018317469401), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1106), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006223969707270323), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1171), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0007471835437784821), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 884), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009698775654796969), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1148), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00040254540020186923), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006444949155593602), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1686), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000460820733883972), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Average scores:	 r: 0.410.19	 r2: 0.160.18
Monomer
Filename: (Mordred)_NGB
Saved results to:
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(Mordred)_NGB_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(Mordred)_NGB_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Monomer/(Mordred)_NGB_predictions.csv

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n04>
Subject: Job 829787: <Monomer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Done

Job <Monomer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c024n02> by user <sdehgha2> in cluster <Hazel> at Thu Oct 17 12:03:45 2024
Job was executed on host(s) <4*c207n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 17 15:46:06 2024
                            <4*c207n05>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 17 15:46:06 2024
Terminated at Fri Oct 18 02:12:00 2024
Results reported at Fri Oct 18 02:12:00 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Monomer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Monomer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Monomer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Monomer

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   167377.59 sec.
    Max Memory :                                 2 GB
    Average Memory :                             2.00 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               62.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   37580 sec.
    Turnaround time :                            50895 sec.

The output (if any) is above this job summary.

/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(
/usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1295), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0005115560646102343), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008794341668409592), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1230), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1195), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000583654100605917), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1743), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1053), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000819699798667327), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1490), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0004972046886068338), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008337905534141323), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1692), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006326450972140343), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1177), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008999428854059867), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1221), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1538), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1375), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0007310077755650323), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1070), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008882918265878672), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0007902092457638804), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1318), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0007052662043509235), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0003889738108297441), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1565), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009891934278371433), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1467), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1694), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1083), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000878302159071575), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 829), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008155461159726098), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000477375305079555), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.001), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0008524391211194743), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1693), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.00039657236942490656), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0009698775654796969), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1148), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0006383354322189706), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1561), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.000788667908143918), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__verbose', False)])


Average scores:	 r: 0.420.19	 r2: 0.160.18
Trimer
Filename: (Mordred)_NGB
Saved results to:
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(Mordred)_NGB_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(Mordred)_NGB_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_Rg/Trimer/(Mordred)_NGB_predictions.csv

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n09>
Subject: Job 829789: <Trimer_Rg1 (nm)_mordred_NGB_structure_only> in cluster <Hazel> Done

Job <Trimer_Rg1 (nm)_mordred_NGB_structure_only> was submitted from host <c024n02> by user <sdehgha2> in cluster <Hazel> at Thu Oct 17 12:03:45 2024
Job was executed on host(s) <4*c205n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Thu Oct 17 15:50:08 2024
                            <4*c205n10>
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training> was used as the working directory.
Started at Thu Oct 17 15:50:08 2024
Terminated at Fri Oct 18 02:27:31 2024
Results reported at Fri Oct 18 02:27:31 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -n 8
#BSUB -W 70:05
#BSUB -R span[ptile=4]
#BSUB -R "rusage[mem=32GB]"
#BSUB -J "Trimer_Rg1 (nm)_mordred_NGB_structure_only"  
#BSUB -o /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Trimer_structure_only.out
#BSUB -e /share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/model_mordred_Rg1 (nm)_NGB_Trimer_structure_only.err

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python train_structure_only.py mordred --regressor_type NGB --target "Rg1 (nm)" --oligo_type Trimer

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   173476.34 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.89 GB
    Total Requested Memory :                     64.00 GB
    Delta Memory :                               61.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   38270 sec.
    Turnaround time :                            51826 sec.

The output (if any) is above this job summary.

